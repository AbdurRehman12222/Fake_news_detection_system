title,text
'Crisis actor' conspiracy theory: How anti-vax activists targeted a Covid patient,"A man was targeted with hundreds of abusive messages after being featured in a year-end BBC News report. The source? Anti-vaccine activists who falsely believed he was a so-called ""crisis actor"" pretending to be sick with Covid-19. A few days after Christmas, Henry Dyne nonchalantly checked his phone while ordering a couple of drinks at a bar. As he unlocked it, he was greeted by more than 600 notifications. He began to despair - it was something he'd experienced before - but, says the 29-year-old from Surrey, this time was ""a hundred times worse"". The messages were nasty, abusive, even threatening. ""Next time you're in a hospital bed,"" one read, ""it won't be with Corona."" Dyne's misfortune began when he contracted the virus in summer 2021. He hadn't been vaccinated, he said, thinking that his relative youth would make any infection pretty mild. But the IT consultant - who also enjoys posting jokes on his Instagram account - was unlucky. ""Every time I'd sleep, I'm not sleeping. I'm all over the place. And then one day, I just woke up at about six in the morning and said I'm calling an ambulance,"" he says. ""The scariest part was the fever and the hallucinations."" In July, he ended up in hospital, hooked up to an oxygen tank, and spoke to BBC journalists who were visiting to report on a rise in Covid cases in young people for the News at Six. ""I just thought it probably would be quite good to go on record and say 'this is my experience, it is a lot worse than I thought, so get the vaccine',"" he says. He didn't think he'd soon find himself the focus of a group of anti-vaccine activists. It was the start of allegations that he was a so-called ""crisis actor"". The idea of ""crisis actors"" - people who pretend or are hired to act out some particular tragedy or disaster - is part of many contemporary conspiracy theories. The concept was notoriously used to allege that parents of dead children in the Sandy Hook shooting were somehow faking their personal tragedies. The idea allows motivated activists to explain away real suffering by pretending it was somehow staged. Of course, BBC News does not use ""crisis actors"", and does not pay interviewees. Dyne was not paid for his contribution. But that did not stop committed anti-vaccine activists from making up false information and going on the attack. ""How much did the BBC pay you to pretend you had Covid-19?"" one message read. Another said: ""You're a dirtbag, mate. Karma is real my friend."" There were much worse comments as well - many too explicit to share here. Wild theories spiralled further out of control as activists trawled through his online accounts. Some discovered his LinkedIn profile, which listed one of his former employers, a company that had secured government contracts providing laptops to schools during the pandemic. The detail was true, but he was no longer employed by the company - the connection was both tenuous and coincidental. After the initial wave of abuse tailed off and Dyne was on the road to making a full recovery, he tried to joke about it on his Instagram bio, sarcastically describing himself as a ""1x Academy Award Winning Crisis Actor"". ""Humour is my way of coping, all you can do is laugh,"" he explains, ""Little did I know this joke would get me in so much trouble."" Round two came after a BBC News Special broadcast on 27 December, called Review 2021: The Coronavirus Pandemic. It included the clip of Dyne's original interview. Someone posted a video of themselves watching the special, googling Henry Dyne's name, finding his Instagram bio and reading the phrase ""crisis actor"". It's unclear who made the original video - but it was quickly reposted in anti-vaccine circles on YouTube and Facebook, before really taking off on Twitter. One of the main drivers of the Twitter storm was an aspiring Welsh politician, Richard Taylor. He posted the video on Facebook and racked up thousands of reactions with a tweet. Taylor received 20% of the vote in Blaenau Gwent standing for the Brexit Party in the 2019 General Election. He recently set up a crowdfunding campaign that raised Â£61,000 for a Swansea cinema closed after breaching Covid regulations. Taylor's posts read ""We see you"" along with the video, but when contacted said via email: ""In my original post, I was not implying anything... It us up to my social media followers to draw a conclusion from what they see or read. ""It is unfortunate that Mr Dyne decided to reference himself sarcastically in his social media accounts,"" Taylor wrote, ""I have lived believing that when someone tells you who or what they are, believe them, so I would have taken Mr Dyne at face value when he referenced himself as a crisis actor."" He also condemned the abuse and threats. ""I would never intentionally contribute to abusing or threatening another individual, having spent a large part of my vocation life helping and serving others,"" he wrote. But the viral video did result in Dyne receiving hundreds more abusive and threatening messages - he estimates three times as many as in the initial wave in July, including several death threats and fake accounts set up in his name. Taylor's post on Facebook was labelled as false by fact-checkers. A video on YouTube remains live, as do several viral tweets showing the video on Twitter. Meta - which owns Instagram and Facebook - has since taken down the fake accounts. ""We apologise to Henry for the distress that this must have caused,"" a Meta statement said. ""Accounts that impersonate someone else are not allowed on Instagram and we have removed the accounts reported to us."" Twitter said in a statement: ""We continue to take enforcement action on content and accounts that advance demonstrably false or misleading claims about Covid-19 and that may lead to significant risk of harm."" YouTube is investigating the video in question. All three social media companies condemned online harassment and say they have rules and tools to protect against it. While lamenting the repeated rounds of abuse, Henry Dyne has continued to poke fun at his accusers, joking that he's available to ""fake"" other disasters. ""That's literally all you can do,"" he says. ""Something does need to happen with social media. It's just so obvious that it's blown so far out of control."" While he would consider a career in stand-up comedy, he says his bout with Covid-19 wasn't very funny - and was all too real."
'Deepfake is the future of content creation',"A few months ago, millions of TV viewers across South Korea were watching the MBN channel to catch the latest news. At the top of the hour, regular news anchor Kim Joo-Ha started to go through the day's headlines. It was a relatively normal list of stories for late 2020 - full of Covid-19 and pandemic response updates. Yet this particular bulletin was far from normal, as Kim Joo-Ha wasn't actually on the screen. Instead she had been replaced by a ""deepfake"" version of herself - a computer-generated copy that aims to perfectly reflect her voice, gestures and facial expressions. Viewers had been informed beforehand that this was going to happen, and South Korean media reported a mixed response after people had seen it. While some people were amazed at how realistic it was, others said they were worried that the real Kim Joo-Ha might lose her job. MBN said it would continue to use the deepfake for some breaking news reports, while the firm behind the artificial intelligence technology - South Korean company Moneybrain - said it would now be looking for other media buyers in China and the US. When most people think of deepfakes, they imagine fake videos of celebrities. In fact, only last week one such bogus - but very lifelike - video of Tom Cruise made headlines around the world after it appeared on TikTok. Despite the negative connotations surrounding the colloquial term deepfakes (people don't usually want to be associated with the word ""fake""), the technology is increasingly being used commercially. More politely called AI-generated videos, or synthetic media, usage is growing rapidly in sectors including news, entertainment and education, with the technology becoming increasingly sophisticated. One of the early commercial adopters has been Synthesia, a London-based firm that creates AI-powered corporate training videos for the likes of global advertising firm WPP and business consultancy Accenture. ""This is the future of content creation,"" says Synthesia chief executive and co-founder Victor Riparbelli. To make an AI-generated video using Synthesia's system you simply pick from a number of avatars, type in the word you wish for them to say, and that is pretty much it. Mr Riparbelli says this means that global firms can very easily make videos in different languages, such as for in-house training courses. ""Let's say you have 3,000 warehouse workers in North America,"" he says. ""Some of them speak English, but some may be more familiar with Spanish. ""If you have to communicate complex information to them, a four-page PDF is not a great way. It would be much better to do a two or three-minute video, in English and Spanish. ""If you had to record every single one of those videos, that's a massive piece of work. Now we can do that for [little] production costs, and whatever time it'll take someone to write the script. That pretty much exemplifies how the technology is used today."" Mike Price, the chief technology officer of ZeroFox, a US cyber-security company that tracks deepfakes, says their commercial use is ""growing significantly year over year, but exact numbers are difficult to pin down"". However, Chad Steelberg, chief executive of Veritone, a US AI technology provider, says that the increasing concern about malicious deepfakes is holding back investment in the technology's legitimate, commercial use. ""The term deepfakes has definitely had a negative response in terms of capital investment in the sector,"" he says. ""The media and consumers, rightfully so, can clearly see the risks associated. ""It has definitely hindered corporations as well as investors from piling into the technology. But I think you are starting to see that crack."" New Tech Economy is a series exploring how technological innovation is set to shape the new emerging economic landscape. Mike Papas, chief executive of Modulate, an AI firm that allows users to create the voice of a different character or person, says that firms in the wider commercial synthetic media sector ""really care about ethics"". ""It amazing to see the depth of thought these people put into it,"" he says. ""That has ensured that investors also care about that. They're asking about ethics policies, and how you're thinking about it."" Lilian Edwards, professor of law, innovation and society at Newcastle Law School, is an expert on deepfakes. She says that one issue surrounding the commercial use of the technology that hasn't been fully addressed is who owns the rights to the videos. ""For example, if a dead person is used, such as [the actor] Steve McQueen or [the rapper] Tupac, there is an ongoing debate about whether their family should own the rights [and make an income from it],"" she says. ""Currently this differs from country to country."" Deborah Johnson, professor of applied ethics, emeritus, at the University of Virginia, recently co-wrote an article entitled ""What To Do About Deepfakes?"". She says: ""Deepfakes are part of the larger problem of misinformation that undermines trust in institutions and in visual experience - we can no longer trust what we see and hear online. ""Labelling is probably the simplest and most important counter to deepfakes - if viewers are aware that what they are viewing has been fabricated, they are less likely to be deceived."" Prof Sandra Wachter, a senior research fellow in AI at Oxford University, says that deepfake technology ""is racing ahead"". ""If you watched the Tom Cruise video last week, you can see how good the technology is getting,"" she says. ""It was far more realistic than the President Obama one from four years ago. ""We shouldn't get too fearful of the technology, and there needs to be a nuanced approach to it. Yes there should be laws in place to clamp down on bad and dangerous things like hate speech and revenge porn. Individuals and society should be protected from that. ""But we shouldn't have an outright ban on deepfakes for satire or freedom of expression. And the growing commercial use of the technology is very promising, such as turning movies into different languages, or creating engaging educational videos."" One such educational use of AI-generated videos is at the University of Southern California's Shoah Foundation, which houses more than 55,000 video testimonies from Holocaust survivors. Its Dimensions In Testimony project allows visitors to ask questions that prompt real-time responses from the survivors in the pre-recorded video interviews. Mr Steelberg says that in the future such technology will enable grandchildren to have conversations with AI versions of deceased elderly relatives. ""That's game changing, I think, for how we think about our society."" Additional reporting by Will Smale."
'Stop the steal': The deep roots of TrumpÂs 'voter fraud' strategy,"President Trump alleged ""fraud"" even while votes were still being counted - the culmination of a strategy at least months in the making. In the early hours of a frosty November morning in Connecticut, 49-year-old Candy snuggled into her bed after a long night shift. She immediately unlocked her phone - and began scrolling through her social media feed, as she does most nights. But this was different - it was election night. The result was still hanging in the balance. Candy scrolled, catching up on the night's news while waiting for her favoured candidate to speak out. And just after 1 a.m., he did: Candy agreed. She was frustrated and she wanted to do something - so when one of her best friends invited her to join a Facebook group called Stop the Steal, she jumped at the opportunity. ""The Democrats have said since the beginning of all this Covid stuff that they're going to do whatever it takes to get Trump out - and I think that they have succeeded,"" she later said. LISTEN NOW: Trending from the BBC World Service Candy was expecting this. For months allegations of ""rigged elections"" and ""voter fraud"" have been punctuating her Facebook feed. And she's not the only American who had been exposed to voting disinformation for months before polling day. Research by the BBC's Anti-disinformation unit reveals that disinformation about voter fraud has been plugged by influential accounts on social media repeatedly, for months. And it came from the very top. President Trump first started tweeting allegations of fraud as far back as April. Between then and the election, he mentioned rigged elections or voter fraud more than 70 times. For example, he tweeted this in June: And this in August: It's not a new theme. Mr Trump made claims of voter fraud back in 2016 - after an election he won. But this time around, the evidence suggests many more people have been seeing unsubstantiated claims all over their social media feeds for weeks. Candy is just one of them. Hundreds of thousands joined big Facebook groups under the ""Stop the Steal"" banner. Our research found that influential right-wing accounts were instrumental in amplifying these claims - and were frequently retweeted by President Trump. That includes a number of figures with big followings who have gone on to be involved in a protest movement centred around the unsubstantiated idea of a ""rigged"" election. On election night the hashtag #StoptheSteal sprung up on Twitter after the first of many misleading videos about voter fraud went viral. The video showed a poll watcher being denied entry to a Philadelphia polling station. It has almost two million views on Twitter, and was shared by multiple pro-Trump accounts. We investigated the video shortly after it was posted. The man who features in it was asked to wait outside by officials - with a woman telling him that his poll-watching certificate was not valid at that particular polling station. The video was authentic and, as it turns out, the woman was wrong. There was confusion over the rules. Poll watchers used to only be allowed into a particular station in Philadelphia, but they can now visit multiple sites across the city. The situation was later clarified and the man was later allowed into the station, and given an apology. None of that was reflected in the video of course - and the hashtag had already gone viral. The Stop the Steal slogan was then used by those setting up large Facebook groups which, since election night, have cumulatively amassed more than a million members. Several of these groups have been removed after users posted threats of violence and calls for ""civil war"". They have become a hotbed for more misleading videos and false claims - similar to that incident in Philadelphia - which have flooded social media feeds of people like Candy. ""They were saying that we started the group to try to start riots in different places in the country, which wasn't true,"" Candy tells me, increasingly angry about her Stop the Steal Facebook group being closed down. Candy, along with most of the members of these groups, aren't calling for violence. She says she is simply pursuing what she thinks is the truth. ""Everybody was just out there putting out what fraud they were seeing going on with the election,"" she says. She admits to me that she spends too much time on Facebook - and though she says she doesn't quite trust what she sees on the social network, at the same time it has been her main source of election information. She mentioned a number of debunked or evidence-less claims: that certain types of pens were handed out that would invalidate ballots, or that ballots were being dumped or ripped up. We investigated dozens of claims circulating online turned out to be made up, untrue or impossible to prove. One example: A man said that he had thrown away Trump ballots in Wisconsin in a post that went viral on Facebook. But it turns out that he lives in the suburbs of Detroit - in a totally different state, Michigan. The man, a 32-year-old butcher, revealed his real identity to BBC News, and insisted he had nothing to do with counting any ballots - in Wisconsin or anywhere else. The post, he said, was simply a joke. There's no concrete evidence of votes - for any candidate - being thrown away or ripped up. The claims keep coming. ""I saw a video somebody posted that a man had discovered that his wife voted this year,"" Candy says, ""but she died in 2017."" Again, we've looked into these allegations. Many claims about dead voters have been revealed as misinformation or mistaken identities by the authorities. We found one case where a living person accidently submitted an absentee ballot that was sent to a dead parent. There are others where the voters in question died before the election. Authorities in Michigan confirmed that when that is the case, the vote is thrown out. In the background - and occasional foreground - of this election is a series of increasingly popular conspiracy theories that encourage the idea everything is rigged, suspicious and not as it seems. Professor Whitney Phillips of Syracuse University says the QAnon conspiracy theory may explain in part why these rumours about voting have spread like wildfire. This is the baseless belief that President Trump is waging a secret war against Satanic paedophiles. ""Journalists and commentators have focused on the satanic child sex ring elements of the theory,"" she says. ""But buried within that narrative was a deeper 'deep state' narrative,"" which caused Trump supporters to question and doubt almost everything. In her view, even before the first vote was cast there were ""breadcrumbs and a whole narrative framework"" that the Democrats were going to steal the election. Her greatest fear is not about violence on the streets. She doesn't think people like Candy who join Stop the Steal groups are going to riot because of fake news online. Instead, Whitney Philips and other experts I speak to worry about the slow, gradual erosion of people's faith in democracy. Additional reporting by Olga Robinson Subscribe to the BBC Trending podcast or follow us on Twitter @BBCtrending or Facebook."
'We know where your family live' - Ukrainian fighters face online death threats,"Ukrainian soldiers and pro-Ukrainian activists are receiving death threats, threats of rape against their relatives and other horrific abuse after systematic sharing of their personal information on pro-Kremlin social channels, a BBC investigation has found. The ""doxxing"" - leaking of private information online - is apparently intended to demoralise the fighters. ""We were among those few citizens who tried to physically oppose the Russian invasion of our town,"" recalls Oleksii from Berdyansk, a Ukrainian port city that has been occupied by Russian forces since the first days of the war. Oleksii and his wife Anastasiya threw a Molotov cocktail at a Russian armoured vehicle driving through their city. They immediately went into hiding. ""We knew Russians would be searching for us,"" says Anastasiya. ""We tried not to use our phones, so we couldn't be tracked. But when we turned them on, we saw hundreds of messages with threats from strangers, saying they would hang us, they would burn us with our own Molotov cocktails. It was an absolute nightmare."" Russian state TV reported on the couple's actions, and revealed their identities. On the same day their birth dates, home addresses, telephone numbers, tax information, social media accounts and even their car's number plate were posted on Telegram, in a pro-Kremlin channel called ""Work, brothers"". The account has more than 46,000 subscribers. The Telegram post called Oleksii, who used to be a member of the right-wing organisation ""Right Sector"", and Anastasiya ""Nazis"", an insult often thrown at Ukrainians by Russian state media. The couple would sometimes receive more than 1,000 offensive messages a day. ""All my social media accounts were full of abuse. I tried not to read them,"" recalls Anastasiya. ""Where are the pictures of your dead bodies?"" read one of the messages. Another said: ""We know where you live."" ""It was terrifying,"" says Anastasiya, ""When you go to bed you can't sleep because you're listening to every noise, wondering if somebody has come for you."" After two months in hiding, they managed to escape to Ukrainian-controlled territory. The BBC has found that the ""Work, brothers"" channel and another pro-Russian channel - ""Tribunal"" - has shared the private data of almost 300 Ukrainian activists, soldiers and their relatives, to more than 120,000 subscribers. Both channels were created on 1 March 2022; the sixth day of the Russian invasion of Ukraine. Alongside private information, the channels regularly promote Russian disinformation and pro-Kremlin narratives. Oleksandr, a Ukrainian soldier currently fighting on the front line in eastern Ukraine, recalls how in August he discovered that a video of his battalion destroying a Russian armoured vehicle was posted on Telegram, alongside his date of birth, phone number and email address. The post was published in ""Work, brothers"", and said that Oleksandr's family was living in Nova Kakhovka, a town in the Kherson region, which is occupied by Russian troops. ""In the texts that I received, they called me a 'bloody khokhol' [a derogatory Russian term for Ukrainians] and threatened to find my mum and sister in Nova Kahovka and rape them,"" said Oleksandr. His mother died in 2015 and his sister had moved to Turkey seven years ago. His home address was also published. Soon afterwards, his flat was broken into and his possessions stolen. The BBC has tracked down some of those closely associated with the Telegram channels. Olesya Orlenko, 41, from Moscow, describes herself as a historian and journalist. She was one of the founders of an online project called ""Tribunal"", which runs a website and the Telegram channel we have been monitoring. In the past she has promoted this work on Russian state media. Ms Orlenko claims she is no longer associated with Tribunal, but uses familiar Kremlin narratives when describing the objectives of the project. ""It was created to collect information about Ukrainian Nazis [a term used by Russian state media] who committed crimes during the conflict in Donbas [in eastern Ukraine], so that later this information could be used by Russian or international courts,""  she said. She denied she had anything to do with the sharing of soldiers' personal details. However, she was still one of those in charge of Tribunal when the doxxing started on its Telegram channel. The BBC has also contacted one of the administrators of the chat group associated with the channel ""Work, brothers"". Tatyana is 39 and an office worker from Podolsk in the Moscow region. She told the BBC that in her free time she ""helps 'Work, brothers' as a volunteer"". She denied seeing Ukrainian soldiers' personal information and threats on the channel. We sent Tatyana a screenshot with a profile of a Ukrainian soldier and her comments below the post. She stopped replying to us. ""These channels break Telegram's terms of service because they promote violence in a systematic way"", says Julia Smirnova, a senior analyst at Institute for Strategic Dialogue focused on disinformation and online hate speech. ""They call for 'punishing' people whose data they publish, use hateful terms and slurs to describe them,"" says Ms Smirnova. ""The channels also publish posts that celebrate killings of Ukrainian military personnel or violence against people supporting the Ukrainian army."" Telegram prohibits the promotion of violence on public channels. It also has an in-app reporting feature where users can flag violence and shared personal details. Remi Vaughn, Telegram's spokesperson, told the BBC that the company ""actively moderates"" the publication of private data and ""diligently removes"" content that breaches its terms of service. To test this, we used the in-app feature to report 50 posts which included the personal information of Ukrainian soldiers and comments with clear calls for violence. A week later the posts and comments remained online. This comes as no surprise to Viktor, another Ukrainian soldier who had previously experienced harassment online for being an LGBT+ activist. ""I always reported such things to Telegram, but I've never heard back from them. There was no reaction at all,"" he says. Earlier this year, his personal details and pictures were again posted on Telegram. There were death threats in the comments, but what really angered him was that this time the abuse went further, and targeted his family. ""They shared addresses of my parents and even of my granny. They texted my sister. They even posted her address in Mykulichi that was occupied by Russians."" The village is near Bucha, where dozens of civilians were killed by Russian troops. ""It's good they posted it after the village was liberated. But what if they did it earlier?"" says Viktor. ""There were real cases when relatives of Ukrainian soldiers were shot dead. These people [who share it] and Telegram itself should be held to account."""
11 September 2001: The conspiracy theories still spreading after 20 years,"The first 9/11 conspiracy theories appeared on the internet just hours after the attacks, on 11 September 2001, and with the rise of social media, have grown in scope and scale ever since. Extensive reports by the 9/11 Commission, US government agencies and expert groups have refuted the existence of any hidden conspiracy. But activist groups in the US and elsewhere, the 9/11 Truth movement, say the facts have been hidden. Some leading members of the movement have also embraced conspiracies about Covid-19 and vaccines. And some senior politicians, celebrities and media figures have also disputed the official account. The rise of new conspiracy movements online, such as QAnon, whose followers, among other conspiratorial views, believe  a US ""deep state"" responsible for the attacks, has kept these conspiracy theories in circulation and brought them to a far larger audience. And online clips from a series of films known as Loose Change have reinforced many of the falsehoods circulating. Some claim the US government staged the attacks or knew of them in advance and allowed them. And these falsehoods mesh with more recent online movements' belief global elites plan to curtail civil liberties in response to the attacks and facilitate the establishment of an authoritarian world government. A claim widely shared online, ""Jet fuel cannot melt steel beams,"" suggests the World Trade Center's Twin Towers were demolished by explosives. But according to an official report, the crashed planes considerably damaged support columns of both the towers and dislodged fire-proofing. Additionally, the fires reached up to 1,000C in some areas, causing the steel beams to warp and the eventual collapse of the buildings. The collapse of 7 World Trade Center, a 47-storey skyscraper in the vicinity of the Twin Towers, has attracted many conspiracy theories, some of which were trending on major social networks on last year's 9/11 anniversary. This building - containing offices of the CIA, the Department of Defense, and the Office of Emergency Management - collapsed hours after the Twin Towers without being hit by a plane or directly targeted. But in 2008, a three-year investigation by the National Institute of Standards and Technology concluded it had collapsed because of intense and uncontrolled fires - lasting for nearly seven hours - started by debris from the fall of the nearby North Tower. 7 World Trade Center was the first tower of its kind to collapse because a fire. But in 2017, the Plasco tower in the Iranian capital, Tehran, became the second. The fact the collapse of 7 World Trade Center was announced in a live report by BBC News correspondent Jane Stanley - while it was still visibly standing behind her - has been cited by conspiracy theorists as evidence major media organisations were part of the inside-job plot. The Reuters news agency had mistakenly reported the collapse of the building, which was also picked up by CNN, just before the live report. Reuters later issued a correction - but clips of the report continue go viral in the days leading up to 9/11 anniversaries. Some online conspiracy theories suggest US missiles were fired at the Pentagon, as part of a government plot, and the hole left in the building was too small to have been caused by a passenger plane. But a member of the American Society of Civil Engineers told Popular Mechanics magazine the size and shape of the hole was due to one wing of the Boeing 757 hitting the ground and the other being severed on impact with the building. Meanwhile, United Airlines Flight 93 crashed near Shanksville, Pennsylvania, after passengers tried to take control of the plane from the hijackers. Online theories claim it was shot down by a white business jet flying into a nearby airport. But aviation officials had requested the jet inspect the area, which it did, reporting back evidence of a big hole in the ground with smoke coming out of it. Vice-President Dick Cheney later revealed in his autobiography that following the attack on the Twin Towers, he had ordered the shooting down of any commercial airliner believed to have been hijacked. But in the chaos and confusion that followed the attack, his order was not passed to fighter pilots, according to the 9/11 Commission report. Another theory falsely claims no Jewish people were killed in the attacks because 4,000 Jewish employees at the World Trade Center had received advance notice not to turn up for work. Believers conclude the Israeli government mounted the attacks to goad the US into attacking its regional enemies or responsibility lies with powerful Jewish elites who control world events from the shadows. But of the 2,071 victims of 9/11 who worked at the World Trade Center, 119 were confirmed to be Jewish and at least a further 72 were believed to be Jewish. That would constitute 9.2% of the victims, according to research by BBC documentary Conspiracy Files, broadly in line with the 9.7% of New York's commuting population believed to be Jewish at the time. And some estimate up to 400 Jewish people might have died that day. Similar theories surround other states, including Iraq and Iran, but no evidence of their direct involvement has ever been found."
AI: Can you tell that these 'photographs' are artificial?,"Whether it be artwork, literature, music or photography, content created by artificial intelligence (AI) is on the rise. So advanced is the content being generated that it is becoming increasingly difficult to determine what is real and what is artificial. All of these images have been created using AI software on the website Night Cafe. None of the people depicted are real and each picture has been generated by a text prompt. A text prompt can be something as simple as ""woman shouting"" or ""twins"". The potential pitfalls of such content were recently demonstrated when German artist Boris Eldagsen entered this year's Sony World Photography Award with an AI-generated image and won. Mr Eldagsen refused the award and stated he was just being a ""cheeky monkey"" to see if any of the judges ""knew or suspected that [the image] was AI-generated"". ""AI images and photography should not compete with each other in an award like this,"" he added. Night Cafe founder Angus Russell said: ""Five years ago, People were saying AI would take over the borings jobs, but things that require creativity will be safe for a long time. ""But it's turned out the exact opposite. Creative jobs and knowledge-based work could be the earliest things to be replaced."" BBC News picture editor Phil Coomes said that while fake or manipulated images were ""nothing new"", the growth of AI would ""produce some challenges"". ""There are tools out there that can help us spot images that have been manipulated,"" he said. ""And these can help with AI too. ""But these are not fool proof, of course, and much still relies on close visual examination of the picture."" Dr David Gyimah is an associate professor of innovation at Cardiff University's School of Journalism and is impressed by the hyper-realism of these images. ""Everything that you would expect of a good photograph is there,"" he said. ""There's nothing in these in these images that could lead you to believe that they were generated in any other way [such as AI]."" Dr Gyimah thinks it is worth considering the potential ill-intentioned uses of AI imagery in journalism and factual content. ""We've sort of entered a territory where technology has raced ahead of policy frameworks. And that leaves us in very precarious positions,"" he said. ""It can be used for real maleficent purposes, [and] there may well have to be sanctions. ""Otherwise, how do you enforce people not to use images which they purposefully know are not generated by a camera? So therefore may spur different narratives to the ones that are real as opposed to the ones that perpetrate falsehoods."" As AI-generated imagery becomes more advanced and the code it uses becomes open source, we may be forced to ask the question more often than not: Is it real or is it AI? Whether it be artwork, literature, music or photography, content created by artificial intelligence (AI) is on the rise. So advanced is the content being generated that it is becoming increasingly difficult to determine what is real and what is artificial. All of these images have been created using AI software on the website Night Cafe. None of the people depicted are real and each picture has been generated by a text prompt. A text prompt can be something as simple as ""woman shouting"" or ""twins"". The potential pitfalls of such content were recently demonstrated when German artist Boris Eldagsen entered this year's Sony World Photography Award with an AI-generated image and won. Mr Eldagsen refused the award and stated he was just being a ""cheeky monkey"" to see if any of the judges ""knew or suspected that [the image] was AI-generated"". ""AI images and photography should not compete with each other in an award like this,"" he added. Night Cafe founder Angus Russell said: ""Five years ago, People were saying AI would take over the borings jobs, but things that require creativity will be safe for a long time. ""But it's turned out the exact opposite. Creative jobs and knowledge-based work could be the earliest things to be replaced."" BBC News picture editor Phil Coomes said that while fake or manipulated images were ""nothing new"", the growth of AI would ""produce some challenges"". ""There are tools out there that can help us spot images that have been manipulated,"" he said. ""And these can help with AI too. ""But these are not fool proof, of course, and much still relies on close visual examination of the picture."" Dr David Gyimah is an associate professor of innovation at Cardiff University's School of Journalism and is impressed by the hyper-realism of these images. ""Everything that you would expect of a good photograph is there,"" he said. ""There's nothing in these in these images that could lead you to believe that they were generated in any other way [such as AI]."" Dr Gyimah thinks it is worth considering the potential ill-intentioned uses of AI imagery in journalism and factual content. ""We've sort of entered a territory where technology has raced ahead of policy frameworks. And that leaves us in very precarious positions,"" he said. ""It can be used for real maleficent purposes, [and] there may well have to be sanctions. ""Otherwise, how do you enforce people not to use images which they purposefully know are not generated by a camera? So therefore may spur different narratives to the ones that are real as opposed to the ones that perpetrate falsehoods."" As AI-generated imagery becomes more advanced and the code it uses becomes open source, we may be forced to ask the question more often than not: Is it real or is it AI?"
Actress Letitia Wright criticised for sharing vaccine doubter's video,"Actress Letitia Wright has become embroiled in controversy after sharing a video making unsubstantiated claims about the safety of Covid-19 vaccines. The Black Panther star posted a link to a video whose host said people taking the vaccines would have to ""hope it doesn't make extra limbs grow"". After being criticised on Twitter, she said she wasn't against vaccines but it was important to ""ask questions"". The BBC has contacted Wright's representatives for comment. In the video, presenter Tomi Arayomi explains he is a ""big sceptic of needles and vaccinations in general"" and hasn't decided whether to take a Covid vaccine. While discussing his doubts about their safety and effectiveness, he also admits ""I don't understand vaccines medically"", and doesn't present medical evidence. Wright's initial post, which has been retweeted more than 3,000 times, featured a link to the video along with the prayer hands emoji. She then became involved in heated exchanges with users who accused her of spreading misinformation. ""It is not my intention to make anyone upset, nor am I saying don't take it,"" she wrote. ""I'm just concerned about what's in it that's all. Isn't that fair to question?"" The UK's medicines regulator has approved the first vaccine, made by Pfizer and BioNTech, saying the process had been robust with safety considerations paramount. Regulators around the world are assessing the safety of that and other vaccines. Wright stood by her comments after the backlash, adding: ""If you don't conform to popular opinions, but ask questions and think for yourself... you get cancelled."" Her co-star in the Marvel Cinematic Universe, Don Cheadle, also became involved after Twitter users copied him in to her tweets. The actor said he had watched some of the video and described its content as ""hot garbage"", adding that he would raise the issue with Wright directly. Arayomi's video remains on YouTube. The company recently pledged to delete misleading claims about coronavirus vaccines. Last month, Labour called for financial and criminal penalties for social media firms that do not remove false scare stories about vaccines. The BBC's disinformation reporter Marianna Spring explained: ""Baseless conspiracy theories about a coronavirus vaccine have been spreading on social media for months - and the latest vaccine news rekindled these pre-existing narratives online. ""Within hours of news breaking about the Pfizer/BioNTech vaccine, comments and memes suggesting it will deliberately harm us were popping up in local Facebook groups, parent chats and on Instagram. ""This kind of disinformation is worlds away from legitimate concerns that a vaccine is safe and properly tested."" Wright was recently seen in one of Oscar-winning director Steve McQueen's Small Axe films on BBC One. Wright has previously starred in the Avengers films Infinity War and Endgame, and won the rising star prize at the Bafta Film Awards last year. Follow us on Facebook, or on Twitter @BBCNewsEnts. If you have a story suggestion email entertainment.news@bbc.co.uk."
Alan MacMasters: How the great online toaster hoax was exposed,"For more than a decade, a prankster spun a web of deception about the inventor of the electric toaster. His lies fooled newspapers, teachers and officials. Then a teenager flagged up something that everyone else had missed. ""I read through Wikipedia a lot when I'm bored in class,"" says Adam, aged 15, who studies photography and ICT at a school in Kent. One day last July, one of his teachers mentioned the online encyclopaedia's entry about Alan MacMasters, who it said was a Scottish scientist from the late 1800s and had invented ""the first electric bread toaster"". At the top of the page was a picture of a man with a pronounced quiff and long sideburns, gazing contemplatively into the distance - apparently a relic of the 19th Century, the photograph appeared to have been torn at the bottom. But Adam was suspicious. ""It didn't look like a normal photo,"" he tells me. ""It looked like it was edited."" After he went home, he decided to post about his suspicions on a forum devoted to Wikipedia vandalism. Little did he know that he had just set in motion a chain of events that would lead me to ""Alan MacMasters"" - not the inventor of the electric toaster, but his real-life alter ego. Until recently, if you had searched for ""Alan MacMasters"" on Wikipedia, you would have found the same article that Adam did. And who would have doubted it? After all, like most Wikipedia articles, this one was peppered with references: news articles, books and websites that supposedly provided evidence of MacMasters' life and legacy. As a result, lots of people accepted that MacMasters had been real. More than a dozen books, published in various languages, named him as the inventor of the toaster. And, until recently, even the Scottish government's Brand Scotland website listed the electric toaster as an example of the nation's ""innovative and inventive spirit"". In his supposed home country, MacMasters had become a folk hero of sorts. One Scottish primary school organised a day of activities in his memory - children were invited to write journal entries about MacMasters, paint slices of toast, and build pretend toasters out of building blocks. Edinburgh-based chef Scott Smith also created an elaborate dessert in his honour, while taking part in Great British Menu, the BBC cookery show. Smith says MacMasters' name was suggested to him by the producers, but they didn't respond to our requests for comment. In 2018, when the Bank of England asked the British public who should appear on the next Â£50 note, MacMasters was nominated - and included on a list along with 988 other apparently eligible contenders who had made significant contributions to science. The Bank of England did not want to comment on this story, but confirmed MacMasters had been dropped from the longlist after extra checks were made. All the while, as the world got to know the supposed Scottish inventor, there was someone in London who could not avoid a smirk as the name ""Alan MacMasters"" popped up - again and again - on his screen. Alan MacMasters, 30, is an aerospace engineer from London ""and not the inventor of the toaster"", he assures me with a giggle. ""You shouldn't just believe everything you read on the internet."" I feel nervous about the possibility of falling prey to another prank. So I ask Alan to send me a photo of his passport, which he does. He is not lying: even if he lacks the voluminous quiff of his namesake, he really is Alan MacMasters (""half Japanese and half Scottish"", he adds by text). ""One day, my father said to me: 'Maybe we are related to the inventor of the toaster?' And I had to disappoint him,"" he recalls. And that was because Alan knew the truth: he was there when the toaster hoax began more than a decade ago. On 6 February 2012, Alan was at a university lecture, when the class was warned against using Wikipedia as a source. To hammer the point home, the lecturer said that a friend of his - one ""Maddy Kennedy"" - had named himself on the site as the inventor of the toaster. Alan and his classmates found the story ""amusing"" but pondered correcting the article - after all, one of Wikipedia's distinguishing features is that pretty much anyone can edit it. Sitting right next to Alan was one of his closest friends, Alex, who volunteered to do the editing himself. Alex recalls: ""I just changed it so that it said that my friend, who sat next to me, Alan MacMasters, had in fact invented the toaster in Edinburgh in 1893. ""We had no idea who invented the toaster."" Internet history had just been made, but Alan was not bothered. ""Alex is a bit of a joker, it's part of why we love him,"" he says. ""The article had already been vandalised anyway, it was just changing the nature of the incorrect information. I thought it was funny, I never expected it to last."" Listen to The Alan MacMasters' Toaster Hoax on BBC Sounds Wikipedia relies on volunteers to ensure articles are as accurate as they can be. This involves checking articles are properly sourced, clearly written, and that - in general - they have not been vandalised or tampered with. But it is a huge job. On English Wikipedia alone, there are more than 6.5 million articles and fewer than 125,000 regular editors. It is almost inevitable that some articles will fall through the cracks - and the article exploring the origins of the toaster was one of them. ""At the time, we had a good laugh about the change, but we quickly forgot about it,"" says Alex, the hoaxer. But the internet does not forget. From that day onwards, anyone who looked up the inventor of the toaster on Wikipedia would have found ""Alan MacMasters"" as the answer. And it was not long before the Daily Mirror wrongly listed MacMasters' toaster as a ""life-changing everyday invention that put British genius on the map"". Reach, which owns the Mirror, declined to comment. Alex felt mischievous, and wondered how far his prank could go. He asked himself what would happen if he created a Wikipedia article entirely devoted to the supposed inventor of the toaster. More importantly, he wondered how long it would be before the platform's volunteer editors exposed his forgery. In February 2013, Alan MacMasters' very own Wikipedia article was born. To illustrate it, Alex grabbed a photo of himself and edited it to look like an image from the 1800s - this was the very same photo that, years later, would catch Adam's eye. At the time, Alex felt this was a harmless prank. ""If you get false information about who invented the toaster, the consequences might be that you get a question wrong in a pub quiz,"" he says. ""It's a bit of trivia, which doesn't have a significant real-world impact."" But was that really the case? Soon, the name ""Alan MacMasters"" would spread rapidly around the world as the inventor of the toaster. Over more than a decade, his life story was retold by major news outlets, official bodies and even a US museum. The more people became aware of MacMasters, the more complex Alex's deception became. ""The article started out as just a couple of sentences and, over time, I decided to start writing more and more ridiculous things,"" he says. Among other details, he falsely suggested MacMasters had helped develop lighting systems for the London Underground. ""These [claims] would get picked up in different types of media, I would cite them, and they would become fact,"" Alex says. This may well be part of the reason why the MacMasters hoax survived for so long. ""What you have here is circular referencing,"" says Heather Ford, an associate professor at the University of Technology Sydney. When journalists repeat a claim that is made online, their reporting can then be used on Wikipedia as evidence to back the original claim. ""Wikipedia is just collecting all of these sources and citations, as it continues to build this article that originally was built on this lie,"" Ford says. For years, no one appears to have raised any suspicions online - at least, until 15-year-old Adam posted his concerns on a Reddit forum. His thread was titled: ""The picture of the inventor of the toaster on Wikipedia was faked."" At this stage, Adam was unaware that Scottish inventor Alan MacMasters was not real - only that the photo used to illustrate his Wikipedia article appeared to be fake. ""A lot of people actually replied: 'I have used that picture in a presentation for school,'"" Adam recalls. ""I thought it was hilarious."" But after his post went live, it was rapidly shared on Wikipediocracy, a forum known for scrutinising the online encyclopaedia. This in turn alerted Wikipedia editors who, in less than 24 hours, had nominated the article for deletion. Within a week, a ""hoax"" label had been added at the top of the article. And, in September, the article was changed so that anyone looking for MacMasters on Wikipedia was redirected to a page about hoaxes instead. Alex's Wikipedia account, which he used to create the MacMasters article, has been blocked. The Wikimedia Foundation, which runs Wikipedia, tells the BBC it takes hoaxes and misinformation ""very seriously"". It accepts hoaxes take place ""from time to time"", but says the site is protected ""through a combination of machine learning tools and human oversight from volunteer editors"". It also says misinformation and hoaxes are ""generally addressed by volunteers via existing rules and processes"", and that they are ""outside of the Wikimedia Foundation's remit"". In a statement, it says: ""In general, the Foundation only gets involved in content related issues on the platform in case of specific cases of disinformation or legal matters."" Getting to the bottom of this mystery was not easy. I spoke to toaster collectors in Europe and in the US, as well as museum curators with expertise in domestic appliances. According to multiple sources, the first patent for a commercially available and successful toaster was submitted by Frank Shailor in 1909, on behalf of the General Electric company in the US. The toaster, named the D-12, is understood to be the first commercially available electric toaster. ""It is beautiful,"" says Rebecca Dolgoy, curator of natural resources and industrial technologies at Ingenium, Canada's museums of science and innovation (which hold two D-12 toasters). ""You would put the bread inside, it would toast one side at a time, and you would have to switch it. The machine is very elegant, but also utilitarian."" As I speak to her, I notice the passion in Ms Dolgoy's words. ""I'm interested in the toasters because they are fascinating, but also because of the kinds of stories that they allow us to tell,"" she tells me. And the story of Alan MacMasters, the inventor, is certainly one of them. It just happens not to be true. For more than a decade, a prankster spun a web of deception about the inventor of the electric toaster. His lies fooled newspapers, teachers and officials. Then a teenager flagged up something that everyone else had missed. ""I read through Wikipedia a lot when I'm bored in class,"" says Adam, aged 15, who studies photography and ICT at a school in Kent. One day last July, one of his teachers mentioned the online encyclopaedia's entry about Alan MacMasters, who it said was a Scottish scientist from the late 1800s and had invented ""the first electric bread toaster"". At the top of the page was a picture of a man with a pronounced quiff and long sideburns, gazing contemplatively into the distance - apparently a relic of the 19th Century, the photograph appeared to have been torn at the bottom. But Adam was suspicious. ""It didn't look like a normal photo,"" he tells me. ""It looked like it was edited."" After he went home, he decided to post about his suspicions on a forum devoted to Wikipedia vandalism. Little did he know that he had just set in motion a chain of events that would lead me to ""Alan MacMasters"" - not the inventor of the electric toaster, but his real-life alter ego. Until recently, if you had searched for ""Alan MacMasters"" on Wikipedia, you would have found the same article that Adam did. And who would have doubted it? After all, like most Wikipedia articles, this one was peppered with references: news articles, books and websites that supposedly provided evidence of MacMasters' life and legacy. As a result, lots of people accepted that MacMasters had been real. More than a dozen books, published in various languages, named him as the inventor of the toaster. And, until recently, even the Scottish government's Brand Scotland website listed the electric toaster as an example of the nation's ""innovative and inventive spirit"". In his supposed home country, MacMasters had become a folk hero of sorts. One Scottish primary school organised a day of activities in his memory - children were invited to write journal entries about MacMasters, paint slices of toast, and build pretend toasters out of building blocks. Edinburgh-based chef Scott Smith also created an elaborate dessert in his honour, while taking part in Great British Menu, the BBC cookery show. Smith says MacMasters' name was suggested to him by the producers, but they didn't respond to our requests for comment. In 2018, when the Bank of England asked the British public who should appear on the next Â£50 note, MacMasters was nominated - and included on a list along with 988 other apparently eligible contenders who had made significant contributions to science. The Bank of England did not want to comment on this story, but confirmed MacMasters had been dropped from the longlist after extra checks were made. All the while, as the world got to know the supposed Scottish inventor, there was someone in London who could not avoid a smirk as the name ""Alan MacMasters"" popped up - again and again - on his screen. Alan MacMasters, 30, is an aerospace engineer from London ""and not the inventor of the toaster"", he assures me with a giggle. ""You shouldn't just believe everything you read on the internet."" I feel nervous about the possibility of falling prey to another prank. So I ask Alan to send me a photo of his passport, which he does. He is not lying: even if he lacks the voluminous quiff of his namesake, he really is Alan MacMasters (""half Japanese and half Scottish"", he adds by text). ""One day, my father said to me: 'Maybe we are related to the inventor of the toaster?' And I had to disappoint him,"" he recalls. And that was because Alan knew the truth: he was there when the toaster hoax began more than a decade ago. On 6 February 2012, Alan was at a university lecture, when the class was warned against using Wikipedia as a source. To hammer the point home, the lecturer said that a friend of his - one ""Maddy Kennedy"" - had named himself on the site as the inventor of the toaster. Alan and his classmates found the story ""amusing"" but pondered correcting the article - after all, one of Wikipedia's distinguishing features is that pretty much anyone can edit it. Sitting right next to Alan was one of his closest friends, Alex, who volunteered to do the editing himself. Alex recalls: ""I just changed it so that it said that my friend, who sat next to me, Alan MacMasters, had in fact invented the toaster in Edinburgh in 1893. ""We had no idea who invented the toaster."" Internet history had just been made, but Alan was not bothered. ""Alex is a bit of a joker, it's part of why we love him,"" he says. ""The article had already been vandalised anyway, it was just changing the nature of the incorrect information. I thought it was funny, I never expected it to last."" Listen to The Alan MacMasters' Toaster Hoax on BBC Sounds Wikipedia relies on volunteers to ensure articles are as accurate as they can be. This involves checking articles are properly sourced, clearly written, and that - in general - they have not been vandalised or tampered with. But it is a huge job. On English Wikipedia alone, there are more than 6.5 million articles and fewer than 125,000 regular editors. It is almost inevitable that some articles will fall through the cracks - and the article exploring the origins of the toaster was one of them. ""At the time, we had a good laugh about the change, but we quickly forgot about it,"" says Alex, the hoaxer. But the internet does not forget. From that day onwards, anyone who looked up the inventor of the toaster on Wikipedia would have found ""Alan MacMasters"" as the answer. And it was not long before the Daily Mirror wrongly listed MacMasters' toaster as a ""life-changing everyday invention that put British genius on the map"". Reach, which owns the Mirror, declined to comment. Alex felt mischievous, and wondered how far his prank could go. He asked himself what would happen if he created a Wikipedia article entirely devoted to the supposed inventor of the toaster. More importantly, he wondered how long it would be before the platform's volunteer editors exposed his forgery. In February 2013, Alan MacMasters' very own Wikipedia article was born. To illustrate it, Alex grabbed a photo of himself and edited it to look like an image from the 1800s - this was the very same photo that, years later, would catch Adam's eye. At the time, Alex felt this was a harmless prank. ""If you get false information about who invented the toaster, the consequences might be that you get a question wrong in a pub quiz,"" he says. ""It's a bit of trivia, which doesn't have a significant real-world impact."" But was that really the case? Soon, the name ""Alan MacMasters"" would spread rapidly around the world as the inventor of the toaster. Over more than a decade, his life story was retold by major news outlets, official bodies and even a US museum. The more people became aware of MacMasters, the more complex Alex's deception became. ""The article started out as just a couple of sentences and, over time, I decided to start writing more and more ridiculous things,"" he says. Among other details, he falsely suggested MacMasters had helped develop lighting systems for the London Underground. ""These [claims] would get picked up in different types of media, I would cite them, and they would become fact,"" Alex says. This may well be part of the reason why the MacMasters hoax survived for so long. ""What you have here is circular referencing,"" says Heather Ford, an associate professor at the University of Technology Sydney. When journalists repeat a claim that is made online, their reporting can then be used on Wikipedia as evidence to back the original claim. ""Wikipedia is just collecting all of these sources and citations, as it continues to build this article that originally was built on this lie,"" Ford says. For years, no one appears to have raised any suspicions online - at least, until 15-year-old Adam posted his concerns on a Reddit forum. His thread was titled: ""The picture of the inventor of the toaster on Wikipedia was faked."" At this stage, Adam was unaware that Scottish inventor Alan MacMasters was not real - only that the photo used to illustrate his Wikipedia article appeared to be fake. ""A lot of people actually replied: 'I have used that picture in a presentation for school,'"" Adam recalls. ""I thought it was hilarious."" But after his post went live, it was rapidly shared on Wikipediocracy, a forum known for scrutinising the online encyclopaedia. This in turn alerted Wikipedia editors who, in less than 24 hours, had nominated the article for deletion. Within a week, a ""hoax"" label had been added at the top of the article. And, in September, the article was changed so that anyone looking for MacMasters on Wikipedia was redirected to a page about hoaxes instead. Alex's Wikipedia account, which he used to create the MacMasters article, has been blocked. The Wikimedia Foundation, which runs Wikipedia, tells the BBC it takes hoaxes and misinformation ""very seriously"". It accepts hoaxes take place ""from time to time"", but says the site is protected ""through a combination of machine learning tools and human oversight from volunteer editors"". It also says misinformation and hoaxes are ""generally addressed by volunteers via existing rules and processes"", and that they are ""outside of the Wikimedia Foundation's remit"". In a statement, it says: ""In general, the Foundation only gets involved in content related issues on the platform in case of specific cases of disinformation or legal matters."" Getting to the bottom of this mystery was not easy. I spoke to toaster collectors in Europe and in the US, as well as museum curators with expertise in domestic appliances. According to multiple sources, the first patent for a commercially available and successful toaster was submitted by Frank Shailor in 1909, on behalf of the General Electric company in the US. The toaster, named the D-12, is understood to be the first commercially available electric toaster. ""It is beautiful,"" says Rebecca Dolgoy, curator of natural resources and industrial technologies at Ingenium, Canada's museums of science and innovation (which hold two D-12 toasters). ""You would put the bread inside, it would toast one side at a time, and you would have to switch it. The machine is very elegant, but also utilitarian."" As I speak to her, I notice the passion in Ms Dolgoy's words. ""I'm interested in the toasters because they are fascinating, but also because of the kinds of stories that they allow us to tell,"" she tells me. And the story of Alan MacMasters, the inventor, is certainly one of them. It just happens not to be true."
Alex Jones: 'Moment of reckoning' for Infowars conspiracist,"""The money you donate does not go to these people. It goes to fight this fraud."" Those were the words of conspiracy theorist Alex Jones broadcasting live from his studio as a court in Connecticut ordered him to pay $965m (Â£869m) in damages for pushing the false theory that the 2012 Sandy Hook school shooting was a hoax. ""These people"" he refers to are the parents of the victims of that shooting, one of whom you can see in tears on screen on Jones' live stream. They'd taken Jones to court after the online abuse they received following the conspiracies he promoted on his Infowars website and talk show, The split screen on his live stream is a stark moment where the conspiracy world he has created comes up against reality. Never have his words sounded colder when contrasted with the emotion of grieving families. They have had to deal with the loss of their children while at the centre of this disinformation campaign. This marks a moment of reckoning. Jones has never been handed damages of this scale before, nor has any other conspiracy theorist - and it sets a huge precedent. The question everyone is asking now: Will this put an end to these kinds of conspiracies and the harm they can cause? That's what the Sandy Hook parents hope. When it comes to Alex Jones himself, a former insider who worked at Infowars tells me that he thinks this could be the beginning of the end. He'll struggle to continue if he does have to pay these damages. Jones' livestream during the court hearing is very revealing of the approach he plans to take in the coming weeks. After the comments about donations, he goes on to say: ""They want us shut down"". He's already attempting to claim this verdict is just more proof that the State is trying to stop him telling the truth. The bereaved families who were in court know all too well that what he's been doing is far from that. The problem is that Alex Jones' audience isn't these families. Polling from the Journal of Social and Political Psychology suggests that almost 20% of Americans believe high-profile mass shootings have been staged, usually by the government.  This survey was carried out in 2020 but there's no reason to believe that figure would be any less if carried out today. Conspiracy movements have swelled online during the Covid pandemic, and there's a growing group of people vulnerable to the tactics and rhetoric used by a conspiracy theorist like Jones. People who often start with legitimate questions are drawn into these social media worlds that offer definitive answers to great uncertainty and horrific events. They make up a captive audience for the outspoken proponents of conspiracy theories. And this isn't limited to the United States. Conspiracy theories about hoaxes and crisis actors, turbo-charged by Jones, have gone global. Their tentacles have reached as far as the UK. The jury's out on whether the huge damages that Jones has been ordered to pay will deter others promoting disinformation or damaging conspiracies. For the Sandy Hook families and others I've interviewed who've been targeted by disinformation and hate - this court case hasn't been about money. It's about the truth. For them, the huge sum of money in this trial symbolises a turning point. Many have told me how they feel let down by social media sites and policy makers. They often tell me how they feel like no-one cares. Now, it seems they're turning to the courts to seek justice - and the message sent from this jury to those victims is loud and clear. Pandora's box of conspiracies is wide open and it's very hard to close. At the very least, this shows the tide may be starting to turn."
Alex Jones: Five revealing moments from Sandy Hook trial,"For years, bombastic radio host Alex Jones has peddled a stream of conspiracy theories in his distinctive loud, gravelly voice to an audience of millions. Among the most incendiary falsehoods he ever circulated was that the 2012 shooting at Sandy Hook Elementary School in Connecticut, which left 20 children and six adults dead, was completely fabricated by the US government in a plot to strip American citizens of their guns. After a two-week defamation trial full of twists and turns, a jury in Austin, Texas, has ordered Jones to pay nearly $50m (Â£41m) in compensatory and punitive damages to the parents of a boy killed in that attack. Here are five key moments from the case. Among the viral moments that emerged from the proceedings was one that left Jones visibly dumbfounded, when it was revealed that his lawyer had accidentally sent two years of potentially damaging text messages from Jones' phone to Mark Bankston, a lawyer representing the parents. According to Mr Bankston, Jones had sent texts about Sandy Hook, contradicting trial testimony that he hadn't mentioned the shooting in any private communications. Jones said that was the reason he hadn't provided his phone records to the court. Jones' claims prompted Mr Bankston to ask him: ""Do you know what perjury is?"" The 6 January congressional committee, which is investigating the Capitol riot, has now requested access to Jones' text messages, which Mr Bankston said he intended to provide to the committee unless the judge intervenes. The committee had previously requested records and a deposition from Jones about his role in the riot, which saw supporters of former President Donald Trump storm the US Capitol on 6 January 2021. Earlier this year, companies owned by Jones, including his right-wing conspiracy website Infowars, filed for bankruptcy. In the US, declaring bankruptcy provides a route for companies to remain in operation and negotiate their debts, with settlements overseen by the court. It puts a hold on other litigation. Challenging his bankruptcy claims, Mr Bankston said Jones' texts revealed that in 2018 his companies were still netting approximately $800,000 each day. That information came via an email from an Infowars employee to Jones, who had earlier testified that he did not use emails at all. Jones was questioned about the Infowars online store and the authenticity of the products his business sells to customers, which include diet supplements, health and wellness products, gun paraphernalia and survivalist equipment. In court, Jones admitted that vitamin supplements listed on the Infowars store had not been certified for use by the US Food and Drug Administration (FDA). When asked why his supplements did not have FDA approval, he claimed the products underwent rigorous checks and were ""the best out there"". During the Covid-19 pandemic, Jones falsely claimed on his show that some of his products, including a ""supersilver whitening toothpaste"" and a ""superblue silver immune gargle"", could stop or treat Covid, resulting in an FDA warning letter sent to him and Infowars for selling ""unapproved and misbranded"" products related to the pandemic. Forensic economist Bernard Pettingill testified on Friday that Jones' businesses were worth somewhere between $135m and $270m , a claim Jones and his defence team deny. One of the most tense moments came when a plaintiff - the mother of a six-year-old boy killed at Sandy Hook - addressed Jones from the witness stand. Scarlett Lewis told the radio host that she was not an actress or part of the ""deep state"". She said her son, Jesse Lewis, and the other children who died at the primary school were real. She added that Jones' claims had led to 10 years of ""hell"". Jones acknowledged during the trial that the Sandy Hook attack was ""100% real"" and apologised for having ""hurt these people's feelings"". ""I know you believe me, yet you're going to leave this courthouse and you're gonna say it again on your show,"" Mrs Lewis said, looking directly at Jones, as he shook his head. Ms Lewis and Jesse's father, Neil Heslin, filed the lawsuit seeking at least $150m in damages against Jones. Judge Maya Guerra Gamble had several tense exchanges with Jones during the trial, reminding him at one point that he had to tell the truth under oath. ""It seems absurd to instruct you again that you must tell the truth while you testify... This is not your show,"" Ms Gamble said. On another occasion, she told Jones to spit out a piece of gum. Jones denied he was chewing any gum, saying that he was sticking his tongue into a gap where he had had a tooth removed. ""Would you like me to show you?"" Jones asked the judge, prompting her to respond: ""I don't want to see the inside of your mouth."" During the proceedings, Mr Bankston asked Jones if he had shown pictures of the judge ""on fire"" on his show, which Jones denied, resulting in the lawyer putting up a picture broadcast on Jones' show which depicted Ms Gamble in flames alongside Lady Liberty. Jones' claims about the jury were also brought up by the parents' defence team. Footage was played of Jones saying on his show that the jury was made up of ""extremely blue collar folks"", adding that ""half that jury panel does not know who I am""."
Alex Jones: Will a $965m damages demand crush his Infowars empire?,"Conspiracy theorist Alex Jones was handed a major defeat in a Connecticut court this week. But will relatives of the Sandy Hook victims be able to collect the money - and does it mean he'll stop spreading lies? He hasn't been deterred yet. Alex Jones was at it again the day after being handed a $965m (Â£860m) judgement in court, fulminating against what he calls the ""globalist"" ""New World Order"" forces attempting to muzzle him. ""Their mission is to shut me up and take me off the air and they say I'm the lead elephant,"" he told his Infowars audience. ""They take me out, they think they're going to take you out."" Far from shutting up, Jones has continued his broadsides against the legal system and what he calls the evil forces that oppose him. But experts say Jones is now in deep trouble. This latest verdict comes after a similar award in Texas totalling nearly $50m (Â£44m). And further action is yet to come - another defamation case later this year and a possible investigation into the role Jones and other Infowars employees played in the 6 January attack on the US Capitol. The lawyer for the Sandy Hook families, Chris Mattei, called the Connecticut decision ""a verdict against Alex Jones's lies and their poisonous spread, and a verdict for truth and our common humanity."" But anyone hoping that court judgements would deter Jones and Infowars from spreading paranoia and conspiracy theories will be sorely disappointed. Rumour and suspicion has been very lucrative for Jones and Infowars' parent company Free Speech Systems. His empire has grown from a local public-access TV show in Austin, Texas to a multimedia company hawking nutritional supplements and survivalist gear. ""We know he makes a lot of money,"" says Bernard Pettingill Jr, a forensic economist who testified at Jones's defamation hearing in Texas. ""He just won't turn over the records."" Pettingill estimates that Jones and Free Speech Systems have combined net assets of between $135m and $270m. Jones personally took $62m out of the company last year, Pettingill says. Despite his wealth and thriving sales business, the talk show host has repeatedly claimed he's out of money and has ""only"" $2m to his name. Earlier this year, Free Speech Systems filed for bankruptcy. A trustee has been assigned to probe exactly how much Jones and his various companies are worth, and whether the debts the company claims it has are in fact real. ""If the trustee comes back and says 'I don't believe this debt is legitimate', then Alex Jones's argument that he doesn't have enough money to pay any amount of the judgement evaporates,"" says Nicholas Koffroth, a bankruptcy attorney with legal firm Fox Rothschild. ""These massive judgements give the plaintiffs a lot of power in the bankruptcy case and in their pursuit of Alex Jones individually,"" he says. But any such pursuit means further litigation - and that gives Jones opportunity to stall. He's been open about his intent to do exactly that. The Texas judgement will be reduced because of a state law that limits punitive damages, says Steven Lubet, a law professor at Northwestern University. A judge could similarly knock down the huge compensatory damages awarded in Connecticut, so it's unlikely that he will be forced to pay anywhere near a billion dollars to Sandy Hook families. But the initial amounts are so great, any reduction might not matter. ""By making fun of the damages and calling the Connecticut judge a tyrant, he has not laid the groundwork for getting a reduction,"" Lubet says. ""It still might happen, but even if the judge cuts it in half, he still can't pay it. This is crushing for him."" Jones, who did not respond to a request for comment, still has a receptive audience - millions of listeners and viewers both in the United States and elsewhere around the world. He spent a large part of his on-air time this week drumming up donations and advertising product discounts. His business model depends on maintaining a state of perpetual anxiety about powerful, shadowy forces. On his show, Jones riffs on news stories and breaking events, asking questions and supposedly probing for hidden meanings. At every turn he casts doubt on what he calls ""official narratives"". The strategy has cultivated a loyal fan base. Pettingill, the forensic economist, points out that someone sent Jones $9m in Bitcoin the day after the Texas verdict. And no matter his legal woes, or what happens with his Infowars brand or other companies, Jones will still have broad free speech protections under the US Constitution as long as he steers clear of defamatory broadcasts like the ones that got him into trouble over Sandy Hook. ""This is America,"" says Lubet. ""He can talk about whatever he wants."""
Algeria: The forest fires that led to an artist's lynching,"The BBC's Kayleen Devlin tells a harrowing story of how the life of a young artist who came to help fight deadly forest fires in Algeria was ended by a mob. On 9 August, Algeria experienced the worst fires in the country's history: some 71 blazes spread across 18 provinces, and raged for three days. At least 90 people were killed and scores injured. The Kabylie region, east of the capital Algiers, was the worst hit. A flurry of images and videos have emerged on social media showing hillside homes ablaze. Desperate villagers were seen fleeing their homes and trying to extinguish the fires with makeshift brooms, branches, and buckets of water. Two days after the fires broke out, artist Djamel Ben Ismail tweeted saying he would travel over 200 miles (322km) from his home in Miliana to ""give a hand to our friends"" fighting the blazes. On his Facebook page, he reposted desperate calls for urgent relief assistance. He was described as ""an artist, a young man who loves the guitar and loves life... not a violent man"" by one of his friends. Yet upon reaching Algeria's Tizi Ouzou province, Kabylie region, the artist was about to have his own life cut tragically short. On 11 August, graphic footage began circulating purportedly showing Mr Ben Ismail being attacked. He was falsely suspected of having started fires, and locals tortured and burned him before taking his body to the village square. The videos immediately caused national outrage. The artist's brother later urged social media users to delete the footage of the attack. His mother, he said, still did not know how her son had died. Mr Ben Ismail's father said he was ""devastated"". ""My son left to help his brothers from Kabylie, a region he loves. They burned him alive,"" he said. According to some local media reports, paranoia and rumours spread throughout parts of Tizi Ouzou, with some residents becoming suspicious of people driving cars with licence plates from other provinces. This panic and paranoia is alleged to have been stoked by accusations of arson. The evening before Mr Ben Ismail's death, Prime Minister Aymen Benabderrahmane said the fires were the result of a ""criminal act"". In a televised address, he added: ""Preliminary investigations in Tizi Ouzou have proven that the starting points of these fires were carefully chosen to cause the largest possible losses."" On the same day, Interior Minister Kamel Beldjoud visited Tizi Ouzou, telling reporters the fires had been caused by ""criminals filled with hatred against our country"". This week, Algeria announced it will review its relations with Morocco after accusing it of complicity in the deadly fires. According to BBC Monitoring, neither officials nor the country's main media outlets have mentioned climate change as a cause of the fires, or as a reason for their vast spread. This is despite the fact that temperatures of up to 46C (115F) were forecast for the week in which the fires raged. Also about that time, a major UN scientific report warned of increasingly extreme heatwaves, droughts, and flooding globally. In the wake of Mr Ben Ismail's death, public anger has been stoked and political reprisals have ensued. Some social media users circulated pictures of the alleged killers, trying to identify them, and many gathered under a hashtag calling for justice to be served. So far, 61 people have been arrested after the artist's death, with the finger being pointed at members of the Movement for the Self-Determination of Kabylie (MAK). The movement was declared a terrorist organisation by Algerian authorities in May. On 17 August, state TV broadcast ""confessions"" of the killing from MAK suspects, although the investigation is still continuing."
Amazon and Facebook staff warned of threats to safety,"Amazon and Facebook have warned staff about threats to their safety amid fears of a backlash against ""big tech"". Amazon Web Services (AWS) employees were told to ""be vigilant"" after the firm removed Parler from its web-hosting service. The app is popular with some supporters of President Donald Trump. Facebook staff were also instructed not to wear company-branded clothing in public following its ban of the US President's account. The companies cited the deadly siege on US Congress and civil unrest as reasons for concern. ÂIn light of recent events, and to err on the side of caution, global security is encouraging everyone to avoid wearing or carrying Facebook-branded items at this time,"" an internal Facebook memo obtained by The Information, said. According to an email reviewed by Business Insider, AWS vice-president Chris Vonderhaar urged his team to ""be safe, be vigilantÂ and report any unusual activity related to the companyÂs data centres. Amazon Âcontinues to closely monitor civil unrest in the United StatesÂ, the email added. ÂWe all need to [be] vigilant during this time to keep one another and our facilities safe,Â the email said. ÂIf you see something, say something - no situation or concern is too small or insignificant.Â The email also told employees to quickly escalate life-threatening or dangerous situations, as well as other serious incidents. It also contained guidelines on how to respond to members of the press, Business Insider reported. The company has also told its engineers that it is making Monday and Tuesday a ÂBlocked DayÂ in the US - which means employees cannot make any major updates or changes to existing services without the approval of senior leaders. This suggests a growing concern for a potential cyber-attack or volatility to its service. AWS's decision to remove Parler is the latest in a series of responses by tech companies, following the riots on Capitol Hill last week. Facebook boss Mark Zuckerberg said President Trump would be banned from its platform ""for at least the next two weeks until the peaceful transition of power is complete"". President-elect Joe Biden is due to take office on 20 January. Facebook is also suspending all donations to political parties and launching a review into its political spending practices, Axios reported. Airbnb condemned the attack on the Capitol, saying it will update its political spending framework and ""withhold support from those who voted against the certification of the presidential election results."" Google and Microsoft have similarly frozen political donations, in light of last week's events. Twitter, Instagram, Snapchat and Twitch have also taken action against President TrumpÂs accounts."
Anti-abortion groups target women with misleading ads,"When Hana found out she was pregnant, she knew she wanted to have an abortion - but her search for a clinic on Google led her to an anti-abortion centre, set on talking her out of her decision. In many US states, BBC News has seen misleading websites advertising these clinics appearing high up in Google search results - and Facebook adverts with inaccurate medical advice - while genuine abortion providers are having their ads rejected and accounts restricted. Advice centres, such as the one visited by Hana - a 19-year-old living in the north-eastern US state of Massachusetts - are often run by Christian organisations. They may offer some medical services such as pregnancy tests and ultrasounds - but some of their online promotion falsely suggests they also provide pregnancy-termination services. It wasn't until Hana was walking down the centre's corridor, lined with posters comparing the procedure to murder, that it began to dawn on her this was not the abortion clinic she believed it to be. Hana describes herself as a ""nerdy researcher"", studying a health-related course at college - but nothing about the clinic's website tipped her off to the service it actually provides. The home page says: ""Take control - start with a free abortion consultation."" And in a tab labelled: ""Get care,"" it lists the types of abortion (medical and surgical) that can be performed during different trimesters of pregnancy, under the heading: ""You just found out you're pregnant and want to know your options."" Once there, Hana says, she was told, inaccurately, abortions were linked to infertility and breast cancer - and having had a Covid-19 vaccine, she might lose the pregnancy anyway, making abortion unnecessary, despite the evidence suggesting vaccinated people are no more likely to miscarry and, in fact, better protected against the risks of pre-term and still birth associated with Covid. She was also pressured to view the ultrasound scan against her wishes. ""What kind of mother doesn't want to see a picture of their child?"" asked the person attending to her. Hana was left feeling deceived and betrayed. The Human Coalition, an anti-abortion group providing marketing for the centre and more than 40 others, told BBC News: ""We find in our work, most abortion-determined women do not desire an abortion, they desire help. ""We're here to empower women by filling that gap - connecting women to the care and support they want, to choose life."" Google displays adverts above search results for certain terms. Advertisers bid to have their ads appear first, Google says, although the order should also be determined by ""relevance"" and ""overall quality"". But, Whitney Chinogwenya, of MSI Reproductive Choices (formerly Marie Stopes international) says, this creates a ""battle of budgets"", with regulated abortion clinics competing with anti-abortion clinics or unregulated pill providers for ad space on specific search terms. Several large global abortion providers have also told BBC News they regularly have their online material referring to abortion censored without explanation, including having YouTube channels suspended, social-media accounts restricted and Facebook and Google ads rejected. In 2019, having been criticised for hosting misleading adverts, Google tried to crack down on abortion-advice clinics, which are most common in the US but can also be found across Europe (including the UK), Africa and Latin America. In the US, UK and Ireland, anyone running an ad mentioning abortion must first apply for a certificate. Ads from advice clinics not offering abortions can still run but will be given a disclaimer the advertiser ""does not provide abortions"". Hana says she did not see this disclaimer. It appears in very small font underneath the search headline and description. Sarah Eagan, a researcher for campaign group the Center for Countering Digital Hate, questions whether Google should be taking money at all for anti-abortion ads that target keywords used by people actively seeking terminations. The CCDH has also found anti-abortion ads promoting unproven medicines remaining on Facebook. And at the other end of the spectrum, the researchers found Google's autocomplete function suggesting ineffective do-it-yourself abortion methods. Kelly, like Hana, says she was given inaccurate medical information as she struggled to find an affordable and safe way to terminate her pregnancy in her home state of Texas. Between jobs and without insurance, she could not afford ""an actual doctor's visit"" so searched for affordable clinics. Finding her way to an anti-abortion centre, Kelly says she was frightened with warnings she could ""bleed out"" and risk her life but not given the context medical abortion is an extremely safe procedure. Kelly feels promoting free pregnancy tests targets low-income women. The centre appears to be using organic search, not adverts, making it more complicated to regulate. It says its website clearly states: ""We do not refer or perform abortions,"" adding it provides ""free services annually to over 5,000 minority poor under-served single mothers"". Eventually, Kelly was prescribed termination drugs - just hours before she passed the 12-week limit for a safe medical abortion. But Elisa Wells, co-founder of Plan C, the organisation that helped Kelly access these abortion pills, says its online material is routinely ""disallowed for violating community standards"" on Facebook, Instagram and Google. Google says it has clear policies governing abortion-related ads, some determined by local laws and regulations. Some of the posts and channels flagged by BBC News had been removed in error and since reinstated, it said. Facebook said it had restored a small number of incorrectly rejected ads for abortion providers. Read more from Reality Check Send us your questions"
Anti-vax protests: ÂSovereign citizensÂ fight UK Covid vaccine rollout,"Opposition to Covid vaccinations has come in many forms, but none stranger than the ""sovereign citizen"" defence. It uses defunct ancient English law to try to challenge regulations. Some anti-vaccination protesters outside schools and hospitals have used this to hand out fake legal documents to teachers, parents and health workers. Others have sought to remove Covid patients from intensive care wards, citing non-existent ""common law"" empowering them to do so. They also accuse the government of ""vaccine genocide"" in videos shared on social media. Some groups have even held training camps for their members. Images have emerged of black-clad men being coached in ""direct action"" techniques. Followers of ""sovereign citizen"" and ""freeman on the land"" conspiracy theories wrongly believe they possess the legal power to bring leading politicians, civil servants and scientists before so-called ""common law courts"". They allege ""crimes"" over Covid restrictions and vaccinations, even though such claims have no basis in law. But that has not deterred a newly-formed group calling itself Alpha Men Assemble, which combines anti-vaccine and sovereign citizen beliefs. It has been holding training sessions in several UK locations where volunteers prepare for ""direct action"", such as breaking through police lines, marching formations and sparring. Launched on the Telegram chat app in mid-December, the group has amassed 8,000 members, and posts footage of training sessions online. According to the Daily Mail, at a recent training session in Staffordshire activists were urged to ""hit vaccine centres, schools, head teachers, colleges, councillors and directors of public health in every area"". The group has described itself as ""free thinking men and women living as sovereign beings under common law"". They say that they reject violence and are in favour of ""body autonomy"". Its training events, it says, are ""non-combative and are in no way to be linked to any militia or extremism"". We asked the Alpha Men Assemble group for comment, but have not yet received a response. In December, two Covid patients were taken out of hospitals in Liverpool and Milton Keynes, against the advice of doctors and nurses. Video of the incident in Liverpool's Aintree University Hospital shows activists boasting of their presumed legal jurisdiction as ""common law constables"". They told staff and police they were under ""open arrest"". A man was later arrested in connection with the incident. There was a similar incident last year in Ireland when an elderly Covid patient was removed from a hospital and taken home by a man citing a combination of anti-vaccine and sovereign citizen beliefs. The patient was returned to hospital two days later, and eventually died. Conspiracy-laden criminal complaints have recently been filed with police in the UK and also the International Criminal Court, alleging ""genocide"" and ""depopulation"" via vaccinations. Anti-vax activists have also picketed schools, hospitals, politicians' homes, police stations, vaccination centres and the homes of celebrities who have publicly supported vaccines. Politicians and journalists have been ""served"" with fake legal papers. In August, a group attempted to ""seize"" Edinburgh Castle, claiming sovereignty over the landmark under Magna Carta. They told police they rejected ""fake acts and statutes"" that were ""made up by paedophiles"". One person was arrested. The sovereign citizen movement originated in anti-government protests in the US in the 1970s and rose in prominence along with the militia movement in the 1990s. It was in that decade that the UK version of the movement surfaced. British believers think that they can opt out of laws with which they do not agree, based on a clause - or, as they term it, Article 61 - of Magna Carta. The clause describes a process of electing representative barons who had the power to seize property in order to redress grievances. It was struck from Magna Carta within a year of its signing and, like much of the document, has no legal standing today. UK sovereign citizen activists often cite obscure terms such as ""legal name fraud"" and ""wet signatures"", and organise on social media. Volunteers are encouraged to attend training to qualify as ""common law constables"", which they falsely believe grants powers akin to, or even higher than, the police. Activists believe that government-issued documents such as birth certificates and driving licences are ""legal fictions"". An online ""common law court"" allows followers to register as ""living men and women"". It also hands out identification documents to volunteers and provides so-called legal advice and services, for a range of fees. ""There is no such concept in our law as a sovereign citizen,"" said the Law Society's Ellie Cumbo. Some followers have learned this the hard way, finding out in court that their beliefs don't form a legal defence from criminal charges. Among these is a hairdresser in Bradford who was fined thousands of pounds after citing Magna Carta in an attempt to stay open during lockdown. A tattoo artist who insisted on keeping his business open during Covid restrictions also eventually lost his case. Sovereign citizen activists have also issued fake legal ""writs"" calling for the recipient to stop promoting or administering Covid vaccines. These threaten prosecution for violating the Nuremberg Code against human experimentation. They urge ""all constables and sovereign men and women"" to arrest these figures ""on sight and without delay"". One sent to the BBC's disinformation reporter Marianna Spring said she was being served with a ""notice of liability for harm and death"". Ms Cumbo said: ""These bogus writs have no legal validity, and in many cases do not even seem to involve or resemble a claim that would be recognised by the courts. ""Historically, writs were used to start any civil claim against someone else, but today this has to be done via a claim form issued under the authority of the relevant court."""
Assam: Muslims falsely accused of waging Âflood jihadÂ,"After devastating floods hit India's north-eastern state of Assam, claims that members of the local Muslim community were to blame for the disaster began circulating online. But was there any truth to these allegations? One of the accused told the BBC his story. When the police knocked on his door in the early hours of 3 July, Nazir Hussain Laskar was puzzled. For years, he had worked as a construction worker in Assam, helping the state build flood protections. But, on that morning, the officers who arrested Mr Laskar accused him instead of ""damaging public property"" - more specifically, an embankment meant to protect communities from flooding. ""I have spent 16 years working for the government to build embankments"", Mr Laskar said. ""Why would I damage one?"" Mr Laskar spent nearly 20 days behind bars, before being released on bail. No evidence of his involvement has been found, but the social media storm around him has been raging ever since. Two waves of flooding hit Assam in May and June, killing at least 192 people. While the state floods every monsoon, this year rains came early and were heavier than usual. But for a number of social media users, something more sinister was at play here. They claimed, without proof, that the floods were man-made, and that a group of Muslim men had deliberately inundated the neighbouring Hindu-majority city of Silchar, by damaging flood defences. Mr Laskar's arrest, along with that of three other Muslim men, triggered a barrage of social media posts accusing them of supposedly waging a ""flood jihad"". These posts were shared thousands of times, including by prominent influencers with verified accounts. The claims were then repeated by some local media outlets. But the gravity of his situation only dawned on him when, already in prison, Mr Laskar caught a mention of his name on television: a news channel accusing him of ""flood jihad"". ""I was afraid and could not sleep that night. The other inmates were talking about it. I thought I might get attacked."" The construction of embankments has been central to flood management in Assam since the 1950s. The state has more than 4,000km (2,500 miles) of embankments and many of these are said to be brittle and prone to damage. On 23 May, an embankment was damaged on the Barak River, which flows through north-east India and eastern Bangladesh. The breach happened in a Muslim-majority area called Bethukandi - and it was one of several contributing factors to heavy floods in Silchar, which is majority Hindu. ""The cut was one of the causes"", says Ramandeep Kaur, superintendent of police in Silchar. ""But it wasn't the only point from where water entered the town."" The BBC understands it was this particular incident that led to the arrest of Mr Laskar and three other Muslim men. Later, a fifth man was also arrested. No evidence has been found linking any of them to the breach. ""A lot of these breaches take place because of the lack of repair and maintenance of the embankments,"" said Nirmalya Choudhury, an associate professor at the Jamsetji Tata School of Disaster Studies in Mumbai. ""Some of it could be also human-induced. It could be that there were instances where people deliberately breached the embankment so that the water would move out, and would not flood their area."" The Silchar police agrees. ""There is no such thing as 'flood jihad',"" said superintendent Kaur. ""In earlier years, the administration would make a cut in the embankment themselves to drain the water out. This year it wasn't done, and some people took it into their own hands."" ""To make this kind of claim [of 'flood jihad'] is to take an easy way out,"" said Prof Choudhury. ""This is a managerial problem, and I think it requires a far more mature response."" According to Google Trends, searches for ""flood jihad"" hit a five-year peak in July, fed by the social media frenzy around this claim. But this is hardly the first time anti-Muslim conspiracy theories have hit the mainstream in India. During the pandemic, Indian Muslims were at times falsely accused of deliberately spreading Covid-19 (what some Indian media outlets described as ""corona jihad""). Critics say violence, hate speech and misinformation targeting Muslims has increased since 2014, when Prime Minister Narendra Modi's Hindu nationalist Bharatiya Janata Party came to power. The party disputes this. Meanwhile, in Assam, Mr Laskar continues to live in fear after his release from jail. ""My family and I are still afraid to leave the house. My children have been skipping school. If I must leave the house, I sometimes wear a helmet to hide my face. I am afraid of being lynched by an angry mob."" ""I was accused of 'flood jihad' because I am a Muslim. This is false. Those who are spreading this are doing something very wrong."" Additional reporting by Dilip Kumar Sharma"
Australia floods: Unfounded cloud seeding claims spread online,"For the third time this year, Sydney has been hit by major floods. Scientists blame intense rainfall on a combination of factors - but, on social media, unfounded allegations of ""weather manipulation"" have spread widely. About as much as eight months' worth of rain has come down in just four days, bringing parts of Australia's largest city to a standstill. Experts say no single factor can explain this extreme weather, pointing instead to warmer oceans and saturated soils as contributing factors. But conspiracy theorists aren't buying it. On social media, they blame the extreme rainfall on ""cloud seeding"" and ""weather manipulation"". There is no evidence to back up such theories, but this hasn't prevented falsehoods from reaching thousands of people online. Cloud seeding is a real thing. It involves manipulating existing clouds to try and help them produce more rain or snow. This is done by firing small particles (usually silver iodide) into clouds. Water vapour gathers around the particles and eventually falls as precipitation. The technique has been around for decades. It's not infallible, but it's been used all around the world to - for example - help irrigate crops. But there is no evidence to suggest cloud seeding has anything to do with the current rainfall in Sydney. That hasn't stopped some TikTok users from denouncing ""weather engineering"". They say it's all part of a government plan to ""weaponise"" the weather against its own people - a popular conspiracy trope that has been around for years. ""The idea that this is happening on a widespread scale, and that there is some motive to manipulate the weather is a complete myth,"" says Dr Ella Gilbert, a climate scientist at the British Antarctic Survey. And yet, this myth seems to have found an audience on various social media platforms. Many of the accounts seen by the BBC posting this type of content have also shared other conspiracy theories involving global warming, Covid vaccines, and the Moon landings. Some conspiracy theorists have been sharing a 2016 news report from the Australian TV network 7News - which has now been watched thousands of times. In it, the newsreader reports on concerns by Tasmanian residents that the region's worst floods in 40 years could have been linked to cloud seeding. But a probe by the Tasmanian government found that cloud seeding did not contribute to or worsen the heavy rains - a conclusion since backed by independent scientists and experts. ""We don't have a co-ordinated effort to change the weather, because it's just physically and financially unfeasible,"" says Dr Gilbert, who adds that even if cloud seeding played a role, it would have ""an absolutely minuscule effect."" There is no single cause for the intense rainfall Sydney has experienced in the last few days. But experts say the flooding has been worsened by climate change and a La NiÃ±a weather phenomenon. A La NiÃ±a develops when strong winds blow the warm surface waters of the Pacific away from South America and towards Indonesia. In their place, colder waters come up to the surface. In Australia, a La NiÃ±a increases the likelihood of rain, cyclones, and cooler daytime temperatures. Do you have a story for me? Get in touch."
BFM journalist Rachid M'Barki suspended in scandal linked to disinformation firm,"The suspension of a senior journalist at France's leading TV news channel has uncovered what appears to be a well-organised system of corruption and influence buying in the international media. It was reported in January that 54-year-old Rachid M'Barki, a respected BFM veteran, had been summarily removed from his duties as overnight presenter pending an internal enquiry. The reason was a mystery. But now an investigation by Le Monde newspaper in conjunction with the campaigning organisation Forbidden Stories has revealed more details. According to the investigation, M'Barki ran reports on a variety of subjects - luxury yachts in Monaco, a Sudanese opposition leader, allegations of corruption in Qatar - that had all one thing in common: they were planted by an Israel-based outfit specialising in 'news for hire'. M'Barki has denied being paid to run the stories, but he admits to bypassing BFM's editorial checks. He says he was offered the reports by an intermediary and exercised his own professional judgment in selecting to use them. But the investigators say they have evidence that the origin of the stories lies in the shadowy Team Jorge, an operation based in Tel Aviv and run by a former Israeli special forces officer whose real name is Tal Hanan. According to Le Monde and Forbidden Stories, Team Jorge is one of several players in a growing world of disinformation mercenaries - private sector experts in intelligence who for a price will use the internet to damage an enemy's reputation or influence an election. To get access to Team Jorge, three journalists from the Forbidden Stories consortium posed as potential clients seeking to shape opinion in French-speaking Africa on behalf of a major multinational. After a lengthy negotiation, they finally arranged a face-to-face meeting and got what amounted to a sales pitch. Hanan claimed to have intervened in more than 30 elections and to have access to email and social media accounts of prominent African figures. Central to the Team Jorge offer was a platform called Advanced Impact Media Solutions (AIMS), which generates tens of thousands of fake identities with accounts on Facebook and Telegram. These accounts then spread the content of a campaign. The investigators identified around 20 different international campaigns which they believed Team Jorge had organised. Among the material being circulated on social media, they especially noticed two television news reports in French that purportedly ran on BFM. After checking with BFM's management, they had confirmation: the reports were shown late at night on the channel, but without the knowledge of the editorial team. At that point, on January 11, M'Barki was called in and suspended. The first of the reports was on the EU's Russia sanctions, and their impact on the luxury yacht business in Monaco. It was claimed that 10,000 jobs were at risk and that the industry had appealed to Prince Albert to intervene on their behalf. None of that has been proved. The second report, broadcast in mid-December, was about a leafleting campaign in Paris accusing a former state prosecutor in Qatar of corruption. When originally shown in the early hours of the morning, the reports would have gone almost unobserved. But that changed when they were picked up by social media and Team Jorge's massed avatars. Suddenly they were viral. By seemingly planting the reports onto mainstream French television, the organisers would have immeasurably boosted the credibility of what would otherwise have been unsubstantiated gossip. It also would mean Team Jorge had evidence for future clients of its access to western media. M'Barki's late night show also ran items on a Sudanese general who was considering running for the presidency, and a trade show in the disputed territory of Western Sahara. In this second piece, the name of the territory was replaced by the politically-charged term Moroccan Sahara. The area has been the subject of a long-running territorial dispute between Morocco and the indigenous Sahrawi people, led by the Polisario Front. The people or organisations that ultimately commissioned the suspected campaigns remain a mystery, according to Le Monde and Forbidden Stories. Some may have been commissioned by governments, but most - like the yacht story - were probably ordered by private interests, the investigation concluded. A worrying sign, the investigators say, of the growing ""Uberisation"" of the fake news business. The suspension of a senior journalist at France's leading TV news channel has uncovered what appears to be a well-organised system of corruption and influence buying in the international media. It was reported in January that 54-year-old Rachid M'Barki, a respected BFM veteran, had been summarily removed from his duties as overnight presenter pending an internal enquiry. The reason was a mystery. But now an investigation by Le Monde newspaper in conjunction with the campaigning organisation Forbidden Stories has revealed more details. According to the investigation, M'Barki ran reports on a variety of subjects - luxury yachts in Monaco, a Sudanese opposition leader, allegations of corruption in Qatar - that had all one thing in common: they were planted by an Israel-based outfit specialising in 'news for hire'. M'Barki has denied being paid to run the stories, but he admits to bypassing BFM's editorial checks. He says he was offered the reports by an intermediary and exercised his own professional judgment in selecting to use them. But the investigators say they have evidence that the origin of the stories lies in the shadowy Team Jorge, an operation based in Tel Aviv and run by a former Israeli special forces officer whose real name is Tal Hanan. According to Le Monde and Forbidden Stories, Team Jorge is one of several players in a growing world of disinformation mercenaries - private sector experts in intelligence who for a price will use the internet to damage an enemy's reputation or influence an election. To get access to Team Jorge, three journalists from the Forbidden Stories consortium posed as potential clients seeking to shape opinion in French-speaking Africa on behalf of a major multinational. After a lengthy negotiation, they finally arranged a face-to-face meeting and got what amounted to a sales pitch. Hanan claimed to have intervened in more than 30 elections and to have access to email and social media accounts of prominent African figures. Central to the Team Jorge offer was a platform called Advanced Impact Media Solutions (AIMS), which generates tens of thousands of fake identities with accounts on Facebook and Telegram. These accounts then spread the content of a campaign. The investigators identified around 20 different international campaigns which they believed Team Jorge had organised. Among the material being circulated on social media, they especially noticed two television news reports in French that purportedly ran on BFM. After checking with BFM's management, they had confirmation: the reports were shown late at night on the channel, but without the knowledge of the editorial team. At that point, on January 11, M'Barki was called in and suspended. The first of the reports was on the EU's Russia sanctions, and their impact on the luxury yacht business in Monaco. It was claimed that 10,000 jobs were at risk and that the industry had appealed to Prince Albert to intervene on their behalf. None of that has been proved. The second report, broadcast in mid-December, was about a leafleting campaign in Paris accusing a former state prosecutor in Qatar of corruption. When originally shown in the early hours of the morning, the reports would have gone almost unobserved. But that changed when they were picked up by social media and Team Jorge's massed avatars. Suddenly they were viral. By seemingly planting the reports onto mainstream French television, the organisers would have immeasurably boosted the credibility of what would otherwise have been unsubstantiated gossip. It also would mean Team Jorge had evidence for future clients of its access to western media. M'Barki's late night show also ran items on a Sudanese general who was considering running for the presidency, and a trade show in the disputed territory of Western Sahara. In this second piece, the name of the territory was replaced by the politically-charged term Moroccan Sahara. The area has been the subject of a long-running territorial dispute between Morocco and the indigenous Sahrawi people, led by the Polisario Front. The people or organisations that ultimately commissioned the suspected campaigns remain a mystery, according to Le Monde and Forbidden Stories. Some may have been commissioned by governments, but most - like the yacht story - were probably ordered by private interests, the investigation concluded. A worrying sign, the investigators say, of the growing ""Uberisation"" of the fake news business."
Biden inauguration leaves QAnon believers in disarray,"Followers of the baseless QAnon conspiracy theory are divided after Joe Biden's inauguration confounded their predictions that Donald Trump would remain president in order to punish his enemies in the ""deep state"". Many reacted with shock and despair as Joe Biden was sworn in as the 46th US president. ""I just want to throw up,"" said one in a popular chat on the Telegram messaging app. ""I'm so sick of all the disinformation and false hope."" Others insisted ""the plan"" had not failed, finding new theories to latch on to. For weeks, QAnon followers had been promoting 20 January as a day of reckoning, when prominent Democrats and other elite ""Satanic paedophiles"" would be arrested and executed on the orders of President Trump. But, as Mr Biden took his oath and no arrests were made, some in the QAnon community had an uncomfortable meeting with reality. ""It's done and we were played,"" wrote another. In the hours that followed, thousands more made similar comments on platforms like Gab, Telegram and other online forums where believers go to discuss the conspiracy, after being kicked off mainstream social media in the wake of the Capitol riots. Doubt even seeped into posts by some of the biggest influencers of the movement, as some started to question the phrase ""Trust the plan"" - a key QAnon slogan that has been used by ""Q"", an anonymous figure whom followers believe to be an influential government insider. ""This is a very difficult day for all of us,"" said one influencer whose Twitter account with 200,000 followers was recently suspended. ""Today's inauguration makes no sense to the Christian patriots and we thought 'the plan' was the way we would take this country back."" One woman whose husband is a QAnon follower told the BBC that inauguration day had been ""the most disappointing"" of his life. She's hopeful Wednesday's events may have shaken his faith in the conspiracy, but fears what comes next. ""I'm not a told-you-so kind of person and never seek to belittle or humiliate,"" she said, adding that his beliefs had put a strain on their marriage in recent months. The QAnon community ""risks fracturing"", said another influencer on Gab, a right-wing social media platform, adding that ""real friendships might be irreparably damaged because people are angry"". The widely accepted belief within the movement was that at some point before Joe Biden stepped on the stage to take the presidential oath, members of the military - on the orders of Mr Trump - would intervene to arrest Mr Biden and his wife along with Kamala Harris, Nancy Pelosi, Chuck Schumer, Barack and Michelle Obama, Hillary and Bill Clinton, George and Laura Bush and other members of ""the deep state"". A number of extremist and neo-Nazi Telegram channels have already tried to capitalise on the chaos in the QAnon community, asking their members to seek out and convert distraught followers. Some influential accounts told followers to keep the faith and not give up so easily. One popular Telegram channel reassured its 130,000 subscribers that Mr Trump and the ""Q"" team were still in control behind the scenes, and the ""evil deeds"" of the deep state would be exposed ""over the next four years"". Some doubled down, criticising those who in their view had rushed to judgement. One claimed Mr Biden was running his administration as an inmate inside a military compound, but he ""doesn't know it yet"". Later in the day, Ron Watkins, one of the most influential figures in the QAnon community, called on his followers to move on - to the surprise of many observers. The son of Jim Watkins, the man behind 8chan and 8kun - message boards filled with extreme language and views, violence and extreme sexual content on which ""Q"" posts - the younger Watkins has been one of the main purveyors of election conspiracies and played a vital role in encouraging some QAnon supporters to gather in Washington DC on 6 January. ""We gave it our all,"" he said to his 120,000 subscribers on Telegram. ""Now we need to keep our chins up and go back to our lives as best we are able."" As inauguration day drew to a close, QAnon communities were still filled with mixed emotions. Some said they were waiting for ""Q"", who has been largely silent since election day, to post as they had so many unanswered questions. And some expressed hope that Mr Trump would communicate directly with them soon. A considerable chunk of the community remains steadfast in their belief, urging one another to remain patient and keep the faith. It is difficult to predict where the movement goes from here. But some experts and researchers think that QAnon, which has successfully duped hundreds of thousands of followers into thinking they alone could stop a global cabal of criminals ruling the world, will not simply vanish overnight. Followers ""will likely remain a threat until they can exit the QAnon space"", tweeted extremism researcher Marc-Andre Argentino. ""Even without QAnon, without 'Q', without Trump, the core elements that lead these individuals to believe in QAnon will still remain and they will need to find outlets for their conspiratorial mindsets and their anti-democratic ideals,"" he added. Additional reporting by Marianna Spring Subscribe to the BBC Trending podcast or follow us on Twitter @BBCtrending or Facebook."
Biden inauguration: What are far-right Trump supporters saying?,"Mass armed protests initially called for by some extreme Trump supporters in the lead-up to inauguration day have so far not materialised, following an apparent change of heart by the groups involved. One flyer shared on Gab, a Twitter-like platform popular with far-right groups, had called for armed protests in Washington and 50 state capitals ahead of Joe Biden's inauguration. The plans prompted a warning from the FBI. But in recent days those calls have been reversed and a new theory put forward on fringe platforms - that plans for armed protests were instead a ""trap"" set up by the FBI, or supporters of the left-wing Antifa or Black Lives Matter (BLM) groups. Some of these discussions have been happening on less popular and less public online platforms, where many Trump supporters from far-right and conspiracy groups have migrated after being kicked off Facebook and Twitter in the wake of the Capitol riots on 6 January. The vast majority of armed rallies that were initially being promoted have so far not gone ahead following the warnings. On Sunday, despite earlier fears of violence, there were only a few armed protesters in front of state capitols in several states, including Michigan and Ohio. Those who did turn out were not dedicated Trump supporters but mainly members of the extreme libertarian Boogaloo Bois movement, whose followers advocate an armed overthrow of government. Despite a continued belief in unsubstantiated claims of election fraud, many of Mr Trump's supporters seem resigned to the reality that Mr Biden will be inaugurated as president on Wednesday. Although some claim they will never accept him as their president. Alongside the new online warnings to avoid armed protests in Washington DC and elsewhere, there are a few posts by furious supporters of the president calling for ""guerrilla warfare"". The lack of armed protests for now could be down to ""increased fear about crackdowns by law enforcement following the 6 January,"" says Alex Newhouse, research lead at the Center on Terrorism, Extremism, and Counterterrorism in the US. He also warns of a different kind of threat from the Capitol riots: ""The level of desensitisation to concepts like race war, civil war, and political violence that occurs in these chatrooms means that if even a tiny fraction of 1% of followers take it seriously, that could indicate a higher potential of individual acts of extreme violence."" And what about the baseless QAnon conspiracy theory, which has been blamed for radicalising so many and whose members were among those that stormed the Capitol? QAnon followers remain convinced that somehow Mr Trump, with the help of the military, will successfully overturn the outcome of the election on inauguration day. They believe Mr Trump will invoke the Insurrection Act, a rarely used 1807 law that allows the president to deploy military forces inside the US. There is no evidence to suggest this could happen. Followers of the conspiracy have also been sharing false or doctored images and videos of the fencing around the Capitol building - built to ensure the safety of those attending the inauguration and avoid a repeat of the 6 January riots - with claims the fencing is in fact a military prison which will be used to entrap Mr Biden and members of the so-called ""deep state"". There's also an increasing sense of paranoia. Groups on alternative platforms that openly called for violence on 6 January now worry aloud that they have been infiltrated by government agents or left-wing activists. Owners and moderators of right-wing social media platforms have posted messages asking members not to post incitement to violence. But violent threats against House speaker Nancy Pelosi, a Democrat, and Republican Vice-President Mike Pence, whom the groups had hoped would overturn the election result, remain widespread. The move away from mainstream platforms poses a risk, according to Mina al-Lami, jihadism specialist at BBC Monitoring, who sees parallels with Islamist militant groups who have been subject to similar crackdowns. ""Members of the fringe far-right may now slip under the radar into closed spaces which use end-to-end encryption,"" a very secure method of exchanging messages, she says. ""Their radicalisation goes unchecked and unmonitored."" The social media giants acted to remove QAnon groups after the violence in Washington, but they have quickly rebuilt themselves elsewhere. On Gab, groups dedicated to QAnon now boast more than 500,000 members. A similar new channel on Telegram has more than 100,000 subscribers. Meanwhile, accounts spreading conspiracy theories and potentially inciting violence have emerged in surprising places. TikTok, the short-form video platform hugely popular among young people, has seen a flood of clips from pro-Trump militia groups. TikTok videos from militia groups are concerning, says Ciaran O'Connor of the Institute for Strategic Dialogue, a think tank focused on extremism and hate groups. Users have been sharing footage of members preparing firearms, as well as promoting false claims that President Trump has activated the Insurrection Act. Extremist supporters have been taking advantage of TikTok's slow moderation process, which means that videos can stay online for long periods of time before they are deleted for violating the network's terms of service, Mr O'Connor says. Some of the more violent and conspiratorial pro-Trump groups may have been scattered across the internet following purges at mainstream platforms, but that doesn't mean they've gone away. They realise they're under close scrutiny from the US authorities, but they're preparing to dig in for a long fight. A special programme from the BBC Trending team. Listen now on BBC Sounds. Subscribe to the BBC Trending podcast or follow us on Twitter @BBCtrending or Facebook."
Boebert to Lake: How many 2020 election deniers won their races?,"At least 126 Republicans elected in the US midterms have publicly denied the result of the 2020 presidential election, according to a BBC analysis. They include Marjorie Taylor Greene, the controversial politician whose personal Twitter account was suspended for breaking rules on coronavirus misinformation, and JD Vance, a former Trump critic and successful author. Donald Trump continues to insist, falsely, that he won the 2020 election. Before the midterms, we analysed and independently verified data published by the website FiveThirtyEight, which tracked statements from all candidates running for the Senate, House of Representatives and state governor positions. We found 178 of them - all Republicans - had fully and publicly denied the result of the presidential race supporting Trump's false claim that he beat Joe Biden. That accounted for more than one third of all Republicans standing in the races. Our findings so far, one week after election day: There are four House races involving election deniers yet to be called: Alaska's sole seat, where Sarah Palin is the Republican nominee, Lauren Boebert's race in Colorado, and two districts in California. Many candidates were nominated in solid Republican voting areas, so victory was more or less guaranteed, but some surprising election night stories have emerged. Bo Hines, a 27-year-old former college football star running for Congress in North Carolina was favoured to win, and endorsed by Donald Trump as a ""proven winner on and off the field"". It wasn't to be though: he lost to Democrat Wiley Nickel, a lawyer who worked in the Barack Obama administration. Lauren Boebert once shared QAnon conspiracies on her social media accounts and was known for her staunch pro-gun views, including a pledge to carry a handgun with her in Washington DC when she was first elected to Congress. She holds a narrow lead in a district that favours Republicans, and her race against Democrat opponent Adam Frisch appears to be headed towards a recount. In Arizona, former local news anchor Kari Lake was projected to lose her race for governor. Ms Lake's social media pages include frequent allegations about rigged elections. In October 2021, she tweeted: ""Voter fraud will herald the END of the Republic."" During the campaign, she was challenged by the BBC about her claims that there were hundreds of thousands of phoney ballots in 2020. She said - without providing proof - that the government had withheld evidence. There were problems with voting tabulation machines early on election day in Maricopa County, Arizona, home to the state's largest city Phoenix. About a fifth of machines in the county were failing to read ballot printouts which led to delays, although the problem was later resolved and election officials said there were backup systems in place to ensure votes were counted. After news organisations called the governor's race for her opponent, Democrat Katie Hobbs, Ms Lake tweeted late Monday: ""Arizonans know BS when they see it."" She did not elaborate further. Some election deniers exceeded expectations. George Santos, a New York Republican who attended the 6 January riot at the US Capitol but later called the event ""a dark day in America"", was considered unlikely to win, but secured a seat in the House. But overall, many of the most devoted election deniers underperformed or lost outright. Author of memoir-turned-film Hillbilly Elegy, JD Vance, won his race to represent Ohio in the Senate. Despite once describing Mr Trump as ""reprehensible"", he was later backed by the former president and flatly denied the result of the 2020 election. While he won with 53% of the vote, Mr Vance garnered 380,000 fewer votes than Republican governor Mike DeWine, out of a total of about 4 million cast in Ohio. Among the most staunch election deniers were seven candidates from the America First Secretary of State Coalition, a group that explicitly campaigned on the issue. The group's founders also have links to QAnon - a wide-ranging, unfounded conspiracy theory that says that President Trump is waging a secret war against elite Satan-worshipping paedophiles. Ms Lake was one of the members, but only one of the seven won - Diego Morales will be the secretary of state in Indiana. At least 126 Republicans elected in the US midterms have publicly denied the result of the 2020 presidential election, according to a BBC analysis. They include Marjorie Taylor Greene, the controversial politician whose personal Twitter account was suspended for breaking rules on coronavirus misinformation, and JD Vance, a former Trump critic and successful author. Donald Trump continues to insist, falsely, that he won the 2020 election. Before the midterms, we analysed and independently verified data published by the website FiveThirtyEight, which tracked statements from all candidates running for the Senate, House of Representatives and state governor positions. We found 178 of them - all Republicans - had fully and publicly denied the result of the presidential race supporting Trump's false claim that he beat Joe Biden. That accounted for more than one third of all Republicans standing in the races. Our findings so far, one week after election day: There are four House races involving election deniers yet to be called: Alaska's sole seat, where Sarah Palin is the Republican nominee, Lauren Boebert's race in Colorado, and two districts in California. Many candidates were nominated in solid Republican voting areas, so victory was more or less guaranteed, but some surprising election night stories have emerged. Bo Hines, a 27-year-old former college football star running for Congress in North Carolina was favoured to win, and endorsed by Donald Trump as a ""proven winner on and off the field"". It wasn't to be though: he lost to Democrat Wiley Nickel, a lawyer who worked in the Barack Obama administration. Lauren Boebert once shared QAnon conspiracies on her social media accounts and was known for her staunch pro-gun views, including a pledge to carry a handgun with her in Washington DC when she was first elected to Congress. She holds a narrow lead in a district that favours Republicans, and her race against Democrat opponent Adam Frisch appears to be headed towards a recount. In Arizona, former local news anchor Kari Lake was projected to lose her race for governor. Ms Lake's social media pages include frequent allegations about rigged elections. In October 2021, she tweeted: ""Voter fraud will herald the END of the Republic."" During the campaign, she was challenged by the BBC about her claims that there were hundreds of thousands of phoney ballots in 2020. She said - without providing proof - that the government had withheld evidence. There were problems with voting tabulation machines early on election day in Maricopa County, Arizona, home to the state's largest city Phoenix. About a fifth of machines in the county were failing to read ballot printouts which led to delays, although the problem was later resolved and election officials said there were backup systems in place to ensure votes were counted. After news organisations called the governor's race for her opponent, Democrat Katie Hobbs, Ms Lake tweeted late Monday: ""Arizonans know BS when they see it."" She did not elaborate further. Some election deniers exceeded expectations. George Santos, a New York Republican who attended the 6 January riot at the US Capitol but later called the event ""a dark day in America"", was considered unlikely to win, but secured a seat in the House. But overall, many of the most devoted election deniers underperformed or lost outright. Author of memoir-turned-film Hillbilly Elegy, JD Vance, won his race to represent Ohio in the Senate. Despite once describing Mr Trump as ""reprehensible"", he was later backed by the former president and flatly denied the result of the 2020 election. While he won with 53% of the vote, Mr Vance garnered 380,000 fewer votes than Republican governor Mike DeWine, out of a total of about 4 million cast in Ohio. Among the most staunch election deniers were seven candidates from the America First Secretary of State Coalition, a group that explicitly campaigned on the issue. The group's founders also have links to QAnon - a wide-ranging, unfounded conspiracy theory that says that President Trump is waging a secret war against elite Satan-worshipping paedophiles. Ms Lake was one of the members, but only one of the seven won - Diego Morales will be the secretary of state in Indiana."
Brazil election: Accusations and misinformation on the campaign trail,"Claims about corruption, Covid, deforestation, and even cannibalism grabbed attention in the build-up to Brazil's presidential election. Luiz InÃ¡cio Lula da Silva defeated current President Jair Bolsonaro in a second-round run-off on Sunday, and will take office on 1 January. During the campaign, we looked at some of the main lines of attack for both candidates. Bolsonaro and Lula, who are both Catholic, sought support among evangelical Christian voters, who make up almost a third of Brazil's population. However, their strategies were rife with religious disinformation. One example of this is a video shared by two of Bolsonaro's sons and other politicians, in which a social influencer who describes himself as Satanist, declares his support for Lula. The video went viral, alongside messages saying that Brazil would be running a ""spiritual risk"" if Lula was elected - despite the influencer having no relationship with the former president nor any influence on his policies. Lula's campaign team released a statement rejecting any involvement with devil worship and the video was banned by the Electoral Court, the body overseeing the vote. Meanwhile, Lula's campaign team highlighted a 2016 New York Times interview with Bolsonaro in which he says he visited an indigenous community in Brazil that was allegedly cooking a dead person, and that he had asked to watch. To see it, he recalls in the interview, he was told he'd have to join in the meal. ""I would eat it,"" he said. ""I'd have no problems in eating the indigenous person."" But he added that his entourage did not want to go, and so he didn't, either. Lula's campaign produced a video featuring the 2016 interview, saying: ""It's monstrous. Bolsonaro reveals that he would eat human flesh."" Bolsonaro complained to the Electoral Court, which then banned Lula's campaign video, saying that it had portrayed the interview out of context. Leaders of the Yanomami people, the indigenous group Bolsonaro was referencing, reject his claim and say that they do not practise cannibalism. The rainforest plays a vital role in absorbing harmful carbon dioxide that would otherwise escape into the atmosphere, and about 60% of the Amazon is in Brazil. Both Bolsonaro and Lula claim to have a better record at protecting it. During a live presidential debate in October, Lula said: ""In our government, [we had] the lowest deforestation in the Amazon, and in yours it is the highest every year."" Bolsonaro replied: ""Google 'deforestation from 2003 to 2006', in the four years of Lula's government. Then search for 'deforestation from 2019 to 2022'. ""During your government, twice as much was deforested as in mine,"" he added. It's true the amount of ??deforestation during the first three years of Bolsonaro's government is significantly less than in the same period under Lula - about 34,000km squared, compared with 71,000km, according the National Institute for Space Research (Inpe). But after Lula's first two years in office, the rate of deforestation dropped significantly, and by the time he left office in January 2011, it had reached historic lows. Under Bolsonaro, the rate of deforestation has gone up each year, continuing a trend that began a couple of years before he took office in January 2019. He has implemented policies that critics say roll back crucial safeguards, and prosecutions against illegal logging have dropped during his time in office. Corruption was a central theme in the campaign. Bolsonaro highlighted a major corruption scandal, which began during Lula's previous period as president, when billions of dollars were stolen in bribes and overpriced oil contracts linked to the state-run oil company, Petrobras. Lula himself was found guilty of involvement and in 2017 he was sent to prison. His conviction was annulled last year, enabling him to stand in this election. For his part, Lula pointed the finger at Bolsonaro for enabling corruption, and accusing him of losing control of the country's finances. By this he's referring to a ""secret budget"" included in the budget law passed in 2019, allowing for public funds to be spent by federal lawmakers with limited oversight. Bolsonaro denies having approved the scheme. ""I vetoed it and [Congress] overrode the veto,"" he said during a debate on October 16. That's not true. At first, in November 2019, Bolsonaro did veto the new mechanism included in the budget. One month later, however, the presidency itself sent Congress a new proposed bill, including the ""secret"" mechanism within it, and it was approved. ""It's an institutionalisation of corruption, a way of buying Congress using the country's budget,"" says Bruno BrandÃ£o, executive director of the Brazilian national chapter of Transparency International. He points out that press and police investigations have shown there are widespread fraud schemes involved in the application of these public funds. Bolsonaro has been accused of spreading misinformation about Covid vaccines, and has refused to get the jab himself. Lula has heavily criticised Bolsonaro's efforts to control the pandemic. During the campaign, he highlighted the country's death toll, saying: ""Brazil has 3% of the world population, and Brazil has had 11% of deaths from the pandemic in the world."" It's correct that Brazil has accounted for almost 11% of the world's official Covid deaths, with more than 687,000 recorded, according to Johns Hopkins University. That's the second-highest official death toll in the world after the United States. It also has one of the highest recorded global death tolls as a proportion of its population - although not as high as neighbouring Peru. But official figures may not fully reflect the true number of dead in many countries, as testing is not always available. Lula also questioned the amount of time it took to roll out Covid vaccines. Defending his government's record, President Bolsonaro said: ""We have purchased over 500 million doses of vaccineÂ and Brazil is one of the most vaccinated countries in the world and in the fastest time."" Bolsonaro's government has now purchased about 750 million doses, but its first orders went in much later than those of some other countries. This meant vaccine delivery was delayed, and Brazil's rollout initially lagged behind many other countries in Latin America and around the world. Brazil has now administered more than 220 doses per 100 people, but this is still below the levels of several other countries in the region, including Argentina, Chile and Peru. Graphics produced by Sarah Habershon. Read more from Reality Check Send us your questions"
Brazil election: Do voting machines lead to fraud?,"President Jair Bolsonaro has said that the voting machines used across Brazil are open to fraud - with echoes of Donald Trump's rhetoric around the 2020 US election. Brazil's presidential election is going to a second round, after voting on 2 October finished with no candidate achieving 50% of votes needed to prevent a run-off. ""The system is completely vulnerable,"" claimed President Bolsonaro while campaigning, without providing evidence. In this election voting is being done electronically, as has been the case since 1996. Each candidate has a number, and on election day voters type the number of their chosen candidate into a voting machine at polling stations across the country. The votes are then counted by the machines, and the totals are sent electronically to a central office. Votes from across the country are tallied up and a final result is announced, usually within hours of polls closing. Each machine also prints out a paper copy of the totals for each candidate. When polls close they are displayed publicly at polling sites, and each machine's votes can be compared with the total recorded by the electoral court. This year, for the first time, these paper copies were published online on the day of the first round vote. President Bolsonaro has said: ""We cannot have dubious elections in 2022. Public counting of votes is needed."" He's been making similar claims for years. After winning the 2018 presidential election in a run-off, he claimed voting fraud robbed him of an outright victory in the first round, which he won by a 17 point margin with 46% of the vote. Subsequent studies of the 2018 election didn't find any evidence of voting irregularities. Brazilians vote electronically, so there are no paper copies of individual ballots. This has been highlighted by President Bolsonaro as a security issue, and he has called for ""printable and auditable"" paper ballots to safeguard the electronic system. ""It's impossible to audit elections in Brazil,"" President Bolsonaro declared in July during a meeting with ambassadors. He says it is ""easy to rig"" electronic voting machines by altering their source code, the internal commands within a machine's software. It's not true to say you can't audit the vote in Brazil. The machines can retrieve votes cast for an electronic recount. Such an audit took place in the 2014 presidential election, which concluded that there was no foul play. ""There is no reasonable proof of fraud going on in the past, at least in big audits that have been done,"" says Prof Marcos Simplicio, who took part in the auditing of the 2014 election. The Supreme Electoral Court, the body that oversees Brazil's election, says the system has a series of procedures in place to secure the vote. For example, a number of voting machines are selected at random to be removed from polling sites for a test vote alongside the actual vote on election day. These are checked to be working correctly by entering test votes for each of the candidates in a process witnessed by party representatives. ""The vote placed in the electronic ballot box is secured by several mechanisms. The software goes through several tests, including tests with experts and outside investigators who try to break its security,"" says Julio Valente, the Information Technology Secretary of Brazil's electoral court. Before each election the court invites researchers and software experts to look for vulnerabilities in the voting system. This year, more than 20 experts tried to penetrate the system but failed to do so. However, over the years experts have said improvements could be made. ""The security of the Brazilian election system relies heavily on the system's software, which has been the main point of criticism from the academic community since the 90s,"" says Prof Paulo Matias, a computer security specialist at the University of SÃ£o Carlos. President Bolsonaro has also claimed votes are counted in a ""secret room"" out of public view at the central electoral office. The votes are counted by computers that are located in a secure room but party representatives can monitor the process. ""The view of most of the technical community is that fraud is really hard in the current system. The system can be improved and should be, but that doesn't mean there's been fraud,"" says Prof Simplicio. Allegations that the system is unreliable have spread across social media - often in groups backing the president. Just a quarter of Bolsonaro supporters say they trust the electoral system ""a lot"", and almost a third don't trust it ""at all"" according to a recent survey. Videos containing misleading information from previous elections are used to cast doubt on the system.  Two videos that were spread following the 2018 election showed voters entering Bolsonaro's number and receiving the message ""null vote"". However, Brazilians don't only vote for the president. Votes are also cast for other political representatives such as senators and governors, using unique numbers to identify the candidates. A closer look at the two videos shows that Bolsonaro's number had been pressed when the voter was asked to choose a  governor. When there is no candidate with that number, a ""null vote"" message is displayed. Voters can still correct the mistake and press the right number before confirming their vote. Another video allegedly showed a man pressing Bolsonaro's number and the machine showing his rival's picture instead. At the time, the electoral court debunked the video, saying it had been edited. The video didn't show the voting machine buttons and screen at the same time, which meant different images could've been stitched together. Additional reporting by Mariana Sanches Read more from Reality Check Send us your questions"
Brazil senators back criminal charges against Bolsonaro over Covid handling,"Brazilian senators have voted to recommend charging President Jair Bolsonaro over his handling of the devastating Covid pandemic. A Senate panel backed a report calling for charges against Mr Bolsonaro including crimes against humanity, after 600,000 deaths from coronavirus. The report has been handed to the chief prosecutor, a Bolsonaro appointee. The president has maintained he is ""guilty of absolutely nothing"" but the crisis has dented his popularity. Brazil's death toll is second only to that of the United States. There is no guarantee this vote will lead to actual criminal charges, as the report's recommendations must now be assessed by Prosecutor-General Augusto Aras, who is expected to protect the president. The report alleges that Mr Bolsonaro's government pursued a policy of allowing coronavirus to rip through the country in the hope of achieving herd immunity. It describes the president as ""the main person responsible for the errors committed by the federal government during the pandemic"". The report's lead author, centrist Senator Renan Calheiros, called for the panel's recommendation to charge President Bolsonaro with crimes against humanity to be submitted to the International Criminal Court (ICC). Brazil is a party to the Rome Statute, which created the ICC, so the international court could take up the case. But a referral would only be a first step in a lengthy process in which it would be up to the ICC to determine the merits of the case and whether to take it forward. In addition to crimes against humanity, the Senate committee has recommended eight further charges be brought against Mr Bolsonaro in Brazilian courts, including incitement to crime, falsification of documents and the violation of social rights. Mr Bolsonaro is also accused of misusing public funds and spreading fake news about the pandemic. The 1,300-page report also recommended bringing charges against two corporations and 77 other people, including three of the president's adult sons. Following the announcement, Senator Calheiros said that the ""chaos of Jair Bolsonaro's government will enter history as the lowest level of human destitution"". The vote concludes a six-month inquiry which has highlighted scandals and corruption inside the government. The Senate's recommendation is expected to be delivered to the prosecutor-general on Wednesday morning. His office said it would be carefully reviewed as soon as it was received, the Associated Press reports. Throughout the process, Mr Bolsonaro has insisted that his government ""did the right thing from the first moment"" of the pandemic and his allies have been quick to dismiss Tuesday's recommendations as being driven entirely by ""political and electoral"" motivations. ""It is a totally political report, without any legal basis,"" said Flavio Bolsonaro, one of the president's sons accused in the report. ""The intent of some senators on the investigative committee is to cause the maximum amount of wear and tear on the president."" Former US President Donald Trump, a Bolsonaro ally, said in a statement he endorsed the Brazilian president because ""he fights hard for, and loves, the people of Brazil"". Today marked the end of a long process. Six months of hearings, scandals uncovered, a light shone on a government accused of recklessness. Just before the vote, leading senators delivered impassioned speeches. Senator Calheiros said the inquiry had slowed down the clock of death in Brazil. The inquiry's vice-president, Randolfe Rodrigues, underlined how important the process had been to put pressure on the government and speed up vaccinations, and he paid tribute to those on the front line of containing the pandemic. But for many, it's too little, too late - the families of the dead will be wanting to know where this inquiry will lead. Will Mr Bolsonaro have to stand up in court to defend his actions? The inquiry's president, Omar Aziz, said the federal prosecutor had a duty to investigate the evidence gathered these past few months - but not everyone thinks justice will be done. In March, Mr Bolsonaro caused outrage when he told Brazilians to ""stop whining"" about Covid, a day after the country saw a record rise in deaths over a 24-hour period. He has continued to spread misinformation on social media and, on Monday, Facebook removed a video in which the president falsely claimed a link between Covid-19 vaccines and Aids. YouTube blocked the video and suspended Mr Bolsonaro's channel for a week. Brazil, a country of 208 million people, has recorded at least 606,000 deaths and 21.7 million cases of infection, Johns Hopkins University reports."
Brazil: The code word used to invite protesters to a riot,"On Sunday, the world watched, stunned, as thousands of supporters of Jair Bolsonaro stormed Brazil's Congress, Supreme Court and presidential palace. In echoes of the attacks on the United States Capitol almost exactly two years ago, they tore through buildings shouting the false accusation that the presidential election had been rigged, and that Bolsonaro was the true winner. But how was a violent protest organised in plain sight of security services and social media moderators? The BBC's Global Disinformation Team has been investigating. In recent months, Bolsonaro's supporters have been spreading conspiracy theories online, pushing the idea that the former president was the real winner of the election. The BBC has found no evidence for these claims. In the days leading up to the attack on Brazil's Congress, the rhetoric intensified and included a series of thinly veiled metaphors. The main one was an invitation for Brazilians to attend 'Selma's Party'. 'Selma' is a play on the word 'selva', which means jungle in Portuguese, and is also used by the Brazilian military as a greeting or war cry. Four days before the riot, a video about 'Selma's Party' went viral in groups on the social media app Telegram. In it, a man describes the 'ingredients' for the 'party', including a brand of Brazilian sugar called Union, and five large heads of corn. Corn is another wordplay. 'Milho' means corn and 'milhÃ£o' means a million. The suggestion is that five million people were invited to attend the protest. Other posts on social media offered free transportation from different parts of the country to BrasÃ­lia. They advertised ""free buses"" with ""everything for free: water, coffee, lunch, dinner"". The party metaphor continued on the day of the protests on Twitter, where a video was posted showing hundreds of people marching with a long yellow and green banner in Brasilia. The caption reads: ""The first guests are arrivingÂ As soon as everyone gets here, the cake can be cut."" Most social media platforms prohibit and take down calls to violence. It's likely metaphors like 'Selma's Party' were used to evade content moderators. In a TikTok video that has since been taken down, a woman explicitly says that she's no longer talking about politics on TikTok because she doesn't want her account to be removed. She then proceeds to talk about 'Selma's Party'. Elsewhere, people have been posting about other 'parties', including one for Selma's cousin 'Telma', in SÃ£o Paolo, and her sister 'Velma', in Rio de Janeiro. For now, these events have not gained much traction. According to analysis by Arcelino Neto from the University of SÃ£o Paolo, the words Festa Da Selma first appeared on Twitter on 5 January. They have since been used by more than 10,000 accounts in tweets that were shared more than 53,000 times. The hashtag #festadaselma was used to 'invite' people to turn up at a the complex of government buildings known as ""PraÃ§a dos TrÃªs Poderes"" (Three Powers Square) outside Congress. On Telegram, the rhetoric was more explicit. Bolsonaro fans asked ""hackers and IT experts"" to ""invade all government systems"" and armed men to ""protect the patriots"". They also invited reservists from the ""military and police"" to ""share tactic experience and lead the seizure of Brasilia and its phoney government"". Brazilian authorities are under scrutiny for an alleged lack of plans to avoid the crisis. ""The coup is not by president Bolsonaro. The coup is not by the Armed Forces"", reads another message shared days before the invasion. ""The coup is by the Brazilian people and will be fatal"". Emillie de Keulenaar, a researcher from the University of Groningen who monitors pro-Bolsonaro groups on Telegram, has been looking into the language used. She says that, after Lula's inauguration on 1 January, small private Telegram groups began to appear, organising events around different regions of Brazil. On 6 January, she says the language used became ""increasingly aggressive"", inciting ""civil war"". That's when metaphors began to appear. She says Bolsonaro's fans wanted to evade ""infiltration by leftists who they think will confuse their plans"". ""They used 'Festa da Selma' as a codename for the assault, but they also call it 'popular intervention', 'people taking power', or 'general strike'."" Social media's role in the riots is under scrutiny. Since Elon Musk took over, Twitter has laid off staff including those in Brazil whose role was to tackle misinformation around the election. Twitter and Musk have repeatedly said they are addressing the most harmful content on the site. It's not the first time that misinformation online has fuelled a physical assault on democracy. The former Chief Executive of Twitter, Jack Dorsey, admitted to a hearing into the storming of the U.S. Capitol in 2021, that misinformation on social sites played a role in inciting the violence. Meta, which owns Facebook, and Google, YouTube's parent company have said they are removing content that praises or supports anti-democratic demonstrators in Brazil. Edited by Rebecca Skippage On Sunday, the world watched, stunned, as thousands of supporters of Jair Bolsonaro stormed Brazil's Congress, Supreme Court and presidential palace. In echoes of the attacks on the United States Capitol almost exactly two years ago, they tore through buildings shouting the false accusation that the presidential election had been rigged, and that Bolsonaro was the true winner. But how was a violent protest organised in plain sight of security services and social media moderators? The BBC's Global Disinformation Team has been investigating. In recent months, Bolsonaro's supporters have been spreading conspiracy theories online, pushing the idea that the former president was the real winner of the election. The BBC has found no evidence for these claims. In the days leading up to the attack on Brazil's Congress, the rhetoric intensified and included a series of thinly veiled metaphors. The main one was an invitation for Brazilians to attend 'Selma's Party'. 'Selma' is a play on the word 'selva', which means jungle in Portuguese, and is also used by the Brazilian military as a greeting or war cry. Four days before the riot, a video about 'Selma's Party' went viral in groups on the social media app Telegram. In it, a man describes the 'ingredients' for the 'party', including a brand of Brazilian sugar called Union, and five large heads of corn. Corn is another wordplay. 'Milho' means corn and 'milhÃ£o' means a million. The suggestion is that five million people were invited to attend the protest. Other posts on social media offered free transportation from different parts of the country to BrasÃ­lia. They advertised ""free buses"" with ""everything for free: water, coffee, lunch, dinner"". The party metaphor continued on the day of the protests on Twitter, where a video was posted showing hundreds of people marching with a long yellow and green banner in Brasilia. The caption reads: ""The first guests are arrivingÂ As soon as everyone gets here, the cake can be cut."" Most social media platforms prohibit and take down calls to violence. It's likely metaphors like 'Selma's Party' were used to evade content moderators. In a TikTok video that has since been taken down, a woman explicitly says that she's no longer talking about politics on TikTok because she doesn't want her account to be removed. She then proceeds to talk about 'Selma's Party'. Elsewhere, people have been posting about other 'parties', including one for Selma's cousin 'Telma', in SÃ£o Paolo, and her sister 'Velma', in Rio de Janeiro. For now, these events have not gained much traction. According to analysis by Arcelino Neto from the University of SÃ£o Paolo, the words Festa Da Selma first appeared on Twitter on 5 January. They have since been used by more than 10,000 accounts in tweets that were shared more than 53,000 times. The hashtag #festadaselma was used to 'invite' people to turn up at a the complex of government buildings known as ""PraÃ§a dos TrÃªs Poderes"" (Three Powers Square) outside Congress. On Telegram, the rhetoric was more explicit. Bolsonaro fans asked ""hackers and IT experts"" to ""invade all government systems"" and armed men to ""protect the patriots"". They also invited reservists from the ""military and police"" to ""share tactic experience and lead the seizure of Brasilia and its phoney government"". Brazilian authorities are under scrutiny for an alleged lack of plans to avoid the crisis. ""The coup is not by president Bolsonaro. The coup is not by the Armed Forces"", reads another message shared days before the invasion. ""The coup is by the Brazilian people and will be fatal"". Emillie de Keulenaar, a researcher from the University of Groningen who monitors pro-Bolsonaro groups on Telegram, has been looking into the language used. She says that, after Lula's inauguration on 1 January, small private Telegram groups began to appear, organising events around different regions of Brazil. On 6 January, she says the language used became ""increasingly aggressive"", inciting ""civil war"". That's when metaphors began to appear. She says Bolsonaro's fans wanted to evade ""infiltration by leftists who they think will confuse their plans"". ""They used 'Festa da Selma' as a codename for the assault, but they also call it 'popular intervention', 'people taking power', or 'general strike'."" Social media's role in the riots is under scrutiny. Since Elon Musk took over, Twitter has laid off staff including those in Brazil whose role was to tackle misinformation around the election. Twitter and Musk have repeatedly said they are addressing the most harmful content on the site. It's not the first time that misinformation online has fuelled a physical assault on democracy. The former Chief Executive of Twitter, Jack Dorsey, admitted to a hearing into the storming of the U.S. Capitol in 2021, that misinformation on social sites played a role in inciting the violence. Meta, which owns Facebook, and Google, YouTube's parent company have said they are removing content that praises or supports anti-democratic demonstrators in Brazil. Edited by Rebecca Skippage"
British Asian celebrities unite for video to dispel Covid vaccine myths,"Celebrities including comedians Romesh Ranganathan and Meera Syal and cricketer Moeen Ali have made a video urging people to get the Covid vaccine. The video was co-ordinated by Citizen Khan creator Adil Ray, who said he wanted to dispel vaccination myths for those from ethnic minority communities. Mayor of London Sadiq Khan and former Conservative Party Chairman Baroness Warsi are among the others taking part. ""We all just feel we needed to do something,"" Ray told the BBC. Fake news about the vaccine, particularly in the South Asian community, has led to concerns about uptake. Ray appears in the five-minute video alongside stars like former Coronation Street actress Shobna Gulati, who tells viewers: ""We will find our way through this. And we will be united once again with our friends and our families. All we have to do is take the vaccination."" Somali-born British journalist Rageh Omaar and his ITV colleague Ranvir Singh join comedians like Sanjeev Bhaskar, Asim Chaudhry and Ranganathan to debunk common vaccine misinformation and misconceptions. Ranganathan says: ""There's no chip or tracker in the vaccine to keep watching where you go. Your mobile phone actually does a much better job of that."" After posting the video, Ray told BBC Radio Leicester: ""For the British Asian and black communities, at the very beginning of the pandemic we were told they were perhaps the most vulnerable, that there was a disproportionate number of cases and even deaths. ""Even now there are a disproportionate number of deaths. But nothing was really done about it and that was really quite confusing for a lot of the community. So we felt that we've got to try and take the lead a little bit here and dispel some of these myths."" He added: ""This was recorded entirely independently from the government - the only thing we did do was we went to the NHS website for the correct medical guidance."" With the UK aiming to offer Covid vaccinations to every adult by autumn, vaccine minister Nadhim Zahawi said confidence in the vaccines was high in the UK, with 85% saying they would accept the jab. But he said that those who were hesitant ""skew heavily"" towards black, Asian and minority ethnic communities. The UK is recording the ethnicity and occupations of people who receive the vaccine and figures would be published soon, Mr Zahawi added. Last month, a poll commissioned by the Royal Society of Public Health suggested 57% of black, Asian and minority ethnic people would be happy to have the coronavirus vaccine, compared with 79% of white people. Dr Harpreet Sood, who is leading an NHS anti-disinformation drive, recently said fake news was likely to be causing some people from the UK's South Asian communities to reject the vaccine. Such warnings have led the Mosques and Imams National Advisory Board to urge places of worship and community hubs to be used as vaccination centres in an attempt to inspire confidence. The board's chairman, Imam Qari Asim, said: ""As an imam, my message is simple - do not trust 'fake news', verify before you amplify."" Many mosques are using their Friday sermons to urge people to have the jab, while some imams are sharing photos of themselves getting the jab on social media. Meanwhile, the government has announced Â£23m funding for a network of ""community champions"" to spread accurate information and provide support for people in at-risk groups including older people, disabled people and ethnic minorities. On Monday, Communities Secretary Robert Jenrick visited the UK's first vaccination centre to be opened in a mosque, at Al-Abbas Islamic Centre in Birmingham. ""It is absolutely brilliant to see faith communities like this stepping up and playing their part in the vaccine programme,"" Mr Jenrick said. ""We have to build trust, ensure that we counter misinformation and ensure that everyone, regardless of their faith, regardless of what community they're from, gets access to the programme."" Follow us on Facebook or on Twitter @BBCNewsEnts. If you have a story suggestion email entertainment.news@bbc.co.uk."
Bucha killings: Satellite image of bodies site contradicts Russian claims,"A satellite image of Bucha in Ukraine appears to show bodies lying in the street nearly two weeks before the Russians left the town. The image from 19 March, first reported by the New York Times and confirmed by the BBC, directly contradicts Russian Foreign Minister Sergei Lavrov's claim that footage of bodies in Bucha, that has emerged in recent days, was ""staged"" after the Russians withdrew. The satellite image shows objects that appear to be bodies in the exact locations where they were subsequently found by Ukrainian forces when they regained control of the town north of Kyiv. Along another section of the road, the image shows what appear to be more bodies on the ground. There is an earlier satellite image available from Maxar on 11 March. It appears to show bodies in the same locations but is less clear than the one on 19 March. Russia has made a series of unfounded claims relating to images from Bucha - here's what the evidence tells us. Warning: This piece contains graphic images which some may find upsetting. Russia says its forces withdrew from Bucha on 30 March. The Ukrainians say this happened in the early hours of 31 March. On 1 April, footage was posted filmed from a car driving through the town which showed bodies on either side of a road. Russia has claimed it shows ""fake dead bodies"" and was ""staged"" after its troops left the town. We compared the car footage with the satellite imagery of Bucha from 19 March (when the Russians were in control). In both, there are bodies lying in the same parts of the road (marked in red) and near vehicles (marked in yellow). Pro-Russian social media accounts also circulated a slowed-down version of the footage on the same road, claiming that the arm on one of the bodies moved. The video is grainy but a closer analysis of it shows that what is claimed to be a moving arm, is actually a mark in the bottom right corner of the vehicle's windscreen. Contains disturbing scenes. We've circled this mark - which looks like a raindrop or a speck of dirt - along with similar marks visible on the windscreen earlier in the video. Another Russian claim focuses on a different part of the footage. The car passes another body, lying next to a pavement with red and yellow stones and shattered brown fencing. As it drives on, the body can be seen briefly in the right-hand wing mirror. Pro-Russian accounts claim the body ""sits up"". But a slowed-down version of the video shows the wing mirror is clearly distorting the reflection of the body, as well as houses in the background. The same effect can be seen in videos of similar wing mirrors posted on the internet. The BBC has matched both bodies from the video (posted on 2 April) with high-resolution photos provided by Getty Images and AFP on 3 April. In the video, the first body is lying on their back near a white and yellow kerb. The pavement to the right is part asphalt and part grass. A silver car can be seen on the pavement with its boot open in front of a white fence. The same car, kerb, pavement and fence are visible in the Getty/AFP image. The second body has a black jacket and what appears to be a bloodied tourniquet or bandage on the right arm. They are lying on their side next to a red and yellow pavement, in front of a shattered brown fence. The black jacket, tourniquet/bandage, pavement and fence all match the photo of the body published by Getty/AFP. A pro-Russian social media account, Rybar, says the Maxar satellite images shown in this article were not taken on 19 March - but on 1 April,  the day after Russian forces departed. Russia has made unfounded claims the killings were carried out by Ukrainians, but if the bodies were there on 19 March as the satellite images show, that cannot be the case.  At that time Russia controlled the area. Rybar says its conclusions are based on an analysis of shadows from images downloaded from the Maxar database, revealing the date and time at which the photograph was taken. We contacted Maxar, who said it appeared Rybar had used the company's image search tools wrongly, and that if correctly used, the images can clearly be shown to be from 19 March. The BBC has also checked this analysis, comparing images from three separate companies (PlanetLab, Apollo Mapping and Maxar) taken from the available satellite imagery over this period. We've determined that the lengths of the shadows (and therefore the angle of the sun) is consistent with the satellite images having been taken on the morning of 19 March and not on 1 April. Russia's Ministry of Foreign Affairs tweeted: ""It is of particular worry that all the bodies of the people whose images have been published by the Kiev regime are not stiffened after at least four days."" According to the Ukrainian military, the Russians left in the early hours of 31 March. The Russians say they left on 30 March. In the hours after death, bodies go through a process called rigor mortis where muscles contract and stiffen. We asked a forensic pathologist for their opinion on whether a body would be expected to be ""stiffened"" after four days. One who has worked in places including Kosovo and Rwanda on war crimes investigations, who did not want to be named, told the BBC that by four days rigor mortis has ""usually subsided"". The Russian tweet also claimed that the bodies ""have no typical cadaver stains"". It's not clear what this means but the pathologist said the appearance of someone who has died from a gunshot wound or other act of violence will vary widely depending on the weapon used, from what distance they were shot and so on. There isn't always a lot of visible blood as it may pool underneath people or soak into heavy clothing, especially if someone is dressed for cold weather. The tweet could be referring to the fact the blood within your body pools downwards after death as it stops circulating around the body, which can lead the skin to turn reddish or purple. But if someone is lying down, the site of this blood pooling and discolouration may well not be visible from an image alone. The Russian defence ministry claimed that while Bucha was under Russian control ""not a single local resident has suffered from any violent action"". This claim, however, contradicts numerous eyewitness accounts from residents. A local teacher told Human Rights Watch on 4 March that Russian forces had rounded up five men and summarily executed one of them. Local residents who spoke to the Russian investigative website The Insider painted a similar picture. ""These were horrific days. When neither your courtyard, your house or even your life belongs to you. There is no electricity, water, gas. It's forbidden to leave the house, if you leave - you get shot,"" local resident Kristina told The Insider. Locals told the BBC that the Russians had systematically broken down doors to loot flats, and, while soldiers stole valuables and food, residents were forced to sit in the cellar. This report was originally published on 5 April and has since been updated. Reporting by: Jake Horton, Shayan Sardarizadeh, Rachel Schraer, Olga Robinson, Alistair Coleman, Daniele Palumbo and Joshua Cheetham. Video production by: Sarah Glatte and Jacqueline Galvin. Read more from Reality Check Send us your questions"
Buffalo shooting: How far-right killers are radicalised online,"The racially motivated attack that left 10 people dead at a New York state supermarket is just the latest example of violence inspired by online extremism. The shooting spree in Buffalo followed the exact blueprint of similar attacks around the US and the world. It's also happened in Pittsburgh, Christchurch, Poway, El Paso and Halle - internet-radicalised racist white men deliberately targeting members of a specific community, leaving extensive trails chronicling their extreme views online. How did the perpetrators get immersed in extremist online subcultures? And what can be done to tackle the violence that springs from these groups? Like others before him, Payton Gendron, 18, the main suspect behind the Buffalo attack, posted a lengthy so-called ""manifesto"" explaining his motives and beliefs. Some of the text is copied and pasted from similar racist manifestos written by 2019 Christchurch mass murderer Brenton Tarrant and other violent assailants. Gendron cites Tarrant as his main inspiration and gateway into the world of online extremism and white supremacy. All of the recent far-right assailants cite the internet as the starting place for their journeys towards radicalisation. Their manifestos and writings show they were well-versed in the online subcultures, conspiracy theories and memes, and used those to deliberately ""troll"" or misinform. Notably, all of them are committed anti-Semites and Holocaust deniers, and cite a wide range of conspiracy theories. Nearly all of them reference ""white genocide"" and ""white replacement"" conspiracy theories, as well as their resentment of immigrants and minority groups, as the bedrock of their belief system and the main motivation for their violence. ""The idea of a 'white genocide' creates a sense of urgency and of the need for immediate action,"" says Rajan Basra, a researcher from the International Centre for the Study of Radicalisation (ICSR) at King's College London. ""For white nationalists this can be a powerful motivator, and time and time again they have violently acted on it."" The Buffalo attacker also posted nearly 700 pages of his private diary, dating back seven months - copies of which the BBC has read. The logs are a window into the mind of a clearly troubled young man who regularly spoke about his addiction to gaming and surfing extreme online circles. He carried out extensive research and several reconnaissance journeys to the grocery store in Buffalo to carefully plan the manner and timing of his attack, and practised mock versions. He briefly mentions getting into trouble with authorities a year earlier after writing something that alarmed them. There are brief moments of doubt, as he wonders whether he will be able to carry out a mass shooting without ""messing up"". There are also graphic details of an act of animal cruelty and suicidal thoughts for failing to carry out the attack on the date he'd initially planned. Packed full of racist and anti-Semitic conspiracy theories, memes, hoaxes and and in-jokes, his manifesto is also clearly influenced by the message board 4chan, one of the biggest and most controversial hubs of internet subculture. It is the birthplace of many famous online memes, harassment and trolling campaigns, as well as social, political and conspiratorial movements. Gendron references a 4chan board devoted to guns, and says he was radicalised by the /pol/ or ""politically incorrect"" board. He also mentions other extreme online spaces he visited, including the neo-Nazi website The Daily Stormer. The attacker also live-streamed his killings on the video streaming platform Twitch with a camera mounted on his helmet. Like Tarrant, he wrote white supremacist slogans and racial slurs on his firearm. The stream was only watched by 22 people and Twitch took it down within minutes. However, copies were in wide circulation online within hours, drawing millions of views on Facebook and other platforms. The combination of an online manifesto and video livestream is done to generate maximum media impact and spread the killer's views as far and wide as possible. Copies of the video and manifesto will probably be shared online for years to come, for propaganda purposes and as a recruitment tool. And although mainstream social networks will remove copies, there are many fringe websites where the video can be easily found. Eliminating content from the internet is more or less impossible. For instance, after the violence in the US city of Charlottesville in 2017, the neo-Nazi Daily Stormer came under pressure from hosting and web protection companies. But with enough effort, that site can still be found online, and the Buffalo attacker claims to have been a regular visitor. And as previously seen with fringe platforms like 8chan - where the manifestos of three killers appeared in quick succession in 2019 - even if access to one website is cut off, new ones will pop up in no time. ""On the internet, there will always be a home - however niche or obscure - for extremist content,"" says Mr Basra of the ISCR. The rambling documents aim to inspire the next racist shooter, just as Gendron himself took inspiration from Brenton Tarrant, and Tarrant from Norwegian neo-Nazi murderer Anders Breivik. ""People once shunted to the fringes can form whole cultic [online] communities around the globe,"" says author and journalist David Neiwert, who has been writing about far-right extremism for decades. ""One of the results of this is that far-right domestic terrorism has taken on a chain or serial aspect: one act of violence inspiring the next inspiring the next,"" he says. In response to the rise of home-grown terrorist attacks, many governments have attempted to draw up counter-terrorism plans to prevent such tragedies. The UK government's Prevent scheme is one example. Although criticised for failing to deter some people known to authorities, like Ali Harbi Ali, the Islamist extremist who killed MP Sir David Amess, the government claims it has stopped hundreds of would-be terrorists. No similar scheme exists in the US. In June 2021, the White House released a national plan for countering domestic terrorism. The plan focuses mostly on law enforcement efforts and includes $77 million in grants for local police forces. Mr Neiwert says that while US law enforcement is empowered to become engaged when criminal activities are being discussed online, there's little they can do until a suspect takes action. The assailant in Buffalo did not fly entirely under the radar. Last year, his brush with the authorities resulted in a short stay in a hospital undergoing a mental health evaluation. New York state has a law that allows police to confiscate the guns of people considered dangerous. Local police and the FBI will now face questions about whether they could have done more. But the larger problem remains: a global leaderless movement of young violent extremists, radicalised on the internet, some of whom are prepared to launch deadly attacks against innocent people."
COP26: The truth behind the new climate change denial,"As world leaders met at the COP26 summit to debate how to tackle climate change, misleading claims and falsehoods about the climate spiralled on social media. Scientists say climate change denial is now more likely to focus on the causes and effects of warming, or how to tackle it, than to outright deny it exists. The 'd-words' v the planet We've looked at some of the most viral claims of the past year, and what the evidence really says. People have long claimed, incorrectly, that the past century's temperature changes are just part of the Earth's natural cycle, rather than the result of human behaviour. In recent months, we've seen a new version of this argument. Thousands of posts on social media, reaching hundreds of thousands of people over the past year, claim a ""Grand Solar Minimum"" will lead to a natural fall in temperatures, without human intervention. But this is not what the evidence shows. A grand solar minimum is a real phenomenon when the Sun gives off less energy as part of its natural cycle. Studies suggest the Sun may well go through a weaker phase sometime this century, but that this would lead, at most, to a temporary 0.1 - 0.2C cooling of the planet. That's not nearly enough to offset human activity, which has already warmed the planet by about 1.2C over the past 200 years and will continue to rise, possibly topping 2.4C by the end of the century. We know recent temperature rises weren't caused by the changes in the Sun's natural cycle because the layer of atmosphere nearest the earth is warming, while the layer of atmosphere closest to the Sun - the stratosphere - is cooling. Heat which would normally be released into the stratosphere is being trapped by greenhouse gases like carbon dioxide from people burning fuel. If temperature changes on Earth were being caused by the Sun, we would expect the whole atmosphere to warm (or cool) at the same time. Various posts circulating online claim global warming will make parts of the earth more habitable, and that cold kills more people than heat does. These arguments often cherry-pick favourable facts while ignoring any that contradict them. For example, it's true that some inhospitably cold parts of the world could become easier to live in for a time. But in these same places warming could also lead to extreme rainfall, affecting living conditions and the ability to grow crops, At the same time, other parts of the world would become uninhabitable as a result of temperature increases and rising sea levels, like the world's lowest-lying country, the Maldives. We face climate extinction, at-risk nations say There may be fewer cold-related deaths. According to a study published in the Lancet, between 2000 and 2019, more people died as a result of cold weather than hot. However, a rise in heat-related deaths is expected to cancel out any lives saved. The UN's Intergovernmental Panel on Climate Change (IPCC) says overall, ""climate-related risks to health [and] livelihoods...are projected to increase with global warming of 1.5 degrees"". Any small local benefits from fewer cold days are expected to be outweighed by the risks of more frequent spells of extreme heat. A common claim made by those against efforts to tackle climate change is that fossil fuels have been essential to driving economic growth. So limiting their use, the argument goes, will inevitably stunt this growth and increase the cost of living, hurting the poorest. But this isn't the whole picture. Fossil fuels have powered vehicles, factories and technology, allowing humans over the past century to make things at a scale and speed which would previously have been impossible. This enabled people to make, sell and buy more things, and become richer. But stopping using coal doesn't mean returning to the days of ox-drawn carts and hand-cranked machines - we now have other technologies that can do a similar job. In many places, renewable electricity - powered by wind or solar energy for example - is now cheaper than electricity powered by coal, oil or gas. On the other hand, studies predict that if we don't act on climate change by 2050, the global economy could shrink by 18% because of the damage caused by natural disasters and extreme temperatures to buildings, lives, businesses and food supplies. Such damage would hit the world's poorest the hardest. Misleading posts claiming renewable energy failures led to blackouts went viral earlier in the year, when a massive electricity grid failure left millions of Texans in the dark and cold. These posts, which were taken up by a number of conservative media outlets in the US, wrongly blamed the blackout on wind turbines. ""Blackouts are an artefact of poor electricity generation and distribution management,"" says John Gluyas, executive director of the Durham Energy Institute. He says the claim that renewable energy causes blackouts is ""nonsensical.... Venezuela has oodles of oil and frequent blackouts"". According to Jennie King from the think tank ISD Global, this discrediting of renewable energies is a ""key line of attack for those keen to preserve reliance on, and subsidies for, oil and gas"". Critics of renewable energy schemes also claim the technology kills birds and bats, ignoring the studies that estimate that fossil fuel-powered plants kill many times more animals. There's no doubt some wildlife, including birds, are killed by wind turbines. But according to the LSE's Research Institute on Climate Change and the Environment: ""The benefits for wildlife of mitigating climate change are considered by conservation charities... to outweigh the risks, provided that the right planning safeguards are put in place, including careful site selection."""
Capitol riot anniversary: What QAnon followers believe now,nan
Capitol riots: Who broke into the building?,"Who were the protesters that broke into buildings on Capitol Hill after attending a rally in support of Donald Trump? Some were carrying symbols and flags strongly associated with particular ideas and factions, but in practice many of the members and their causes overlap. Images show individuals associated with a range of extreme and far-right groups and supporters of fringe online conspiracy theories, many of whom have long been active online and at pro-Trump rallies. One of the most startling images, quickly shared across social media, shows a man dressed with a painted face, fur hat and horns, holding an American flag. He's been identified as Jake Angeli, a well-known supporter of the baseless conspiracy theory QAnon. He calls himself the QAnon Shaman. His social media presence shows him attending multiple QAnon events and posting YouTube videos about deep state conspiracies. He was pictured in November making a speech in Phoenix, Arizona, about unproven claims the election was fraudulent. His personal Facebook page is filled with images and memes relating to all sorts of extreme ideas and conspiracy theories. Another group spotted at the storming of the Capitol were members of the far-right group Proud Boys. The organisation was founded in 2016 and is anti-immigrant and all male. In the first US presidential debate President Trump in response to a question about white supremacists and militias said: ""Proud Boys - stand back and stand by."" One of their members, Nick Ochs, tweeted a selfie inside the building saying ""Hello from the Capital lol"". He also filmed a live stream inside. We haven't identified the individual standing on the left in the above image. Mr Ochs' profile on the messaging app Telegram describes himself as a ""Proud Boy Elder from Hawaii."" Individuals with large followings online were also spotted at the protests. Among them was the social media personality Tim Gionet, who goes under the pseudonym ""Baked Alaska"". His livestream from inside the Capitol posted on a niche streaming service was watched by thousands of people and showed him talking to other protesters. A Trump supporter, Mr Gionet has made a name for himself as an internet troll. He's been described by the Southern Poverty Law Centre, a US nonprofit legal advocacy group, as a ""white nationalist"", a label he disputed in a comment to The Insider. YouTube banned his channel in October after he posted videos of himself harassing shop workers and refusing to wear a face-mask during the coronavirus pandemic. Other platforms that have previously shut down his accounts include Twitter and PayPal. A photo that went viral of a man who'd entered the office of senior Democrat politician Nancy Pelosi has been named as Richard Barnett from Arkansas. Outside Capitol Hill buildings, he told the New York Times that he took an envelope from the speaker's office and says left a note calling her an expletive. Reacting to the New York Times interview, Republican congressman Steve Womack said on Twitter: ""I'm sickened to learn that the below actions were perpetrated by a constituent."" Local media reports say Mr Barnett is involved in a group that supports gun rights, and that he was interviewed at a 'Stop the Steal' rally following the presidential election - a movement that refused to accept Joe Biden's victory and supports the president's unsubstantiated claims of electoral fraud. In the interview at the rally organised by 'Engaged Patriots' he said: ""If you don't like it, send somebody out to get me 'cause I ain't going down easy."" The group associated with Mr Barnett held a fundraiser in October with proceeds going towards body cameras for the local police department, according to the Westside Eagle Observer local paper. As the events were unfolding, many social media users, especially those associated with QAnon and supporters of President Trump, were claiming that agitators from the loose-knit left-wing group antifa were involved. The implication was that these activists were disguised as Trump supporters to create disruption. A number of prominent Republican politicians, such as US Representative Matt Gaetz, claimed it was antifa masquerading as Trump supporters. One widely-shared post claimed one protester had a ""communist hammer"" tattoo, as evidence that he wasn't a Trump supporter. On closer inspection, the symbol is from the video game series Dishonored. There have also been suggestions that Mr Angeli, the man wearing fur and horns, was a Black Lives Matter supporter, with users sharing an image of him at a BLM event in Arizona. Mr Angeli was indeed at that event, but he was there as a counter-protester. In images taken there, he's seen holding a QAnon sign. At least one of the rioters was holding a Confederate flag, which represented US states that supported the continuation of slavery during the American civil war. For this reason, it is considered by many to be a symbol of racism and there have been calls to ban it across the US. Others see it as an important part of southern US history. In July it was announced that the flag could no longer be flown on American military properties because of a new policy to reject ""divisive symbols"". President Trump has defended the use of the Confederate flag in the past, saying: ""I know people that like the Confederate flag and they're not thinking about slavery...I just think it's freedom of speech."" There were also protesters holding aloft flags featuring a coiled rattlesnake on a yellow background, often accompanied by the phrase ""don't tread on me"". This is known as the Gadsden flag, harking back to the American revolution and the war to expel British colonialists. It was adopted by libertarians in the 1970s, according to an article in the New Yorker, and more recently became a favourite symbol of conservative Tea Party activists. The flag has been adopted by the right over the past couple of decades, says Prof Margaret Weir, a political science expert at Brown University. It is also used by anti-government, white supremacist groups who embrace violence, she says. Reporting by Jack Goodman, Christopher Giles, Olga Robinson and Shayan Sardarizadeh."
Child hepatitis cases falsely linked to Covid vaccine,"Social media posts have falsely linked a recent spike in unexplained hepatitis in children to the Covid vaccine. The affected children were mostly under the age of five and therefore not eligible for the jab, health agencies monitoring the situation say. But this hasn't stopped the claims - and other theories around lockdown or sending children back to school - being promoted as fact. So what are the established facts of the cases so far? As of 21 April 2022, the World Health Organization had recorded at least 169 cases of unexplained hepatitis  - inflammation of the liver - in children in 11 countries since January. Of these, 114 were in the UK. None of the five specific viruses (labelled A - E) which usually cause hepatitis was found, but the majority of youngsters tested did show up positive for a particular adenovirus - a common family of infections responsible for illnesses from colds to eye infections. The specific one they had causes stomach bugs. Dr Meera Chand, director of clinical and emerging infections at the UK Health Security Agency (UKHSA), said their investigations ""increasingly"" suggested the rise was linked to adenovirus infection. ""However, we are thoroughly investigating other potential causes,"" she said. The UKHSA says the Covid vaccine is the one thing they can definitively rule out - because none of the children affected had received the jab. Nevertheless, on Twitter, Reddit, Facebook and Telegram, the BBC has found false claims that these hepatitis cases were caused by the Covid vaccine. One post on Reddit highlighted the fact that an adenovirus is used in the AstraZeneca and Johnson & Johnson Covid vaccines. The adenoviruses used in the vaccines are harmless transporters which have been modified so they cannot replicate or cause infection. Not only are they completely different adenoviruses to the ones found in the affected children, but these vaccines are largely being restricted to use in people aged 40 and over in the UK. The average age of the children developing hepatitis is three - an age group not eligible for any of the Covid vaccines in the UK, where most of the cases have been recorded. An article from a website known to contain false and misleading information about Covid, claiming the Pfizer vaccine was to blame, was shared on Facebook in English, Spanish, Italian, Chinese and Norwegian. It quoted a much-misinterpreted study which has also been used to make misleading claims about the vaccines and fertility. Some have claimed high levels of Covid and sending children back to school unmasked is to blame. Unlike the vaccine theory, which is firmly discredited, the idea that a Covid infection could play a role in these cases is still being investigated as a possibility. Small studies have found unusual cases of hepatitis in a handful of young children who had previously tested positive for Covid in Israel, Brazil, India and the US. This does not yet conclusively prove Covid played a role though. Prof Anil Dhawan, a liver specialist at King's College Hospital London, who is treating some of these children, says at the moment he does not think Covid is driving these cases. ""Because if you look at number of patients, only 16% tested positive for Covid, and this [hepatitis] is not the feature of Covid,"" he said. Hepatitis is a very rare known reaction to adenoviruses, he added. One line of inquiry is that children who haven't been exposed to as many infections in the early years of life because of the pandemic could be having outsized reactions to the adenovirus. This has been seized on by some as proof lockdown was to blame for the outbreak. But this is still a big unknown. Dr Conor Meehan, a senior lecture in microbiology at Nottingham Trent University, agrees it is possible that not being exposed to as many bugs in their first months and years could have left these children's immune systems more vulnerable. ""The exposure that you have to viruses is important for building your immune system, and it mostly happens in the first five years of life,"" Dr Meehan explains. ""Most of these cases we see in under five-year-old kids, so they definitely haven't had the exposure that other kids would have had that are older,"" he says. This makes its possible they could have a stronger reaction to an adenovirus infection. But, ""we would expect that stronger reaction to still just be worse versions of what we would normally see"", in other words severe vomiting and diarrhoea, but not hepatitis. This extremely unusual reaction suggests there is something else going on, Dr Meehan thinks, like a mutated virus or an interaction between two viruses. However, more investigations are needed before we can say for sure what's causing these still very rare cases. Events that are both distressing and unexplained make fertile ground for confirmation bias - when people look for information to support what they already believe - according to Prof Gina Neff, a senior research fellow at the Oxford Internet Institute. There is a lot of uncertainty in this situation and understandably people are looking for answers, she says. ""When we search online, we feel like we're looking at a library and all the world's information is available to us,"" she explains. But, argues Prof Neff, the results of our online searches are affected by what we've searched for before and by the algorithms used by search and social media companies."
Cinema and big event organisers targeted by extreme anti-vax activists,"Anti-lockdown and anti-vaccine activists have used online groups to circulate the personal details of people helping to run cinema and other large-scale event trials. It's prompted some people to send abusive messages. ""We must be approaching about 300 emails accusing us of things like being a part of a 'medical apartheid.'"" George Wood is managing director of The Luna Cinema, which runs open-air film events. He agreed to participate in the government's pilot scheme to restart large-scale gatherings - but he didn't expect to receive abuse for doing so. The emails accuse Luna of being part of a ""vaccine passport"" scheme - even though attendees won't have to show proof of vaccination, only evidence of a recent negative Covid-19 test. The abuse includes personal attacks and even messages comparing the organisers to Nazis. ""These claims are so ridiculous,"" says Mr Wood. ""The staff are being distressed by it. ""We are doing something positive for the industry,"" he says. ""We're helping return the freedoms that have been removed by Covid."" Mr Wood says that many of the people writing in used the same slogans and phrases, which seemed to indicate a co-ordinated campaign. And he says some of the more extreme messages have been referred to the police. The targeting of The Luna Cinema isn't unique. The BBC has seen details posted online - including phone numbers and email addresses - of several people involved in a number of the mass event pilots. In one group of nearly 16,000 people on the chat app Telegram, contact details of organisers of the events were for a time pinned to the top of the chat. The group itself is devoted to Covid-19 and vaccine conspiracy theories. One post reads: ""Help Kill The Government Trials That Will Inevitably Bring In Vaccine Passports"", and goes on to list contact email addresses for organisers. Other posts, like this one, declare that the events ""must fail"": While the messages avoid specific calls to action, participants in the chat are prodded with phrases like ""YOU KNOW WHAT TO DO"". As Mr Wood's experience shows, some may interpret that as a sign to send abuse. The government is collecting data and research from a number of pilots around the country, including Sunday's FA Cup semi-final at Wembley Stadium, the World Snooker Championships in Sheffield and a number of other smaller events. Findings from these events on testing, social distancing and ventilation will inform how mass venues can reopen safely after 21 June, when all lockdown measures are currently planned to be lifted. The government's initial statement on the pilots referred to ""Covid-status certification"". However that phrase appears to have initially caused some confusion, with some interpreting it as a signal that participants would be required to show proof of a Covid vaccination. One venue, Liverpool's Hot Water Comedy Club, pulled out from the trial because of abuse over inaccurate reports it was involved in a ""vaccine passport"" trial. The cancellation was cheered in anti-vaccine groups. While there has been debate about the ethics of ""vaccine passports"" and the government has launched a review into Covid-status certification, the only requirement for entry into the mass event trials is a negative Covid test. As the exact requirements for the trials have become clearer, however, chat in more extreme anti-lockdown, anti-vaccine groups hasn't subsided. Instead, people consistently talk about the trials bringing in ""vaccine passports"" by the back door. Posts contain a range of suspicions - from mainstream worries about discrimination, all the way to hard-core conspiracy theories that the pandemic is somehow a ""hoax"" or has been ""fabricated"", alongside patently false assertions that vaccines are harming and killing millions. Some claim, again falsely, that Covid testing itself is somehow dangerous. There is also content from far-right activists. ""In terms of the broader Covid conspiracy and anti-lockdown groups, threats and potential violence against people who may be talking about how society changes because of Covid are quite common,"" says Ciaran O'Connor, an analyst at the Institute for Strategic Dialogue. ""The thing about Telegram is that it's anonymous. Hate and anger is not only encouraged but also orchestrated in these spaces,"" adds Mr O'Connor. ""You don't have to dig deep."" The BBC has contacted Telegram for comment."
Climate change: Conspiracy theories found on foreign-language Wikipedia,"Several foreign-language Wikipedia pages seen by BBC News are promoting conspiracy theories and making misleading claims about climate change. A number, including some in Swahili, Kazakh and Belarusian, suggest scientists are divided over its causes. The overwhelming scientific consensus is global warming is caused by humans. A representative of the Wikimedia Foundation, which runs Wikipedia, said they were ""worried"" by the findings and more volunteer editors were needed. The ""climate change"" entry on Chinese Wikipedia lists solar activity as one of the possible explanations for rising temperatures around the world today. Other widely disproven theories listed include unfounded claims about the emergence of a totalitarian world government and tie calls for climate action to secretive financial interests. On Croatian Wikipedia, more than a third of the page on global warming is devoted to questioning the science of climate change, while also pushing conspiratorial views. ""This worries me a lot,"" Wikimedia Foundation senior programme strategist Alex Stinson said. ""And this is why we need more people involved in this project."" Wikipedia is published in more than 300 different languages, each with its own original content and volunteer editors. Open for anyone with an internet connection to edit, the quality of its content is entirely dependent on those volunteers. More volunteers in different languages would decrease the chances of conspiracy theories and bad information lingering on the site, Mr Stinson said. Yumiko Sato, a Japanese writer based in the US who has investigated misinformation on the platform, said: ""Wikipedia only works if the editing community is large and diverse."" Launched in 2001, the online encyclopaedia is one of the world's most visited websites. The English-language version, the largest, has more than 40,000 users actively editing it each month. Its climate-change pages have a group of dedicated volunteer editors who actively patrol for any sign of bad information or pseudoscience. But the same does not apply to many of the pages in languages other than English. In more than 150 languages, fewer than 10 people a month regularly edit any pages. ""[These versions] are much smaller and lack editorial diversity, so that makes them vulnerable to manipulation,"" Ms Sato said. One of Wikipedia's core principles is self-governance. So, unless the community of editors steps in, the Wikimedia Foundation can do little. ""The foundation has never intervened on editorial policies directly and that is not what we do,"" Mr Stinson said. ""We need to push back on this disinformation in science - but that only works if the science-literate show up in that language, in that context, and that Wikipedia [version]."" Listen to The Denial Files: 'We fight climate denial on Wikipedia'  on the BBC World Service."
"Climate change: Facebook fails to flag denial, study finds","Climate change denial is spreading unchecked on Facebook, two studies by disinformation researchers have found. The Center for Countering Digital Hate and the Institute for Strategic Dialogue said less than 10% of misleading posts were marked as misinformation. And the CCDH researchers linked the majority of these to just 10 publishers. Facebook said this represented a small proportion of climate change content. The CCDH is a non-profit organisation which monitors and lobbies against online hate and misinformation. It found that of 7,000 misleading posts describing climate change as ""hysteria"", ""alarmism"", a ""scam"", or other related terms, only 8% were marked as misinformation. Facebook pledged to flag climate denial content early this year. The CCDH looked at a sample of posts from the past year which attracted roughly 700,000 likes and shares. Researchers used social media analytics tool Newswhip to search for strings of key words including ""climate change"", global warming"" and, ""fraud"", ""hoax"", ""cult"", ""scam"", ""lie"" and so on. The researchers manually reviewed every post to make sure it met their definition of climate denial and was not a post condemning such beliefs. Highly shared articles made false assertions that climate change was not confirmed by science or claimed to debunk it with data. Of these, 69% could be traced back to just 10 ""super-polluter"" publishers - dubbed the ""toxic ten"" - the campaign group found. In fact, our understanding of climate change comes from analyses of millions of measurements gathered in different parts of the world. And multiple independent teams of scientists have reached the same result - a spike in temperatures coinciding with the onset of the industrial era. Many of the shared articles also pushed the unsubstantiated belief that ""climate lockdowns"" will be enforced on populations. Yet scientists point out this is highly unlikely given there is no evidence the Covid lockdowns led to a significant improvement for the climate. These posts represent the most extreme types of outright climate denial, according to the CCDH. They can't tell us the true scale of climate misinformation on the site but they do indicate climate conspiracy content is spreading without being labelled or removed by Facebook. Campaign group Stop Funding Heat, working together with think tank the Institute for Strategic Dialogue (ISD), said it had found far more misinformation which more generally ""undermines the existence or impacts of climate change, the human influence on climate change, and the need for urgent action"". Research published on Thursday analysed 48,700 posts between January and August 2021 and found just 3.6% posts containing climate misinformation included a fact-checking label. The group also identified 113 ads on Facebook with messages like ""climate change is a hoax"" between January and October 2021 with an estimated spend of between $58,000-$75,000 (about Â£42,000- 55,000). This appears to be a particular issue on Facebook. Counter-extremism think tank the ISD discovered during the 2021 German election that most of the top shared posts relating to renewable energy on the site (18 out of 25) either doubted climate change or criticised climate action. They found a similar trend on conversations around fossil fuels, with most of the top shared posts on Facebook (19 out of 25) arguing against climate action. On Twitter, on the other hand, the trend was reversed with most posts on the subjects promoting the scientific evidence or in support of climate action. Although the majority of the publishers of climate denial identified by CCDH were in the US, people from Brazil, India, Poland, Haiti, Mexico, Thailand, Russia, France and Germany were among their top viewers. And there were climate denial posts analysed by ISD from the UK, Australia, Russia, India, Poland, South Africa and Japan. A spokesperson, speaking on behalf of the Facebook platform, said the 700,000 interactions with the posts analysed by the CCDH made up a small fraction of the total 200 million interactions with climate change content on the site. ""We continue to combat climate misinformation by reducing the distribution of anything rated false or misleading by one of our fact-checking partners,"" the spokesperson said."
Climate change: How to talk to a denier,"What can you do when the people closest to you believe climate change is a hoax? It was during school pick-up a few years ago that Lance Lawson first asked his father about his views on global warming. ""He basically told me something along the lines of 'It's nonsense',"" Lance recalls. His dad spoke of unscrupulous politicians ""fearmongering"" for electoral gain. Climate change, he told Lance, was completely ""overblown"". Lance, now 21, lives with his father, Brian Anderson, in the US state of Florida. He was just a teenager when that conversation happened, but it made a huge impression on him. ""My father is a very smart man,"" he says. ""So I assumed that, if my father is telling me this, then it must be true."" But, as time went on, Lance started realising his father's views weren't backed by scientific evidence - and he decided to challenge him. ""Whenever he drove me to school, I would give my own argument, and he would downplay the evidence. It would force me to acquire new evidence, and that cycle helped expand my own understanding."" If someone close to you believes climate change is a hoax, you may find it hard to do what Lance did. Maybe you fear confrontation, maybe you simply don't know how to explain the basic science of global warming. But Gail Whiteman, professor of sustainability at the University of Exeter, says it's important to talk: ""If we don't tackle climate denial and climate indifference, then the uphill battle to find a safer future is lost. ""We need to tackle our teachers, our neighbours... All of us have to become vessels for communication."" But how exactly do you go about starting the conversation? Sander van der Linden is professor of social psychology at the University of Cambridge, and studies how people get sucked into conspiracy theories. He says years of research have shown him that confronting people with hard evidence is not the way to go. While it might be tempting to try to bluntly fight conspiracy theories with facts, ""there's a very high chance it backfires"". ""Telling people that they don't know what they're talking about, or that they're wrong, just creates more defensive responses."" Lance says there is a common misconception that people who don't believe that climate change is real are ""stupid or uneducated"". ""But there are a lot of people out there who are just naturally sceptical as part of their personality,"" he says. His father, Brian, is one of them - he grew up in rural Minnesota in the 1970s. ""It was incredibly cold,"" Brian says, and this made it hard for him to believe scientists who spoke of a ""warming planet"". Lance says that his father is a very religious man - so he asked him to assume that climate change might be real, and questioned whether he wouldn't then have a moral responsibility to take care of what God had provided. ""Lance spoke in a language that I could appreciate and understand,"" says Brian. ""You have to approach people in terms of where they're at."" Prof van der Linden believes that changing the minds of climate deniers is impossible without affirming - to some extent - their worldview. He says it's important to ""[expose] techniques of manipulation"" by asking questions such as: ""Have you considered that some of these theories might be created to take advantage of people?"" No-one likes being talked down to, and the same goes for someone engaging with climate change denial. ""You can't convince someone if they perceive that there's a power differential,"" says Prof van der Linden. ""The whole point of a conspiracy is the idea that there are these powerful elites conspiring against us."" Lance's close bond with his dad is something he believes was key to persuading him, but he also says it's important to check your tone: ""Ask yourself, 'Am I sounding sanctimonious?' Remain humble. Be gentle."" Falling down the rabbit hole of conspiratorial thinking can be a long process - taking months, or even years. Prof van der Linden believes that thinking you'll win someone over with a single, one-off conversation is simply not realistic: ""You have to be content with small wins, and compromise."" And yet, some experts question whether talking to climate change deniers is really worth it. Abbie Richards researches the spread of misinformation on social media. ""Effort is better spent on pushing for actual change, rather than trying to combat solidified disinformation that has been pushed... for years,"" she says. ""But I also think trying to find things that you can agree upon might be more helpful, like [other] policies that we could both get behind."" On TikTok, she debunks disinformation about climate change, but says she's given up trying to engage with hardcore conspiracy theorists. ""I don't give credibility to people who are denying climate science, and I don't want to waste my energy on debunking more of their disinformation."" But Prof van der Linden points out that ""some of these dismissive individuals are very loud and have a disproportionate influence on public debate"". ""It's quite risky to do nothing, especially when [they] have outsized voices."" With time and patience, Lance managed to convince his father that climate change was real - so much so that he was surprised by his own success. ""One time, my dad came downstairs in the middle of the night, so enthused after watching a documentary about deforestation that he was like: 'Lance you won't believe what's going on in the rainforest!' ""It was a breathtaking moment, to see him so engaged."" Do you have a story for us? Get in touch."
Commercial TV channels unite to screen Covid vaccine myth-busting video,"A star-filled video urging people from ethnic minority communities to get the Covid vaccine will be shown across the UK's main commercial TV channels later. Sanjeev Bhaskar, Meera Syal and Romesh Ranganathan are among the celebrities who feature in the video, which has previously been released online. More stars have been added to the version that will be screened on ITV, Channel 4 and Channel 5 at 21:56 GMT. STV and various Sky TV channels will also take part in the TV ""roadblock"". The film will not be shown on the BBC because the corporation's charter prevents it from taking part in campaigns, but the issues it raises and some of the participants will feature on BBC TV and radio programmes on Thursday. Citizen Khan creator Adil Ray, who co-ordinated the video, said: ""We are in unprecedented times and the fact remains this pandemic disproportionately affects people from ethnic minority communities. ""It's heartening to see all the major broadcasters come together in an equally unprecedented television broadcast at this crucial time."" The campaign comes amid growing concern about the uptake of Covid vaccines among black, Asian and other ethnic minority communities in the UK. Official figures suggest that people from ethnic minorities are less likely to get vaccinated. The latest evidence comes from a study published overnight of GP records looking at vaccine take-up among people. Fake news about the vaccine has been a particular problem in the South Asian community, and is addressed in the #TakeTheVaccine video. ""There's no chip or tracker in the vaccine to keep watching where you go,"" says comedian Ranganathan in the film. ""Your mobile phone actually does a much better job of that."" The video also rebuts claims that the vaccine contains animal products and is not halal, or that it causes infertility. Ranganathan told BBC Breakfast on Thursday he and his brother had to sit down with their mother - who has previously appeared on his show The Ranganation - to talk through her concerns about the vaccine. ""My mum is a key worker, where she works it's a lot of people from South Asian backgrounds and so my brother and I were obviously very worried about her and we just assumed that she was going to be willing and ready to take the vaccine,"" he said. ""And then when it came down to us actually discussing it with her, she said, 'I've actually got some doubts', and so it took us by surprise but we were able to talk to her about and explain the various issues and now she feels OK to take it."" He added: ""But it just feels so heart-breaking to me that people from ethnic minorities are inflicting a degree of separation upon themselves from not trusting in this, and I understand all the reasons why - I've heard all the arguments - but I just feel so strongly that we need to make sure we dispel some of these myths, so that people are getting involved and we can get ourselves out of this pandemic."" Appearing on the programme alongside the comedian, Dr Farzana Hussain said she hoped that such celebrities could have a key influence. When asked if she had noticed a shift in attitudes yet, she replied: ""Not hugely sadly, I know it's still early days and I think that's why it's so important to keep repeating the message. ""I have an 18-year-old-son and he would never take a message from me or a doctor, but when I told him that I was going to be on TV with Romesh, he was so excited about it. ""We obviously have a place as doctors, but I think everybody has a place, and I think this message is going to be a long, hard one. ""As Dr Nikki Kanani - our GP leader - has said: we are fighting two pandemics here. We're fighting the Covid virus, but we're also fighting this huge tsunami of misinformation that's coming out."" Singer Beverley Knight, Olympic heptathlete Denise Lewis, historian David Olusoga and actor Hugh Quarshie are among the stars in the video's latest version. The three-and-a-half minute broadcast will also be shown at a webinar event addressing vaccine hesitancy in ethnic communities, to be introduced by the Prince of Wales on Thursday morning. In his video address, Prince Charles will say he has been ""saddened"" by ""the variable uptake of the vaccines which finally offer us a way out of the suffering of the past year"". Speaking to Radio 4's Today programme, broadcaster and historian David Olusoga said he understood why people from ethnic minority backgrounds may be wary, due to the ""entanglements in history between the history of medicine and the history of colonialism and racism"". ""There is a history that is well known, and that helps fuel people who are spreading misinformation,"" he said. ""But the reality is that although there is a chequered and disturbing history, vaccines are safe, are necessary and are the key to ending this pandemic."" Olusoga said he was also ""very happy to take part"" in order to help avoid a ""double tragedy"". ""We know from studies that there is a lower uptake of the vaccine amongst BAME (black and ethnic minority) communities and we also know that BAME communities have suffered disproportionately so I just want to help in a small way to avert what will be a double tragedy,"" he continued. ""There's already been a falling of this pandemic more heavily on the shoulders of minority communities."" ITV chief executive Carolyn McCall said Thursday's simultaneous broadcast would ensure the campaign's message reached ""the most people at the same time"". Alex Mahon, her Channel 4 counterpart, said: ""We're delighted to be able to help get this important message far and wide at such a critical time."" Sky's Stephen van Rooyen, meanwhile, said the network was ""proud to be part of the biggest roadblock in television history"". BBC director general Tim Davie added: ""We know there is lots of misinformation online and elsewhere. That's why the BBC will be looking at the issues raised so extensively."" Follow us on Facebook, or on Twitter @BBCNewsEnts. If you have a story suggestion email entertainment.news@bbc.co.uk."
Coronavirus doctor's diary: 'Fake news makes patients think we want them to die',"Conspiracy theories have been spreading within parts of the BAME community that hospital staff want them to die, reports Dr John Wright of Bradford Royal Infirmary (BRI) - meanwhile, figures suggest an increase in deaths in the city outside hospital. There is a flurry of news stories about black, Asian and minority ethnic communities being at greater risk of dying from Covid-19, and this is a big concern in Bradford, where almost a third of our population is of South Asian heritage. There are two factors at play here. The first is the increased risk of catching Covid-19 - living in more densely populated areas in overcrowded housing will be important risk factors. The second is the risk of adverse outcomes: diabetes, high blood pressure and heart disease have all been found to be risk factors, and these are much more common in our South Asian patients. I know from my work in epidemics in Africa that where there is fear and panic, and patients become isolated from their families, it doesn't take long for rumours and fake news stories to start circulating. In the Covid pandemic, smartphones and social media have connected families who are separated because of the risk of infection - but they've also helped generate a blizzard of dangerous fake news. In Bradford there are online reports that non-white patients admitted to the hospital are being left to die. Anonymous posts are shared thousands of times. Here's one, which is totally false: ""Please don't show my details. I work for BRI hospital trust. I am begging all the ummati [community], if you have any health condition please do NOT go to hospital. You will not come back alive from this trustÂ Also have your daily black seed oil which prevents all disease."" The effect of this kind of thing is being felt in the hospital, where we have noticed that some patients are scared to be admitted. ""I've had patients who want to self-discharge because they think we're trying to kill them. I've had a patient a couple of weeks ago, who wanted to self-discharge because her family was messaging her telling her that if she dies in our care, we won't tell them and we'll just burn her body. These are the things that are being spread around,"" a nurse, Sophie Bryant-Miles, tells me. Sophie complained to Facebook about a group that she says was posting pictures of NHS staff - naming them, and accusing them of leaving people to die - but often such groups are able to continue operating under a different name, she says. Ward manager Jennie Marshall-Hamad notes that the danger of such rumours is that they deter sick people from seeking medical help ""and they will just die outside alone"". And in fact in Bradford we have figures that suggest death rates are going up, outside the hospital. Prof John Wright, a medical doctor and epidemiologist, is head of the Bradford Institute for Health Research. He has looked after patients in epidemics all over the world, including outbreaks of cholera, HIV and ebola in sub-Saharan Africa. In this diary he is reporting for the BBC on how the Bradford Royal Infirmary is coping with Covid-19. Read other recent posts: Messages like the WhatsApp example above are in wide circulation and some have been sent to community workers like Ali Jan Haider, director of the Keeping Well At Home project in Bradford. ""I was receiving a number of WhatsApp messages that are quite alarming, because their tone was quite clear in the way they were criticising hospitals,"" he says. ""The overall message was saying to local people 'don't send your loved ones to hospital because if you do it, chances are they will not return home alive'. ""And some of the so-called accounts of what's really going on create suspicion - they are peppered with emotions, and quite a strong level of unhappiness about the way that their relatives have been treated by staff within the hospitals."" He says that some of these highly critical messages have come from influential people in the Muslim community, and even from an imam in the south of England. If someone already has misgivings about their local hospital this kind of messaging will ""certainly make them think twice"", he says. It's natural for people to want to share any concerns they may have on WhatsApp or on Facebook, Ali Jan Haider concedes, but these messages worry him. ""My fear is, and my concern is, that quite a few of them could be unfounded, and I'm not even sure if they're authentic. They could be quite malicious or they could be there just to create panic and trepidation at a time when people are feeling very vulnerable,"" he says. Some Asian doctors and nurses at Bradford Royal Infirmary are so worried about fake news scaring away people in their own community who need to be in hospital that they've started a counter-offensive, making short videos of themselves and their patients and posting them online. Ali Jan Haider has been spreading the same reassuring message, though he is also keen to point out that most of the South Asian community in Bradford has no doubt about the good intentions of medical staff. ""The local community has been absolutely amazing in the way that it's been supporting the NHS staff in Bradford,"" he says. ""We've had donations from parts of Bradford where we have communities that live on the edge of poverty, but they have dug deep, and they've been immensely supportive."" So the false news is coming from strange and isolated voices in the community, but it's still troubling, and the support of community leaders is very important. The president of the Bradford Council of Mosques, Zulfi Karim, has seen fake news of a different kind. In an earlier diary I pointed out that the city's mosques suspended gatherings without waiting for the government-imposed lockdown. But he has heard that Muslims are nonetheless being blamed for the spread of the virus. ""I have various concerns around the rise of Islamophobia and claims that this is a Muslim thing, that Muslims congregate more and that Ramadan is around the corner,"" he says. ""That is the message that's out there, and I think that's rubbish. I do think that Ramadan, this year, will be in isolation. I don't think there will be any public events. So I think there is a lot of fake news, which is really, really concerning for all of us."" He also worries about Islamophobic rhetoric arising from the news that members of the BAME community are more at risk of dying from Covid-19. The emphasis now should simply be on saving lives, supporting the NHS and making sure that everyone is getting fair and equal treatment, he says. But afterwards he would like to see more research to establish whether the reports are true, and investment to tackle the problem if they are. Follow @docjohnwright on Twitter"
Coronavirus doctor's diary: 'They say I have blood on my hands',"Within Bradford's Asian community a few individuals are spreading fake news that non-white patients will be left to die in hospital. Dr John Wright of Bradford Royal Infirmary hears from an anaesthetist who has been receiving abusive messages as a result. The isolation of patients in the hospital from the community outside continues to spark small fires of uncertainty and false rumours. This is happening in cities across the country, and Bradford is no exception. Sometimes it's claimed that the higher death rate among black, Asian and other ethnic minority patients is because they are being killed off by the very hospital staff meant to help them. For our Muslim clinicians, to have their dedication and professionalism questioned as they work long shifts in the Covid wards while fasting during the holy month of Ramadan must be especially galling. But one of my colleagues, consultant anaesthetist Fozia Hayat, has been telling me about a malicious and foolish message she recently received from a local scaremonger. It came after her husband tried to dispute a story about hospitals leaving people to die that has been circulating for weeks, as I wrote on 18 April. He said it was wrong, and that his wife, Fozia, could vouch for this as a result of her work in the infirmary's intensive care unit. Prof John Wright, a doctor and epidemiologist, is head of the Bradford Institute for Health Research, and a veteran of cholera, HIV and Ebola epidemics in sub-Saharan Africa. He is writing this diary for BBC News and recording from the hospital wards for BBC Radio. At this point Fozia started getting sent videos, most of which she didn't open. But there was one she did watch, and she posted a brief reply. ""I essentially replied to say, 'Just be careful what you share, and look at both sides of the argument. It's important to ensure that you've got all the information as you might cause harm - you might stop somebody coming into hospital.'"" The abusive messages continued, despite the start of Ramadan and one text message was particularly offensive. ""I've been sent a message saying that NHS workers are working on bonuses, that we're taking money for putting Covid on death certificates and we are essentially taking money for life. And I think that's a really cruel thing to say to someone,"" she told me. The message accused doctors of forcing people to sign Do Not Resuscitate forms. It also suggested that Covid-19 didn't actually exist. Then it said: ""Please stop selling out and being a mushroom and stand up for the truth. You'll be held responsible in the court of Allah for the deaths of these people, for negligence in this life, and life is very short."" Fozia looked up the meaning of ""mushroom"" on the internet and discovered it was someone who was kept in the dark and fed false information. ""This is the month of Ramadan and we fast in our family, we are practising, and it was quite hard to have somebody send me a message to say, 'You're a sell-out, you're corrupt, a mushroomÂ You've got blood on your hands,'"" she says. She was also surprised that it was sent by someone who runs a successful business in Bradford. Not the kind of person you would necessarily expect to fall for fake news. ""They seem like fairly sensible people, but that makes it even more worrying,"" she says. ""It's fine to have an opinion. But don't be cruel. And don't accuse people of things. It's Ramadan and it's meant to be a time to be kind and generous to each other."" Our concern is that one or two scaremongers are influencing our patients to stay away from hospital when they really need care. We know from our own data in the hospital that outcomes for our white and South Asian patients are equally good, but careless talk will cost lives and change this for the worse. We also know that overall - looking at national and international data - black and South Asian patients are at greater risk of dying from Covid-19, so it is imperative that they seek appropriate care without delay. Fozia reported the offensive message to the police. They were sympathetic, but she decided not to take it further. Instead, she is going to talk about it on Radio Ramadan, at the suggestion of Zulfi Karim, head of the Bradford Council of Mosques - and she will reassure people that if they are sick they will be looked after in hospital regardless of their creed or colour. When I put Zulfi and Fozia in touch, he was disturbed by what she had been through, at a time when she had been working hard to save lives, and said he was determined to tackle false rumours. ""We can investigate where it's coming from and perhaps speak to some of those involved. So much good work is going on in the community to educate and inform people and it's really sad that this is happening, and it's very worrying,"" he said. ""I think we need to deal with the urgent issues and we need to react to messages to make sure we keep people coming into the hospital."" Follow @docjohnwright and radio producer @SueM1tchell on Twitter"
Coronavirus doctor's diary: The fake news about schools that's misleading parents,"Just as children are about to return to school, a video in Urdu has been widely shared in Bradford, and possibly elsewhere, falsely claiming that sick pupils could be removed from their families without parental consent. Dr John Wright of Bradford Royal Infirmary is joining efforts to debunk the idea - and says the reopening of schools is important for children, and parents. This week the schools are going back and everyone is nervous. We have grown accustomed to home working and social distancing, so the idea of hundreds of thousands of children and young people suddenly coming together in confined environments for long periods of time is hard to comprehend - a throwback to the pre-Covid-19 era. From the start, Covid-19 created fertile ground for the spread of fake news, as I wrote in April. The ban on hospital visiting at the peak of the pandemic led to a disconnect between patients and staff and relatives. We struggled to counter the rumours in different communities that we were harming patients or that coronavirus was a cunning attempt by the Home Office to lure in people to repatriate them. We had sick patients who refused to be admitted for fear of what we were going to do to them. Now the anxiety about returning to school has caused a new round of false rumours. This time the claim is that if children fall sick they will be removed from their families and taken into care. Head teachers, school governors and parents who have heard the story have approached Bradford City Council seeking reassurance that it isn't true. I myself was contacted by the chair of governors of a local school, who told me that despite her efforts to dispel the rumours she was ""concerned that accurate information may not be getting through"". Prof John Wright, a doctor and epidemiologist, is head of the Bradford Institute for Health Research, and a veteran of cholera, HIV and Ebola epidemics in sub-Saharan Africa. He is writing this diary for BBC News and recording from the hospital wards for BBC Radio. In an attempt to understand why people are falling for the conspiracy theories, my colleague, consultant anaesthetist Fozia Hayat, spoke to one father of three, Arshid Siddique, who told her he disbelieved a lot of what he had been told about Covid-19. He accepted that Covid-19 existed, but didn't believe people had died from it. ""They've committed suicide and Covid-19 has been written on the death certificates,"" he said. ""Doctors are being paid to put Covid-19 down for anyone who dies in the hospital."" This is a myth that Fozia and I have heard many times. Arshid said the video of a woman warning that children could be quarantined by the state and not allowed home had been sent to his wife, and that they believed her, so would not be sending their children back to school. The speaker, whom he described as ""a very well-spoken lady"", says she is a tabeeba, an Urdu word for doctor, and uses the title ""doctor"" in English, though her website describes her as ""a qualified practitioner of prophetic medicine"". She clearly doesn't have a degree in medical science and isn't a doctor in the usual sense of the word. So why did Arshid believe this person who had popped up on social media, while rejecting information from the government and the NHS? ""The government isn't telling the truth and everyone in power keeps changing their minds,"" he replied. ""First there's no Covid for kids and then there is, and then it's no masks for kids and now that's changing. ""No-one believes the officials. People aren't telling the truth in government. There was that Dominic whatever-it-is and he got caught red-handed. So if it's real, and if it's dangerous, and if it's life-threatening, then why are these people acting like this?"" I've heard other reasons for scepticism, too. The additional lockdown restrictions in West Yorkshire and Manchester were announced with poor timing on the evening before Eid al-Adha, when the food had already been prepared. And the contrast of being able to visit the pub but not your own family comes across to some as insensitive and unfair. There has been a loss of trust in authority, which makes people more receptive to fake news. West Bradford MP Naz Shah, who says people started questioning her about the video a few days ago, says it's always a difficult decision to debunk fake news, because by doing so you give it the oxygen of publicity. But Bradford City Council clearly thinks the story has already spread so far that it needs tackling head on. Education safeguarding officer Shaqib Juneja and deputy leader Imran Khan have recorded videos assuring people that there is no truth in the story, and that if children are unwell parents will be asked to take them home. Zahabia Naveed, 15, is nervous about going back to school for another reason. During lockdown she has been learning how to grow vegetables from 73-year-old Alan Wainwright, and wants to continue after the start of term. Alan has only had contact with two other people throughout the period of lockdown, his wife and her daughter. The last thing Zahabia wants to do is to catch the virus from one of the 1,400 pupils at her school and accidentally bring it into Alan's bubble. A Bradford rapper, Faisal, is also spreading the message and there is a plan to ask GPs to send a text message to their patients, assuring them that there is no question of separating sick children from their families. I've been asked to record a video myself, which I am very glad to do. There is much we know about Covid-19 and much we don't, and this partly explains why advice on masks - as noted by Arshid Siddique - has changed over time. Importantly, the evidence is becoming clearer about the risk of Covid-19 in schools. Children have lower rates of infection and generally much milder disease. Child-to-child transmission in schools is rare and serious outbreaks in schools are unusual. Evidence from other countries suggests that re-opening schools does not increase community transmission. Of course, parents will be worried about their children bringing the virus home, and in Bradford, where there are many multi-generational households, the risk to older family members is real. But there is nothing more important than a safe return to school. The loss of education during lockdown will have lasting effects. Our children and young people need to reclaim their youth and their friends, while parents need to be freed from the challenges of home-schooling and allowed to return to work. Health and education are so closely linked, yet schools are historically isolated from health services. This is the time to link arms and we have been working closely with public health colleagues to support head teachers as they face the sleepless nights that we experienced in hospitals in the spring. We have produced webinars and guidance on how to prepare the schools for opening, how to use face masks, what to do when a child gets symptoms, how to manage an outbreak, and how to provide mental health support. We will also be helping to reduce uncertainty by teaming up with leading scientists from across the UK to help understand children's immunity in the coming months. A couple of days after Fozia's conversation with Arshid Siddique there was some good news - his wife had received an encouraging call from an Urdu-speaking teacher at his daughter's school. ""She told my wife that it would never happen, that they can't take children away. She's been reassuring people, and I've told my wife that we won't let them test the children,"" he said. There is still a lively debate about the video going on among parents of pupils at the school, according to Arshid, but he and his wife are now planning to send their children back. Then, on Saturday, Fozia managed to speak to the woman who made the video that has caused so much havoc. Her name is Alia Syed and she is based in Derby. She told Fozia she had made a huge mistake and that she had now removed the video from her website and put out a retraction, in English and in Urdu. ""I am hoping you will be able to put your mind at rest now. Please send your children to school, it's very important they continue with their education,"" her new video says. It seems, though, that the original video is still circulating on social media and messaging apps. If some of Bradford's Asian children stay at home this week, rather than returning to school, we will be able to guess how much harm it has done. Dr Fozia Hayat will be reporting on this story for My City in Lockdown on BBC Radio 4 at 11:00 on Tuesday 1 September Follow @docjohnwright and radio producer @SueM1tchell on Twitter"
Coronavirus vaccine resistance: Birmingham's uptake challenge,"Misinformation and mistrust are fuelling resistance to the Covid-19 vaccine in Birmingham, health chiefs say. In areas such as Newtown, as few as 50% of people have had their first jab. Other wards report low uptakes too. On the streets, people repeat conspiracies, saying authorities are ""lying"", using the public as ""guinea pigs"". The city council is working in communities to reassure residents. The move to address the public's concerns - said to be driven in part by social media ""sofa heroes"" - comes as Birmingham falls behind the national average for vaccine rollout. Latest government figures show fewer than 40% of the city's residents aged over 12 have been fully vaccinated, including a booster. For England, the figure is more than 55%. ""I've seen there's a Covid disease out here, but I haven't seen personally that the vaccines have helped,"" said one resident, who did not wish to be identified. ""I don't feel like this vaccination is doing anything to stop this disease."" Another, Raza Rafiq, was even more blunt: ""I don't believe in it,"" he said. ""If I catch it I catch it, it doesn't matter if I'm vaccinated or not. There's no point really."" In the city's worst affected areas, such as Newtown, Holyhead and Soho, as many as one in two people have not even had their first vaccination. However, some parts of Birmingham are performing much better. In Sutton Coldfield wards, about 90% of people have received their first jab. Dr Justin Varney is the city's director of public health. He said areas where vaccine uptake was low tended to be home to Birmingham's youngest and most diverse populations. ""We know we've still got a lot to do when it comes to answering the questions of young people,"" Dr Varney said. ""And in some of our global communities, those questions are driven by what's happening in other parts of the world. ""We're still facing that challenge but we continue to work with those communities."" The Office for National Statistics (ONS) found the most common concerns for vaccine-hesitant adults were centred around side effects, long-term health outcomes and the speed of the vaccine rollout. To deal with vaccine resistance in Birmingham, Dr Varney said council workers had been going door-to-door, asking people about their concerns and trying to answer their questions. The council is also working closely with faith leaders and community groups, Dr Varney adds, with strategies including a TikTok series debunking myths with a youth group. ""One of the challenges in today's digital age is there is so much information out there and so many people have an opinion, it's quite easy to get sucked into some of these sofa heroes who are giving their opinion,"" he said. As well as encouraging vaccine uptake, the council is encouraging people to check their facts and resources, Dr Varney explains. ""If you break your leg, you trust your doctor, you don't go and listen to someone on YouTube. Why's this any different?"" Follow BBC West Midlands on Facebook, Twitter and Instagram. Send your story ideas to: newsonline.westmidlands@bbc.co.uk"
Coronavirus: Health claims debunked,nan
Could AI swamp social media with fake accounts?,"Whether it's getting cookery advice or help with a speech, ChatGPT has been the first opportunity for many people to play with an artificial intelligence (AI) system. ChatGPT is based an an advanced language processing technology, developed by OpenAI. The artificial intelligence (AI) was trained using text databases from the internet, including books, magazines and Wikipedia entries. In all 300 billion words were fed into the system. The end result is a Chatbot that can seem eerily human, but with an encyclopedic knowledge. Tell ChatGPT what you have in your kitchen cabinet and it will give you a recipe. Need a snappy intro to a big presentation? No problem. But is it too good? Its convincing approximation of human responses could be a powerful tool for those up to no good. Academics, cybersecurity researchers and AI experts warn that ChatGPT could be used by bad actors to sow dissent and spread propaganda on social media. Until now, spreading misinformation required considerable human labour. But an AI like ChatGPT would make it much easier for so-called troll armies to scale up their operations, according to a report from Georgetown University, Stanford Internet Observatory and OpenAI, published in January. Sophisticated language processing systems like ChatGPT could impact so-called influence operations on social media. Such campaigns seek to deflect criticism and cast a ruling government party or politician in a positive manner, and they can also advocate for or against policies. Using fake accounts they also spread misinformation on social media. One such campaign was launched in the run-up to the 2016 US election. Thousands of Twitter, Facebook, Instagram and YouTube accounts created by the St Petersburg-based Internet Research Agency focused on harming Hillary Clinton's campaign and supporting Donald Trump, concluded the Senate Intelligence Committee in 2019. But future elections may have to deal with an even great deluge of misinformation. ""The potential of language models to rival human-written content at low cost suggests that these models, like any powerful technology, may provide distinct advantages to propagandists who choose to use them,"" the AI report released in January says. ""These advantages could expand access to a greater number of actors, enable new tactics of influence, and make a campaign's messaging far more tailored and potentially effective,"" the report warns. It's not only the quantity of misinformation that could go up, it's also the quality. AI systems could improve the persuasive quality of content and make those messages difficult for ordinary Internet users to recognise as part of co-ordinated disinformation campaigns, says Josh Goldstein, a co-author of the paper and a research fellow at Georgetown's Center for Security and Emerging Technology, where he works on the CyberAI Project. ""Generative language models could produce a high volume of content that is original each time... and allow each propagandist to not rely on copying and pasting the same text across social media accounts or news sites,"" he says. More technology of business: Mr Goldstein goes on to say that if a platform is flooded with untrue information or propaganda, it will make it more difficult for the public to discern what is true. Often, that can be the aim of those bad actors taking part in influence operations. His report also notes how access to these systems may not remain the domain of a few organisations. ""Right now, a small number of firms or governments possess top-tier language models, which are limited in the tasks they can perform reliably and in the languages they output. ""If more actors invest in state-of-the-art generative models, then this could increase the odds that propagandists gain access to them,"" his report says. Nefarious groups could view AI-written content similar to spam, says Gary Marcus, an AI specialist and founder of Geometric Intelligence, an AI company acquired by Uber in 2016. ""People who spread spam around rely on the most gullible people to click on their links, using that spray and pray approach of reaching as many people as possible. But with AI, that squirt gun can become the biggest Super Soaker of all time."" In addition, even if platforms such as Twitter and Facebook take down three-quarters of what those perpetrators spread on their networks, ""there is still at least 10 times as much content as before that can still aim to mislead people online"", Mr Marcus says. The surge of fake social media accounts became a thorn in the sides of Twitter and Facebook, and the quick maturation of language model systems today will only crowd those platforms with even more phony profiles. ""Something like ChatGPT can scale that spread of fake accounts on a level we haven't seen before,"" says Vincent Conitzer, a professor of computer science at Carnegie Mellon University, ""and it can become harder to distinguish each of those accounts from human beings."" Both the January 2023 paper co-authored by Mr Goldstein and a similar report from security firm WithSecure Intelligence, warn of how generative language models can quickly and efficiently create fake news articles that could be spread across social media, further adding to the deluge of false narratives that could impact voters before a decisive election. But if misinformation and fake news emerge as an even bigger threat because of AI systems like Chat-GPT, should social media platforms be as proactive as possible? Some experts think they'll be lax to enforce any of those kinds of posts. ""Facebook and other platforms should be flagging phony content, but Facebook has been failing that test spectacularly,"" says LuÃ­s A Nunes Amaral, co-director of the Northwestern Institute on Complex Systems. ""The reasons for that inaction include the expense of monitoring every single post, and also realise that these fake posts are meant to infuriate and divide people, which drives engagement. That's beneficial to Facebook."" Whether it's getting cookery advice or help with a speech, ChatGPT has been the first opportunity for many people to play with an artificial intelligence (AI) system. ChatGPT is based an an advanced language processing technology, developed by OpenAI. The artificial intelligence (AI) was trained using text databases from the internet, including books, magazines and Wikipedia entries. In all 300 billion words were fed into the system. The end result is a Chatbot that can seem eerily human, but with an encyclopedic knowledge. Tell ChatGPT what you have in your kitchen cabinet and it will give you a recipe. Need a snappy intro to a big presentation? No problem. But is it too good? Its convincing approximation of human responses could be a powerful tool for those up to no good. Academics, cybersecurity researchers and AI experts warn that ChatGPT could be used by bad actors to sow dissent and spread propaganda on social media. Until now, spreading misinformation required considerable human labour. But an AI like ChatGPT would make it much easier for so-called troll armies to scale up their operations, according to a report from Georgetown University, Stanford Internet Observatory and OpenAI, published in January. Sophisticated language processing systems like ChatGPT could impact so-called influence operations on social media. Such campaigns seek to deflect criticism and cast a ruling government party or politician in a positive manner, and they can also advocate for or against policies. Using fake accounts they also spread misinformation on social media. One such campaign was launched in the run-up to the 2016 US election. Thousands of Twitter, Facebook, Instagram and YouTube accounts created by the St Petersburg-based Internet Research Agency focused on harming Hillary Clinton's campaign and supporting Donald Trump, concluded the Senate Intelligence Committee in 2019. But future elections may have to deal with an even great deluge of misinformation. ""The potential of language models to rival human-written content at low cost suggests that these models, like any powerful technology, may provide distinct advantages to propagandists who choose to use them,"" the AI report released in January says. ""These advantages could expand access to a greater number of actors, enable new tactics of influence, and make a campaign's messaging far more tailored and potentially effective,"" the report warns. It's not only the quantity of misinformation that could go up, it's also the quality. AI systems could improve the persuasive quality of content and make those messages difficult for ordinary Internet users to recognise as part of co-ordinated disinformation campaigns, says Josh Goldstein, a co-author of the paper and a research fellow at Georgetown's Center for Security and Emerging Technology, where he works on the CyberAI Project. ""Generative language models could produce a high volume of content that is original each time... and allow each propagandist to not rely on copying and pasting the same text across social media accounts or news sites,"" he says. More technology of business: Mr Goldstein goes on to say that if a platform is flooded with untrue information or propaganda, it will make it more difficult for the public to discern what is true. Often, that can be the aim of those bad actors taking part in influence operations. His report also notes how access to these systems may not remain the domain of a few organisations. ""Right now, a small number of firms or governments possess top-tier language models, which are limited in the tasks they can perform reliably and in the languages they output. ""If more actors invest in state-of-the-art generative models, then this could increase the odds that propagandists gain access to them,"" his report says. Nefarious groups could view AI-written content similar to spam, says Gary Marcus, an AI specialist and founder of Geometric Intelligence, an AI company acquired by Uber in 2016. ""People who spread spam around rely on the most gullible people to click on their links, using that spray and pray approach of reaching as many people as possible. But with AI, that squirt gun can become the biggest Super Soaker of all time."" In addition, even if platforms such as Twitter and Facebook take down three-quarters of what those perpetrators spread on their networks, ""there is still at least 10 times as much content as before that can still aim to mislead people online"", Mr Marcus says. The surge of fake social media accounts became a thorn in the sides of Twitter and Facebook, and the quick maturation of language model systems today will only crowd those platforms with even more phony profiles. ""Something like ChatGPT can scale that spread of fake accounts on a level we haven't seen before,"" says Vincent Conitzer, a professor of computer science at Carnegie Mellon University, ""and it can become harder to distinguish each of those accounts from human beings."" Both the January 2023 paper co-authored by Mr Goldstein and a similar report from security firm WithSecure Intelligence, warn of how generative language models can quickly and efficiently create fake news articles that could be spread across social media, further adding to the deluge of false narratives that could impact voters before a decisive election. But if misinformation and fake news emerge as an even bigger threat because of AI systems like Chat-GPT, should social media platforms be as proactive as possible? Some experts think they'll be lax to enforce any of those kinds of posts. ""Facebook and other platforms should be flagging phony content, but Facebook has been failing that test spectacularly,"" says LuÃ­s A Nunes Amaral, co-director of the Northwestern Institute on Complex Systems. ""The reasons for that inaction include the expense of monitoring every single post, and also realise that these fake posts are meant to infuriate and divide people, which drives engagement. That's beneficial to Facebook."""
Could US abortion bans affect miscarriage treatment?,"The debate over abortion rights in the United States has been accompanied by widespread misinformation about health concerns and legal rights. We've looked at some of the most controversial issues and the facts behind them. The American Center for Law and Justice, a Christian legal advice centre with 3.7 million Facebook followers, has written a widely-shared post claiming that ""abortion is not safe"" and calling on the US Supreme Court to reject arguments that it is. This is a common claim but it's not supported by evidence. While all medical procedures carry some risk, the US-based Centers for Disease Control and Prevention (CDC) says that between 2013 and 2018 there were 0.4 deaths per 100,000 legal abortions in the US. This compares with 23.8 deaths per 100,000 live births in 2020. In a recent court case in Florida, obstetrician and anti-abortion campaigner Dr Ingrid Skop recommended setting the abortion limit at 15 weeks, saying the procedure became more ""difficult and dangerous"" after this point. Complications do increase slightly with abortions carried out in later pregnancy, but a report by the National Academies of Science, Engineering and Medicine says serious complications remain very rare. In the US, 98% of all abortions take place within the first 15 weeks. During roughly the first 10-12 weeks of pregnancy, a non-surgical abortion can be carried out by taking two drugs - mifepristone and misoprostol. This has become the most common abortion method in the US and is widely considered by expert bodies to be safe. However, anti-abortion campaign group Students for Life of America, is one of several that claims the medication is dangerous. The group said in a post on Facebook: ""If the abortion industry truly cared about women's health they wouldn't encourage women to put their health and lives at risk with dangerous chemical drugs."" The Food and Drug Administration reports a rate of 0.35 deaths per 100,000 medication abortions - once again, a very low rate compared with the risks from live births. As the use of abortion pills has grown, another trend has emerged - the promotion of ""abortion-reversal pills"", advertised as a way to halt the procedure if a patient changes her mind after having taken the first of the two abortion pills. The American College of Obstetricians and Gynecologists says there is no evidence that these ""reversal"" pills are effective. And a trial of this method had to be halted before the results could be gathered, after three out of the 12 participants experienced dangerous levels of bleeding. Despite this, promoters of abortion reversal point to research that they say shows the drugs do work, and to case studies as proof. These studies have been criticised as poorly designed and ignore the fact that some pregnancies would continue anyway if only one of the two required abortion pills had been taken. Nevertheless, at least eight US states have passed laws requiring doctors to inform people having medication abortions about these ""reversal pills"" as an available option. ""The treatment for an ectopic pregnancy, a septic uterus, or a miscarriage that your body won't release, is abortion. If you can't get those abortions, you die,"" reads one Twitter post. There are hundreds of similar posts circulating online, suggesting these life-saving treatments will be prevented in states introducing strict abortion laws. All US states that have or are preparing to introduce bans on abortion have exceptions in their proposed legislation to save the life of the woman. In Arkansas, where abortion is banned except to save the woman's life, legislation states that the removal of a potentially life-threatening ectopic pregnancy - where an egg is fertilised outside the womb - is ""not an abortion"". Nevertheless, concerns remain over the health consequences for women of stricter abortion laws. Dr DeShawn Taylor, who runs a family-planning clinic, providing abortions in Arizona, has experienced this first-hand, having treated women with ectopic pregnancies who had been turned away from emergency departments. She said: ""The physician, who would be tasked with providing them the life-saving medication... won't do it because of their beliefs."" And, she adds, doctors may delay treatment, allowing patients' condition to worsen, until it's really clear it is life threatening. Posts shared hundreds of thousands of times have suggested a woman who has been raped could serve a longer sentence for having an abortion than her rapist would. However, most states that have imposed abortion bans target punishments at the abortion provider rather than the person having the abortion. Penalties already in place for abortion providers vary from one year in Ohio, for example, to life imprisonment in Texas and Alabama. So, could the punishment for a rapist in Alabama be less than that for the doctor who provides the abortion, as this tweet claims? In Alabama, the most serious category of rape - having sex with someone who is incapacitated and incapable of consent, or who is less than 12 years old and the offender is 16 or older - is a class-A felony, punishable by up to 99 years in prison. The next-most serious category - which could include an adult having sex with a 12-year-old - carries a maximum sentence of 20 years. So it's possible that an abortion provider could face a more severe penalty than a rapist in Alabama. However, much is still unknown about how the laws are going to be enforced."
"Covid Vaccines: No, your jab isn't magnetic",nan
Covid denial to climate denial: How conspiracists are shifting focus,"Members of an online movement infected with pandemic conspiracies are shifting their focus - and are increasingly peddling falsehoods about climate change. Matthew is convinced that shadowy forces lie behind two of the biggest news stories of our time, and that he's not being told the truth. ""This whole campaign of fear and propaganda is an attempt to try and drive some agenda,"" he says. ""It doesn't matter whether it's climate change or a virus or something else."" Originally from the UK, Matthew has been living in New Zealand for the past 20 years. The country is one of several that have aimed to completely stamp out Covid-19 through strict lockdowns. Troubled by the New Zealand government's approach, he turned to social media for news and community. The online groups he joined - opposed to vaccines and masks - exposed him to completely unfounded conspiracies about sinister global plots behind the Covid-19 pandemic. His immersion in this conspiratorial world has coloured his outlook and affected his relationships. He's speaking to me on a video call while hidden away at the end of his garden, because he's afraid his partner - who doesn't share some of his views - might hear him. And recently, groups like the ones he's a part of have been sharing misleading claims not only about Covid, but about climate change. He sees ""Covid and climate propaganda"" as part of the same so-called plot. It's part of a larger pattern. Anti-lockdown and anti-vaccine Telegram groups, which once focused exclusively on the pandemic, are now injecting the climate change debate with the same conspiratorial narratives they use to explain the pandemic. The posts go far beyond political criticism and debate - they're full of incorrect information, fake stories and pseudoscience. According to researchers at the Institute for Strategic Dialogue (ISD), a think tank that researches global disinformation trends, some anti-lockdown groups have become polluted by misleading posts about climate change being overplayed, or even a so-called ""hoax"" designed to control people. ""Increasingly, terminology around Covid-19 measures is being used to stoke fear and mobilise against climate action,"" says the ISD's Jennie King. She says this isn't really about climate as a policy issue. ""It's the fact that these are really neat vectors to get themes like power, personal freedom, agency, citizen against state, loss of traditional lifestyles - to get all of those ideas to a much broader audience."" One group which has adopted such ideas is the White Rose - a network with locally-run subgroups around the world, from the UK to the US, Germany and New Zealand - where Matthew came across it. ""It's not run by any one or two people,"" Matthew explains. ""It's kind of a decentralised community organisation, so you obtain stickers and then post them on lampposts and things like that."" These stickers bear slogans with anti-vaccine, anti-mask and conspiratorial content, including slogans such as ""Resist the New Normal"", ""Real Men Don't Wear Masks"", and false statements such as ""There Is No Pandemic"". Matthew first joined his local White Rose channel after seeing it advertised on a sticker - and he now puts up the same slogans on lamp posts around his home near Auckland. While we chat, he mentions ""The Great Reset"" - an unfounded conspiracy theory that a global elite is using the pandemic to establish a shadowy New World Order, a ""super-government"" that will control the lives of citizens around the world. Although he thinks some of the theories posted online are too conspiratorial, Matthew does believe there's a ""confluence of vested interests, the governments, major corporations"" running the show. His views are having a real impact on Matthew's life - setting him apart from those he's closest to. Recently, he says, he felt uncomfortable because his nine-year-old daughter was doing a climate change presentation at school. At the same time, he regrets falling down a conspiratorial rabbit hole. ""I have woken up every day the last three or four months, feeling very anxious around the world about the world and what's happening,"" he says. ""And I often wish I hadn't."" Christine is looking at this from the other side of the coin. She's a nurse in Belfast who has been treating Covid patients. During the pandemic, her girlfriend began to believe extreme conspiracies about Covid-19 and vaccines. She even started to think that Christine was part of a vast conspiracy. Just like Matthew, she joined the White Rose channel for her local area. The BBC contacted Telegram for comment. ""It's crazy. It's scary,"" Christine tells me just before she heads into the hospital for a night shift. Her girlfriend then got hooked by false claims about climate change - repeatedly posting about the topic on Instagram. It became so difficult, Christine had to call the relationship quits. ""She now believes climate change isn't real - and that everything is a scheme to depopulate the Earth and wipe out humanity."" Christine shakes her head in despair. As the pandemic progresses, vaccines take effect and many countries - particularly rich ones - inch closer to normality, this pivot from Covid towards climate change is something researchers have observed across a number of online spaces. One way that ISD has seen this play out is around the term ""climate lockdown"". It's used to refer to the completely unfounded idea that in the future we might have Covid-style lockdowns to counteract climate change. The term has found popularity with YouTubers who peddle conspiracy theories - but climate scientists say lockdowns would not be a serious climate change mitigation strategy. Covid lockdowns, for instance, only marginally reduced greenhouse gas emissions. However, the distress caused by Covid and lockdowns - and the falsehoods that have sprung up around them - have laid the groundwork for yet more conspiracies to spread. A mindset has gripped a group of people who blame all bad news on shady plots by powerful people - rather than accepting the reality about the future of the planet. With reporting from Ant Adeane"
Covid deniers blamed over Shrewsbury man Gary Matthews' death,"A man whose cousin died after a positive Covid test says coronavirus deniers are ""complicit"" in the death. Gary Matthews, 46, was found dead in his Shrewsbury flat the day after he tested positive. He had been part of a Facebook group that, according to his cousin Tristan Copeland, spread false conspiracy theories about Covid-19. ""I just wish these ideas had not taken over his life,"" Mr Copeland said. He claimed the group was now ""harassing"" the family and asking for a post-mortem test, but that the cause of death had ""already been confirmed due to being Covid by his dad, by the coroner, by the hospital who took his body"". Mr Matthews, who described himself as an artist and painter, lived alone but was close to his family and would talk to them regularly on the phone or over the internet. He was interested in conspiracy theories before the pandemic and joined the group last year, his cousin explained. ""I think they were complicit in Gary's death for sure,"" Mr Copeland said. ""They encouraged him not to wear a mask and I think if he had been wearing a mask, if he had been locking down, if he had not been going to work, I think he would have had a greater protection - I think he would be alive today."" The case was highlighted on Saturday in The Guardian, in which Mr Copeland said his cousin's life had been ""endangered by a flood of fake news"". Mr Copeland said his cousin had been sick for about a week before he went to get a test, adding Mr Matthews' family had begged him to take one. ""He tested positive and he was told to go home and isolate, which he did, and I think he died the next morning."" His father discovered his body. Mr Copeland added: ""[The family] feel harassed by this [Facebook] group and they have asked that people leave them in peace. ""They keep being approached by the group; they have been asking for an autopsy to investigate Gary's death. They do not believe he did [die from Covid]."" Mr Copeland said he regretted that he ended up muting his cousin on Facebook. ""I wish I had stayed in contact with Gary; spoken to him more over the past six months. ""His birthday was on the 10th of January and he passed on the 13th, I really wish I had reached out to him because I wanted to."" Follow BBC West Midlands on Facebook, Twitter and Instagram. Send your story ideas to: newsonline.westmidlands@bbc.co.uk"
Covid lockdown: Seven enduring claims fact-checked,"Opposition to the UK lockdown has led to street protests and campaigns on social media. Many of the grievances expressed have been fuelled by false and misleading claims. We've investigated seven of the most frequently-shared examples. Verdict: This figure and similar figures being widely shared, are incorrect. One recent estimate shows that overall, on average, about 99.3% of people who catch coronavirus survive it, according to statistics analysed by University of Cambridge. That might not seem like a big difference, but it means that about 70 in 10,000 people are expected to die - not three in 10,000. The death rate is much higher for older and more vulnerable people. And many people across all age groups suffer serious long-term effects from the virus. About 10% of people still have symptoms 12 weeks or more after their positive test, according to an Office for National Statistics (ONS) study. (The symptoms are wide-ranging, including cough, loss of smell, fatigue and sore throat. The study is still a work in progress. And it's worth noting that some people may have dropped out, and that those with symptoms are more likely to report them.) Verdict: The only reliable recent data available on suicides in England - from the University of Manchester - has found that rates have not risen during lockdown. Stay-at-home orders and the economic impact of the pandemic have undoubtedly taken a toll on people's mental health. However, shared posts saying suicides have gone up by 200% during the pandemic are false. Verdict:  Flu, a serious respiratory virus can be deadly - but there are vaccines and treatments available. Only very recently have vaccines for Covid-19 started to be rolled out, and only now are more effective treatments available. The long-term effects of Covid can also be much more severe for many people and it's more infectious than flu. Covid is also deadlier, says Prof Andrew Pekosz, faculty director at Johns Hopkins University in the United States. ""Covid-19 has a higher severe disease and mortality rate than influenza in all age groups, except perhaps children under the age of 12."" The risk of serious illness and death from coronavirus is significantly higher for older age groups. Verdict: More than 125,000 Covid deaths have been recorded in the UK so far. There are different ways of recording these deaths, but all broadly agree on the scale of the crisis. About 90% of the deaths where Covid appeared on the death certificate had the virus as the underlying cause attributed by a doctor, according to the ONS. The ONS total roughly matches up with Public Health England's count, which looks at anyone who died within 28 days after a positive test, as well as the number of excess deaths, which is measured against a five-year average. Almost all of these have been attributed to coronavirus, according to the UK's three national statistics agencies. Verdict: It's true that Sweden has had a lower Covid death rate than the UK, but it has fared significantly worse than its neighbours, all of which had tighter initial lockdown restrictions. Many people opposed to Covid restrictions point to the example of Sweden, a country which at the beginning of the pandemic avoided introducing a compulsory lockdown, and instead issued voluntary distancing advice. However, Sweden is a very different country to the UK and has characteristics that may have helped it during the pandemic. It has a lower population density, and a high proportion of people live alone. The capital, Stockholm, is also less of an international transit hub than London. When compared to other Scandinavian countries with similar population profiles, Sweden has fared much worse and recorded a significantly higher number of deaths than its neighbours, all of which have had tougher restrictions during much of the pandemic. It is hard to separate all the factors that might have caused this, but the absence of strict lockdown measures is likely to have contributed. There's also no evidence that Sweden's economy did any better than its neighbours. Although Sweden chose not to lock down early in the pandemic, with bars, restaurants and shops remaining open, increasingly tighter legally-binding restrictions have been imposed over the last five months. These include a ban on public gatherings of eight or more people, limits on numbers in stores, gyms and on bookable public transport and a stop on serving food and drink after 20:00. Daily reported deaths have been falling since early January, but the infection rate remains high. Verdict: Hospitals were very busy, particularly over the winter months, but the NHS has been able to cope, largely because of restructuring and lockdown restrictions. The strain on critical-care beds has been acute, along with the specialist staffing required. The number of adults in critical care was far higher than previous winters. In the last week of January 2021, some 2,000 more critical care beds a day were occupied in England compared with the previous year. Some non-Covid-related care has been shelved temporarily, and wards have been restructured to ensure the virus doesn't spread, which inevitably means fewer beds are available. In some hospitals, overall occupancy rates might have appeared lower than expected, but there's been a big effort to ensure enough spare capacity to cope with surges in coronavirus cases. Coronavirus has also had a big impact on staffing, with large numbers off sick or self-isolating. The PCR (polymerase chain reaction) test is considered the most reliable way to detect coronavirus. The process was invented in the 1990s, long before Covid appeared, by Californian scientist Kary Mullis. At a public event, he once said: ""With PCR, if you do it well you can find almost anything in anybody."" This has since been used to discredit PCR testing for Covid, but these criticisms are unfounded. Mr Mullis was referring to the high level of sensitivity of his test. PCR testing can pick up a tiny amount of virus, so it is possible for someone to get a positive result if they go for a test days or weeks after an infection and are not actually infectious any more. However, this is unlikely to have a significant effect on the number of cases, and people tend to have a test when they have symptoms."
Covid lockdown: Why Magna Carta wonÂt exempt you from the rules,"Business owners determined to escape coronavirus restrictions have resorted to citing obsolete and irrelevant laws. Sinead Quinn owns a hair salon in Oakenshaw near Bradford. She attempted to open the shop during lockdown, putting a sign in the window declaring that Article 61 of Magna Carta allowed her to opt out of the law and that she ""does not consent"". She now owes nearly Â£20,000 in fines and costs after repeatedly trying to defy coronavirus laws. Ms Quinn is one of a small number of business owners who have tried to use an obsolete clause in the 800-year-old charter of rights to insist on their freedom to reopen. Such attempts are part of a larger ""pseudolaw"" movement - the use of non-existent or outdated legal arguments to defend a case - which goes back decades. In addition to Article 61, this includes bizarre sounding and legally invalid concepts like ""freeman on the land"", ""sovereign citizens"" and ""legal name fraud"". They're all based on invalid legal arguments - and on several occasions they've resulted in fines and other legal trouble for the people who attempt to use them. Some might characterise such attempts as a wilful defiance of the law. But according to Ellie Cumbo, head of public law at the Law Society, such cases often arise from ignorance of the legal system, which is then made worse by poor advice found online. Ms Quinn has defended her actions, saying that she had a right to earn a living, gaining her support among fringe anti-lockdown campaigners. She has reportedly crowdfunded a five-figure sum to help pay her fines. She's one of several businesses in the UK, including a tattoo parlour in Bristol and a Christian bookshop in Nottinghamshire, whose owners claim the medieval charter gives them the right to ignore ""unjust"" laws. The same notice was posted in extreme anti-lockdown groups on social media, as part of a campaign that called for a ""great reopening"" of businesses in defiance of the law at the end of January, which largely failed to materialise. The BBC has asked Ms Quinn for comment. Magna Carta, signed in 1215 by King John, was a royal charter of rights designed to bring peace between the King and his barons. Although it is one of the foundational documents of English law, only four parts of Magna Carta remain valid today - including the right to a fair and timely trial. None of those still-valid clauses allows citizens to decide which laws should apply to them. The portion that the activists have been citing, Article 61, was struck from Magna Carta within a year of its signing, and only applied to a small group of barons in the first place, according to fact-checking website Full Fact. However, belief in Article 61 remains strong in extreme right-wing and anti-establishment circles. Despite the fact that it has no legal standing, it's held up as ""the one true law"" and seen as justification for rebellion against legal and political ""elites"". Ellie Cumbo of the Law Society says that the embrace of ""alternative"" legal concepts has parallels with the rejection in some quarters of so-called ""elitist"" scientific expertise across society, which has accelerated during the pandemic. ""Some think they can opt out of law in the same way that some people think they can opt out of science and vaccines,"" she says. Beyond Article 61, people are using other ""pseudolaws"" to try and fight prosecutions unconnected to Covid legislation. In recent months, there have been cases in English and Scottish courts where baseless legal concepts have been raised to avoid planning enforcement and driving offences. In January, a man said he did not consent to a ruling by Stockton Council's planning department that he should remove a balcony from his home, on the grounds that he was a so-called ""Freeman on the Land"" and did not recognise legal entities such as courts and local councils. Similarly, a man in Fife told the Kirkcaldy Sheriff Court in February that he did not recognise its authority, saying - according to Dundee's Courier newspaper: ""I am a living man, the blood flows, the flesh moves - I wish for remedy"". In both cases, their arguments did not prevail. In fact, no defence based on so-called freeman on the land, sovereign citizen or legal name fraud theory has ever succeeded in court. These theories aren't new either. Sovereign citizen theory - which maintains that the individual is independent of the state and can ignore its laws - has been around for decades, and is seen as a domestic terrorism threat by the FBI in the United States. A lack of basic legal knowledge means that people get the wrong idea about how law works, according to Ms Cumbo. ""We rightly celebrate Magna Carta as an important part of our legal system, so it's understandable that people think that the full original text still has full legal standing,"" she says. But there is a difference, she notes, between people who deliberately take a stand against laws passed by elites which they think are unfair or not particularly clear and those who have been swept along by bad legal advice from inaccurate sources found online. A final piece of advice for those wanting to use Magna Carta as the go-to law to fight any grievance? ""Go to a lawyer, not Google,"" Ms Cumbo says. Read more from Reality Check Send us your questions"
Covid misinformation on Facebook is killing people - Biden,"US President Joe Biden has warned that the spread of Covid-19 misinformation on social media is ""killing people"". He was responding to a question from a reporter about the alleged role of ""platforms like Facebook"" in spreading falsehoods about vaccines and the pandemic. The White House has been increasing pressure on social media companies to tackle disinformation. Facebook says it is taking ""aggressive action"" to protect public health. ""They're killing people,"" Mr Biden told reporters at the White House on Friday. ""The only pandemic we have is among the unvaccinated."" US health officials have warned that the country's current spike in Covid-19 deaths and infections is exclusively hitting unvaccinated communities. Earlier on Friday, White House Press Secretary Jen Psaki said Facebook and other platforms were not doing enough to combat misinformation about vaccines. ""Obviously, there are steps they have taken,"" she said. ""It's clear that there are more that can be taken."" A spokesman for Facebook, Kevin McAlister, said the company would ""not be distracted by accusations which aren't supported by the facts"". ""We've removed more than 18 million pieces of Covid misinformation [and] removed accounts that repeatedly break these rules,"" the company said in a separate statement. You get the sense Facebook is becoming increasingly tired of being criticised by US governments.Â Mr Trump and fellow Republicans believed Facebook was restricting free speech by cracking down on voter-fraud conspiracies. Mr Biden and his team have a different criticism - that Facebook doesn't do enough to take down conspiracies - such as anti-vax content.Â Last week the president signed an executive order aimed at trying to check the power of companies like Facebook. Facebook is by no means the only company that has been accused of failing to act on conspiracies. YouTube, for example, has been slammed for its moderation practices. That Mr Biden picks out Facebook is indicative of a personal grudge he has with the company.Â In January 2020 he told the New York Times: ""I've never been a big Zuckerberg fan. I think he's a real problem."" Concerningly for Facebook, Mr Biden is now the president, and his rhetoric is only getting harsher. Facebook has faced criticism for its moderation, and misleading content about the pandemic is still widely available on its platforms. Earlier on Friday Rochelle Walensky, director of the US public health body Centers for Disease Control and Prevention (CDC), told reporters: ""There is a clear message that is coming through: this is becoming a pandemic of the unvaccinated."" About 67.9% of US adults have received one dose of the vaccine, while 59.2% of adults are fully vaccinated. Many eligible people refusing vaccinations in the US have said they don't trust them. In March, a report said anti-vaccine activists on Facebook, YouTube, Instagram and Twitter had reached ""more than 59 million followers, making these the largest and most important social media platforms for anti-vaxxers"". That same month, Mark Zuckerberg, Sundar Pichai and Jack Dorsey - the CEOs of Facebook, Google and Twitter respectively - were questioned in Congress over disinformation. Mr Dorsey told the senators that Twitter was committed to moderating posts. Mr Pichai said YouTube worked to remove misleading content, and highlighted its role in relaying vaccine information. It comes after social media platforms admitted censoring revelations about politically embarrassing emails leaked from Mr Biden's son's laptop in the run-up to last November's presidential election. Twitter and Facebook blocked links to the New York Post reporting on Hunter Biden's dealings after his father's campaign team claimed without evidence that it was ""disinformation""."
Covid vaccinations: Anti-vaxers use 'crime number' to try to halt jabs,"Anti-vax campaigners are using a ""crime number"" issued to them by the police to claim vaccination centres are breaking the law. They were given the number after making a formal allegation to the Metropolitan Police that vaccines are dangerous. Police say it ""merely acknowledges"" an allegation has been received but there is currently no criminal investigation. On Thursday, campaigners tried to close a centre in Stockport, falsely claiming police were investigating a crime. Greater Manchester Police say officers were called by a group saying a crime was being committed at the health centre and it wanted the police to ""seize the evidence"". In a video shot by the protesters, one man falsely claims there is a ""live criminal case"", which will be ""fought through the courts"". Officers tell them that they will be arrested for aggravated trespass and the group then leaves the centre. The campaigners' claims about a police investigation stem from an allegation made to the Metropolitan Police on 20 December last year, accompanied by a large number of documents. They claim these contained evidence, gathered by a doctor and a former police officer, of the health risks of Covid vaccines. In a statement the Metropolitan Police said: ""A crime reference number was created and provided to the complainants. ""This is not an indication that an investigation is under way or that a crime has been committed. ""It merely acknowledges that an allegation has been received and recorded. ""While the assessment continues, to date there is nothing to indicate that a crime has been committed and no criminal investigation has been launched."" However, the concern is that there is a co-ordinated campaign to produce more ""evidence"" against vaccines which could take police forces months to deal with. The National Police Chiefs Council said: ""We are also aware of individuals attending police stations to report what they believe to be criminal offences relating to the Covid-19 vaccine. ""Police have a long history of upholding the right to freedom of expression. ""This must be balanced with the rights of others, keeping the public safe, preventing crime and disorder, and seeking to minimise disruption. ""Any efforts to intimidate, harass, or commit assault against emergency service workers, staff and volunteers will not be tolerated and will be treated and investigated as a criminal matter by police forces."" The visits to vaccination centres are being co-ordinated online by groups sharing a ""script"", which refers to a ""crime"" being committed, for members to deliver while talking to vaccination staff. The script says campaigners have the ""right to use force as is reasonable, necessary and proportionate in order to prevent that crime from happening"". The document also advises protesters: ""Do not become angry or disruptive to the vaccination centre."""
Covid vaccine hesitancy: Misinformation 'spreads faster than virus',"Covid vaccines are now open to most of the UK population, but some people - particularly young black people - are still reluctant to get a jab. Black adults are the most likely to be hesitant and people aged 18-21 are least likely to have a jab, according to data from the Office for National Statistics (ONS). BBC Radio 1Xtra's If You Don't Know podcast spoke to some people who said the reason for this was the spread of misinformation. YouTube has removed more than 900,000 videos related to dangerous or misleading information about Covid since February 2020, according to statistics given to the podcast. One person who was initially reluctant to have the vaccine because of rumours online is Grace. She's a mental health nurse for the NHS, which means she was offered the vaccine right at the start of the rollout. ""I didn't want it for the longest time,"" the 25-year-old from Milton Keynes tells the podcast. ""Social media was just moving so mad, telling me all the black people are going to be infertile, they're trying to kill us all off."" Not only is there no evidence that vaccines cause fertility problems in men or women, but experts say there's no realistic way they could. Claims to the contrary on social media are false. Despite being ""really shocked"" by those claims, Grace soon realised that a return to normal life wouldn't happen without having the vaccine - so she agreed to take it. Sharnie Crooks is a student from London and has decided against booking a Covid jab in for the moment, ""simply because it hasn't been around for long enough"". The 19-year-old is worried the speed that vaccines have been developed means we don't yet know about any potential long-term side effects of taking it. ""I personally feel as though the nation has been very much rushed into taking it and I'd like to wait for more research to just be carried out."" Speaking on the podcast, Dr Tosin Sotubo, a black doctor, says she's ""had all kinds of conversations"" about the vaccine and has heard concerns like Sharnie's. ""People are nervous that the vaccine is coming around too fast, wondering if we're experimenting with it, if we know the real side effects, and some have religious concerns."" Dr Tosin admits having to ""pause and think"" about the speed of vaccine development herself. But she says people should realise ""the research and foundation of the vaccine was in the works for many years"" and governments around the world pumped money into developing a Covid jab, to help speed up the process. ""The vaccine didn't skip any steps, it had to pass the same safety regulations all other vaccines pass."" Checks continue to happen after approval to make sure there are no further side effects or long-term risks. Another factor around hesitancy, she says, is the long-term differences in healthcare between white people and ethnic minorities, in things like maternal mortality rates. Black women in the UK are much more likely to die from complications surrounding pregnancy and childbirth than white women, according to a 2019 report. ""When you see those disparities and black people are more affected in some cases, compared to their white counterparts, you have to question if we're doing enough,"" Dr Tosin says. ""We need to talk to the black community and educate them around the facts."" She says at times it feels like ""misinformation spreads faster than the virus"", adding: ""It's crazy how one message can go completely viral and that message becomes the 'truth'."" But she encourages people to take the jab: ""You're taking the vaccine for everyone globally."" Follow Newsbeat on Instagram, Facebook, Twitter and YouTube. Listen to Newsbeat live at 12:45 and 17:45 weekdays - or listen back here."
Covid vaccine: 'Disappearing' needles and other rumours debunked,"The roll out of Covid-19 vaccines in the UK and US this week has led to a spate of new false claims about vaccines. We've looked into some of the most widely shared. BBC News footage is being passed off as ""proof"" on social media that Covid-19 vaccines are fake, and that press events showing people being injected have been staged. The clip, from a report which aired on BBC TV this week, is being shared by anti-vaccine campaigners. They claim fake syringes with ""disappearing needles"" are being used in an attempt by the authorities to promote a vaccine that doesn't exist. One version posted on Twitter has had more than 20,000 retweets and likes, and half a million views. Another major spreader of the video has been suspended. The posts use genuine footage showing healthcare professionals using a safety syringe, in which the needle retracts into the body of the device after use. Safety syringes have been in widespread use for over a decade. They protect medical staff and patients from injuries and infection. It's not the first time claims of fake needles have appeared since vaccine roll out began. One showed an Australian politician posing with a syringe next to her arm, the needle clearly covered with a safety cap, with claims that her Covid-19 vaccination had been faked. But in reality, it showed Queensland premier Annastacia Palaszczuk posing for the cameras after receiving a flu vaccine in April. The video has had close to 400,000 views on Twitter. Photographers had asked for more photos because the real injection happened too quickly. Public Health authorities in Alabama released a statement condemning ""misinformation"" after a false story that a nurse died after taking the coronavirus vaccine spread on Facebook. The state had just started injecting its first citizens with the jab. After being alerted to the rumours, the department of public health contacted all vaccine-administering hospitals in the state and ""confirmed there have been no deaths of vaccine recipients. The posts are untrue."" The story emerged with Facebook posts saying one of the first nurses - a woman in her 40s - to receive the Covid vaccine in Alabama, was found dead. But there's no evidence this has happened. One user said it happened to her ""friend's aunt"" and posted text message conversations she said she'd exchanged with the friend. Some of the original posts about the nurse are no longer online, but screenshots are still being shared and commented on. One of these suggests the incident took place in the city of Tuscaloosa, Alabama. The city hospital told us the very first Covid vaccine was only administered on the morning of 17 December - after the reference to Tuscaloosa was mentioned on Facebook. As of 00:30 on 18 December, the US Centers for Disease Control say they have received no reports of death anywhere in the country following the coronavirus vaccine. The posts have been labelled ""false"" on Facebook but some people claim without evidence that the ""powers that be are already trying to cover it up"". A 30-minute video which went live as the first people in the UK received the Pfizer Covid-19 vaccine, contains a host of false and unsubstantiated claims about the pandemic. The film, called ""Ask the experts"", features around 30 contributors from several countries, including the UK, US, Belgium and Sweden. Covid-19 is described by one of these people as the ""greatest hoax in history"". It begins with the claims that there is ""not a real medical pandemic"", and that the coronavirus vaccine is not proven safe or effective because there ""has not been enough time"". Both of these claims are untrue. The BBC has written at length about how any vaccine approved for use against coronavirus will have been rigorously tested for safety and efficacy. It's true Covid-19 vaccines have been developed at a remarkable pace, but none of the steps needed to ensure safety have been skipped. ""The only difference is that some of the stages overlapped so, for example, phase three of the trial - when tens of thousands of people are given the vaccine - started while phase two, involving a few hundred people, was still going on,"" says BBC Health reporter Rachel Schraer. Other participants in the video who appear on screen repeat the same unfounded claims. We also hear inaccurate theories about the technology behind Pfizer's Covid-19 vaccine. And that, because of the pandemic, the pharmaceutical industry has been given permission to ""skip the animal trials...we humans will be the guinea pigs."" This is false. The Pfizer BioNTech, Moderna and Oxford/AstraZeneca vaccines have all been tested in animals as well as thousands of people, before they could be considered for licensing. The video was posted on a hosting platform that positions itself as an alternative to YouTube, says Olga Robinson, a disinformation expert from BBC Monitoring. ""Promising low content moderation, sites like this have in the past months become a go-to place for those users kicked off major social media platforms for spreading misinformation."" Additional reporting by Alistair Coleman and Olga Robinson."
Covid vaccine: Fertility and miscarriage claims fact-checked,"False and misleading claims about Covid-19 vaccines, fertility and miscarriages are still circulating online, despite not being supported by evidence. Doctors are extremely cautious about what they recommend during pregnancy, so the original advice was to avoid the jab. But now, so much safety data has become available that this advice has changed and the vaccine is now actively encouraged (as getting Covid itself can put a pregnancy at risk). We have looked at some of the more persistent claims - and why they are wrong. This theory comes from a misreading of a study submitted to the Japanese regulator. The study involved giving rats a much higher dose of vaccine than that given to humans (1,333 times higher). Only 0.1% of the total dose ended up in the animals' ovaries, 48 hours after injection. Far more - 53% after one hour and 25% after 48 hours - was found at the injection site (in humans, usually the arm). The next most common place was the liver (16% after 48 hours), which helps get rid of waste products from the blood. The vaccine is delivered using a bubble of fat containing the virus's genetic material, which kick-starts the body's immune system. And those promoting this claim cherry-picked a figure which actually referred to the concentration of fat found in the ovaries. Fat levels in the ovaries did increase in the 48 hours after the jab, as the vaccine contents moved from the injection site around the body. But, crucially, there was no evidence it still contained the virus's genetic material. We don't know what happened after 48 hours as that was the limit of the study. Some posts have highlighted miscarriages reported to vaccine-monitoring schemes, including the Medicines and Healthcare products Regulatory Agency (MHRA) Yellow Card scheme in the UK and the Vaccine Adverse Event Reporting System (VAERS) in the US. Anyone can report symptoms or health conditions they experience after being vaccinated. Not everyone will choose to report, so this is a self-selecting database. There were indeed miscarriages reported in these databases - they are unfortunately common events - but this does not mean the jab caused them. A study has found data showing the miscarriage rate among vaccinated people was in line with the rate expected in the general population - 12.5%. Dr Victoria Male, a reproductive immunologist at Imperial College London, says these reporting systems are very good for spotting side-effects from the vaccine that are normally rare in the general population - that's how a specific type of blood clot was linked in some rare cases to the AstraZeneca vaccine. If you suddenly start seeing unusual symptoms in vaccinated people, it raises a red flag. They are not so good at monitoring side-effects that are common in the population - such as changes to periods, miscarriages and heart problems. Seeing them in the data doesn't necessarily raise these red flags because you'd expect to see them anyway, vaccine or not. It's only if we start getting many more miscarriages than are seen in unvaccinated people that this data would prompt an investigation - and that's not been the case so far. Some people have also shared graphs showing a big rise in the overall number of people reporting their experiences to these schemes compared with previous years, for other vaccines and drugs. This has been used to imply the Covid vaccine is less safe. But the rise can't tell us that, it can only tell us that lots of people are reporting - possibly because an unprecedented proportion of the population is being vaccinated and it is a much talked-about subject. A widely shared petition from Michael Yeadon, a scientific researcher who has made other misleading statements about Covid, claimed the coronavirus's spike protein contained within the Pfizer and Moderna vaccines was similar to a protein called syncytin-1, involved in forming the placenta. He speculated that this might cause antibodies against the virus to attack a developing pregnancy, too. Some experts believe this was the origin of the whole belief that Covid vaccines might harm fertility. In fact syncytin-1 and the coronavirus's spike protein are just about as similar as any two random proteins so there is no real reason to believe the body might confuse them. But now evidence has been gathered to help disprove his theory. US fertility doctor Randy Morris, who wanted to respond directly to the concerns he'd heard, began monitoring his patients who were undergoing IVF treatment to see whether vaccination made any difference to their chances of a successful pregnancy. Out of 143 people in Dr Morris's study, vaccinated, unvaccinated and previously infected women were about equally likely to have a successful embryo implantation and for the pregnancy to continue to term. The women were similar in most other respects. The study is small, but it adds to a large volume of other evidence - and were the claim true, you would expect that to show up even in a study of this size. Dr Morris pointed out that people spreading these fears had not explained why they believed antibodies produced in response to the vaccine could harm fertility but the same antibodies from a natural infection would not. The problem is, while scientists are rushing to provide evidence to reassure people, by the time they can report their findings people online have moved on to the next thing. As Dr Morris explained: ""The hallmark of a conspiracy theory is as soon as it's disproven, you move the goalpost."" Follow Rachel on Twitter"
Covid vaccines: Misleading claims targeting ethnic minorities,"There have been growing concerns about the uptake of Covid vaccines among black, Asian and other ethnic minority communities in the UK. Some fear vaccine ""hesitancy"" could be increased by false and misleading information shared online. We've been investigating some examples. In the early months of the pandemic, a video was widely shared online of two French doctors discussing the initial testing of a possible vaccine in Africa first, before being tried elsewhere. The comments, which led to an angry response on social media, fuelled existing concerns that Africans could be used as ""guinea pigs"" for a future Covid-19 vaccine. But that didn't happen - vaccine trials got under way in sites spread around the world. The Oxford University vaccine team, for example, initiated testing in the UK and later in Brazil and South Africa. The Pfizer-BioNTech vaccine had clinical trial sites in Argentina, Brazil, Germany, Turkey, South Africa and the US. In June, Health Secretary Matt Hancock announced initial advice from the Joint Committee on Vaccination and Immunisation (JCVI) on who might be first in line for a vaccine, including health and social care workers and those at increased risk of serious disease from coronavirus. He added that ""we will continue to take into account which groups may be particularly vulnerable, including those from ethnic minority backgrounds. So we can protect the most at risk first should a vaccine become available"". But his comments were greeted with suspicion by some and sparked more claims about ethnic minority people being used as ""guinea pigs"" for the vaccines. A black British woman posted a video in June saying, ""why should these vaccines be trialled on me and my people"". In the end, ethnic minority groups were not included on the priority list, which includes the elderly, those in care and frontline health workers. The video - which has had around 50,000 views - also falsely claimed that people had already died from the ""trial vaccines"". There were no deaths caused by vaccines administered during the Pfizer and Oxford trials. Some of the most persistent myths surround the contents of the vaccines. We've previously dealt with false claims that they contain microchips, aborted fetus cells or that they can somehow alter our human genetic code (DNA).  None of these are true. But there have also been specific concerns over whether they may contain ingredients that are forbidden under religious beliefs. Rumours that vaccines contain traces of pork (not eaten by Muslims) or beef (cows are considered sacred by Hindus) have been circulating online, particularly within South Asian communities. It's true that some other non-coronavirus vaccines have contained gelatine derived from pork, added as a stabiliser.  However, none of the Covid-19 vaccines currently approved for use in the UK contain gelatine. In fact, the body that approves vaccines has made it clear that the Moderna, AstraZeneca and Pfizer vaccines ""do not contain any components of animal origin."" ""We need to be clear and make people realise there is no meat in the vaccine, there is no pork in the vaccine,"" says Dr Harpreet Sood, who is leading an NHS anti-disinformation drive. He adds that this ""has been accepted and endorsed by all the religious leaders and councils and faith communities"". Some of the anti-vaccination discussion online has referenced cases of mistreatment of black people by the medical establishment in the past. The Tuskegee scandal is one example. From the 1930s, and lasting for several decades, hundreds of African American men had their syphilis left untreated without their knowledge as part of an experiment. Dozens suffered terribly and died and the case remains one of the worst examples of racism from the field of medical research. More recently the case has been used to stoke fears about medical malpractice in the black community online. There is of course no evidence of any  unethical practice in any of the vaccine trials. The teams behind the research say they have ensured a diverse range of trial participants. To take the example of the Pfizer trial in the US, 10% of participants were black, 13% Hispanic, 6% Asian, 1.3% Native American, with the rest white. ""While it's important to acknowledge unethical experiments on black people, to ensure those in power don't let it happen again, using these examples to deter people from taking the coronavirus vaccine is exploitative,"" says Dr Winston Morgan, reader in toxicology and clinical biochemistry at the University of East London. ""Trying to compare what happened [then] to what's happening now is wrong."""
Covid-19 leaflets: How pandemic disinformation went offline,"False and misleading information about the coronavirus pandemic has proliferated online over the past year, but it's also now become a familiar sight on doormats across the country. Charles Crane was watching television one evening when a DVD in an unmarked plastic wallet landed in his hallway. On the disc was a 45-minute video claiming to expose ""the truth"" about coronavirus vaccines. One section promoted the debunked theory that the vaccine could alter the recipient's genetic code, or DNA. Another discredited idea put forward in the video was that micro-particles within the vaccine are able to collect and transmit biometric data. ""I was appalled at the whole thing,"" says Mr Crane. ""Many of my neighbours are in their 80s, and could easily be discouraged from taking the vaccine if they saw this off-the-wall material."" Mr Crane, who alerted BBC Look East about his unwanted delivery, is far from alone in receiving such material. A newspaper dropped through Mark Langford's letterbox. It was called The Light. ""The first thing you saw was the main headline: 'Covid jabs kill and injure hundreds.' I was horrified."" Mr Langford confronted the woman who had delivered it. She told him she was a nurse, that the pandemic was a hoax and that no-one had died from coronavirus. He said he didn't believe a nurse would say that but didn't challenge her credentials at the time. The paper itself contained an article listing people who had allegedly died after receiving the vaccine, but provided no evidence that any of these deaths had been caused by the jab. Another section of the paper claimed face masks were responsible for ""thousands"" of deaths from bacterial pneumonia. There is no evidence whatsoever for this claim. The Light calls itself a ""truthpaper"" and is managed through a Facebook group with about 6,000 members. Reports of it have appeared across the country, most recently being tucked under doors in Manchester. We approached the paper for comment and received a reply with links to government reports on vaccine side-effects. There is a fundamental difference however, between the reporting on side-effects in these government documents and the misleading, sensationalised claims of widespread deaths and injuries from the vaccine. Another article published in The Light claimed face masks can damage the brain. The World Health Organization is clear in its guidance: ""The prolonged use of medical masks can be uncomfortable. However, it does not lead to CO2 intoxication nor oxygen deficiency."" A Facebook post including a photograph of the article was shared 64,000 times and subsequently flagged as ""false"" by a fact-checking website. ""My worry is there are other people who haven't been paying attention to the news and then this lands on the doorstep,"" says Mark Langford. We've been alerted to many similar leaflets in recent months. A flyer calling the pandemic an ""illusion"" has been spotted in both Leicester and Manchester, falsely claiming there were just 1,614 UK deaths from Covid up to October last year. The official UK death toll at the end of that month was 46,555. Another leaflet doing the rounds warns of oxygen-reducing face masks, untested and unproven vaccines and says that we've all been hoodwinked during the pandemic, calling it a ""global scam"". A copy of this flyer dropped through the door of former journalist John Andrews in Cambridge. ""I would find these claims of a worldwide conspiracy involving every health worker, immunologist, epidemiologist, virologist, and journalist funny if they weren't so widely believed, and so dangerous,"" he says. It's not possible to say how many of these leaflets are being distributed around the country. But the existence of an online site providing all the tools needed to put these leaflets together, and to spread these false and misleading stories, does suggest a fairly significant level of organisation. On the site (which we've chosen not to name), there is a choice of leaflets to download as well as stickers for sale. There's also advice on how to refuse a vaccine, ways to reject wearing a face mask at work and advice on avoiding coronavirus testing of your child at school. These examples are just the tip of the iceberg of leaflets being distributed. Others cover the widest range of conspiracy theories from anti-Semitic tropes, to those of the QAnon movement with its promotion of the falsehoods that an elite group of Satan-worshipping paedophiles operates in government, business and the media. Some leaflets simply present a QR code, which links to a website full of pandemic-related conspiracy theories, suggesting these flyers also serve as a way of drawing people into the mire of online disinformation."
Covid-19: Debunking the latest wave of medical misinformation,"Posts spreading unverified theories about the pandemic continue to spread on social media platforms. We've examined the latest wave of false information covering subjects including Covid testing kits and vaccines. Lateral flow tests for coronavirus are becoming widespread in workplaces and schools, but viral Facebook posts are incorrectly claiming that they are a cancer risk. The videos and photos claim that they contain ethylene oxide, a known carcinogen. The packaging for the NHS test kits says ""sterilised in ethylene oxide"", but this only tells part of the story. The Department of Health and Social Care told us that while the chemical is used in gaseous form to sterilise test swabs, the amounts used are well within safety limits and are ""rigorously tested and are safe to use on a regular basis"". In fact, up to half of all US medical devices are sterilised with ethylene oxide, which is an effective method that doesn't damage equipment. Further stages in the sterilisation process remove the gas almost entirely. The US Centers for Disease Control says that while acute exposure to the chemical - many times greater than any residual chemical that might be left in a test swab - can increase the risk of cancer, these tiny amounts are not harmful. A blog post claiming that rates of miscarriage ""as a result"" of receiving a Covid-19 vaccine have increased by 366% has been shared widely on social media. There is no evidence that Covid-19 vaccines can increase the risk of miscarriage. The figures used in the blog post are a distorted interpretation of data from the yellow card scheme of the UK medicines regulator, the MHRA. The scheme allows health professionals and the public to report medical incidents or suspected side effects of medicines, so that their quality and safety can be monitored and very rare side effects picked up. Data showing a miscarriage occurred after a vaccine does not mean that the two events are linked. Miscarriage is sadly very common, and among women who know they're pregnant, about one in eight pregnancies will end in miscarriage, according to the NHS. Identifying miscarriages that happen after a vaccine allows the MHRA to assess whether the number of miscarriages in the vaccinated population is any higher than usual. The claim that miscarriages among vaccinated people have increased by 366% is taken from an increase in the number of miscarriages reported to the yellow card scheme since Covid-19 vaccines first started being rolled out in December and January. It doesn't take into account the fact that millions more people have been vaccinated since January - which would lead to an expected increase in reports to the yellow card scheme. In a response to the Reuters news agency about the claims, the MHRA said: ""There is no pattern to suggest an elevated risk of miscarriage related to exposure to the Covid-19 vaccines in pregnancy."" But it added that current advice does not routinely recommend Covid-19 vaccines for pregnant women because of limited data, and that?individuals at high risk?from?the virus could?talk to a doctor about vaccination. A recent cause taken up by anti-vaccination activists concerns the spread of new coronavirus variants. Many referred to statements published by Geert Vanden Bossche, a Belgian veterinarian and vaccine researcher. He says he supports vaccines, but in a series of letters warns about the dangers of Covid-19 vaccinations, which he says risk creating new variants of coronavirus that may ""result in a global catastrophe without equal"". The World Health Organization says that as more people get vaccinated it expects ""virus circulation to decrease, which will then lead to fewer mutations."" All viruses mutate as they make copies of themselves to spread and thrive. Viruses do this in different ways, including while inside the bodies of people who have already been vaccinated but who are still developing an immune response. This may drive the virus to evolve to escape the effects of such immunity. Scientists are studying whether the vaccines still work against new strains of the virus and from where such mutations come. These types of mutations might be happening even now at a low level, says Dr Julian Tang, a virologist at the University of Leicester, ""but this is less of a concern relatively, compared to getting more people vaccinated against the virus strain that is still circulating widely, globally."" There are risks associated with mutations that evolve in largely vaccinated populations, says Dr Ravi Gupta, a microbiologist at University of Cambridge who has been researching new variants. But he says: ""The benefits of mass vaccination to curb transmission...outweigh the risks."" As such, according to the experts we spoke to, there's no evidence that vaccines will lead to more dangerous variants that would merit the drastic change in strategy being suggested by Mr Bossche. We requested a comment from Mr Bossche, who referred us to his website where he has previously responded to questions about his work. Finally, a post that echoes another familiar theme of pandemic-related misinformation - the totally fabricated link between 5G electro-magnetic radiation and coronavirus. Russian doctors have performed post-mortem examinations on Covid-19 patients and discovered proof that Covid ""does not exist as a virus"", claim the posts on secure messaging app Telegram which say the people examined died of ""electromagnetic radiation"". There's no evidence of this happening. A near identical post - claiming to cite Italian health authorities and doctors - went viral in spring last year. These theories simultaneously referred to radiation poisoning and claimed that Covid is caused by a bacteria and not a virus - which is also incorrect. The recent iteration of the copy and paste postings are incorrectly sourced to the Russian health authorities this time. The claim has been circulating on Facebook in Austria and Germany since at least late February and a shortened version of the message was shared in big anti-vaccine and QAnon conspiracy channels on Telegram. Additional reporting by Olga Robinson and Alistair Coleman. Read more from Reality Check Send us your questions"
Covid-19: Facebook to take down false vaccine claims,"Facebook says it will start removing false claims about Covid-19 vaccines to prevent ""imminent physical harm"". The company says it is accelerating its plans to ban misleading and false information on its Facebook and Instagram platforms following the announcement of the first vaccine being approved for use in the United Kingdom. Among already-debunked claims that won't be allowed are falsehoods about vaccine ingredients, safety, effectiveness and side-effects. Also banned will be the long-running false conspiracy theory that coronavirus vaccines will contain a microchip to control or monitor patients. Facebook has come under fire for what's been seen as a patchy approach to fake news and false claims, and misleading content about the pandemic is still widely available on its platforms. It says it will remove false claims about Covid-19 vaccines ""that have already been debunked by public health experts"". Facebook says that since January it has been removing content about the pandemic, such as false cures and treatments or claims that the disease doesn't exist at all. In October, it banned advertisements that discouraged people from taking vaccines. This is a continuation of the policy ""to remove misinformation about the virus that could lead to imminent physical harm"", the company said. ""This could include false claims about the safety, efficacy, ingredients or side effects of the vaccines [and] false claims that Covid-19 vaccines contain microchips, or anything else that isn't on the official vaccine ingredient list. ""We will also remove conspiracy theories about Covid-19 vaccines that we know today are false."" However, Facebook warned that these policies, which the BBC understands have been brought forward following the approval of the Pfizer/BioNTech vaccine by the British medicines regulator, will take some time to come into effect. ""We will not be able to start enforcing these policies overnight,"" a Facebook statement said. Social media is awash with conspiracy theories about coronavirus vaccines, which resurface whenever news breaks - like the approval of the Pfizer/BioNTech vaccine for use in the UK. These conspiracies are worlds away from legitimate concerns, making false allegations of microchipping, genocide and DNA alternation. For that reason, many will welcome the announcement of this crackdown by Facebook - including politicians who have been calling for action from the social media giants. It's tougher than previous announcements - this time a commitment to removing conspiracies rather than just fact-checking or labelling these posts as misleading. But fears remain that yet another commitment to tackle misinformation by the social media site will not translate into effective action - or be the right approach. Conspiracy narratives about the coronavirus vaccine have become so prevalent, often originating in anti-vaccination and pseudoscience circles before spilling into parent chats, community forums and Instagram feeds. Undoing those narratives months after they first began to spread may not be enough to reverse the seeds of doubt they have sown in communities around the world. While Facebook's announcement has been broadly welcomed, there are concerns that the company might not follow through on its promises. Imran Ahmed, CEO of the Center for Countering Digital Hate, said in a statement: ""Today's policy change is long overdue, but there is no guarantee that it will be properly enforced."" ""As we saw in the months following Facebook's promise to remove misinformation about coronavirus earlier this year, they rarely enforce their own policies"". Mr Ahmed went on to urge governments to accelerate plans to regulate harmful online content. ""They must introduce tough regulations as soon as possible to ensure these policies are enforced, including criminal sanctions for breaches of their duty to remove harmful material that puts lives at risk."" The UK government has been planning an Online Harms Bill for this very purpose, but it has been criticised over ""unacceptable"" delays in its publication, while Jo Stevens, Labour's Shadow Secretary of State for Digital, called for emergency legislation ""to protect people from this dangerous disinformation""."
Covid-19: Fake 'immunity booster' found on sale in London shops,"Fake ""Covid-19 immunity boosters"" are being sold over the counter in London shops, a BBC investigation has found. Coronil, a herbal remedy from India, was found on sale in shops in predominantly Asian areas across the capital. Manufacturers Patanjali Ayurved claim the pills protect against ""respiratory tract infections"". Tests carried out for the BBC show the pills offer no protection from coronavirus. A lab test of the drug carried out by Birmingham University for the BBC showed the pills contained plant-based ingredients which cannot protect against Covid-19. Virologist Dr Maitreyi Shivkumar said the idea of ""boosting"" immunity makes no sense in terms of treating coronavirus. ""There are lots of nuances in how our immune system responds to the virus. We do not even know that heightening immunity helps,"" she said. ""It is unclear what Coronil is trying to do to the immune system."" UK advertising rules ban references to Covid-19 and ""boosting immunity"". Similar claims are permitted in India, where Patanjali Ayurved has a large following. One shop in Wembley advertises Coronil as a ""Covid-19 immunity booster"" both in store and on its website. The BBC has located at least four other stores that sell the pills, claiming they treat Covid-19. One customer told the BBC: ""I take it because I'm 78. ""If I go out shopping I could catch coronavirus from anybody. That's why I take itÂ to protect myself."" There are no authorised health claims in the UK that any substance can ""boost"" immunity, according to the Advertising Standards Authority (ASA). Claims to prevent, treat or alleviate the symptoms of coronavirus cannot be made without a product being licensed by the Medicines and Healthcare products Regulatory Agency (MHRA). The MHRA, which has not approved Coronil for any use, said: ""Appropriate action will be taken where any unauthorised medicinal product is offered or sold on the UK market."" Patanjali Ayurved founder Baba Ramdev claimed in June that Coronil had cured Covid-19 patients. ""Our medicine resulted in 69% of coronavirus patients testing negative after three days and 100% after seven days,"" he said. The Indian government has said Patanjali Ayurved can market Coronil as an immunity booster but not a cure. Patanjali Ayurved has now withdrawn its claim that Coronil is a cure for Covid-19. According to Full Fact, an independent fact-checking organisation, ""misinformation like this can cause harm to people's health and finances"". Abbas Panjwani, a researcher at Full Fact, said: ""During a pandemic, it is natural and perhaps understandable for people to seek out answers."""
Covid-19: How did a volunteer panel react when we showed them an anti-vax video?,"Activists have been targeting people with fears about vaccines in a social media blitz. In an experiment, BBC Panorama showed a panel one video filled with falsehoods to see how it affected their willingness to get a jab. In a sleepy suburb of Norwich, 83-year-old Rosemary opens a WhatsApp message from a relative. It contains a video called Ask the Experts. The clip features people with impressive medical and scientific titles based in the UK, US, Spain and Sweden. Some allege, contrary to the evidence, that Covid-19 vaccines are unsafe, that they can alter a person's DNA - and even that the pandemic is somehow not real. Rosemary is frightened - and suddenly unsure about whether she'll get vaccinated. ""It sounded so real and the people were so plausible and they were named as clinicians and doctors,"" she says. With the majority of the elderly and at-risk groups having had their jabs, the next big challenge for the government is to vaccinate everyone else in the UK. Most people say they want a jab, but the latest anti-vaccine tactics deployed by a committed minority seek to exploit people's nervousness. Rosemary is just one of millions exposed to tactics used by anti-vaccine activists - a loose collection of people who make a variety of claims about vaccines, including suggesting they are dangerous and a form of state control. Over the course of 27 minutes, the Ask the Experts video relentlessly introduces 33 people, many brandishing their credentials, often sitting in what look like medical consultation rooms. They confidently and calmly repeat similar messages - although many of the claims are misleading or just plain untrue. Rosemary was left shocked as these people - who looked similar to the doctors she would usually turn to for sound advice -  said that Covid-19 was ""not a real medical pandemic"", that vaccines alter your DNA, that they cause infertility and that they're part of a deliberate global plan to hurt people. She's not alone in being scared by the video. One London council has issued a warning after the Ask The Experts video started circulating in Asian and black communities. These groups have been disproportionately affected by coronavirus - and there are indications that some ethnic minority groups have a higher level of reluctance when it comes to Covid-19 vaccines. ""The fact that they are targeting it at those communities will mean that there will be people who die as a result of not having the vaccine,"" says Westminster council leader Rachael Robathan. Despite being removed from YouTube, Twitter and Facebook, it's been claimed that Ask the Experts has been seen more than 250,000 times. It's gone viral on WhatsApp and its producers have been asking for donations via PayPal. The video is just one part of an online anti-vaccine blitz. Exclusive research by BBC Monitoring has found a huge increase in followers of social media accounts promoting anti-vaccine material during the pandemic. These aren't accounts asking legitimate medical questions - but people and organisations who've already made up their minds against vaccinations, and are manufacturing evidence or twisting facts to support their conclusions. On Instagram, the number of followers of major anti-vaccination accounts increased nearly five-fold in 2020, to more than four million. On Facebook, the top anti-vaccination pages grew by 19% in the last year and followers of Twitter accounts sharing anti-vaccine claims almost trebled. The increases came alongside a huge overall surge in people seeking out health information online due to the pandemic. But the raw numbers still mean false anti-vaccine claims are reaching millions more than ever before. How do the misinformation and conspiracy theories pushed by the video affect the views of people who have legitimate questions about vaccines? I ran a test for BBC Panorama. Our team assembled a panel of eight people from across the country who were unsure about having a Covid-19 vaccine. Logging on to a Zoom call on a January evening, they view the Ask the Experts video as we observe their reactions. Our experiment happens under the watchful eye of Dr Liam Smeeth, a professor of epidemiology at the London School of Hygiene and Tropical Medicine who's also a GP. Rob - a 27-year-old volunteer radio DJ in Norfolk who's spending the latest lockdown trying to raise people's spirits with music - questions the speed of vaccine trials. It's a concern shared by 20-year-old law student Phoebe, who has other worries. ""Every time I search about the Covid vaccine and fertility, it literally changes, so often it's quite overwhelming,"" she says. Experts say that the coronavirus vaccines have gone through the same rigorous process as other vaccines - and there's no biological mechanism by which it could affect fertility. After expressing their concerns, the panel begins watching Ask the Experts. I didn't tell them what the video was about - and reactions vary. Eddie, a 76-year-old from Northumberland, furrows his brow in front of a backdrop of watercolours he's painted during lockdown. ""I thought at first 'Are these actors? Is this just a sham?'"" he says. ""And as I went on, I realised that they were real."" Another person in the video appears wearing a white lab coat, pictured in what looks like a hospital. Matt - a 31-year-old who works in IT - nods along, listening attentively. ""I feel I could trust some of them,"" he says, eyes glued to the screen. But the footage turns off others. As one of the people in the video argues, with an air of authority, that this is ""not a real medical pandemic"", Russell from Norwich puts his head in his hands. He was ill with coronavirus last year. ""Blimey! It's like being hit over the head a number of times. For half-an-hour,"" he says. ""I feel like I'm being brainwashed."" Phoebe, the law student, also senses she's being fed misinformation. She crumples her face in disgust. ""If these people are saying the virus isn't real, I'm less inclined to believe what they say about the vaccine being dangerous,"" she says. However, after watching the video half of the group says they are more worried about having a Covid-19 vaccine than before. ""It's being rushed, and there hasn't been too much information,"" says decorator Steven from Inverness, who has had cancer. ""I do agree with all that part of it."" Shaun, who's a chef, was also swayed. ""The video says what I've had in the back of my mind,"" he says, running his hand through his hair as he tries to make sense of what he has just watched. Dr Smeeth's main fear, that the video would amplify people's pre-existing fears, has materialised. He wants any doctor or professional promoting false claims to face disciplinary action. ""I would certainly be very pro them being investigated and any evidence of harm being looked at,"" he says, ""and them being stopped from using their title."" We have one more question - in the face of bad health information, can accurate advice from a respected expert increase trust in science? One by one, Dr Smeeth tackles the concerns raised by the panel. The vaccine doesn't change your DNA, he explains. It has been through animal trials, and there's no biological mechanism by which it would affect your fertility, he adds. After the discussion, all our volunteers say they're leaning towards having the vaccine. And some are even enthusiastic. ""I will definitely have it now,"" says Eddie, the painter from Northumberland, chuckling as he logs off. Back in Norwich, once Rosemary also realised that many of the claims made in the video were false, she made her decision. ""I'm so relieved to be getting the vaccine,"" she told me as her husband Donald prepared to visit their local GP. Panorama contacted all 33 people in the video. Eleven responded - four defended the video's contents, five said if we referred to them as anti-vaccine they'd take legal action, and one made no comment. Another acknowledged the virus is real and causes diseases and deaths, but said the measures to manage the pandemic are disproportionate. Panorama invited Oracle Films, which produced the video, to comment. The filmmakers chose not to. After Panorama contacted PayPal about the request for donations, its account was taken down. Facebook - which also owns WhatsApp and Instagram - removed a number of the pages and posts flagged by Panorama. The company says it continues to step up its enforcement policies about harmful misinformation and actively points people towards credible information. Twitter gave us a similar statement and said it's prioritising the removal of Covid-19 content that could potentially cause harm. But the Ask the Experts video is still in circulation on WhatsApp - one of thousands of videos and posts by anti-vaccine activists, who are still fighting to scare people away with false claims. Watch Panorama, Vaccines: The Disinformation War in the UK only, on BBC One, Monday 15 February at 19:30 GMT or later after broadcast on BBC iPlayer."
Covid-19: Police warning over vaccine scam messages,"Fraudsters are sending out fake texts offering a Covid vaccine in an attempt to steal personal and financial information, police have warned. Derbyshire Constabulary says that the text offers a link to an ""extremely convincing"" fake NHS website where people are asked to input their bank details to register for a vaccine. They also say cold callers are asking people to pay for the vaccine over the phone. There is no charge for the vaccine. A spokesperson for Derbyshire Police said: ""The scam message reads 'we have identified that your are eligible to apply for your vaccine' and then prompts you to click on a link for further information or to 'apply' for the vaccine."" ""If you receive a text or email that asks you to click on a link or for you to provide information, such as your name, credit card or bank details, it's a scam,"" the police added. Similar warnings about the fraud attempt have been posted on local Facebook pages over Christmas and the New Year period. When checked by the BBC, this particular fake NHS website appears to have been taken down. It's not the first time this scam has been attempted since the start of the vaccine roll-out. In late December, Sussex Community NHS Foundation Trust issued a similar warning about fraudulent phone calls and messages. ""In some cases, people are asked to press a number on their keypad or to send a text message to confirm they wish to receive the vaccine. Doing so is likely to result in a charge being applied to their phone bill,"" the warning said. A spokesperson for the Sussex trust said: ""The NHS will never ask you to press a button on your keypad or send a text to confirm you want the vaccine, and will never ask for payment or for your bank details."" Criminals have preyed on people's fears over the coronavirus pandemic to steal millions of pounds, according to Action Fraud, the UK's national reporting centre for fraud and cyber crime. Scams include selling fake Covid cures and non-existent or low quality PPE, as well as posing as official sources to steal personal and banking details from victims. Action Fraud says that you should never give out personal details to organisations or people before verifying their credentials first, even if the message appears to be genuine. Major organisations will never send unsolicited emails or texts asking for banking details, it says. Sussex Community NHS adds: ""If you receive a phone call you believe to be fraudulent, hang up; and in the case of vulnerable victims, call the police on their non-emergency number."""
Covid-19: Recent claims about cremations and vaccines fact-checked,"Throughout the pandemic, statistics have been used in misleading and false claims about the impact of Covid-19 and the use of vaccines. Here are four recent claims we've fact-checked. Verdict: This is not correct. Across the UK, there was a sharp increase in cremations in 2020. Over recent months, people have been sharing data from Freedom of Information Requests (FOIs) about cremations and burials in different local authorities across the UK. They claim the figures are no higher than in previous years and question whether there are really any excess Covid deaths. One widely shared example looks at data released by Birmingham City Council. The council told us the figures initially provided in response to FOIs were wrong because of a glitch in the reporting process. These suggested the 2020 figure was the lowest in the last six years. But according to the corrected data, there were 8,316 burials and cremations in 2020, more than the previous year and just about the highest since 2009 (the earliest data available). We looked at the national picture on cremations, using figures from a charity which collects this data. The Cremation Society has counted 70,000 more cremations in 2020 than in 2019. We looked but couldn't find national burial figures. We also know that there have been more than 115,000 excess deaths - over and above the usual number at the time of year - in the UK since the outbreak began. Verdict: This is not correct. Vaccines are highly effective at keeping people out of hospital On Tuesday, Sir Patrick Vallance, the UK's Chief Scientific Officer, posted a correction about a statistic he had referred to during a press conference the day before. ""About 60% of hospitalisations from Covid are not from double-vaccinated people, rather 60% of hospitalisations from Covid are currently from unvaccinated people,"" he said on Twitter. Before his correction, the figures had been used as proof of ""vaccine failure"". But claims that vaccines aren't effective aren't correct, reports BBC Health Correspondent Nick Triggle, who crunched the numbers. By looking at the ratio of vaccinated versus unvaccinated people in hospital, it's possible to show that ""the vaccines are a little over 90% effective at keeping people out of hospital."" Verdict: While studies show the chances of dying from Covid-19 are higher in those who are obese and over 65, it is not correct to say the virus poses no risk to people who are not in these categories. Two recent tweets from US Republican lawmaker Marjorie Taylor Greene resulted in Twitter suspending her account for 12 hours. In one, she claimed that Covid-19 was not dangerous for non-obese people and those under 65. She later said in a statement that it was not wrong to highlight obesity as a risk factor for Covid. In a report released earlier this year by the World Obesity Federation, data on 2.5 million Covid-19 deaths was drawn from more than 160 countries. 2.2 million of these deaths occurred in countries where at least 50% of the population was overweight. Yet while the report does point towards a strong link between Covid-19 deaths and countries with higher obesity rates, Prof John Wilding of the World Obesity Federation, says that to suggest people who aren't obese aren't at risk is a ""complete fallacy."" ""Yes, obesity is an important factor, but it's not the only factor. There are lots of people at risk who have all other sorts of conditions who may not be living with obesity."" One report published in the Lancet Diabetes and Endocrinology, which looked at associations between Body Mass Index (BMI) and Covid-19 severity in England, confirmed the association between Covid-19 severity and death in those with obesity. But it also found that hospital admissions and deaths due to Covid-19 were higher among those who were underweight, compared to those with a healthy BMI. Then there's the risk of long Covid, which affects people across age groups. Verdict: These reports, which have been widely shared online, are not correct. The starting point for these erroneous claims is a US government database called VAERS, where anyone in the US can report adverse effects after receiving a vaccine. TikTok videos claim to show people how to find data relating to deaths from the Covid-19 vaccine on the VAERS website. The video claimed that this search reported more than 51,000 results and evidence of a ""cover-up"". However, we spoke to the US Centers for Disease Control, who told us the methodology used to search for data in this video was wrong. The correct figure of reported deaths among people who received a Covid-19 vaccine from December 14, 2020 through to July 19, 2021 is 6,207. Importantly, the VAERS system is not designed to determine whether a vaccine caused a problem. In other words, correlation does not equal causation - it's wrong to draw any conclusion about how many of these 6,207 deaths may have occurred because of the vaccine. In an earlier statement, VAERS said its database may include ""incomplete, inaccurate, coincidental and unverified information"" and ""cannot be used to determine if a vaccine caused or contributed to an adverse event or illness"". Read more from Reality Check Send us your questions"
Covid-19: The disinformation tactics used by China,nan
Covid-19: YouTube launches vaccination ad campaign,"YouTube has launched a multi-million-pound advertising campaign to encourage young people in the UK to get vaccinated against Covid-19. It said the partnership with the NHS would involve ads on buses, billboards, bus stops and YouTube, with the video-sharing site paying for them. YouTube has been criticised for being slow to stop the spread of coronavirus disinformation. But it said it had removed 900,000 Covid-19 videos that broke its rules. The campaign will feature the slogan Let's Not Go Back and will show group activities and events - such as concerts - that will be possible again after the pandemic. YouTube's UK managing director, Ben McOwen Wilson, said he wanted to avoid ""vaccine ambivalence"" among young people as life starts to return to normal over the summer. He said the video-sharing platform had ""huge reach"" among under-35s and could communicate with young people in a way that was light-hearted and not preaching. In October, YouTube changed its policy to ban misleading claims about the coronavirus vaccine. However, it faced continued criticism about the spread of disinformation. In March, the Center for Countering Digital Hate (CCDH) released a report, stating: ""Anti-vaccine activists on Facebook, YouTube, Instagram and Twitter reach more than 59 million followers, making these the largest and most important social-media platforms for anti-vaxxers."" Mr McOwen Wilson said the coronavirus pandemic had ""moved rapidly"" and that YouTube had regularly reviewed its policies, working with information partners such as the NHS and World Health Organization. He said the platform had removed 900,000 videos that broke its rules on coronavirus misinformation and said banners linking to authoritative sources of information had been clicked 500 billion times. Dr Nikki Kanani, medical director for primary care at NHS England, said: ""It is great to have support from platforms such as YouTube, to reassure people that the vaccine is safe, simple and effective. ""I urge everyone to book in for a vaccine when you are eligible."" YouTube was typically ahead of the curve when it came to introducing policies to tackle harmful anti-vaccine content. And this marks another new - and critics would argue much-needed - initiative. Young people are more active users of social-media sites and as a consequence are more likely to be exposed to conspiracies and falsehoods online. I have investigated the impact of anti-vaccine content online for months, and there is no doubt that the very conspiracies that may have heightened vaccine hesitancy among young people have spread on sites such as YouTube. Several popular influential users promoting harmful falsehoods about vaccines have cultivated their followings on YouTube over the past year - and the site has come under fire for only recently acting on those accounts. The conspiracies they have spread, including about fertility, have often been aimed directly at younger women in a bid to put them off the jab. While a campaign like this might reiterate the science of vaccines and value of collective immunisation, it may struggle to undo the damage done by emotive anti-vaccine propaganda to which younger social-media users have been hyper-exposed."
Covid: 'How a picture of my foot became anti-vaccine propaganda',"Warning: this article contains images that some readers may find distressing Patricia is suffering from an unexplained skin condition - but a misunderstanding about what might have caused it set off a chain of events that turned her foot into fodder for anti-vaccine activists. The picture showed purple and red sores, swollen and oozing with pus. ""Supposedly this is a [vaccine] trial participant,"" read the message alongside it. ""Ready to roll up your sleeve?"" Within a day, those same feet had been mentioned thousands of times on Instagram and Facebook. The picture went viral on Twitter as well. ""See they are trying to deliberately hurt us with the vaccine,"" one tweet read. The feet belong to Patricia - a woman in her 30s living in Texas. And it's true - she was a participant in a trial for the Pfizer/BioNTech vaccine that started to be administered on Tuesday. But this is also true: Patricia never received the actual vaccine. Medical records show that she received a placebo, a small injection of salt water. (Researchers do this as a matter of routine, to compare groups that receive a drug or a vaccine with those who receive the placebo.) Her illness had nothing to do with injections. But that didn't stop activists twisting her story to advance their own agendas. And on top of the physical pain caused by her condition, Patricia received a wave of online abuse. Patricia says her illness began in late October, when she went on a chilly walk. She noticed feel pain in her left foot. Her husband suggested it might be her shoes rubbing. But when she got home, she found that her sole had become painfully swollen. A big blister had appeared, much too large to be caused by footwear. It was so big that she had to use one of her daughter's nappies to dress it. When the sole of her other foot also blistered and it became difficult to walk, she visited a number of doctors, who mentioned a number of possible causes. One of several possibilities they mentioned was fixed drug eruption - a bad skin reaction to a medicine. Their minds then went to the vaccine trial she was participating in at the time. She had received her second injection five days before the blisters first developed on her feet. After seeing these doctors, Patricia talked to a relative who was so concerned that she set up a GoFundMe page to raise money for medical bills. Under America's mostly private health care system, Patricia was already struggling with medical costs due to a back condition. Now she had to take time off from her job as an archival assistant due to her foot sores. The GoFundMe page made a direct link between the blisters and the vaccine trial. It read: ""Patricia... was a volunteer in a COVID-19 vaccine study recently and had a severe adverse reaction"". Patricia had agreed with the wording. She didn't realise how it would be used online. The story spread quickly. After an anti-vaccine influencer posted it, it was picked up in several places, including an apocalypse-themed evangelical Christian site that promotes conspiracy theories about vaccines, the Covid-19 pandemic and the US election. The site posted a version of Patricia's story along with passages from the Bible describing her feet as having ""crusting holes that look a whole lot like the 'grievous sores' described in [the book of] Revelation"". From there it spread to religion-themed and anti-vaccine Facebook groups around the world. Links to the story and the photo of Patricia's feet went viral in Romanian, Polish and Portuguese. As word began to spread, Pfizer and Patricia's doctors started looking into her participation in the vaccine trial. Normally, participants are not told whether they receive a vaccine or a placebo - that information is only revealed to researchers once the study is complete, so as not to influence the results. But Patricia says that because of the unusual circumstances, researchers and the drug company revealed to her that she had received the salt water placebo, not the trial vaccine. We independently confirmed that fact, and consulted several independent dermatologists who said a saline solution injected into an arm would not cause a skin condition to flare up in someone's foot. In-depth reporting on social media, from the BBC World Service. Listen now on BBC Sounds. After receiving the news, and realising how the otherwise well-meaning GoFundMe page had been portrayed, Patricia was contrite. ""I have to assume some culpability for putting my story out there,"" she says. ""It's social media. You share it for one second and it can get picked up and go viral."" ""My injury had nothing to do with the vaccine. My bad. People make mistakes."" Her doctor is continuing to search for the real cause behind her condition. The spread continues The newly revealed facts of the story didn't stop misleading information from spreading. Within a week, Patricia's foot had reached the Twitter feeds of British people with large followings who spread coronavirus conspiracy theories. It ended up in Facebook groups devoted to local areas and parenting, in the US and the UK. And Patricia got messages from pseudoscience influencers, looking to discuss her story on their YouTube channels. The best of BBC reporting, education and training to help you understand the challenges posed by misinformation and fake news. READ MORE She also received a torrent of abuse on social media. She says people called her ""an idiot, a drug addict, a convicted felon, con artist, a person of questionable character and worse."" Anti-vaccine activists sent her angry messages saying she should never have taken part in the trial. At the same time, others sent her abusive messages accusing her of deliberately fuelling disinformation. Patricia insists she never meant to deliberately deceive. She disabled her social media profiles because of the messages, and says she's particularly upset by the anti-vaccine lobby. ""The fact that these anti-vaxxers are using this to fuel their agenda is infuriating,"" she says. Patricia still has medical bills to pay. With the help of her relative, the GoFundMe page - which was briefly removed by the site over concerns it was promoting misinformation - is back up, in edited form. This time, it reads: ""Patricia is still suffering from the painful skin condition on her feet; however, the cause has become unclear."" GoFundMe has offered a refund to anyone who donated money under the false impression the injury was caused by the vaccine trial. The page has now raised more than $5,000. Patricia's story is just one example of a recurring pattern. Fringe activists find a story that seems to supports their entrenched views, and work to spread it rapidly online, regardless of the underlying truth. For her part, Patricia just ""wants this to all be over"". She's hoping that her doctor can find the cause of her condition, and that she can get back to work soon. Subscribe to the BBC Trending podcast or follow us on Twitter @BBCtrending or Facebook."
Covid: Claims vaccinations harm fertility unfounded,"Claims on social media that the Covid vaccine could affect female fertility are unfounded, experts have said. Posts have incorrectly suggested the Pfizer vaccine could cause infertility in women, or cause their bodies to attack the placenta. But there is no ""plausible biological mechanism"" by which the vaccine could affect your fertility, says Prof Lucy Chappell, a professor in obstetrics at King's College London and spokesperson for the Royal College of Obstetricians and Gynaecologists. The vaccine works by sending a message to the body with a blueprint, allowing it to manufacture a small, harmless fragment of the coronavirus's distinctive ""spike"". This prompts your immune system to kick into action, producing antibodies and white blood cells to fight off the virus - and recognising it if you encounter it again. It can't give you the virus, and it has no way of affecting your own genetic information. These ""messenger particles"" are extremely short-lived: they deliver their message and then they are destroyed. That's why the Pfizer vaccine in particular has to be stored so carefully - the genetic material it contains falls apart and becomes useless very easily. Prof Nicola Stonehouse, a virologist at the University of Leeds, said there was no possible way she could think of that this could have an impact on reproductive health. Online, some people have pointed to a line in an earlier version of guidance published by the UK government stating it was ""unknown"" whether the Pfizer vaccine had an impact on fertility. This has since been updated to clarify that animal studies don't indicate any harmful effects on the reproductive system. Part of the confusion here is down to how scientists describe things compared with how most of us would understand them in our daily lives. When scientists say there is ""no evidence"" they mean there hasn't yet been a long-term study on this specific vaccine - but that doesn't mean there are no facts here at all or we're shooting in the dark. In fact, Prof Chappell pointed out, there is lots of evidence from other non-live virus vaccines, including the flu jab, that they have no impact on fertility and are completely safe and recommended for use during pregnancy. And getting the Covid virus itself - which the vaccine protects against - has the potential to affect fertility, so ""you're much more likely to have fertility issues post-Covid than after the vaccine,"" Prof Stonehouse said. Some of the rumours have suggested the vaccine could threaten fertility because it contains proteins also used to make the placenta. Posts on social media have claimed this could lead the body to attack the placenta. This is not true - the vaccine does contain a protein which slightly resembles one used in the development of the placenta but it's not similar enough to confuse the body. Vaccines are designed around the most distinctive parts of the virus's spike to make sure it recognises only that. The fact that the respective proteins bear a passing resemblance ""doesn't mean anything"", says Prof Chappell, since there are lots of similar proteins existing in different places in nature - it's their precise length and sequence that makes them distinctive. Prof Chappell, who specialises in the health of pregnant women and people hoping to conceive, said she had ""no concerns"" about fertility and the Covid vaccine. And the deputy chief medical officer for England, Jonathan Van-Tam, when answering questions from BBC viewers, said: ""I have never heard of a vaccine that affects fertility."" He described the suggestion as ""a nasty, pernicious scare story, but that's all it is"". During pregnancy women are understandably very concerned about their health and may be conscious of scandals such as the one surrounding thalidomide - a drug used for morning sickness, that affected thousands of babies, leaving many with impaired limb development. But as a direct result of these experiences, our understanding and treatment of drugs during pregnancy is entirely different. The advice on treatments during pregnancy is extremely cautious. And pregnant women are generally not included in clinical trials - including those for the Covid vaccine. Though vaccines are quite different from powerful drugs like thalidomide, most health services are erring on the side of caution. They are generally not recommending pregnant women have the jab unless they are at particular risk from Covid. That might be because they are highly exposed to the virus in their jobs, or at high risk of becoming very sick if they contracted Covid due to health conditions. The UK government says: ""The vaccines have not yet been tested in pregnancy, so until more information is available, those who are pregnant should not routinely have this vaccine."" Like all things in healthcare, there is an element of balancing risks. Even something as simple as an over-the-counter painkiller carries a tiny risk of ulcers and internal bleeding. But the risk for most people is so small when used correctly, that it is outweighed by the benefits of treating relatively mild pain. And the benefits of preventing an illness that we know can be life-threatening have been judged to be much greater than any theoretical risk of vaccination. Follow Rachel on Twitter Read more from Reality Check Send us your questions"
Covid: Conspiracy and untruths drive Europe's Covid protests,"Further Covid protests are being planned this weekend in Austria and the Netherlands, after recent demonstrations against reimposed coronavirus restrictions tipped over into violence. Many of the concerns being expressed, both on the streets and in social media posts, contain legitimate questions about recent political decisions, but there is also a plethora of false information being spread by those involved in the protests. From unfounded accusations that the vaccine is a plot to poison the population, to criticism of governments as ""dictatorships on the march"" - more extreme sentiments are being shared alongside general anger over political choices. ""The violence is needed because there needs to be change,"" organiser Ricardo told BBC Newsnight, after Dutch protesters fought with riot police. In Austria, the newly-formed, anti-vaccination, People, Freedom, Fundamental Rights party (MFG), has been instrumental in planning the recent protests on the ground. The MFG has drawn spurious parallels between Covid restrictions and Nazi rule, using inflammatory words like ""dictatorship"" and ""apartheid"". The Austrian far-right Freedom Party (FPOe), the third largest in Austria's parliament, is also strongly opposed to Covid restrictions. Its new leader has expressed false and misleading views, including describing the vaccination programme as a genetic experiment. These same phrases can be found littered throughout groups on Facebook, of people who turned out to protest in Austria last week - as the country returned to a full national lockdown. Opposition to lockdowns and Covid passes is not limited to the far right, however, with dissent coming from a range of voices in Austria, according to research by BBC Monitoring. On Twitter, an Austrian rapper posted a cartoon showing two men in prison - one for killing six people, the other for being unvaccinated - evoking an imagined future where people might be incarcerated for refusing to have a Covid jab. It reveals a shared fear of governments abusing their power - although the same rapper has also posted a number of more outlandish conspiracy theories, including about the Great Reset. Recent research carried out in Austria suggests a low trust in the Covid vaccine is strongly associated with a low trust in authority more generally. Among Dutch protesters, members hark back to Nazi occupation amid unfounded beliefs that vaccines are poisonous or part of sinister global plot, with memes which compare a QR code to a Swastika. An EU-commissioned survey tracked trust in governments and found some of the biggest falls were in Austria and Croatia between the spring of 2020 and 2021 - both countries where protests have recently broken out. In Russia, although mistrust of the authorities is not expressed on the streets - because unsanctioned street protest is banned - it is clearly present online. Protests at the introduction of vaccination certificates are widespread on social media, says Olga Diakonova of the BBC Russian service in Moscow - driven by a mistrust in the government and authorities more generally. Vaccination levels in Russia are amongst the lowest in Europe. Earlier in the year, Prof Melinda Mills, at the University of Oxford, warned the introduction of vaccine passports carried ""a risk of unjustly discriminating in hiring, attending events, insurance [and] housing applications"", but said these concerns needed to be balance with legal and ethical duties to protect people's health. But Miro Dittrich, at the German think tank the Centre for Monitoring, Analysis and Strategy (CeMAS), believes people with those types of concerns don't make up the majority of protesters. ""If you look at the organisers, if you look at the people who mobilised these events, these are not people with rightful concerns - these are people with conspiracy narratives or far-right views,"" he says. An online group involved in organising the Austrian protests claims vaccines are ""turning out to be more and more ineffective"". But this is not supported by the evidence from rigorous clinical testing, nor the practical policy of injecting billions of people worldwide with the various vaccines available. Multiple studies show vaccines are very effective at preventing hospitalisation and death, and can also play a role in reducing transmission and symptomatic disease. No medicine is risk-free, but complications are rare and most are not serious, paling in comparison with the potential harm caused by Covid, even to younger people. Such social media posts overstate the risk of the vaccine, while understating the risk of the virus. Along with valid questions about whether things like mandatory vaccinations and vaccine passes might have the potential to discriminate, highly misleading and false information is also circulating on social media, where many of  these street protests are being organised. ""There are, of course, lots of people who have genuine frustrations with restrictions in place in their own country,'"" Ciaran O'Connor, a researcher at the Institute for Strategic Dialogue, who monitors disinformation and extremism online, told BBC Newsnight. But Mr O'Connor explained ""the danger of these kinds of events, or groups, or movements is that they represent a potential pathway towards radicalisation or towards extremism, because they are basing their arguments on misinformation, misleading claims and conspiracies"". Additional reporting by Marianna Spring Follow Rachel on Twitter or get in touch rachel.schraer@bbc.co.uk"
Covid: Fake news 'causing UK South Asians to reject jab',"Fake news is likely to be causing some people from the UK's South Asian communities to reject the Covid vaccine, a doctor has warned. Dr Harpreet Sood, who is leading an NHS anti-disinformation drive, said it was ""a big concern"" and officials were working ""to correct so much fake news"". He said language and cultural barriers played a part in the false information. A GP in the West Midlands told the BBC some of her South Asian patients had refused the vaccine when offered it. Dr Sood, from NHS England, said officials were working with South Asian role models, influencers, community leaders and religious leaders to help debunk myths about the vaccine. Much of the disinformation surrounds the contents of the vaccine. He said: ""We need to be clear and make people realise there is no meat in the vaccine, there is no pork in the vaccine, it has been accepted and endorsed by all the religious leaders and councils and faith communities."" ""We're trying to find role models and influencers and also thinking about ordinary citizens who need to be quick with this information so that they can all support one another because ultimately everyone is a role model to everyone"", he added. ""There's a big piece of work happening where we're translating information, we're making sure the look and feel of it reaches the populations that matter."" Some of the disinformation seen by the BBC on social media and on WhatsApp is religiously targeted. Messages falsely claim the vaccines contain animal produce - eating pork goes against the religious beliefs of Muslims, as does eating beef for Hindus. Dr Samara Afzal has been vaccinating people in Dudley, West Midlands. She said: ""We've been calling all patients and booking them in for vaccines but the admin staff say when they call a lot of the South Asian patients they decline and refuse to have the vaccination. ""Also talking to friends and family have found the same. I've had friends calling me telling me to convince their parents or their grandparents to have the vaccination because other family members have convinced them not to have it"". Reena Pujara is a beauty therapist in Hampshire and a practising Hindu. She said she's been bombarded with false information. ""Some of the videos are quite disturbing especially when you actually see the person reporting is a medic and telling you that the vaccine is going to alter your DNA,"" she said. ""For a layman it is very confusing. And also when you read that the ingredients in the vaccine derive from a cow - and as Hindus the cow is sacred to us - it is disturbing."" About 100 mosques have a joined a campaign to counter vaccine disinformation and persuade their communities to take the vaccine. They've said they'll use their Friday sermons to urge people to have the jab. ""There should be no hesitation in taking [the vaccine] from a moral perspective,"" said Qari Asim, chair of the Mosques and Imams National Advisory Board (MINAB), which has organised the campaign. ""It is our ethical duty to protect ourselves and others from harm."" Vaccines minister Nadhim Zahawi told the BBC's Asian Network that faith and community leaders had a big role to play in ensuring a high take-up of the vaccine. He said he had met with more than 150 leaders from Sikh, Hindu, Jewish and Muslim communities who were taking the message out ""that it's the right thing to do"". He added that the government was taking steps to tackle online disinformation around the vaccine, as well as making sure vaccine guidance was available in many different languages. A recent poll, commissioned by the Royal Society of Public Health, suggested just over half of black, Asian and minority ethnic (BAME) people would be happy to have the coronavirus vaccine. It found 57% said they would take the vaccine - compared with 79% of white people."
Covid: Misleading stat claims more vaccinated people die,"Some people, including those pushing an anti-vaccine agenda online, have been misinterpreting figures showing that a large proportion of those dying with the Delta variant of coronavirus had been vaccinated. One conspiracy site even claimed vaccinated people were dying at higher rates than those who had not received the jab, which is untrue. This site and others use real figures in a misleading way, to arrive at a completely false conclusion - that the vaccine may not be working or even doing more harm than good. The latest Public Health England (PHE) figures show there were 92,029 confirmed Delta cases between 1 February and 22 June,  most of which were identified in June. Of these, 58% were in completely unvaccinated people and only 8% were fully vaccinated. For context, by the start of June more than half of adults in the UK were fully vaccinated.  If the vaccines weren't helping, we would expect them to make up more than half the cases. So we can see the vaccine is reducing cases. The figures for hospital admissions and deaths are a bit more confusing. Of the 117 people who died with the Delta variant, first identified in India, 50 (43%) had been fully vaccinated. And on 13 June, a Daily Mail headline claimed the proportion of those dying who had been fully vaccinated had ""scared"" Prime Minister Boris Johnson into delaying the 21 June easing of restrictions, describing it as a ""blow"". But what these figures actually show is less alarming. The 43% figure relates to deaths only - so it misses all the vaccinated people who were exposed to Covid but did not catch it, or caught the virus but did not become very ill. And by now, almost everyone at risk of dying from Covid has been vaccinated (more than 90%). No vaccine is perfect in preventing people from getting Covid and therefore a small number of people will still die. And in a world where every single person had been vaccinated, 100% of Covid deaths would be of vaccinated people. But the actual number of people dying would be much lower - a 20th as many as if no-one was vaccinated, according to PHE estimates. The vaccines are already estimated to have saved 27,000 lives in England. And there is another reason you cannot currently just compare the number of Covid deaths among vaccinated and unvaccinated people and come to any conclusions about how effective the jabs are. Because most fully vaccinated people are over the age of 50 - and therefore more likely to die - while most unvaccinated people are young and healthy. What claims do you want BBC Reality Check to investigate? Get in touch Read more from Reality Check Follow Rachel on Twitter."
Covid: Misleading vaccine claims target children and parents,"Campaigners have been gathering outside schools, handing out what they claim are legal documents or ""notices of liability"" to head teachers, warning them not to vaccinate children. Before the government's decision to extend the UK Covid vaccination programme to 12- to 15-year-olds was announced, debate simmered over whether the jab should be offered to healthy children, who are at a much lower risk from the virus than older age groups. But alongside genuine discussion, campaigners opposed to the vaccine have been spreading misinformation. A fake vaccine-consent letter, pretending to be from the NHS, was sent to schools in England. The letter falsely stated there was a ""one in 29,389 chance of dying from the vaccine"", comparing that with children's extremely low risk of death from the virus. The figure appears to have been taken from the Medicines and Healthcare Products Regulatory Agency's Yellow Card scheme, for people to report any suspected side-effects after vaccination. Roughly 49 million people have had at least one vaccine dose and about 1,600 deaths have been logged in the scheme so far. But someone dying after a jab does not mean the vaccine is responsible. People die from all sorts of causes every day and most of the adult population has now been vaccinated, including the vast majority of those most at risk of death - the elderly or those with underlying illnesses. The MHRA investigates the reported side-effects, including deaths, to see whether they are higher in vaccinated people than would be expected in the population normally - which, generally, they have not been. As of August, the Office for National Statistics (ONS) had recorded nine deaths to which the vaccine was found to have contributed, five of which had the vaccine as the underlying cause. This was determined by doctors who examined the patient and had access to their medical records and test results. That suggests a one in five million risk of dying. On the other hand, the risk of dying of Covid if you are unvaccinated has been estimated at 0.8% or 35,000 deaths per five million for all ages. And there have been 161,000 deaths so far where Covid was judged to be an underlying cause, including at least 76 children, according to ONS records. The UK's Joint Committee on Vaccination and Immunisation (JCVI), which produces recommendations for government, said the benefits for 12- to 15-year-olds from the vaccine were marginally greater than the risks but acknowledged that ""there is considerable uncertainty regarding the magnitude of the potential harms"". The form also suggests the vaccine may not stop people catching Covid or passing it on. In fact, the vaccine reduces the chances of catching the virus by about half and, even if someone does catch it, reduces the amount of virus in the system, making it less likely they will pass it on. Teenage boys' very slightly but genuinely elevated risk of developing a condition called myocarditis - inflammation of the heart - after vaccination has been highlighted by campaigners opposed to Covid jabs. They emphasise these rare negative events from the vaccine while downplaying the risks to children of catching the virus - including ""long Covid"". Most cases of myocarditis after vaccination were resolved quickly following treatment. It is a case of balancing risks. The JCVI estimates a single first dose of the Pfizer vaccine prevents 87 Covid-related hospital admissions per million children but comes with a risk of three to 17 cases of vaccine-induced myocarditis per million children. The second dose is estimated to prevent a further six hospital admissions per million but comes with the risk of a further 12 to 34 cases of myocarditis - which is why the chief medical officers decided to recommend just one dose. Myocarditis is actually more common after catching Covid than after the vaccine. But the MRHA says it is important anyone who experiences a ""new onset of symptoms such as chest pain, shortness of breath or feelings of having a fast-beating, fluttering, or pounding heart"" after the vaccine seeks medical attention. It is difficult to pin down how many people are actively campaigning against the vaccine for children - but there is evidence it is fewer than they would like people to think. Several seemingly grassroots groups have sprung up appearing to be operating separately - but they seem to consist of a relatively small number of overlapping members. Leaked chat logs from the anti-lockdown Health Advisory and Recovery Team show members discussing putting their message against vaccines out under the banner of another organisation, the UK Medical Freedom Alliance, ""if it is too inflammatory for Hart"". Another member discussed sharing research from a third vaccine-detracting body, the British Ivermectin Recommendation and Development Group, because ""psychologically this then looks like two groups of professionals agreeing with each other (making the content more believable as it looks like two separate groups)"". Members of these organisations also have links to Us for Them, which says it represents parents, and the campaign group Safer to Wait. Safer to Wait's founder can be seen in the leaked Hart members chat, asking the group to distribute the group's leaflet with misleading claims about the vaccine to primary-school parents. These campaigns appear to be having a wide reach, with protests at schools across the UK. Clarification: This piece was published on 13 October and was updated on 14 December to add more detail on the JCVI's position on teen vaccination."
Covid: Most popular Facebook link in US spread vaccine doubt,"A news article about a doctor who died after receiving a Covid-19 vaccination was Facebook's most viewed link in the US in the first quarter of 2021, a previously shelved report shows. The piece - updated after a report said there was no proven link to the vaccine - was popular with vaccine sceptics. The New York Times claimed that Facebook initially held back its report because it would ""look bad"". Facebook said the delay was in order to make ""key fixes"". The company had already published its ""Widely Viewed Content"" report for the second quarter of 2021, in which it found a word search promising to reveal ""your reality"" was the most popular post. Similarly frivolous ""question posts"" formed most of the top 20. But the New York Times revealed on Friday that the company had held back the earlier report covering January to March 2021. The paper alleged the report had not been shared because of fears that it would ""look bad for the company"". The most-viewed link was an article published by a mainstream US newspaper reporting that a doctor had died two weeks after getting a Covid-19 vaccine. The link attracted nearly 54 million views. The article was subsequently updated to reflect the findings of the Medical Examiner that there was insufficient evidence to conclude whether the vaccine was responsible for the death. Health bodies around the world have deemed the vaccine to be both safe and highly effective. The first quarter report also revealed that the 19th most popular page on the platform belonged to the Epoch Times, which has been accused of spreading right-wing conspiracy theories. The widespread circulation of this story of a doctor who died two weeks after receiving a Covid-19 jab exposes just how fertile a breeding ground Facebook can be for anti-vaccination content. This can be partly explained by a committed network of activists, under a variety of different guises, who oppose coronavirus vaccines. Promoting emotive, personal stories like this one on Facebook has been one of their primary tactics in scaring others from getting jabbed - even when, as was the case with this story, it turns out the death has no link to a Covid-19 vaccine at all. Throughout the pandemic, these activists have muddled together real - and rare - stories of potential adverse side effects from vaccines with extreme online conspiracies, exploiting medical debates, genuine grief, and legitimate questions. This also demonstrates the complexity of the disinformation ecosystem on social media - where users seize on a grain of truth, in this case an accurate news story, and spin it into a misleading narrative, without the facts to back it up. I previously reported on how activists misappropriated the image of one woman's foot on Facebook, after she took part in the Pfizer vaccine trials. After the publication of the NY Times' story, Facebook released the report. A spokesperson for the company said: ""We considered making the report public earlier but since we knew the attention it would garner, exactly as we saw this week, there were fixes to the system we wanted to make."" According to Facebook, these fixes included dealing with bugs in some of the queries on which the report was based. The firm's Andy Stone added more detail on a Twitter thread. Both the quarterly reports focus on what is most viewed in the USA, rather than what is engaged with through likes, comments, and shares. They paint a different picture to data gathered by researchers and journalists with Crowdtangle, Facebook's engagement-measuring tool, which suggests that right-leaning political content is dominant on the platform. Facebook has fiercely pushed back against that idea, saying that only 6% of content seen by users is political. But some misinformation researchers worry that Facebook is going cold on Crowdtangle. The company did not answer a BBC question about whether the tool was under threat."
"Covid: Posts claiming only 17,000 died of virus 'factually incorrect'","A misleading claim that ""only"" 17,000 people in England and Wales have died of Covid has been circulating online. The UK's Office for National Statistics (ONS) has stepped in to correct the record - but not before the false claim went viral. ""It has become a weapon of the cruel and heartless to dismiss the deaths of the people we love."" Matt Fowler lost his dad to Covid-19 in April 2020. Ian Fowler was 56 at the time of his death, and lived with type 2 diabetes - which his son said had a ""minor, barely perceptible impact on his life that he controlled with his diet"". But the suggestion that ""only"" 17,000 people in England and Wales have died of Covid - a figure arrived at by removing from the data anyone with a pre-existing health condition - completely discounts the deaths of people like Ian. The true death toll is more than 140,000, the ONS says. That number is limited to deaths directly caused by the virus, not those ""involving"" Covid or people who happened to test positive but died of other causes. There are other ways of calculating deaths by the virus, but all give figures in a similar ballpark. Covid myths that spread on social media very often have a kernel of fact at their heart - a real statistic that gets misused - to tell a story which ends up far from reality. In this case, that information was figures released by the ONS looking at people who died of Covid and who had no other health conditions. But the false implication made in social media posts - that if someone had any pre-existing health condition, they did not really die of the virus - doesn't logically follow. ""It is very common for the person dying to have a pre-existing health condition of some sort, but this does not mean that the person was at imminent risk of dying from that condition, or even considered to have a reduced life expectancy,"" the ONS explained. It described the 17,000 figure as ""factually incorrect and highly misleading"". Deaths which would not have been counted in the 17,000 include people with asthma, diabetes, an irregular heartbeat or high blood pressure - all conditions with which many can expect to live a normal lifespan. In other words, these are not terminal conditions that would have killed people had they not caught Covid. ""It wasn't type 2 diabetes that killed my dad, it was Covid-19,"" says Mr Fowler, who co-founded the group Covid-19 Bereaved Families for Justice. ""Were it not for the unchecked spread of the virus, my dad would still be alive today."" He describes such posts as ""deeply offensive"" and condemns people on social media for peddling ""heartless conspiracy theories...to attack us in our grief"". The idea, popular in some online groups, that a large proportion of virus deaths are people who died ""with"" but not necessarily ""of"" Covid - coincidentally testing positive when dying of another cause - is based on a misinterpretation of how deaths are recorded. When doctors fill in death certificates, they record the chain of events that led directly to a patient's death based on physical examinations, tests, symptoms and medical records. For example, someone may catch Covid, which causes pneumonia, which leads to acute respiratory distress syndrome (Ards), culminating in their death. A doctor would list all three as causes. If someone was in hospital dying of another cause and happened to test positive for Covid, it would not be recorded in the same way. There is another section of the death certificate form where doctors can add pre-existing conditions which may have contributed, like asthma. In some cases, the underlying condition may be very serious, like cancer or dementia. But the fact a doctor decided to note it in this separate section, and not as an underlying cause, suggests the patient would not have died then just because of that condition alone. As an extreme example, imagine someone is stabbed but had an irregular heartbeat which contributed to cardiac failure when they were attacked. The irregular heartbeat might appear on their death certificate, but we wouldn't say the person who stabbed them was not responsible for their death. The idea that deaths can be mistakenly recorded as being due to Covid-19 can occasionally be true when considering a different measure used in the UK - deaths within 28 days of a Covid positive test. However, even those cases which may be erroneously picked up by that statistic aren't artificially inflating the death toll. In fact, the figure for deaths within 28 days of a positive Covid test are actually lower than the number of death certificates listing Covid-19 as the cause. That's because some people are ill for longer than 28 days before dying of Covid. To complicate things further, another claim started to circulate at the same time the 17,000 claim went viral - that the death toll was in fact only 6,000. This is the number of people with just Covid-19 and nothing else on their death certificate - and is possibly even more inaccurate since it excludes people with conditions directly caused by Covid. That means the example above, of someone who caught Covid which developed into pneumonia, would not be counted as a Covid death. While it's been made clear from the start of the pandemic that older and sicker people are at much higher risk from the virus, research has found on average people who died of Covid lost 10 years of life. The misleading ""17,000"" figure was spread by influential accounts online. On 14 January, former Islamist turned counter-extremism activist Maajid Nawaz tweeted that the figures were evidence of ""narrative collapse"", implying the larger reported death figures were not genuine. Then on 20 January, Dr John Campbell, a retired nurse educator who has amassed a huge following on YouTube, released a video describing the figures as a ""huge story"" and suggested Covid deaths were ""much lower than mainstream media seems to have been intimating"". His video has been viewed more than 1.5 million times to date and was shared by Conservative MP David Davis. On the same day, The Daily Expose, a website that has published a variety of misleading and false claims, posted an article falsely claiming the ONS had: ""admit[ted] just 6,000 people died of Covid-19 in England and Wales"". This and related claims began to spread in the following days: to French accounts, a 50,000-member Greek Facebook group, a Swedish group of 20,000 people and a Slovakian political blogger, suggesting the government had distorted death figures or been ""forced to tell the truth"". The ONS said: ""To exclude individuals with any pre-existing conditions... greatly understates the number of people who died from Covid-19 and who might well still be alive had the pandemic not occurred."" The BBC has contacted Mr Nawaz, Dr Campbell and Mr Davis. Read more from Reality Check Send us your questions"
Covid: Pregnant women targeted with false vaccine claims,"Covid vaccination advice in pregnancy has not changed, contrary to false social media posts, UK health agencies have clarified. Inaccurate messages shared by thousands claimed that pregnant or breastfeeding women were now recommended not to take the vaccine. In fact, the NHS says the vaccine is both safe and strongly recommended for this group. The misleading claim came from a now out-of-date document from 2020. The document went viral after a Twitter user - whose account has since been suspended - shared a post stating incorrectly that the UK government had, ""quietly remove[d] approval for use of Covid vax in pregnant and breastfeeding women"". She linked to a report from December 2020 which said, ""reassurance of safe use of the vaccine in pregnant women cannot be provided at the present time"", because of an absence of data and that, ""women who are breastfeeding should also not be vaccinated"". This was true at the time, but since then data has been gathered finding no link between the vaccine and problems in pregnancy or birth. In fact, the Covid vaccine seems to reduce the risk of still-birth and pre-term delivery. And unvaccinated pregnant women are more likely to need hospital treatment if they catch Covid, especially in the third trimester. This evidence led to the recommendation being changed - so the statement found in this report no longer stands. A Department of Health and Social Care spokesperson said: ""Covid vaccines are safe and highly effective both for pregnant women and for those who are breastfeeding. ""This is backed by extensive real-world data, including global analysis outside of clinical trials and in healthcare settings."" Despite this, the misleading message that the advice had changed was picked up by several accounts with large numbers of followers. A link to the outdated report was viewed across major social media platforms thousands of times, along with inaccurate claims including that the government had performed a ""U-turn"" and admitted the vaccine was ""not safe for pregnant or breastfeeding women"". It was also shared in a number of other languages and countries and territories including Germany, Singapore, Hungary, Sweden, Bulgaria, Hong Kong, Poland and the US. Part of the confusion appeared to stem from the fact that a different part of the same webpage had been updated on 16 August 2022, to include some information about boosters. But the report about vaccine safety, which social media users highlighted this week, ""was not updated"", the UK's Medicines & Healthcare products Regulatory Agency (MHRA) confirmed. ""The text referred to in the social media posts...reflects our assessment at the time of approval for the vaccine,"" it said. Since then, ""new data has come to light"" which supports the current advice in favour of vaccinating pregnant and breastfeeding women, an MHRA spokesperson said. The MHRA, which manages the site, will look into making the page clearer, it added. We did not have data at first, because pregnant women were not included in the original Covid-19 vaccine trials. The NHS's Health Research Authority explains this is ""usual...for new vaccine trials"", because doctors are extra cautious about doing anything that could affect a developing foetus. However, some trial participants became accidentally pregnant and, once the vaccine became publicly available, some received it without knowing they were pregnant. This gave researchers a group of women they could study, who had the jab during pregnancy. They did not seem any more likely to have miscarriages or other issues. Then more research was able to take place. In 27 studies, across eight countries, involving 316,470 women vaccinated while pregnant, no increased risk of miscarriage, still-birth, premature birth, low birth weight or babies with abnormalities was detected. The UK's Joint Committee on Vaccination and Immunisation said it also used evidence from the US's V-Safe study, which followed more than 20,000 people vaccinated during pregnancy and found no safety concerns. Studies of tens of thousands of women, including in Scotland, Canada, Israel and Switzerland, found the same thing. Analysis of safety reports that let anyone record anything that happens to them after being vaccinated - like the UK's Yellow Card scheme or the US's Vaccine Adverse Event Reporting System - suggests vaccinated women are no more likely to miscarry than those are unvaccinated. However, premature birth and still-birth are more likely after a Covid infection."
Covid: The truth behind videos of 'empty' hospitals,"Multiple videos posted online claim to show empty hospitals in the UK as evidence that the coronavirus pandemic has been exaggerated. It has provoked a strong reaction from healthcare officials, who have encouraged the public to heed government advice as coronavirus infections surge - putting pressure on the NHS. Responding to a question about hospital beds being empty, NHS England chief executive Sir Simon Stevens said: ""When people say that, that is a lie."" They're mostly filmed by individuals walking through quiet hospital corridors and are being posted in Facebook groups and on the Twitter feeds of coronavirus sceptics and anti-lockdown activists. There have been videos taken of dozens of locations and some have been viewed hundreds of thousands of times. The number of Covid patients has increased significantly in recent weeks and there are serious concerns about the NHS's ability to cope with the surge. However, because of the way healthcare trusts have reorganised hospitals, often separating Covid patients from others, and cancelling non-urgent care to free up capacity, some parts of hospital buildings will currently look empty.  That doesn't mean hospitals aren't busy. We've examined videos from two different locations and sought responses to them from the hospitals. A video posted on social media purports to show an empty Croydon University Hospital, with a commentary claiming that the government is exaggerating the scale of the pandemic. The video, posted in three parts, has been viewed thousands of times and shared across multiple anonymous social media accounts. It has prompted other users to make comments below the post that their local hospitals are empty too. Croydon University Hospital is a large centre treating patients on a 24-hour basis. In a statement in response to the video posts, the hospital trust said: ""Contrary to videos circulating online claiming to show our hospital is empty, our services remain extremely busy."" The video starts with the camera entering the main reception room through signs saying ""NO ENTRY"". The main reception area has a closed coffee shop and the person filming says: ""I've never seen this place so empty."" Responding to the footage, a spokesperson for Croydon Health Services told us: ""We have a one-way system in the main entrance to help with social distancing when entering or leaving the hospital. The video shows this person arriving via the exit. ""The video was also filmed overnight, when the coffee shops would be closed and when we would expect to see our corridors less busy,"" they added. The video shows empty corridors. But there's a good reason the corridors are empty. ""We provide this care in our wards and in other clinical areas - not corridors or waiting rooms,"" said the hospital spokesperson. The man then walks around the outside of the A&E waiting room. ""Urgent treatment - empty. Look at this place,"" says the individual, filming the outside of a waiting room which looks fairly full of people sitting socially distanced. ""Regarding the A&E waiting area, the video shows only the entrance to the department,"" said the hospital. ""Patients brought in by ambulance, or those in a serious condition or requiring admission to hospital, are unlikely to be waiting in this area. ""Perpetuating myths and rumours only undermines their [NHS staff] hard work. It also risks the spread of misinformation, which could lead people to risk their own health and the health of their loved ones,"" said the hospital official. Another set of videos, posted on Twitter but without commentary, shows an individual walking down apparently empty corridors of the Princess Royal Hospital in Bromley on - it's claimed - New Year's Day. The NHS says the footage ""misrepresents what is really happening"". Four clips have been uploaded of someone passing down a corridor with a sign for the critical care unit, with a twitter thread referring to ""spare beds"" and the ""closed bereavement unit"" along with the hashtag ""film your hospital"". The videos have been watched tens of thousands of times, but reveal very little about how this particular hospital is dealing with the pandemic. In response, the King's College NHS Trust say the parts of the hospital dealing with the pandemic are extremely busy: ""This corridor is not representative of what is happening in wards across the hospital, which have seen a more than ten-fold increase in Covid admissions in the space of a month."" The bereavement suite, briefly shown in one of the videos, is apparently closed. But according to the Princess Royal University hospital website, it shuts at 4pm and on bank holidays. In a further clip, the person filming the video appears to enter an urgent care centre and on Twitter questions whether it is ""overrun"". The room looks relatively full of people. One particular Facebook group in the UK dedicated to sharing pictures and videos of empty hospitals, had more than 13,000 members. This group was taken down by Facebook on 8 January. Another similar group subsequently set up was taken down by Facebook on 11 January. The administrators of the original group appear to be linked to another Facebook page promoting a baseless conspiracy about the global Covid pandemic, known as the 'Great Reset' theory. In March last year, several viral videos purported to show empty hospitals across the United States, with the hashtag 'film your hospital' being tweeted by thousands of accounts. This sparked a trend that has been repeated in other countries. These videos in the UK are the latest example of people taking direct action to spread misinformation about the pandemic. The year 2020 ended with a group of people standing outside St Thomas' Hospital in London shouting that the pandemic is a ""hoax"". One doctor witnessed the gathering and posted on Twitter that he was ""disgusted but mostly heartbroken."" What do you want BBC Reality Check to investigate? Get in touch Read more from Reality Check"
Covid: Vaccine conspiracies debunked in South Asian languages,"The South Asian community has one of the highest levels of vaccine hesitancy in the UK, surveys suggest. More than 40% of Pakistani and Bangladeshi people say they are unlikely to get the jab, while more than 20% of Indian people do not want to be vaccinated, according to a document from the government's Scientific Advisory Group for Emergencies (SAGE). Some doctors believe fake news could be causing some people to reject the Covid vaccine. Some of these myths include claims the vaccine contains animal products and is not halal, or that it causes infertility. Another is false information around the scale of the pandemic, with claims that hospitals are empty, when in fact many are overwhelmed. BBC Asian Network debunks these rumours in five South Asian languages: Urdu, Tamil, Gujarati, Sylheti and Punjabi. Raj Kaur Bilkhu looks into false claims around coronavirus and vaccines in Punjabi. Haroon Rashid looks into false claims around coronavirus and vaccines in Urdu. Jeyapragash Nallusamy looks into false claims around coronavirus and vaccines in Tamil. Poppy Begum looks into false claims around coronavirus and vaccines in Sylheti. Sarika Unadkat looks into false claims around coronavirus and vaccines in Gujarati."
Covid: Van-Tam warns over jab misinformation online,"People worried about Covid jabs should seek advice from health professionals, not social media, the deputy chief medical officer for England has said. Speaking to BBC Sport about the uptake among footballers, Prof Jonathan Van-Tam - an avid Boston United fan - said that was ""where you get good advice"". ""If your boiler goes, don't call a doctor, call a central heating engineer,"" he said. Likewise, for vaccine advice talk to a doctor, nurse or pharmacist, he added. Prof Van-Tam, who is famous for his football analogies during television coronavirus briefings, said: ""My message to footballers who are yet to be vaccinated is really the same to any young adult. ""It is the best thing you can do for yourself, your friends and your family. ""If you want to know something about vaccines, and you want trusted, reliable, information... turn to somebody who's spent years and years training for that role. ""You really don't get it from the internet, Facebook or Instagram,"" he said. Prof Van-Tam, who previously helped to deliver jabs to Boston United's players, said vaccine take-up at both the club and around the country had been ""fantastic"". He said it showed the majority of people were listening to sensible messages from well-informed health professionals. However, there was still a lot of misinformation being spread online, along with ""a tiny minority who very vocally express their disagreement in the form of abuse"", he said. ""It saddens me when people have worked so hard to try and save thousands of lives,"" he added. Prof Van-Tam said the vaccine was proven to ""massively reduce the chances of you getting infected, and even if you are... it is going to massively reduce the chances of anything bad happening to you."" His comments came as new figures showed daily Covid cases in the UK have been above 40,000 for seven days in a row, with 43,738 new infections reported on Tuesday, and the number of patients in hospital rose by 10% in a week to 7,749 on Monday. Dr Andrew Lee, incident director for Covid-19 at the government's UK Health Security Agency (UKHSA) said: ""Cases are rising across all parts of the country. This is a reminder to us all that the pandemic is not over. ""There are steps we can all take to help protect each other from Covid-19. If you are offered a vaccine take it as soon as you can."" Follow BBC East Yorkshire and Lincolnshire on Facebook, Twitter, and Instagram. Send your story ideas to yorkslincs.news@bbc.co.uk."
Damar Hamlin: How anti-vaxxers exploited player's collapse,"Online activists used the on-field collapse of American football star Damar Hamlin to spread anti-vaccination messages starting just minutes after Monday night's incident. In what has become a familiar pattern since Covid vaccines became available about two years ago, several influential accounts used the event to spread anti-vaccination content. They included the Georgia congresswoman Marjorie Taylor Greene, who tweeted: ""Before the covid vaccines we didn't see athletes dropping dead on the playing field like we do now... Time to investigate the covid vaccines."" That tweet was viewed around a million times within a day. But the idea that young, healthy athletes have never collapsed suddenly before Covid vaccines is easily disproven. A US study looking at athletes over four years found many unexplained deaths were in fact caused by cardiac arrest - a cause more common in male and African-American players. Previous studies pre-dating Covid-19 note that there are approximately 100 to 150 sudden cardiac deaths during competitive sports in the United States each year. While rare and potentially dangerous cases of heart inflammation have been associated with some Covid vaccines, these real cases have been muddled together with unrelated illnesses and misinterpreted, sometimes cherry-picked data. Combined with a wave of anti-vaccine activity online throughout the pandemic, it has given birth to a group of activists who ascribe nearly any tragic or unexplained death to vaccines. The loudest voices in the anti-vaccination lobby have followed this pattern throughout the pandemic, even though heart problems are a symptom of Covid itself. Hamlin, a defensive back for the Buffalo Bills, suffered a cardiac arrest during Monday night's high-profile matchup against the Cincinnati Bengals. On Wednesday he remained in hospital, but an uncle said he was showing signs of improving. There has been no further information about any underlying causes which could have contributed to his cardiac arrest. Research by the Center for Countering Digital Hate (CCDH), a non-profit campaign group based in London and Washington, found that mentions of an anti-vaccine film quadrupled after the player's collapse. CCDH chief executive Imran Ahmed said activists were ""cynically exploiting tragedy to baselessly connect any injury or death of a notable person to vaccinations"". The day after the match the documentary Died Suddenly, which was released in November last year, was mentioned nearly 17,000 times, the CCDH says. The BBC previously looked into the claims in the film and found little or no evidence behind many of them. Caroline Orr Bueno, a researcher on misinformation who has spent a decade looking at the anti-vaccination movement, says the film gave rise to communities of people across several social media platforms primed to hunt for news events to back up their views. ""They believe the anti-vaccine rhetoric that they are seeing,"" she says, ""and they are joining in out of genuine concern without necessarily knowing that they're being misled."" A Twitter account promoting the Died Suddenly video sent out a message just minutes after Hamlin was transported off the field in Cincinnati claiming there was an ""undeniable pattern"". When contacted for a response, the owners of the account responded with a list of anecdotal reports of athletes suffering heart problems. Backers of the film and other anti-vaccination activists collect news reports of heart attacks and unexplained deaths, automatically ascribing them to Covid-19 vaccines. This focused obsession has created a hypersensitive pattern-spotting spiral, with activists and followers often believing the link between every sudden athlete death and vaccines is ""obvious"", although there is scant solid research to back up their claims. While it might seem unusual for young, healthy people to experience heart problems, there are important differences between a heart attack and cardiac arrest. Most heart attacks are caused by blockages in arteries and are associated with older people as well as lifestyle factors like smoking and diet. Most cardiac arrests are caused by a problem with the heart's electrical system which keeps it pumping. These heart rhythm malfunctions are often genetically inherited and can be seen in young people who appear otherwise healthy. Premier League fans will remember the dramatic moment in 2012 when Bolton's Fabrice Muamba collapsed, having suffered a cardiac arrest. The 23-year-old's heart stopped beating for 78 minutes. A 2018 study by the Football Association looked back over 20 years of data from screening more than 11,000 players and found not only were cardiac deaths more common than previously thought - although still rare - but that most of them were in people with no previously diagnosed heart problem. One of the first clear examples of anti-vaccination activists taking advantage of a high-profile news event was the televised collapse of Danish football star Christian Eriksen during the European football championships in June 2021. Influential accounts immediately began blaming Covid vaccines. Only after the initial wave of speculation and misinformation was it revealed by the director of Eriksen's club at the time, Inter Milan, that the midfielder had not received a Covid-19 vaccine prior to his collapse. In November, Twitter stopped enforcing its Covid misinformation policy, a development that Imran Ahmed of the CCDH called ""particularly worrying"". ""Anti-vax lies are deadly and platforms must stop allowing dedicated spreaders of disinformation from abusing their platforms and the trust of other users."" The BBC has contacted Twitter and Marjorie Taylor Greene for comment. Online activists used the on-field collapse of American football star Damar Hamlin to spread anti-vaccination messages starting just minutes after Monday night's incident. In what has become a familiar pattern since Covid vaccines became available about two years ago, several influential accounts used the event to spread anti-vaccination content. They included the Georgia congresswoman Marjorie Taylor Greene, who tweeted: ""Before the covid vaccines we didn't see athletes dropping dead on the playing field like we do now... Time to investigate the covid vaccines."" That tweet was viewed around a million times within a day. But the idea that young, healthy athletes have never collapsed suddenly before Covid vaccines is easily disproven. A US study looking at athletes over four years found many unexplained deaths were in fact caused by cardiac arrest - a cause more common in male and African-American players. Previous studies pre-dating Covid-19 note that there are approximately 100 to 150 sudden cardiac deaths during competitive sports in the United States each year. While rare and potentially dangerous cases of heart inflammation have been associated with some Covid vaccines, these real cases have been muddled together with unrelated illnesses and misinterpreted, sometimes cherry-picked data. Combined with a wave of anti-vaccine activity online throughout the pandemic, it has given birth to a group of activists who ascribe nearly any tragic or unexplained death to vaccines. The loudest voices in the anti-vaccination lobby have followed this pattern throughout the pandemic, even though heart problems are a symptom of Covid itself. Hamlin, a defensive back for the Buffalo Bills, suffered a cardiac arrest during Monday night's high-profile matchup against the Cincinnati Bengals. On Wednesday he remained in hospital, but an uncle said he was showing signs of improving. There has been no further information about any underlying causes which could have contributed to his cardiac arrest. Research by the Center for Countering Digital Hate (CCDH), a non-profit campaign group based in London and Washington, found that mentions of an anti-vaccine film quadrupled after the player's collapse. CCDH chief executive Imran Ahmed said activists were ""cynically exploiting tragedy to baselessly connect any injury or death of a notable person to vaccinations"". The day after the match the documentary Died Suddenly, which was released in November last year, was mentioned nearly 17,000 times, the CCDH says. The BBC previously looked into the claims in the film and found little or no evidence behind many of them. Caroline Orr Bueno, a researcher on misinformation who has spent a decade looking at the anti-vaccination movement, says the film gave rise to communities of people across several social media platforms primed to hunt for news events to back up their views. ""They believe the anti-vaccine rhetoric that they are seeing,"" she says, ""and they are joining in out of genuine concern without necessarily knowing that they're being misled."" A Twitter account promoting the Died Suddenly video sent out a message just minutes after Hamlin was transported off the field in Cincinnati claiming there was an ""undeniable pattern"". When contacted for a response, the owners of the account responded with a list of anecdotal reports of athletes suffering heart problems. Backers of the film and other anti-vaccination activists collect news reports of heart attacks and unexplained deaths, automatically ascribing them to Covid-19 vaccines. This focused obsession has created a hypersensitive pattern-spotting spiral, with activists and followers often believing the link between every sudden athlete death and vaccines is ""obvious"", although there is scant solid research to back up their claims. While it might seem unusual for young, healthy people to experience heart problems, there are important differences between a heart attack and cardiac arrest. Most heart attacks are caused by blockages in arteries and are associated with older people as well as lifestyle factors like smoking and diet. Most cardiac arrests are caused by a problem with the heart's electrical system which keeps it pumping. These heart rhythm malfunctions are often genetically inherited and can be seen in young people who appear otherwise healthy. Premier League fans will remember the dramatic moment in 2012 when Bolton's Fabrice Muamba collapsed, having suffered a cardiac arrest. The 23-year-old's heart stopped beating for 78 minutes. A 2018 study by the Football Association looked back over 20 years of data from screening more than 11,000 players and found not only were cardiac deaths more common than previously thought - although still rare - but that most of them were in people with no previously diagnosed heart problem. One of the first clear examples of anti-vaccination activists taking advantage of a high-profile news event was the televised collapse of Danish football star Christian Eriksen during the European football championships in June 2021. Influential accounts immediately began blaming Covid vaccines. Only after the initial wave of speculation and misinformation was it revealed by the director of Eriksen's club at the time, Inter Milan, that the midfielder had not received a Covid-19 vaccine prior to his collapse. In November, Twitter stopped enforcing its Covid misinformation policy, a development that Imran Ahmed of the CCDH called ""particularly worrying"". ""Anti-vax lies are deadly and platforms must stop allowing dedicated spreaders of disinformation from abusing their platforms and the trust of other users."" The BBC has contacted Twitter and Marjorie Taylor Greene for comment."
Debunking the Covid deniers who enter hospitals,"A man making false and misleading statements about Covid-19 tried to remove a sick coronavirus patient from East Surrey Hospital, and is wanted by police. The man filmed himself arguing with doctors in the ward, demanding to be allowed to take the patient home. Doctors at the hospital are seen in the video warning against such an action - stating that the patient would die if he left their care. It follows a trend of people filming supposedly ""empty hospitals"" and then posting them online and encouraging others to do the same, spread on social media platforms. In a statement, Michael Wilson, chief executive of Surrey and Sussex Healthcare NHS Trust, said: ""Any suggestion that Covid-19 doesn't exist or isn't serious is not only extremely disrespectful to the NHS staff caring for patients affected by the virus, but it also puts the lives of others at risk."" The video has been shared thousands of times on social media. The man behind the camera makes a number of discredited claims - albeit ones that are very popular in Covid-19 conspiracy communities online. What's wrong with his statements? The doctor in the video describes the patient's condition and treatment, and notes that he's on a steroid called dexamethasone and antibiotics ""to treat concurrent bacterial infections"". The man filming insists the patient should be given vitamin C, vitamin D, and zinc instead. ""None of those are proven treatments for coronavirus,"" the doctor replies. Dexamethasone is an anti-inflammatory drug and trials have shown it can be effective in treating Covid-19. While vitamin C, vitamin D and zinc are essential for the body and can support the immune system, they won't cure the disease. The man behind the camera also claims that Covid-19 was ""declassified on 19 March 2020 as no longer highly contagious infectious disease"". He is probably referring to a technical classification - high consequence infectious diseases (HCIDs). Covid initially had this classification in the UK but now does not. This fact is used in online forums as ""proof"" that Covid-19 is not a real disease or that it is essentially harmless. In reality, it means nothing of the sort. Covid is dangerous but HCIDs are very deadly. The designation refers to the fatality rate, and the category includes Ebola and Sars, which have case-fatality rates of about 50% and 15% respectively. But just because Covid-19 does not have a fatality rate comparable to Ebola and Sars, it doesn't mean it's not a significant threat. The man filming also questions if Covid-19 has ""been proven to exist?"" Claims that the virus had not been ""identified"" or ""isolated"" were very popular online in early 2020, and they linger on today. They are often used to imply there is some sort of vague cover-up or ""hoax"". However, such claims are not true. The coronavirus genome was sequenced in early January 2020 - more than a year ago. The BBC attempted to contact Toby Hayden-Leigh, the man thought to have filmed the video. In a statement Thursday, Surrey Police said they arrested a 45-year-old man on suspicion of causing a public nuisance. They also said they arrested a second man on suspicion of assisting an offender. Read more from Reality Check Send us your questions"
Deepfake presidents used in Russia-Ukraine war,"A deepfake video shared on Twitter, appearing to show Russian President Vladimir Putin declaring peace, has resurfaced. Meanwhile, this week Meta and YouTube have taken down a deepfake video of Ukraine's president talking of surrendering to Russia. As both sides use manipulated media, what do these videos reveal about the state of misinformation in the conflict? And are people really believing them? The unconvincing fake of President Zelensky was ridiculed by many Ukrainians. Volodymr Zelensky appears behind a podium, telling Ukrainians to put down their weapons. His head appears too large for and more pixelated than his body - and his voice sounds deeper. In a video posted to his official Instagram account, the real President Zelensky calls it a ""childish provocation"". But the Ukrainian Center for Strategic Communications had warned the Russian government may well use deepfakes to convince Ukrainians to surrender. In a Twitter thread, Meta security-policy head Nathaniel Gleicher said it had ""quickly reviewed and removed"" the deepfake for violating its policy against misleading manipulated media. YouTube also said it had been removed for violating misinformation policies. It had been an easy win for the social-media companies, Nina Schick, author of the book Deepfakes, said, because the video was so crude and easily spotted as fake even by ""semi-sophisticated viewers"". ""The platforms can make a big hoo-ha about dealing with this,"" she said, ""when they aren't doing more on other forms of disinformation. ""There are so many other forms of disinformation in this war which haven't been debunked. ""Even though this video was really bad and crude, that won't be the case in the near future."" And it would still ""erode trust in authentic media"". ""People start to believe that everything can be faked,"" Ms Schick said ""It is a new weapon and a potent form of visual disinformation - and anyone can do it."" A deepfake tool letting users animate old photos of relatives has been widely used and the company behind it, MyHeritage, has now added LiveStory, which allows voices to be added. But there was a mixed reaction last year, when South Korean TV network MBN announced it was using a deepfake of newsreader Kim Joo-Ha. Some were impressed how realistic it was, others concerned the real Kim Joo-Ha would lose her job. Deepfake technology is also being used to create pornography, with a proliferation, in recent years, of websites letting users ""nudify"" pictures. And it can be used for satirical purposes - last year, Channel 4 created a deepfake Queen to deliver an alternative Christmas message. The use of deepfakes in politics remains relatively rare. But a deepfake former US President Barack Obama has been created, to demonstrate the technology's power. ""The Zelensky was a best-case deepfake problem,"" Witness.org. programme director Sam Gregory said. ""It was not very good, for a start so was easily detected. ""And it was debunked by Ukraine and Zelensky had rebutted it on social media, so it was an easy policy takedown for Facebook."" But in other parts of the world, journalists and human-rights groups feared they had neither the tools to detect nor the ability to debunk deepfakes. Detection tools analyse the way a person moves or look for things such as the machine-learning process that created the deepfake. But last summer, an online detector suggested a genuine video of a senior politician in Myanmar, apparently confessing to corruption - debate remains over whether it was a real statement or a forced confession - was a deepfake. ""The lack of 100% proof either way and people's desire to believe it was a deepfake reflects the challenges of deepfakes in a real-world environment,"" said Mr Gregory. ""President Putin was made into a deepfake a few weeks ago and it was widely regarded as satire - but there is a thin line between satire and disinformation."" The transcript of Mr Zelensky's deepfake first appeared on the ticker of Ukrainian TV network Ukrayina 24 during a live broadcast on Wednesday. A screenshot and full transcript later appeared on its website. Ukrayina 24 confirmed both website, inaccessible for most of Wednesday, and ticker had been hacked. The video was then widely shared on Russian-language Telegram and Facebook equivalent VK. From there, it made its way to platforms such as Facebook, Instagram and Twitter. There have been warnings deepfakes could be dangerous, including in a conflict, for some time. But creating a believable deepfake is costly and time consuming. And old videos and doctored memes remain the most common and effective misinformation tactic in this war. Neither well made nor believable, the Zelensky deepfake is among the worst I've seen. But the fact a deepfake has now been made and shared during a war is notable. The next one may not be as bad."
Deepfake technology: Can you spot what's real?,nan
Did misinformation fan the flames in Leicester?,"Recent violent disorder in Leicester caused shock and outrage and prompted dozens of arrests, but how much was it fuelled by misinformation posted online? We've spent the past week trying to unpick some of the false claims in and about Leicester and tried to see how much they spread both in the run-up to the disorder and the aftermath. Temporary chief constable Rob Nixon told BBC Two's Newsnight there had been a deliberate attempt by people to use social media in a destructive way. Mayor Sir Peter Soulsby also blamed online disinformation and said otherwise there was ""no obvious local cause for this at all"". At least one of those sentenced over the disorder has admitted being influenced by social media. When we spoke to people in Leicester, either community leaders, or those who otherwise had experience of the disorder, they singled out particular pieces of misinformation that had fuelled tension in the run-up to the worst of the disorder on the weekend of 17-18 September. One false story was referenced several times. ""Today my 15-year-old daughterÂ was nearly kidnapped,"" read a post uploaded on to Facebook, supposedly by a concerned father. ""3 Indian boys got out and asked her if she was Muslim. She said yes and one guy tried to grab her."" The post was liked hundreds of times, not on Facebook but on Twitter after Majid Freeman, a community activist, shared the family's story on 13 September. He also shared a message from the police which he said was ""confirming the incident which took place yesterday [12 September]"". But there had been no kidnap attempt. A day later, Leicestershire Police issued a statement after investigating and stated that ""the incident did not take place"". Majid Freeman deleted his posts and said the attempted abduction had not happened and that his initial version had been based on conversation with the family making the allegation. But damage had already been done and this false kidnap claim kept being regurgitated on other platforms. On WhatsApp, messages forwarded many times over were initially taken by some as the truth. On Instagram, profiles - some with hundreds of thousands of followers - shared screenshots of the original post and allegedly accused a Hindu man of being behind the ""failed abduction"". But it's not possible to gauge the scale of spread in private networks. And as far as public posts go we have used the CrowdTangle tool and been unable to find any repeating the attempted kidnapping claims. Posts could have been deleted of course, and the claims may still be circulating in private groups. Many in Leicester have said the roots of the tension go back much further. A swathe of media reports have focused on an incident in Leicester following a dramatic victory for India over Pakistan in cricket's Asia Cup in Dubai on 28 August. As with so much misinformation what happened next was a matter of distortion rather than complete fabrication. Something did happen. Video from that night shows a group of men, with several wearing India kits, marching down Melton Road in Leicester shouting ""death to Pakistan"" before scuffles broke out and the police arrived. Many on social media seized on another video supposedly showing a Muslim man being attacked after walking into the crowd. But it has subsequently been widely suggested that the man was a Sikh. There are some in Leicester who trace the disorder back much further, at least to an incident on Sunday 22 May. Video has been circulated on social media purportedly showing a 19-year-old Muslim man being pursued by a group of men described in social media posts as ""Hindu extremists"". Other posts referred to Hindutva, an ideology mostly associated with right-wing Hindu nationalists in India. The video itself does not show much - it is grainy and black-and-white and shows a group of men running down a street before an altercation happens. It's hard to decipher who these men were and what their specific backgrounds are. Police have said they are investigating a report of a public order offence  and have interviewed a 28-year-old man, but that the investigation is ongoing. The religious affiliation of the victim has not been revealed. While the truth of the incident is still being investigated, the social media posts have consistently been explicit in describing it as religiously motivated. Picking apart how much the social media distortion and misinformation has actually driven disorder is extremely difficult. These three incidents are not the only episodes to have prompted flurries of social media activity but they remain the most cited in the run-up to the major disorder on 17 and 18 September. Those events in Leicester, with tensions and disorder suddenly prominent in national media, prompted a massive increase in social media posts. An investigation by BBC Monitoring - using commercial Twitter analysis tool Brandwatch - identified about half a million tweets in English that mention Leicester in the context of recent tensions. Within a sample of 200,000 tweets, BBC Monitoring found that just over half of mentions were made by accounts that the tool geo-located to India. The top hashtags used by many of the Indian accounts in the past week included #Leicester, #HindusUnderAttack and #HindusUnderattackinUK. The BBC found lots of indications of manipulation by accounts using these hashtags. The most prolific user of some of these hashtags, for example, was geo-located to India, had no profile picture and the account was only started earlier this month. These are classic signs that can suggest ""inauthentic activity"" ie a likelihood that individuals are deliberately using multiple accounts to push a narrative. The BBC examined the top 30 URLs that were shared using these hashtags. Of them, 11 were links to articles written by news website OpIndia.com, which describes itself as ""bringing the right side of India to you"".  As well as potentially inauthentic accounts, these articles were also widely shared by genuine accounts including some with hundreds of thousands of followers. One of the OpIndia articles cited British researcher Charlotte Littlewood, from the Henry Jackson Society, who told GB News that several Hindu families had left Leicester due to threats of violence from Muslims. The article was retweeted nearly 2,500 times. Leicester Police have since said that they were unaware of any reports of families having to leave. It's important to stress that there was no significant volume of tweets before the outbreak of the major disorder on 17-18 September. Among the wave of social media activity in the UK prompted by the disorder, claims circulated widely that coach-loads of Hindu activists were being bussed into Leicester to stir up trouble. All we have to go on is the identities of the people arrested by police. As of 23 September they had arrested 47 people, of whom eight had been charged. Of those arrested, 36 were from Leicester, one from Market Harborough, eight from Birmingham and just two from London. All of the eight who were charged were from Leicester. Some posts made allegations that a specific London coach company had been used to bus in Hindu activists. A video that circulated on WhatsApp and Twitter from 18 September showed a coach outside a Hindu temple in London, with a voice claiming the coach had just returned from Leicester. In a video posted the next day on Instagram the owner of the coach company said: ""lots of people are calling me, threatening me, abusing me without any reason."" He said that none of his coaches had travelled to Leicester in the past two months and provided evidence from the GPS tracker of the bus in the video showing it had remained in south-east England on the weekend of 17-18 September. False claims also circulated about the causes of a fire in Birmingham on Monday 19 September. Posts viewed thousands of times on Twitter blamed ""Islamic extremists"" for setting the fire, without evidence. West Midlands Fire Service investigated the fire and concluded it started by accident when outdoor burning of rubbish spread to the building. Of course this is by no means to say that all of the posts that followed in the immediate aftermath of the disorder were misleading or distorted. One of the most circulated videos showed a group of masked Hindu men marching through Green Lane Road, an area of Leicester with a large Muslim population, shouting the Hindu slogan ""Jai Shri Ram"". Another video was circulated with posters saying it showed a Muslim man pulling down a Hindu saffron flag outside a temple. A flag was indeed pulled down at a temple on Belgrave Road in the city on the night of Saturday 17 September and police were investigating. However, the identity of the culprit is unclear.The false claims and inflammatory posts that have exacerbated tensions between Hindus and Muslims have been condemned by many locals from these communities. For decades, the city has been home to South Asians who came to the UK from parts of India and East Africa, and they have lived side-by-side and fought for equal rights together. Some people link the disorder and the reaction to it to the Hindutva ideology. They believe that Indian politics is being imported to the city, but thus far the BBC has found no direct link to such groups in the run-up to the disorder. Another narrative being pushed is that a particular, small South Asian community, allegedly with conservative views, started these tensions. Both Hindus and Muslims we've spoken to have expressed this. Again, there is no concrete evidence to support, nor counter this claim. It is difficult to pinpoint what has caused this violent unrest, but one thing is clear, social media stands accused of being the catalyst for sowing further divisions. Additional reporting by Yasminara Khan, Ahmed Nour, Khush Sameja, Shruti Menon, Ned Davies, Joshua Cheetham and Daniele Palumbo."
Election Day 2023: Local problems fuel baseless 'fraud' allegations,"In a preview of what promises to be a big theme during 2024's presidential election, local voting problems on election day ignited allegations of fraud by Donald Trump supporters. Mr Trump has consistently made false claims about widespread voter fraud costing him the 2020 election. Tuesday's incidents were scattered around the country. Mr Trump did not publicly comment on the allegations, but they were spread by some of his online backers. Two polling locations in Louisville, Kentucky, were ordered to stay open for 30 additional minutes on Tuesday night. A gas leak temporarily shut a polling location at Highland Baptist Church, while another location at Blue Lick Elementary School was also briefly closed due to a nearby police chase. As a result, a judge ordered both locations to briefly stay open to comply with a state law that requires polling places to open for a total of 12 hours. The incidents were seen by online partisans as potential proof of fraud. In just one post viewed almost one million times on X, a Trump supporter commented: ""Both the polling locations are in areas where democrats gain a ton of votes. It appears Democrat Beshear just may find the votes he needs to win tonight. It never ends."" But Erran Huber, a spokesperson for the Jefferson County Clerk, told the BBC that exactly one person voted across both locations during the extended half-hour opening period. ""Any claim that there was election tampering at either location is patently absurd,"" Mr Huber said. Mr Beshear won re-election as the state's governor, beating his Republican opponent Daniel Cameron by more than 65,000 votes. A voting machine bug appeared to flip votes in one county in Pennsylvania. The error occurred in ballot questions asking whether two state judges should retain their seats. Voters marked ""yes"" or ""no"" on each of the two candidates - one Democrat and one Republican. The machine appeared to swap the answers on a summary screen. Once again, news of the glitch was seized upon by Maga activists as proof of a larger ""voter fraud"" conspiracy. One commented: ""Voting machines have been SHUT DOWN at multiple state election locations due to errors, reports of 'votes getting flipped.'"" The problem was flagged up by voters in Northampton County shortly after the polls opened on Tuesday. County officials said in a statement that paper records would be used to correct the tally. State officials said the problem was limited to the two candidates and to Northampton County, and that no other areas or races were affected. In the Houston area, voting machines broke down at several polling stations, the Houston Chronicle newspaper reported on its election day live blog. Other machines at the locations continued to operate, although in some cases the result was long lines for voters. The paper reported that at one location, about 20 voters left a queue before casting their ballots. Again the issues prompted viral online rumours, but there was no indication the problems affected the outcome of any of Tuesday's races. The BBC contacted Harris County officials for comment. Among the rumours and baseless claims, there is one election in Connecticut which has been the subject of potentially credible allegations of vote tampering. Last week, a judge voided the results for the Democratic primary for mayor of Bridgeport, a city of about 150,000 people, after videos emerged of women inserting large numbers of ballots into a drop box. Connecticut law only allows family members or other close contacts to drop off absentee ballots in this way. Incumbent mayor Joe Ganim won the September primary by 251 votes over challenger John Gomes. Mr Ganim appeared headed for a similarly close win in Tuesday's general election, but the election may have to be re-run, pending the final outcome of the court case. Mr Ganim has denied wrongdoing. Both Mr Ganim and Mr Gomes are Democrats. In a preview of what promises to be a big theme during 2024's presidential election, local voting problems on election day ignited allegations of fraud by Donald Trump supporters. Mr Trump has consistently made false claims about widespread voter fraud costing him the 2020 election. Tuesday's incidents were scattered around the country. Mr Trump did not publicly comment on the allegations, but they were spread by some of his online backers. Two polling locations in Louisville, Kentucky, were ordered to stay open for 30 additional minutes on Tuesday night. A gas leak temporarily shut a polling location at Highland Baptist Church, while another location at Blue Lick Elementary School was also briefly closed due to a nearby police chase. As a result, a judge ordered both locations to briefly stay open to comply with a state law that requires polling places to open for a total of 12 hours. The incidents were seen by online partisans as potential proof of fraud. In just one post viewed almost one million times on X, a Trump supporter commented: ""Both the polling locations are in areas where democrats gain a ton of votes. It appears Democrat Beshear just may find the votes he needs to win tonight. It never ends."" But Erran Huber, a spokesperson for the Jefferson County Clerk, told the BBC that exactly one person voted across both locations during the extended half-hour opening period. ""Any claim that there was election tampering at either location is patently absurd,"" Mr Huber said. Mr Beshear won re-election as the state's governor, beating his Republican opponent Daniel Cameron by more than 65,000 votes. A voting machine bug appeared to flip votes in one county in Pennsylvania. The error occurred in ballot questions asking whether two state judges should retain their seats. Voters marked ""yes"" or ""no"" on each of the two candidates - one Democrat and one Republican. The machine appeared to swap the answers on a summary screen. Once again, news of the glitch was seized upon by Maga activists as proof of a larger ""voter fraud"" conspiracy. One commented: ""Voting machines have been SHUT DOWN at multiple state election locations due to errors, reports of 'votes getting flipped.'"" The problem was flagged up by voters in Northampton County shortly after the polls opened on Tuesday. County officials said in a statement that paper records would be used to correct the tally. State officials said the problem was limited to the two candidates and to Northampton County, and that no other areas or races were affected. In the Houston area, voting machines broke down at several polling stations, the Houston Chronicle newspaper reported on its election day live blog. Other machines at the locations continued to operate, although in some cases the result was long lines for voters. The paper reported that at one location, about 20 voters left a queue before casting their ballots. Again the issues prompted viral online rumours, but there was no indication the problems affected the outcome of any of Tuesday's races. The BBC contacted Harris County officials for comment. Among the rumours and baseless claims, there is one election in Connecticut which has been the subject of potentially credible allegations of vote tampering. Last week, a judge voided the results for the Democratic primary for mayor of Bridgeport, a city of about 150,000 people, after videos emerged of women inserting large numbers of ballots into a drop box. Connecticut law only allows family members or other close contacts to drop off absentee ballots in this way. Incumbent mayor Joe Ganim won the September primary by 251 votes over challenger John Gomes. Mr Ganim appeared headed for a similarly close win in Tuesday's general election, but the election may have to be re-run, pending the final outcome of the court case. Mr Ganim has denied wrongdoing. Both Mr Ganim and Mr Gomes are Democrats."
Elon Musk tweet boosts vaccine conspiracies targeting LeBron James' son,"An unfounded belief Covid vaccines are leading to a rise in heart problems, especially in young athletes, has been amplified by Twitter owner Elon Musk. Bronny James - son of basketball legend LeBron James - suffered a cardiac arrest on Monday while practising. In a tweet about the incident, Mr Musk said that ""we cannot ascribe everything to the Covid vaccine, but by the same token we cannot ascribe nothing"". But there is no evidence to support the implication vaccines might be involved. Mr James' family has thanked the doctors who helped him, and asked for privacy. Twitter - which is in the process of rebranding itself as X - allows its users to produce ""community notes"". These notes add further information to any Tweet considered misleading. A community note contextualising Mr Musk's comments initially appeared under his tweet, but it was removed overnight. It's not clear whether the note was removed by Twitter or because it was ""downvoted"" by other users. Twitter has not yet responded to our request for comment. In his tweet, Mr Musk also wrote that, ""myocarditis is a known side effect,"" in response to a post detailing Mr James' hospital admission. We have no information to suggest Mr James's cardiac arrest was linked to myocarditis - inflammation of the heart muscle - or to the vaccine. Pfizer and Moderna's Covid vaccines have been linked to relatively rare cases of myocarditis, but crucially, studies suggest this does not lead to have a higher risk of having a cardiac arrest. Myocarditis is more common and serious after Covid infections than after a vaccine. However, there is evidence cardiac arrests are more common in athletes than in the general population. Young athletes are more likely to experience a cardiac arrest than others their age. There is also evidence that among US athletes, African American players are at the highest risk. Mr Musk says, ""We cannot ascribe everything to the Covid vaccine, but by the same token we cannot ascribe nothing"". Yet it isn't the case that nothing is being ascribed to Covid vaccines. Health conditions, including myocarditis, have indeed been linked to some Covid vaccines - but only after careful medical examination. A number of people have taken to Twitter to suggest seemingly speculating someone's health condition has been caused by Covid vaccines without any evidence is unhelpful. Mr Musk's tweet has been taken as part of a wider trend of baselessly linking reports of illness and death to Covid vaccines before there are any facts available to support it. BBC Verify has been investigating this trend and who has been spreading it. Those caught in its crosshairs told the BBC of the additional distress that being trolled with conspiracy theories causes. And experts have raised concerns that the spreading of unfounded links between illness and Covid vaccines sows distrust in public health information. Glen Pyle, a professor who researches heart disease, said sudden cardiac incidents in athletes were not new, and had not increased following Covid vaccine rollouts. He said speculating on this issue was, ""irresponsible for anyone, but high profile people in particular"". He added that linking Covid vaccines and cardiac arrest might ""instil fear of a non-existent problem"" that could discourage vaccination and therefore actually increase the risk of heart issues, which are ""well-known to be linked to Covid"". Additional reporting by Shayan Sardarizadeh. You can listen to ""Ghouling: The trolls targeting bereaved people"" on BBC Sounds. What do you want BBC Verify to investigate? An unfounded belief Covid vaccines are leading to a rise in heart problems, especially in young athletes, has been amplified by Twitter owner Elon Musk. Bronny James - son of basketball legend LeBron James - suffered a cardiac arrest on Monday while practising. In a tweet about the incident, Mr Musk said that ""we cannot ascribe everything to the Covid vaccine, but by the same token we cannot ascribe nothing"". But there is no evidence to support the implication vaccines might be involved. Mr James' family has thanked the doctors who helped him, and asked for privacy. Twitter - which is in the process of rebranding itself as X - allows its users to produce ""community notes"". These notes add further information to any Tweet considered misleading. A community note contextualising Mr Musk's comments initially appeared under his tweet, but it was removed overnight. It's not clear whether the note was removed by Twitter or because it was ""downvoted"" by other users. Twitter has not yet responded to our request for comment. In his tweet, Mr Musk also wrote that, ""myocarditis is a known side effect,"" in response to a post detailing Mr James' hospital admission. We have no information to suggest Mr James's cardiac arrest was linked to myocarditis - inflammation of the heart muscle - or to the vaccine. Pfizer and Moderna's Covid vaccines have been linked to relatively rare cases of myocarditis, but crucially, studies suggest this does not lead to have a higher risk of having a cardiac arrest. Myocarditis is more common and serious after Covid infections than after a vaccine. However, there is evidence cardiac arrests are more common in athletes than in the general population. Young athletes are more likely to experience a cardiac arrest than others their age. There is also evidence that among US athletes, African American players are at the highest risk. Mr Musk says, ""We cannot ascribe everything to the Covid vaccine, but by the same token we cannot ascribe nothing"". Yet it isn't the case that nothing is being ascribed to Covid vaccines. Health conditions, including myocarditis, have indeed been linked to some Covid vaccines - but only after careful medical examination. A number of people have taken to Twitter to suggest seemingly speculating someone's health condition has been caused by Covid vaccines without any evidence is unhelpful. Mr Musk's tweet has been taken as part of a wider trend of baselessly linking reports of illness and death to Covid vaccines before there are any facts available to support it. BBC Verify has been investigating this trend and who has been spreading it. Those caught in its crosshairs told the BBC of the additional distress that being trolled with conspiracy theories causes. And experts have raised concerns that the spreading of unfounded links between illness and Covid vaccines sows distrust in public health information. Glen Pyle, a professor who researches heart disease, said sudden cardiac incidents in athletes were not new, and had not increased following Covid vaccine rollouts. He said speculating on this issue was, ""irresponsible for anyone, but high profile people in particular"". He added that linking Covid vaccines and cardiac arrest might ""instil fear of a non-existent problem"" that could discourage vaccination and therefore actually increase the risk of heart issues, which are ""well-known to be linked to Covid"". Additional reporting by Shayan Sardarizadeh. You can listen to ""Ghouling: The trolls targeting bereaved people"" on BBC Sounds. What do you want BBC Verify to investigate?"
Escaping the anti-vax conspiracy rabbit hole,nan
Explaining the 'how' - the launch of BBC Verify,"In the early hours of Wednesday 3 May, video footage emerged showing what appeared to be two drones crashing into a dome of the Kremlin complex in Moscow. But was the video real or fake? Did this ""attack"" actually happen? And how could we tell? The exponential growth of manipulated and distorted video means that seeing is no longer believing. Consumers tell us they can no longer trust that the video in their news feeds is real. Which is why we at the BBC must urgently begin to show and share the work we do behind the scenes, to check and verify information and video content before it appears on our platforms. And as AI weaponises and turbocharges the impact and consequences of disinformation, this work has never been more important. All day, every day, the BBC's news teams are using ever more sophisticated tools, techniques and technology to check and verify videos like the Kremlin drone footage, as well as images and information. They do this to ensure our journalism meets the rigorous editorial standards the BBC is proud to uphold. But, until now, that work has largely gone on in the background, unseen by audiences. These same audiences are constantly bombarded with mis- and disinformation, and with fake images, including those generated by AI. And they are telling us that amid this noise and sensationalism, they need to see our workings, so we can maintain the trust people have put in the BBC for the last 100 years. People want to know not just what we know (and don't know), but how we know it. And this is how our new brand, BBC Verify, has come into being. We've brought together forensic journalists and expert talent from across the BBC, including our analysis editor Ros Atkins and disinformation correspondent Marianna Spring and their teams. In all, BBC Verify comprises about 60 journalists who will form a highly specialised operation with a range of forensic investigative skills and open source intelligence (Osint) capabilities at their fingertips. They'll be fact-checking, verifying video, countering disinformation, analysing data and - crucially - explaining complex stories in the pursuit of truth. This is a different way of doing our journalism. We've built a physical space in the London newsroom, with a studio that BBC Verify correspondents and experts will report from, transparently sharing their evidence-gathering with our audiences. They will contribute to News Online, radio and TV, including the News Channel and our live and breaking streaming operation, both in the UK and internationally. BBC Verify will be home to specific expertise and technology. But I want the principle of transparently explaining the ""how"" behind our journalism to be shared by every journalist in the BBC - and thank you to those who are experimenting with new ways to do that. ""If you know how it's made, you can trust what it says"" - that's what our audiences have told us. Trust is earned and transparency will help us earn it. And as for that ""drone""? There are a few answers on Ros Atkins' explainer video, which has had more than a million views on our website, and will give people a taste of what Verify will be doing, day in, day out. In the early hours of Wednesday 3 May, video footage emerged showing what appeared to be two drones crashing into a dome of the Kremlin complex in Moscow. But was the video real or fake? Did this ""attack"" actually happen? And how could we tell? The exponential growth of manipulated and distorted video means that seeing is no longer believing. Consumers tell us they can no longer trust that the video in their news feeds is real. Which is why we at the BBC must urgently begin to show and share the work we do behind the scenes, to check and verify information and video content before it appears on our platforms. And as AI weaponises and turbocharges the impact and consequences of disinformation, this work has never been more important. All day, every day, the BBC's news teams are using ever more sophisticated tools, techniques and technology to check and verify videos like the Kremlin drone footage, as well as images and information. They do this to ensure our journalism meets the rigorous editorial standards the BBC is proud to uphold. But, until now, that work has largely gone on in the background, unseen by audiences. These same audiences are constantly bombarded with mis- and disinformation, and with fake images, including those generated by AI. And they are telling us that amid this noise and sensationalism, they need to see our workings, so we can maintain the trust people have put in the BBC for the last 100 years. People want to know not just what we know (and don't know), but how we know it. And this is how our new brand, BBC Verify, has come into being. We've brought together forensic journalists and expert talent from across the BBC, including our analysis editor Ros Atkins and disinformation correspondent Marianna Spring and their teams. In all, BBC Verify comprises about 60 journalists who will form a highly specialised operation with a range of forensic investigative skills and open source intelligence (Osint) capabilities at their fingertips. They'll be fact-checking, verifying video, countering disinformation, analysing data and - crucially - explaining complex stories in the pursuit of truth. This is a different way of doing our journalism. We've built a physical space in the London newsroom, with a studio that BBC Verify correspondents and experts will report from, transparently sharing their evidence-gathering with our audiences. They will contribute to News Online, radio and TV, including the News Channel and our live and breaking streaming operation, both in the UK and internationally. BBC Verify will be home to specific expertise and technology. But I want the principle of transparently explaining the ""how"" behind our journalism to be shared by every journalist in the BBC - and thank you to those who are experimenting with new ways to do that. ""If you know how it's made, you can trust what it says"" - that's what our audiences have told us. Trust is earned and transparency will help us earn it. And as for that ""drone""? There are a few answers on Ros Atkins' explainer video, which has had more than a million views on our website, and will give people a taste of what Verify will be doing, day in, day out."
Facebook adds 'expert' feature to groups,"Facebook is rolling out a way to designate topic ""experts"" inside user-run Facebook groups. The social network says the new feature is designed to help real experts ""stand out"" in discussions about their field of expertise. Group admins will have the power to give the title to nearly any member they want. That could mean that groups promoting conspiracy theories or fringe views may also be able to designate ""experts"". Facebook groups have been used by movements such as QAnon, anti-vaccination groups, and contentious political factions which spread misinformation. Earlier this year, Facebook changed its policies to remove groups which discourage people from getting vaccines, and also stopped recommending political groups to new members. However, a Facebook spokesperson said the function was a ""limited test"" and only available to select groups to begin with. They also said groups were subject to its community standards - and that people who had received more than three ""strikes"" for violating those standards in the past 90 days, would not be eligible to be marked as ""experts"". Facebook said the new feature is a way to promote genuinely knowledgeable voices within groups. ""Admins now have the ability to select specific members in their communities who stand out, empowering them to play a more meaningful role,"" Facebook executive Maria Smith wrote in a blog post. ""Admins can collaborate with group experts to host Q&As, share perspectives on a topic and respond to questions,"" she added. The people selected will have a choice of whether to accept or decline the expert invitation. If they accept, they will get a badge next to their name. The company said that among the active groups currently running on Facebook, there are about 70 million administrators and moderators. As part of the rollout, Facebook said it is also experimenting with ways to let group admins find true experts on a topic to invite to their groups. It said it was testing giving specific, curated people in the fitness and gaming spheres the ability to specify what they have expertise in - ""like yoga or a particular game title"". Group admins could then search for experts to invite to raise the standard of contributions. By Alistair Coleman, BBC Monitoring Despite clamping down on vaccine denial and the QAnon conspiracy, Facebook still remains a significant driver for this type of content, hiding behind the respectable front of groups promoting wellness, parenting, politics and local issues. So while Facebook's plan to allow group admins to appoint experts initially looks appealing as a means of bringing trusted content to users, it offers up the question of whether these experts will be entirely trustworthy. A page with an anti-vaccine agenda could quite easily appoint ""experts"" opposed to vaccines, and use their trusted status to post misleading content. Facebook's announcement currently gives no indication of a vetting process for appointing experts. It allows individual group members to flag up their expertise and hope they are invited by the admins. This is a process that could obviously be gamed by users and admins looking to play the system. With group admins being the final arbiter of who is an expert, it follows that an admin who tolerates or even promotes conspiratorial ideas may not be best placed to decide who is an ""expert"". Facebook rolled out a vaccine misinformation policy earlier this year, saying it would remove anti-vaccine content on pages, groups and personal accounts, but it's become a cat-and-mouse game as users find ways round it, such as anti-vaccine picture frames for avatars - to keep one step ahead."
Facebook drives sceptics towards climate denial,"Facebook pushes climate sceptics towards increasingly extreme disinformation and conspiracy groups, a human-rights body's research suggests. A report released Wednesday by Global Witness found Facebook's algorithm amplified doubts rather than nudging people towards reliable information. Facebook says its systems are ""designed to reduce misinformation"". Researchers created two users - climate sceptic ""Jane"" and ""John"" who followed established scientific bodies. They then tracked what Facebook's algorithm suggested to both accounts. Jane soon saw content denying man-made climate change, including pages calling it a ""hoax"" and attacking measures to mitigate its effects. Examples included posts accusing the ""green movement"" of ""enslaving humanity"" and calling the United Nations ""an authoritarian regime with less credibility than Bugs Bunny"". Other posts, such as this one from CFact Campus, denied humans influenced the climate. The group is part of the Committee for a Constructive Tomorrow, a Washington-based libertarian think tank against the consensus on climate science. The researchers had Jane's account ""like"" a Facebook page spreading climate disinformation, as a ""starter"" page, repeated this process twice, each time choosing a page with at least 14,000 followers, and expressed scepticism about the existence of climate change or its human origins. In one simulation, Jane ""liked"" a Facebook page called I Love Carbon Dioxide. The post above blends fact and fiction. In 2009, former US Vice-President Al Gore cited climate scientists, saying: ""There is a 75% chance that the entire North Polar ice cap during some of the summer months could be completely ice free within the next five to seven years."" Although this was a mischaracterisation of climate scientists' findings, it was not a prediction ""all ice would melt by 2013"". Nor did Mr Gore repeatedly make this claims over the next few years, as the post suggests. Another post on the page highlighted a legitimate concern about the source of power for electric vehicles but also called climate change a ""make-believe"" crisis. From these beginnings, over a period of about two months, Jane was recommended more and more conspiratorial and anti-science content, researchers say. Of all the pages recommended to her account, only one was free of climate-change disinformation. And two-thirds did not contain a warning label pointing towards Facebook's climate-science centre, an information hub created last year, after Meta chief executive Mark Zuckerberg told a US congressional hearing climate disinformation was ""a big issue"". Meanwhile, John's account began by liking the page of the Intergovernmental Panel on Climate Change (IPCC), the United Nations scientific body. And in contrast to Jane, John was consistently shown reliable science-based content. As the simulation continued, Facebook began to recommend even more extreme and fringe content to Jane, including conspiracy theories, such as ones about ""chem trails"" - false claims condensation left by planes contains chemical agents that can control the weather. The Facebook algorithm has been shown to send users down rabbit holes - where content becomes increasingly fringe as users engage with posts on a particular topic - in other areas, such as gender-based abuse. The IPCC says disinformation is one of a number of issues preventing governments and the public from addressing climate change. Its latest report, backed by 195 governments, emphasises misinformation around climate science ""undermines climate science and disregards risk and urgency"". Meta, which owns Facebook, says it is flagging more posts about climate with information labels. A company representative told BBC News: ""Our systems are designed to reduce misinformation, including climate misinformation, not to amplify it. ""We use a combination of artificial intelligence, human review, and input from partners - including fact-checkers - to address problematic content. ""When they rate this content as false, we add a warning label and reduce its distribution so fewer people see it. The company announced a $1m (Â£650,000) grant programme to support organisations working to combat climate misinformation. But another recent study, by the Center for Countering Digital Hate and the Institute for Strategic Dialogue, said less than 10% of misleading posts on the platform were marked as misinformation. Global Witness researcher Mai Rosner said: ""Facebook has repeatedly said it wants to combat climate disinformation on its platform - but our investigation shows how worryingly easy it is for its users to be led down a dangerous path that flies in the face of both science and reality. ""Facebook is not just a neutral online space where climate disinformation exists - it is quite literally putting such views in front of users' eyes. ""The climate crisis is increasingly becoming the new culture war, with many of the same individuals who for years have sought to stoke division and polarise opinion now viewing climate as the latest front in their efforts."""
Facebook earns $9bn despite whistleblower scandal,"Facebook has posted better-than-expected profits for the third quarter, as it continues to face bad press over leaked internal documents. The social media giant made $9bn (Â£6.5bn) of profit in the three months to September, up from $7.8bn last year. However, it was hit by a new privacy update to Apple's iOS 14 operating system, which made it harder for brands to target ads at specific users. It comes amid fresh claims of unethical behaviour made by a former employee. Frances Haugen has released a cache of internal documents to the public, alleging that Facebook put profit before user safety. Multiple media reports say the documents show Facebook struggled to moderate content that promoted hate speech and sex trafficking outside of the US. On Monday, Facebook chief executive Mark Zuckerburg told investors on a conference call: ""What we are seeing is a coordinated effort to selectively use leaked documents to paint a false picture of our company."" In the 12 months to 30 September, the social media giant said its monthly user-base had grown 6% to 2.91 billion. However, despite its strong profits, its revenue slightly undershot analyst expectations, amid ""headwinds"" caused by Apple's privacy rules. Facebook said the privacy update would also have an impact on its digital business in the final quarter of the year, but that it expected to adjust to the changes in time. The firm said it would spend some $10bn on its metaverse division this year - known as Facebook Reality Labs - which is tasked with creating augmented and virtual reality hardware, software and content. The world's largest social media network is under scrutiny from global lawmakers and regulators, including from the Federal Trade Commission, which has filed an antitrust lawsuit alleging anticompetitive practices. The whistleblower documents, which were first reported by the Wall Street Journal, have only intensified that pressure. They include internal research about Instagram's effects on teen mental health; whether Facebook's platforms stoke division; and the social media giant's handling of the 6 January Capitol riot. At a hearing on Monday, Ms Haugen told UK MPs that Facebook is ""unquestionably making hate worse"". She said Facebook safety teams were under-resourced, and that ""Facebook has been unwilling to accept even little slivers of profit being sacrificed for safety"". The MPs are considering what new rules to impose on big social networks under the planned Online Safety Bill. But on his conference call, Mr Zuckerberg hit back: ""Good faith criticism helps us get better, but my view is that we are seeing a coordinated effort to selectively use leaked documents to paint a false picture of our company. ""The reality is that we have an open culture that encourages discussion and research on our work so we can make progress on many complex issues that are not specific to just us."" Despite the allegations, shares in Facebook climbed by 1.3% in after hours trading on Monday. The firm's stock is up by about 20% so far this year."
Facebook in Australia: What happened after news was blocked?,"Critics of Facebook say the company's ban on news appearing on its platform in Australia has made it more difficult for people to access reliable sources - and increased the influence of bad and misleading information. But is there any evidence of this since the ban was imposed on Thursday? It quickly became clear that one effect of the tech giant's move was that in addition to news providers, emergency services were also being blocked. Some Australian government health-department and emergency-services pages found that their Facebook accounts had been affected. They were later restored after Facebook was notified. Welfare groups such as Women's Health Tasmania also faced difficulties. ""We stream physical activity classes through Facebook,"" says Jo Flanagan, the group's chief executive. ""We push public-health-generated Covid updates. ""Clients use messages on Facebook to contact us when they don't have phone credit. It was very disruptive."" The page is now working again. Will Easton, managing director of Facebook Australia, said: ""Pages such as government, public-safety and education pages should not be impacted by this announcement. ""We apologise to any pages that were inadvertently impacted."" The day after the ban, we checked some of the pages that had faced problems, including a satirical-news site, a women's legal-services page, and a weather-forecasting platform. They had all been reactivated. Facebook says it's working to restore other sites that have also been blocked inadvertently. We can't give a definitive answer to this for all Facebook users in Australia. But we've done some digging with data-analysis tool CrowdTangle, itself part of the Facebook family of online products. Using CrowdTangle, it's possible to look at the most engaged with posts from Facebook pages with admins based in a country - it therefore gives you a pretty good idea what's been shared on that subject. In one example, we looked at Facebook posts from pages in Australia related to Covid-19 and vaccines over two 24-hour periods - before and after the ban was imposed. We found: Facebook has responded to its critics by saying its commitment to combating misinformation has not changed. ""We are directing people to authoritative health information and notify them of new updates via our Covid-19 Information Centre,"" it says. ""We're also continuing our third-party fact-checking partnerships with AAP (Australian Associated Press) and AFP (Agence France-Press), who review content and debunk false claims online."" However, Peter Bodkin, editor of the AAP fact-checking team, says his news organisation's content is being restricted. The AAP can still rate and label posts on Facebook and tack on links to reliable AAP stories, but users cannot share the site's articles themselves. ""It seems like a terrible outcome, to state the obvious,"" he says. Fact-checking sites are, of course, accessible without any need to go through Facebook. However, Russell Skelton, of ABC's (Australian Broadcasting Corporation) fact-checking project with RMIT University, points out that the ban affects precisely the audience that fact-checkers want to reach. ""Some 11 million-plus Australians use Facebook as their primary source of news,"" he says. ""Facebook's action has certainly prevented us from engaging with a more diverse audience who do not come to the ABC news website for their information."" Reporting by Jack Goodman, Shayan Sardarizadeh, Olga Robinson and Christopher Giles What claims do you want BBC Reality Check to investigate? Get in touch Read more from Reality Check"
Facebook removes anti-vax influencer campaign,"Facebook has removed hundreds of accounts which it says were involved in anti-vax disinformation campaigns operated from Russia. The company said the network of accounts targeted India, Latin America and the US. They attempted to recruit influencers to spread false claims to undermine public confidence in particular Covid-19 vaccines, it added. In its latest report on ""coordinated inauthentic behaviour"", Facebook said it found links between the network and a botched disinformation campaign from influencer marketing agency Fazze - which is part of a Russian-based company called AdNow. Last month a BBC Trending investigation reported how in May this year influencers had been offered money by Fazze to spread false claims about the risks associated with the Pfizer vaccine. According to Facebook, that was the second wave of attempts by the network to smear Western vaccines. Their investigation found that from November 2020 the same network attempted to falsely paint the AstraZeneca vaccine as dangerous because it uses a harmless adenovirus taken from chimpanzees. Posts from accounts in the network spread memes that used images from the Planet of Apes films to give the impression the vaccine would turn people into monkeys. These posts appeared on Facebook in Hindi around the same time the Indian government was discussing emergency authorisation for the AstraZeneca vaccine. The campaign used fake accounts, some of which Facebook says probably originated from account farms in Bangladesh and Pakistan. Facebook said it had removed 65 Facebook accounts and 243 Instagram accounts for violating their policy against foreign interference. Ben Nimmo, Facebook's threat intelligence lead, described the campaign as ""a disinformation laundromat"" which planted content on a few online forums and then amplified that content on other platforms. The operation spanned over a dozen platforms. Misleading posts appeared on Reddit and Medium, and petitions appeared on change.org expressing concern about the safety of the AstraZeneca vaccine. According to Facebook's report, these links were then shared by a handful of influencers on Instagram who used the same hashtags and made references to the fact that the AstraZeneca vaccine was derived from chimpanzee adenovirus. Both waves of the campaign were unsuccessful and failed to gain much traction - despite the diverse methods used. ""In addition to the previously-exposed efforts to enlist social media influencers, this operation appears to have used a whole range of tactics in a wider effort to seed misleading narratives online about Western-made Covid vaccines,"" said Jack Stubbs, Director of Investigations at social media analytics firm Graphika. ""There was a claimed hack-and-leak, the use of pay-to-publish pseudo-news sites, and a network of fake personas on Facebook and Instagram."" Despite the best efforts of the campaign, Facebook's report observed sloppy practices, including mixing languages - such as posting Hindi language memes accompanied by hashtags in Portuguese. BBC Trending's investigation showed Fazze was part of a Russian company, AdNow. The BBC made repeated attempts to obtain a comment from AdNow's headquarters in Moscow, but received no response. However, a director of AdNow's British arm told the BBC that Fazze was being shut down. In response to accusations by a German politician that discrediting Western vaccines was in the interests of the Kremlin, the Russian Embassy in the UK said: ""We treat Covid-19 as a global threat and, thus, are not interested in undermining global efforts in the fight against it, with vaccinating people with the Pfizer vaccine as one of the ways to cope with the virus."" The BBC has again attempted to contact Fazze for comment but the emails sent to Fazze addresses still bounce back from AdNow's domain. Facebook says Fazze is now banned from their platform. Listen to BBC Trending: The anti-vax influencer plot that flopped on the World Service. Download the podcast or listen online."
Facebook's Trump ban upheld by Oversight Board for now,"Donald Trump's ban from Facebook and Instagram has been upheld by Facebook's Oversight Board. But it criticised the indefinite nature of the ban as beyond the scope of Facebook's normal penalties. It has ordered Facebook to review the decision and ""justify a proportionate response"" that is applied to everyone, including ordinary users. The former president was banned from both sites in January following the Capitol Hill riots. The Oversight Board said the initial decision to permanently suspend Mr Trump was ""indeterminate and standardless"", and that the correct response should be ""consistent with the rules that are applied to other users of its platform"". Facebook must respond within six months, it said. At a press conference, co-chair Helle Thorning-Schmidt admitted: ""We did not have an easy answer."" She added that she felt Facebook would ""appreciate the decision"". ""We are telling Facebook to go back and be more transparent about how it assesses these things. Treat all users the same and don't give arbitrary penalties."" In response, Facebook said it would ""consider the board's decision and determine an action that is clear and proportionate"". The board also made a number of recommendations about how Facebook should improve its policies and the social network promised to ""carefully review"" these. The Board was due to announce its decision last month but delayed the ruling in order to review more than 9,000 public responses to cases, it said. In the meantime, Mr Trump, who is also banned from Twitter, launched a new website on Tuesday to update supporters with his thoughts. Following the ruling, Mr Trump wrote that ""what Facebook, Twitter, and Google have done is a total disgrace"". ""Free speech has been taken away from the President of the United States because the radical left lunatics are afraid of the truth,"" he said, referring to himself as president. ""The people of our country will not stand for it! These corrupt social media companies must pay a political price, and must never again be allowed to destroy and decimate our electoral process,"" he said. The administration of Mr Trump's successor, Democratic President Joe Biden, declined to comment on Facebook's ruling on Wednesday. But White House Press Secretary Jen Psaki said it was President Biden's view that ""major platforms have a responsibility related to the health and safety of all Americans to stop amplifying untrustworthy content, disinformation and misinformation"". The ruling means that Mr Trump's suspension remains in place for now. The Oversight Board decided that Mr Trump had broken Facebook's community standards, and upheld the ban. But it is the ""indefinite"" part of the ban that it took issue with because that is not within its own rules. ""It is not permissible for Facebook to keep a user off the platform for an undefined period, with no criteria for when or whether the account will be restored,"" it said in a statement. Applying that type of ban to Mr Trump was not following any clear procedure, it said. The Board argued that Facebook had essentially issued ""a vague, standardless penalty and then [referred] this case to the Board to resolve"". It said doing so meant ""Facebook seeks to avoid its responsibilities"" - and sent the decision back to Facebook. Co-chair Michael McConnell justified the timeframe saying that it was a decision ""not to be rushed"" and admitted that the firm may decide to throw it back to the Oversight Board yet again. Setting up a ""Supreme Court"" to rule on tricky issues seemed like a smart move by Mark Zuckerberg. Whatever the Oversight Board decided, Facebook's boss could say ""not my fault, blame the judges"". But that's unlikely to wash here. There can be no more divisive issue than President Trump's presence on a platform credited or blamed by many for his electoral success in 2016 and probably crucial if he decides to run again in 2024. Now, the Oversight Board has thrown the hot potato right back into Mr Zuckerberg's lap. He and his team have been told to go away and have a long hard think about how they handle tricky cases like this one. They will have to decide the meaning of the term ""newsworthy"" and conduct a proper inquest into the platform's role in the events of 6 January. And at the end of it all, Facebook will still have to decide what to do about Donald Trump. Mark Zuckerberg could be forgiven for wondering whether setting up this body was such a good idea after all - and why he is paying the generous salaries of the board's members. Often referred to as ""Facebook's Supreme Court"", it was set up to rule on difficult or controversial moderation decisions made by Facebook. It was established by Facebook boss Mark Zuckerberg but operates as an independent entity, although its wages and other costs are covered by Facebook. It is made up of journalists, human rights activists, lawyers and academics. The committee has already ruled on nine cases including a comment that seemed derogatory to Muslims. The post from a user in Myanmar, removed for breaking hate-speech rules, was found by the board not to be Islamophobic when taken in context. Following the Capitol Hill riots on 6 January, Facebook announced it was banning Mr Trump for breaking its ""glorification of violence"" rules. Hundreds of his supporters entered the complex as the US Congress attempted to certify Joe Biden's victory in last year's presidential election. Mr Trump was acquitted of a charge of inciting insurrection at the US Capitol in his second impeachment trial in February, after being accused of encouraging the violence, during which four people lost their lives. The social network had originally imposed a 24-hour ban after the attack which was then extended ""indefinitely"". Mr Zuckerberg announced that the risks of allowing Mr Trump to post were ""simply too great"". The former president has also been banned from Twitter and YouTube. Correction 25 May 2021: An earlier version of this article said that five people had died in the violence during the Capitol Hill riots on 6 January and this has been amended to make clear that four people died, in different circumstances."
Fact-checkers label YouTube a 'major conduit of online disinformation',"Fact-checking organisations around the world say that YouTube is not doing enough to prevent the spread of misinformation on the platform. Some 80 groups have signed a joint letter to the Google-owned platform's chief executive Susan Wojcicki. The letter says it is ""one of the major conduits of online disinformation and misinformation worldwide"". The organisations want YouTube to take firmer action against anti-vaccine videos, and election disinformation. Among the signatories from Europe, Africa, Asia, the Middle East, and the Americas are UK charity Full Fact, and the Washington Post's fact-checking team. The open letter states that ""livelihoods have been ruined, and far too many people have lost loved ones to disinformation"". It goes on to accuse YouTube of not making enough effort to address the problem, saying that it ""is allowing its platform to be weaponised by unscrupulous actors to manipulate and exploit others"". The problem is made more complex when the false content is not in English, or originates from developing countries, it says. The letter lists worldwide examples which have the potential to cause real-life harm, which went under the radar of YouTube's content policies. It says these are ""insufficient"" and not working. The fact-checking groups have called for: YouTube should also fix its recommendation algorithms to ensure it ""does not actively promote disinformation to its users, or recommend content coming from unreliable channels"", the letter says. YouTube spokesperson Elena Hernandez told the Guardian the company was already investing in ways ""to connect people to authoritative content, reduce the spread of borderline misinformation, and remove violative videos"". She added: ""We're always looking for meaningful ways to improve and will continue to strengthen our work with the fact-checking community."" While the Covid-19 pandemic has seen a surge in misinformation about the virus and vaccines, YouTube and other social media platforms like Facebook, WhatsApp and Twitter have been plagued with content promoting fake news and conspiracy theories for years. These include election fraud, hate speech, conspiracy theories based around bogus concepts such as the ""new world order"", and the QAnon conspiracy. Critics say that platforms haven't done enough to combat disinformation, which has resulted in injuries, death and the break-up of families. Last year, a British man who died with Covid-19 after refusing to be vaccinated, made - according to his family - a ""terrible mistake"" of being influenced by online anti-vaccine content. In 2020, Florida taxi driver Brian Lee Hitchens lost his wife to Covid-19 after they were influenced by Facebook content that claimed the pandemic is a hoax. YouTube announced last year that it would remove all anti-vaccine misinformation from its platform, and deleted videos posted by Brazilian President Jair Bolsonaro, because they spread misinformation about coronavirus. Full Fact chief executive Will Moy told the BBC he had urged YouTube to work with independent fact-checkers to improve the information ecosystem. ""Bad information ruins lives. Like other fact-checkers around the world, Full Fact has seen examples of harmful content on YouTube,"" he said. ""YouTube, like other internet companies, have up until now been allowed to mark their own homework. It cannot be left to internet companies to decide how to tackle bad information or choose how transparent to be about it."""
Fake Covid videos 'will cost lives',nan
Fake Trump arrest photos: How to spot an AI-generated image,"Fake images created by artificial intelligence (AI) tools depicting Donald Trump have appeared on social media over the past week. Many falsely showed the arrest of the former president, who may face indictment over payment of hush money to a woman he allegedly had an affair with. He has not yet been charged with a crime. Many of those sharing the images pointed out they were fake, and they did not appear to fool lots of people - but a few did seem to be tricked. On Thursday, Mr Trump also shared an AI-generated image on his own social media platform Truth Social. It showed him kneeling in prayer. What are some of the tell-tale signs of AI-generated imagery? And how can you distinguish a real from a fake? The images circulating online, like the one above, look hyper-real - more like staged artistic shots than in-the-moment photographs. A closer look shows some obvious giveaways that something isn't quite right. Look at the centre of the image. Mr Trump's arm is much too short, and the police officer on the left is grabbing something that more resembles a claw than a human hand. Similarly, if you focus on Mr Trump's neck, you'll notice that his head looks as if it's been superimposed on the image. Henry Ajder, an AI expert and presenter of the BBC radio series The Future Will be Synthesised, says current technology is not very good at depicting certain body parts, especially hands. ""If you zoom in on the images you can often see inconsistencies such as the number of fingers,"" he says. A simple check of a few news sites is a sure-fire way to verify that Mr Trump hasn't been arrested or even indicted - at least, not yet. If and when Mr Trump does face charges, his arrest will make headline news all around the world. And you can imagine the media flurry if the former president were to somehow flee from police. Another good idea is to think about the context in which an image is being shared. Who's sharing it - and what are their motives? Often people share pictures to amplify their broader political views, even if they haven't checked whether the photos are authentic, Mr Ajder says. ""We've seen really crude examples of other fakes such as the recording of Nancy Pelosi being slowed down to make her sound drunk,"" he adds. ""That was a super crude piece of manipulation and yet many people were fooled by it - or at least wanted to believe it."" A closer look at the photos themselves reveals more dubious details. Unnatural skin tones and faces with waxy or blurred-out features are strong indications that the image is fake. In the picture above, a person with a blurry face is clearly visible on the centre-right. And Mr Trump's hair appears blurry, while his face is in focus. AI technology has also not yet mastered accurate depictions of eyes. In the image above, officers appear to be chasing Mr Trump - but they're looking in a totally different direction. AI experts told the BBC that while faked imagery is ""nothing new"", the speed of progress within the field, and potential for misuse, is something to be concerned about. ""Synthetic content is evolving at a rapid rate and the gap between authentic and fake content is becoming more difficult to decipher,"" says Mounir Ibrahim of Truepic, a digital content analysis company. The experts agree that Mr Trump's fame makes the fakes easy to spot. But images of unknown people could make the task more difficult - and the technology is getting better all the time. Fake images created by artificial intelligence (AI) tools depicting Donald Trump have appeared on social media over the past week. Many falsely showed the arrest of the former president, who may face indictment over payment of hush money to a woman he allegedly had an affair with. He has not yet been charged with a crime. Many of those sharing the images pointed out they were fake, and they did not appear to fool lots of people - but a few did seem to be tricked. On Thursday, Mr Trump also shared an AI-generated image on his own social media platform Truth Social. It showed him kneeling in prayer. What are some of the tell-tale signs of AI-generated imagery? And how can you distinguish a real from a fake? The images circulating online, like the one above, look hyper-real - more like staged artistic shots than in-the-moment photographs. A closer look shows some obvious giveaways that something isn't quite right. Look at the centre of the image. Mr Trump's arm is much too short, and the police officer on the left is grabbing something that more resembles a claw than a human hand. Similarly, if you focus on Mr Trump's neck, you'll notice that his head looks as if it's been superimposed on the image. Henry Ajder, an AI expert and presenter of the BBC radio series The Future Will be Synthesised, says current technology is not very good at depicting certain body parts, especially hands. ""If you zoom in on the images you can often see inconsistencies such as the number of fingers,"" he says. A simple check of a few news sites is a sure-fire way to verify that Mr Trump hasn't been arrested or even indicted - at least, not yet. If and when Mr Trump does face charges, his arrest will make headline news all around the world. And you can imagine the media flurry if the former president were to somehow flee from police. Another good idea is to think about the context in which an image is being shared. Who's sharing it - and what are their motives? Often people share pictures to amplify their broader political views, even if they haven't checked whether the photos are authentic, Mr Ajder says. ""We've seen really crude examples of other fakes such as the recording of Nancy Pelosi being slowed down to make her sound drunk,"" he adds. ""That was a super crude piece of manipulation and yet many people were fooled by it - or at least wanted to believe it."" A closer look at the photos themselves reveals more dubious details. Unnatural skin tones and faces with waxy or blurred-out features are strong indications that the image is fake. In the picture above, a person with a blurry face is clearly visible on the centre-right. And Mr Trump's hair appears blurry, while his face is in focus. AI technology has also not yet mastered accurate depictions of eyes. In the image above, officers appear to be chasing Mr Trump - but they're looking in a totally different direction. AI experts told the BBC that while faked imagery is ""nothing new"", the speed of progress within the field, and potential for misuse, is something to be concerned about. ""Synthetic content is evolving at a rapid rate and the gap between authentic and fake content is becoming more difficult to decipher,"" says Mounir Ibrahim of Truepic, a digital content analysis company. The experts agree that Mr Trump's fame makes the fakes easy to spot. But images of unknown people could make the task more difficult - and the technology is getting better all the time."
Fake Walmart news release claimed it would accept cryptocurrency,"Cryptocurrency Litecoin saw a sudden surge in price on Monday over a press release about Walmart accepting it for payment - which turned out to be fake. The release, published through a legitimate press channel, claimed that Walmart would accept the currency through all its digital stores. Walmart later told US media outlets the announcement was ""inauthentic"". By that time, several major news websites and press agencies had spread the supposed news. The announcement made it on to Globe Newswire, a service widely used to distribute press material from companies. The faked release has since been deleted, and did not appear on Walmart's own website. A tweet from a verified Litecoin Twitter account linking to the release has also been deleted. Hours later, the Litecoin Foundation tweeted that it had no such partnership. But while it was being reported as fact, the price of Litecoin jumped from about Â£125 per token to close to Â£170, before falling back near its original price, at about Â£128. Globe Newswire said ""a fraudulent user account was used to issue an illegitimate press release"". ""This has never happened before,"" the company said in a statement - adding that it was bringing in ""enhanced authentication"" to stop it happening again. It did not detail exactly what went wrong or who was behind the fake release. But so called ""pump and dump"" schemes are not uncommon in the cryptocurrency world - where bad actors attempt to raise hype around a coin, inflating its price, and quickly sell off their own stock before the market corrects itself. The false press release suggested that Litecoin would be accepted on all Walmart ecommerce platforms from 1 October. It contained quotes that appeared to come from both the Walmart chief executive and the founder of Litecoin. One clue to its nature was that a press contact email address pointed to a web domain which had been registered only last month. Emails to that address bounced as undeliverable. The fabrication was unmasked when CNBC reached representatives of Walmart by phone and were told the press release was fake. CNBC said it had been among the news organisations to publish the story before discovering it was not true. Walmart, the Litecoin Foundation, and Global Newswire have been contacted for comment. The announcement raised eyebrows among some sceptical observers because of the volatility of cryptocurrency prices, which can be an obstacle in using them for retail purchases. Other companies which have accepted Bitcoin have drawn up terms to limit their exposure to large price swings. For example, when Tesla briefly accepted Bitcoin as a payment option for its cars, it made clear that the price was in US dollars - and that any quote in equivalent Bitcoin was only valid for a limited time window. It also said that if a refund was needed, Tesla would have the choice of whether to pay it back in US dollars or Bitcoin, which may work out as a lower cash value than what was paid. Similarly, PayPal recently introduced the ability to buy and sell Bitcoin - but it cannot be used to make payment purchases. Instead, the cryptocurrency assets will be sold for the right amount of real money to make the purchase."
Fake news: The game that shows people how to spread misinformation,nan
False claims of 'deepfake' President Biden go viral,"People are falsely claiming a video of US President Joe Biden posted by the Democratic Party is a deepfake. A deepfake is a video created using artificial intelligence to show someone saying or doing something they didn't do. We've looked into the video. Social media users have claimed the video has been altered to superimpose the president's face on an actor's body using artificial intelligence. In the 17-second clip President Biden speaks about the 6 January riots which saw protesters storm the US Capitol building. The riot is currently being investigated by a congressional panel. The video was published on the Democrats' official Twitter account on Wednesday, and quickly became part of a wider conspiracy theory. Posts doubting the legitimacy of the video have been shared thousands of times, including by prominent pundits from the right-wing US television channels Newsmax and One America News. One reason people have cast doubt on the video is because they say President Biden looks different in another video published on the same day - which some people have also claimed is fake. But the differences in his appearance are clearly due to the lighting used when filming. People have also claimed the video is suspicious because he doesn't blink - but that wouldn't prove the video was a deepfake. One post that has been retweeted almost 40,000 times says ""a normal person blinks their eye 15 to 20 times a minute"". People blink approximately 12 times a minute, but it's perfectly possible not to blink for an extended period of time far longer than the 17 seconds featured in this video. There is also a cut halfway through the clip of President Biden tweeted by the Democrats, so he wasn't holding continuous eye contact for the whole time. A longer version of the video has been published by the White House which shows the president blinking several times. In addition, deepfakes can blink. ""A lot of people think you can spot a deepfake because it doesn't blink, which is actually not correct. A badly made deepfake might not blink, but that is not a categorical sign that it's a deepfake,"" says Sam Gregory, an expert on deepfakes. ""There was research done three or four years ago which found that deepfakes didn't blink, but technology has since improved to enable deepfakes to blink."" Baseless claims about President Biden being a hologram, CGI, deepfake, masked, cloned, played by a body double or recorded in front of a green screen are not new. They have been spreading on the fringes of the internet for a long time, and have sometimes gone viral. Similar false claims have also been made about other world leaders, including former President Donald Trump. Back in March 2021, a video of President Biden answering questions by reporters in front of the White House went viral after false claims were made that he was filmed in front of a green screen. Most of the people making these claims believe such tricks are being pulled by the White House to shield the president from the public because of his age, ill health, or public gaffes. Some on the more extreme conspiratorial fringe believe President Biden has been arrested or executed, or that the president is part of a nefarious plot and a puppet for a shadowy evil elite who run the world. These claims are entirely false. But there is an appetite for such theories in the online world, as this latest viral claim proves. Although the latest videos are not deepfakes, the technology can be used to artificially manipulate the words and actions of public figures. Earlier this year a deepfake video circulated of Ukrainian President Volodymyr Zelensky talking of surrendering to Russia. ""In the majority of claims we see globally they are not deepfakes, rather just people wanting to believe something and people not understanding what deepfakes are,"" says expert Sam Gregory."
False climate lockdown claims in Oxford lead to death threats,"False claims that a lockdown to help fight climate change could soon be enforced in Oxford have spread on social media. Residents are confused and local politicians have received a torrent of abuse as a result. ""I'm still feeling a bit bruised, if I'm honest, and a bit cautious,"" said Duncan Enright, cabinet member for travel and development strategy at Oxfordshire County Council. The last two weeks have been unusual for him, to say the least. He has been berated by complete strangers on social media. Death threats have put him and his family on guard. ""I know people very well in this area, and they're lovely,"" he said. ""This is something I've never experienced before in many years in local politics."" So how did a mainly rural county suddenly find itself at the heart of a social media storm? In November, Oxfordshire County Council approved a Â£6.5m trial scheme designed to stop most drivers in Oxford from using busy city routes at peak times. To achieve that goal, the council proposed the creation of traffic filters, enforced through cameras, in six key locations across the city. Private cars will not be allowed through without a permit. All other vehicles, including public transport and bikes, will be exempt. After the news broke, a number of fringe media outlets began describing the initiative as an effective ""climate lockdown"". They falsely claimed that the scheme would, in practice, ""lock"" residents in their own homes. They also wrongly suggested that, through the use of permits, the council was being given powers to decide who gets to travel around the city. ""It's not a lockdown,"" said Liz Leffman, leader of Oxfordshire County Council. ""People are going to be free to travel around, just as they are at the moment."" The trial scheme, which is not expected to start before 2024, is designed to cut unnecessary car journeys, while making walking, cycling and public transport more appealing. And yet, social media posts about an alleged ""climate lockdown"" found a willing audience among conspiracy-minded users, who shared them thousands of times. Councillors soon found themselves having to respond to these allegations in public. Emily Kerr, from Oxford City Council, was one of them. ""People have come up to me and said: 'Is it true that we're not going to be allowed out of our houses, that it's going to be just like the coronavirus lockdown?'. ""When people get very worried about it, and then realise it's not true, I think they're just relieved,"" she said. ""It's really worrying, it scares people."" Thousands of people have voiced concerns over the scheme, suggesting, for example, that it may hit residents' pockets, as well as put additional pressure on already struggling businesses. ""People had perfectly valid objections,"" said Ms Leffman, who leads Oxfordshire County Council. ""We'd heard a number of those objections before and modified our proposals as a result."" But even among those who oppose the plans, there are concerns over how unfounded claims have entered the public debate. ""Attack them on the facts not on conspiracy theories,"" tweeted Conservative councillor Liam Walker. After claims of a ""climate lockdown"" were picked up by outlets in the US and Australia, councillors were targeted by a fresh wave of online abuse. ""I began to get trolled,"" said Mr Enright. ""At its height, I had text messages, which is unusual, a couple of calls, and direct emails as well making threats, and that was alarming. ""The messages are coming from all over the world."" Oxfordshire County Council told the BBC that some of its staff members have also been receiving threats over the phone. In a joint statement with Oxford City Council, it condemned the abuse, which it said was ""due to inaccurate information being circulated online"". It also said it was working with Thames Valley Police to ""report the most extreme abuse"". ""I feel quite angry about it,"" said Mr Enright. ""This is illegitimate in a modern democracy like ours, that people should behave in this way. ""I've been built up into some huge monster,"" he said. ""I'm not a lizard, I'm not a person from another planet who is trying to take over people's lives."" Several councillors suspect the ""climate lockdown"" conspiracy is being pushed by groups from outside the county. ""It's an organised sort of group of climate change deniers,"" said Ms Kerr. The BBC has seen evidence that protests against the supposed ""climate lockdown"" in Oxford are being planned in 2023. Promotional material has been shared online by groups known for spreading conspiracy theories, including about Covid-19 and vaccines. So is the social media storm likely to die down then? ""The people who are spreading this misinformation will continue to do so,"" said Ms Leffman, urging caution to other councils. ""This is going to happen in other parts of the country, because I don't think we're going to be the only city that will make the decision to limit traffic."" False claims that a lockdown to help fight climate change could soon be enforced in Oxford have spread on social media. Residents are confused and local politicians have received a torrent of abuse as a result. ""I'm still feeling a bit bruised, if I'm honest, and a bit cautious,"" said Duncan Enright, cabinet member for travel and development strategy at Oxfordshire County Council. The last two weeks have been unusual for him, to say the least. He has been berated by complete strangers on social media. Death threats have put him and his family on guard. ""I know people very well in this area, and they're lovely,"" he said. ""This is something I've never experienced before in many years in local politics."" So how did a mainly rural county suddenly find itself at the heart of a social media storm? In November, Oxfordshire County Council approved a Â£6.5m trial scheme designed to stop most drivers in Oxford from using busy city routes at peak times. To achieve that goal, the council proposed the creation of traffic filters, enforced through cameras, in six key locations across the city. Private cars will not be allowed through without a permit. All other vehicles, including public transport and bikes, will be exempt. After the news broke, a number of fringe media outlets began describing the initiative as an effective ""climate lockdown"". They falsely claimed that the scheme would, in practice, ""lock"" residents in their own homes. They also wrongly suggested that, through the use of permits, the council was being given powers to decide who gets to travel around the city. ""It's not a lockdown,"" said Liz Leffman, leader of Oxfordshire County Council. ""People are going to be free to travel around, just as they are at the moment."" The trial scheme, which is not expected to start before 2024, is designed to cut unnecessary car journeys, while making walking, cycling and public transport more appealing. And yet, social media posts about an alleged ""climate lockdown"" found a willing audience among conspiracy-minded users, who shared them thousands of times. Councillors soon found themselves having to respond to these allegations in public. Emily Kerr, from Oxford City Council, was one of them. ""People have come up to me and said: 'Is it true that we're not going to be allowed out of our houses, that it's going to be just like the coronavirus lockdown?'. ""When people get very worried about it, and then realise it's not true, I think they're just relieved,"" she said. ""It's really worrying, it scares people."" Thousands of people have voiced concerns over the scheme, suggesting, for example, that it may hit residents' pockets, as well as put additional pressure on already struggling businesses. ""People had perfectly valid objections,"" said Ms Leffman, who leads Oxfordshire County Council. ""We'd heard a number of those objections before and modified our proposals as a result."" But even among those who oppose the plans, there are concerns over how unfounded claims have entered the public debate. ""Attack them on the facts not on conspiracy theories,"" tweeted Conservative councillor Liam Walker. After claims of a ""climate lockdown"" were picked up by outlets in the US and Australia, councillors were targeted by a fresh wave of online abuse. ""I began to get trolled,"" said Mr Enright. ""At its height, I had text messages, which is unusual, a couple of calls, and direct emails as well making threats, and that was alarming. ""The messages are coming from all over the world."" Oxfordshire County Council told the BBC that some of its staff members have also been receiving threats over the phone. In a joint statement with Oxford City Council, it condemned the abuse, which it said was ""due to inaccurate information being circulated online"". It also said it was working with Thames Valley Police to ""report the most extreme abuse"". ""I feel quite angry about it,"" said Mr Enright. ""This is illegitimate in a modern democracy like ours, that people should behave in this way. ""I've been built up into some huge monster,"" he said. ""I'm not a lizard, I'm not a person from another planet who is trying to take over people's lives."" Several councillors suspect the ""climate lockdown"" conspiracy is being pushed by groups from outside the county. ""It's an organised sort of group of climate change deniers,"" said Ms Kerr. The BBC has seen evidence that protests against the supposed ""climate lockdown"" in Oxford are being planned in 2023. Promotional material has been shared online by groups known for spreading conspiracy theories, including about Covid-19 and vaccines. So is the social media storm likely to die down then? ""The people who are spreading this misinformation will continue to do so,"" said Ms Leffman, urging caution to other councils. ""This is going to happen in other parts of the country, because I don't think we're going to be the only city that will make the decision to limit traffic."""
False posts about French riots spread online,"France has seen another night of unrest after the fatal shooting by police of a 17-year-old boy in a Paris suburb. Images of the unrest, which has spread to other French cities, are being shared on social media. As well as genuine video, false and misleading claims are also circulating, with the potential to increase tensions. BBC Verify has been investigating some of these. A striking image showing a group of young men driving a French police van, with one hanging out of the window brandishing a gun, has been shared on Twitter with the words ""France, photo of the day"". The tweet, posted early on 2 July had over 1.7m views but it's false - it's not from the current riots in France but is actually a still from a film. BBC Verify examined the image and, searching for previous versions of it on the internet, found it was from the French film, Athena - a fictional account of rioting in a city suburb - made in 2022. The people in the van and the blue motorcycle are exactly the same. The person who posted the tweet later clarified that the image was meant to be of an ""illustrative"" nature, but not before it had been retweeted thousands of times. He subsequently deleted it. Footage of cars falling from the windows of a multi-storey car park has been widely shared online, with the message: ""WTF is going on in FranceÂ"". This is false - it is old footage and it looks like it has come from another film. BBC Verify took images of the video and carried out an online search to see if it had appeared before. The search brought up a tweet from June 2016, which claimed the footage was from the set of the action movie, Fast and Furious 8 - which was filmed in Cleveland, Ohio. Using the information in that tweet, BBC Verify located the footage to a multi-storey car park on Prospect Avenue East in Cleveland. The colours of the cars and the outside of the building match a scene from the film, which came out in 2017. Over the past few days, a video has been shared repeatedly on Twitter and the messaging app, Telegram showing a hooded man, on a rooftop pointing what appears to be a rifle. One Twitter user posted the video with the accompanying message: ""Rioter in France takes up sniper position with stolen police rifle."" Another account claims the rifle was stolen from a police van. A Telegram user displayed the fire emoji next to the French flag and stated: ""looters covered by a sniper."" The video has been viewed hundreds of thousands of times across different platforms and accounts, and retweeted thousands of times. But the video was not filmed during the current disturbances, it is old footage. By searching for previous instances of the video on social media, BBC Verify can confirm it was posted on Twitter on 13 March, 2022. The man's clothing, position on the rooftop and visible buildings are identical in both tweets. The video was likely filmed on the roof of a residential tower block in an eastern suburb of Paris, but it wasn't possible to confirm whether the rifle was real or a replica gun. One Twitter user, aware of the earlier instances of this video, commented that the alleged sniper must have ""been there over a year now."" A video on TikTok - showing a huge crowd of people with the caption, ""Nanterre, France - Nahel,"" and a series of sad emojis - has had more than nine million views. Nanterre is the suburb of Paris where Nahel M, who was 17, was shot by police. But the video of the crowd was actually filmed in another country. BBC Verify ran a search for other versions of the video on TikTok, and found the exact same clip posted last month, claiming to show a concert by the Argentinian band Los Fabulosos Cadillacs in Mexico City on 3 June. An internet search for recent live gigs in a public square in Mexico City brought up an article by music magazine Billboard about a live concert by Los Fabulosos Cadillacs in Mexico City's main square, Zocalo on 3 June, which reportedly drew a crowd of 300,000. BBC Verify has matched the buildings visible in the TikTok video with the Google street view of Zocalo and confirmed it was filmed there. Reporting by Frey Lindsay and Shayan Sardarizadeh. What do you want BBC Verify to investigate? France has seen another night of unrest after the fatal shooting by police of a 17-year-old boy in a Paris suburb. Images of the unrest, which has spread to other French cities, are being shared on social media. As well as genuine video, false and misleading claims are also circulating, with the potential to increase tensions. BBC Verify has been investigating some of these. A striking image showing a group of young men driving a French police van, with one hanging out of the window brandishing a gun, has been shared on Twitter with the words ""France, photo of the day"". The tweet, posted early on 2 July had over 1.7m views but it's false - it's not from the current riots in France but is actually a still from a film. BBC Verify examined the image and, searching for previous versions of it on the internet, found it was from the French film, Athena - a fictional account of rioting in a city suburb - made in 2022. The people in the van and the blue motorcycle are exactly the same. The person who posted the tweet later clarified that the image was meant to be of an ""illustrative"" nature, but not before it had been retweeted thousands of times. He subsequently deleted it. Footage of cars falling from the windows of a multi-storey car park has been widely shared online, with the message: ""WTF is going on in FranceÂ"". This is false - it is old footage and it looks like it has come from another film. BBC Verify took images of the video and carried out an online search to see if it had appeared before. The search brought up a tweet from June 2016, which claimed the footage was from the set of the action movie, Fast and Furious 8 - which was filmed in Cleveland, Ohio. Using the information in that tweet, BBC Verify located the footage to a multi-storey car park on Prospect Avenue East in Cleveland. The colours of the cars and the outside of the building match a scene from the film, which came out in 2017. Over the past few days, a video has been shared repeatedly on Twitter and the messaging app, Telegram showing a hooded man, on a rooftop pointing what appears to be a rifle. One Twitter user posted the video with the accompanying message: ""Rioter in France takes up sniper position with stolen police rifle."" Another account claims the rifle was stolen from a police van. A Telegram user displayed the fire emoji next to the French flag and stated: ""looters covered by a sniper."" The video has been viewed hundreds of thousands of times across different platforms and accounts, and retweeted thousands of times. But the video was not filmed during the current disturbances, it is old footage. By searching for previous instances of the video on social media, BBC Verify can confirm it was posted on Twitter on 13 March, 2022. The man's clothing, position on the rooftop and visible buildings are identical in both tweets. The video was likely filmed on the roof of a residential tower block in an eastern suburb of Paris, but it wasn't possible to confirm whether the rifle was real or a replica gun. One Twitter user, aware of the earlier instances of this video, commented that the alleged sniper must have ""been there over a year now."" A video on TikTok - showing a huge crowd of people with the caption, ""Nanterre, France - Nahel,"" and a series of sad emojis - has had more than nine million views. Nanterre is the suburb of Paris where Nahel M, who was 17, was shot by police. But the video of the crowd was actually filmed in another country. BBC Verify ran a search for other versions of the video on TikTok, and found the exact same clip posted last month, claiming to show a concert by the Argentinian band Los Fabulosos Cadillacs in Mexico City on 3 June. An internet search for recent live gigs in a public square in Mexico City brought up an article by music magazine Billboard about a live concert by Los Fabulosos Cadillacs in Mexico City's main square, Zocalo on 3 June, which reportedly drew a crowd of 300,000. BBC Verify has matched the buildings visible in the TikTok video with the Google street view of Zocalo and confirmed it was filmed there. Reporting by Frey Lindsay and Shayan Sardarizadeh. What do you want BBC Verify to investigate?"
Farm laws: Sikhs being targeted by fake social media profiles,"A network of fake social media profiles of people claiming to be Sikhs, and promoting divisive narratives, has been exposed. A new report shared exclusively with the BBC ahead of its publication on Wednesday identified 80 accounts in the network, which have now been suspended because they were fake. The influence operation used accounts across Twitter, Facebook and Instagram to promote Hindu nationalism and pro-Indian government narratives. The aim of the network appears to have been to ""alter perceptions on important issues around Sikh independence, human rights and values"", according to the report's author, Benjamin Strick. There is no evidence linking this network directly with the Indian government, which has yet to respond to a BBC request for comment. The network used so-called ""sock puppet"" accounts, which are fake ones controlled by real people posing as independent individuals, rather than automated ""bots"". The fake profiles used Sikh names and claimed to be ""Real Sikhs"". They used the hashtags #RealSikh to endorse, and #FakeSikh to discredit, different political viewpoints. The report, from non-profit organisation the Centre for Information Resilience (CIR), found many of the accounts in the network used the same fake profiles across several platforms. These accounts shared the same names, profile pictures and cover photos, and published identical posts. Many of the accounts used profile pictures of celebrities, including actresses in the Punjabi film industry. Using a celebrity profile picture does not in itself prove an account is fake. However, the report says that combined with the co-ordinated messaging, frequently used hashtags, similar biography descriptions and follower patterns, the pictures added to the evidence that each of these accounts was not genuine. The BBC attempted to contact eight of the celebrities whose images had been used, requesting comment. One replied via their management to confirm they were not aware their image had been used in this way, and said they would take action. The management of another celebrity said there are thousands of such fake accounts associated with their client, and there wasn't much they could do about it. On Friday, India's Prime Minister Narendra Modi announced the repeal of three controversial farm laws after a year of farmers protesting against them. The farmers' protests, which started a year ago this week, and the decades-old Khalistan independence movement were the two discussion topics most frequently targeted by the network. According to the report, the accounts sought to label any notion of Sikh independence as extremist, and delegitimise the farmers' protests, claiming they had been hijacked by ""Khalistani terrorists"". But before that, the Indian government had also claimed that the farmers' protest had been ""infiltrated by the Khalistanis"". The farmers who continue to protest believe this may have been a deliberate political move. ""We believe these accounts were set up at the behest of the government and it was done to set a narrative against the protests"" said Jagjit Singh Dalewal, leader of the Bharatiya Kisan Union, one of about 30 unions sitting in protest. Some accounts painted diaspora communities in the UK and Canada as harbouring the Khalistani movement. The accounts had thousands of followers, and posts from the network have been liked and retweeted by real influencers and quoted on news sites. Many influence operations fail to get real people to interact with the fake accounts they create. In the case of this network though, the research identified posts which were interacted with and endorsed by the verified accounts of public figures. The report also identified content from the fake profiles embedded on news blogs and commentary sites. Experts on influence operations describe this as ""amplification"", and the more the network receives, the more impact it can have. The BBC contacted some of the verified accounts which had interacted with posts in the network. Rouble Nagi, who on Twitter describes herself as a humanitarian and social worker, had responded to one of the fake accounts' tweets with two clapping hands emojis. She said she is ""sad that it was a fake account"". Col Rohit Dev, who calls himself a geopolitical military analyst, had responded to one of these accounts' posts with thumbs-up emojis, but told us he did not know the person behind the handle. Nikhil Pahwa, a digital rights activist and editor of technology policy website MediaNama, says that these influence networks target individuals with a particular point of view. ""These 80-odd accounts will not necessarily make something trend, but with consistent posting, they try to discredit a point of view,"" he said. ""This seems to be a sophisticated approach, and seems to be a part of a larger operation."" Very little of the content included text in Punjabi - the biggest language for Sikhs in India - and nearly all the content was in English. Mr Pahwa points out that there was political activity around the farmer's protests from all sides, with people trying to support and discredit them. ""It's all a part of the game to win the political narrative war."" The BBC shared the report with Twitter and Meta - the company which owns Facebook and Instagram - requesting comment. Twitter suspended the accounts for violating their rules prohibiting ""platform manipulation"" and fake accounts. A Twitter spokesperson said: ""At this time, there's no evidence of widespread co-ordination, the use of multiple accounts by single people, or other platform manipulation tactics."" Meta also removed the accounts on Facebook and Instagram for violating its ""inauthentic behaviour"" policies. A Meta spokesperson said the accounts ""misled people about the origin and popularity of their content and used fake accounts to spam people and evade our enforcement""."
France puzzled by mystery anti-Pfizer campaign offer,"Several French social media influencers say they have received a mysterious financial offer to spread negative publicity about the Pfizer vaccine. They say an agency claiming to be based in the UK has contacted them by email offering a ""partnership"". LÃ©o Grasset, who has 1.17m YouTube subscribers, tweeted (in French) that a ""colossal budget"" was promised from a client ""who wants to remain incognito"". He said that the address the agency had given appeared to be bogus. He said the LinkedIn profiles of the agency's alleged employees he had managed to find later disappeared, but not before he noticed that ""everybody there has worked in Russia"". LÃ©o Grasset posted what he said were instructions from the agency, urging him not to use such words as ""advertising"" or ""sponsored video"" if he were to agree to the partnership offer. ""Present the material as your own independent view,"" the email said. It also asked him to spread among his followers a false claim that the death rate among the vaccinated by Pfizer is almost three times higher than among those who have received AstraZeneca. Several other French social media influencers, all of whom are involved in the health and science field, said they had been contacted with a similar offer. Et Ãa Se Dit MÃ©decin, a hospital intern with more than 85,000 Instagram followers, told France's BFMTV that he was offered Â2,050 ($2,510; Â£1,775) for a 30-second story on his account. Meanwhile, French Health Minister Olivier VÃ©ran told BFMTV:  ""I do not know where this [partnership offer] comes from, from France or abroad. ""It is pathetic, it is dangerous, it is irresponsible and it does not work."" The two-dose Pfizer vaccine (full name Pfizer-BioNTech) is the most commonly administered vaccine in France. It is produced by America's Pfizer and Germany's BioNTech companies. AstraZeneca, also a two-dose vaccine being used in France, is manufactured by a UK-Swedish pharmaceutical company. In April, a European Union report said Russian and Chinese state-run media were systematically trying to sow public mistrust in Western Covid vaccines - a claim denied in Moscow."
Frances Haugen says Facebook is 'making hate worse',"Whistleblower Frances Haugen has told MPs Facebook is ""unquestionably making hate worse"", as they consider what new rules to impose on big social networks. Ms Haugen was talking to the Online Safety Bill committee in London. She said Facebook safety teams were under-resourced, and ""Facebook has been unwilling to accept even little slivers of profit being sacrificed for safety"". And she warned that Instagram was ""more dangerous than other forms of social media"". While other social networks were about performance, play, or an exchange of ideas, ""Instagram is about social comparison and about bodies... about people's lifestyles, and that's what ends up being worse for kids"", she told a joint committee of MPs and Lords. She said Facebook's own research described one problem as ""an addict's narrative"" - where children are unhappy, can't control their use of the app, but feel like they cannot stop using it. ""I am deeply worried that it may not be possible to make Instagram safe for a 14-year-old, and I sincerely doubt that it is possible to make it safe for a 10-year-old,"" she said. The committee is fine-tuning a proposed law that will place new duties on large social networks and subject them to checks by the media regulator Ofcom. Asked if the law was ""keeping Mark Zuckerberg awake at night"", Ms Haugen said she was ""incredibly proud of the UK for taking such a world-leading stance"". ""The UK has a tradition of leading policy in ways that are followed around the world. ""I can't imagine Mark isn't paying attention to what you're doing."" Ms Haugen also warned that Facebook was unable to police content in multiple languages around the world - something which should worry UK officials, she said. ""UK English is sufficiently different that I would be unsurprised if the safety systems that they developed primarily for American English were actually under-enforcing in the UK,"" she said. And she said that dangerous misinformation in other languages affects people in Britain. ""Those people are also living in the UK, and being fed misinformation that is dangerous, that radicalises people,"" she warned. Ms Haugen also urged the committee to include paid-for advertising in its new rules, saying the current system was ""literally subsidising hate on these platforms"" because of their algorithmic ranking. ""It is substantially cheaper to run an angry hateful divisive ad than it is to run a compassionate, empathetic ad,"" she said. And she also urged MPs to require a breakdown of who is harmed by content, rather than an average figure - suggesting Facebook is ""very good at dancing with data"", but pushes people towards ""extreme content"". ""The median experience on Facebook is a pretty good experience,"" she said. ""The real danger is that 20% of the population has a horrible experience or an experience that is dangerous,"" she said. She warned that employees were unable to report internal concerns at Facebook - something she called a ""huge weak spot"". ""When I worked on counter-espionage, I saw things where I was concerned about national security, and I had no idea how to escalate those because I didn't have faith in my chain of command at that point,"" she told the committee. And she warned: ""We were told to accept under-resourcing."" Similar problems plague Facebook's Oversight Board, which can overturn the company's decisions on content, she said. She repeated her claim that Facebook has repeatedly lied to its own watchdog, and said this is a ""defining moment"" for the Oversight Board to ""step up"". ""I don't know what the purpose of the Oversight Board is,"" she said. It comes as several news outlets published fresh stories based on the thousands of leaked documents Ms Haugen took with her when she left Facebook. Facebook has characterised previous reporting as misleading, and at one point referred to the leaked documents as ""stolen"". ""Contrary to what was discussed at the hearing, we've always had the commercial incentive to remove harmful content from our sites,"" a spokesperson said, after Ms Haugen finished giving evidence. ""People don't want to see it when they use our apps, and advertisers don't want their ads next to it. That's why we've invested $13bn (Â£9.4bn) and hired 40,000 people to do one job: keep people safe on our apps. "" The company said that over the last three quarters it has halved the amount of hate speech seen on Facebook, which it claims now accounts for only 0.05% of all content viewed. ""While we have rules against harmful content and publish regular transparency reports, we agree we need regulation for the whole industry so that businesses like ours aren't making these decisions on our own,"" the spokesperson said. ""The UK is one of the countries leading the way and we're pleased the Online Safety Bill is moving forward."" An avalanche of information emerged on Monday from leaked Facebook documents - and it was hard to keep up. Allegations include that the social media giant is aware of its role in inciting violence all around the world, or causing harm to its users from US and UK to India and Ethiopia. A common theme runs through each of the stories. They all suggest a tension between employees raising the alarm about their concerns and a corporate machine that does not appear to be using this to inform its policies. Reporters and journalists have been highlighting many of these same concerns, especially for the past 18 months. I've investigated the human cost of online disinformation and abuse again and again and exposed the damage being done to real people offline using these sites. But until these documents were released by Ms Haugen, it was very difficult to know how aware Facebook was of that damage. These latest leaks reinforce the idea that it is conscious of it - although it refutes a number of the claims. And it means pressure is mounting on policymakers around the world to do something about it."
French election: Misinformation targets candidates and voting system,"France chooses a new president on Sunday, in a run-off between incumbent Emmanuel Macron and far-right challenger Marine Le Pen. The French authorities announced measures last year to tackle misinformation aimed at ""undermining the state."" But misleading claims have been spreading during the campaign, aimed at both the candidates and the election process itself. An image of a Twitter post about migration to France  - falsely attributed to BBC News - has been widely shared on Twitter and other platforms, including pro-Russian channels on Telegram. In it, President Macron is reported as saying that Europe should be prepared for mass immigration from Africa and the Middle East, as sanctions against Russia are causing economic collapse in Africa. Supporters of opposition candidates presented it as ""proof"" that Macron was preparing France to accept mass immigration. But the doctored image, which is made to look like it's from a BBC account, is fake. The BBC has confirmed that no such social media post or article exists. And President Macron's campaign team have made clear that he has not made these remarks. False claims have been spread online, largely from right-wing social media accounts, saying that voting machines are being used to help ensure a Macron victory. It echoes the 2019 US election, when unfounded claims were made that voting machines were used to help Joe Biden beat Donald Trump. The rumour comes from French followers of the QAnon movement, according to French newspaper Liberation. The French Interior Ministry has said that the Canadian company named in the claims has no connection to the French elections. The government uses its own computer systems to count votes, the ministry said. Some constituencies have used electronic voting machines, but their number is extremely small. The vast majority of voting takes place in person, using paper ballots. Further claims said the voting machines tactic was trialled in the 2017 election, to give Mr Macron an advantage. But an analysis by television channel TF1 showed no single candidate benefited from their use. Misleading information on social media suggests the election could be invalidated if not enough registered voters cast their ballots. The incorrect claim picked up traction after an interview on French TV by presidential candidate Nicolas Dupont-Aignan, who said that if 30% of registered voters failed to cast their vote, the election will be invalidated. ""If there is no participation, this election will not be valid,"" he told BFM TV. He had a more nuanced point - and went on to say low turn-out would only make the election invalid ""in people's hearts"". However, this was not included when his original comments were shared. There is no valid reason to invalidate the election result if not enough people vote. Under French law, registering to vote is compulsory, but actually casting a vote is not. The French constitution sets no minimum turn-out and says ""the President of the Republic is elected by an absolute majority of the votes cast"". The turn-out for the first round was 73.69%. Salah Abdeslam is currently on trial in France, for his role in the 2015 attacks in Paris, in which 130 people were killed. He has already been convicted for his part in a terrorist shoot-out in Belgium in 2016. One Twitter account, which identifies in its bio as a ""Russian troll"", said that Abdeslam ""in tears at his trial"" urged voters to ""not to commit the irreparable by voting for Le Pen"" in the second round of voting. Amplified by anti-establishment journalists and celebrities, this claim was shared hundreds of times. Liberation newspaper contacted one of Abdeslam's defence lawyers Olivia Ronen, who confirmed that ""at no time did Salah Abdeslam call [on the electorate] to vote for Emmanuel Macron or block Marine Le Pen"". Journalist ChloÃ© Pilorget-Rezzouk, who has been covering the trial for Liberation, said the defendant did not address the issue of the election. A video by an activist in the anti-establishment Gilets Jaunes (Yellow Vest) movement claims some 22,500 of its members have lost their right to vote. The video first appeared on Telegram, before spreading to Facebook and Twitter. In the clip, Gregory Pasqueille claims that ""a Macron law"" has barred 22,552 Gilets Jaunes ""prisoners"" from voting for five years. Mr Pasqueille told AFP that he stands by his statements, and that he is one of those barred from voting. AFP said he provided no evidence for his claims. French law has provisions to remove voting rights from some criminals. Figures from the French justice ministry show the power was applied about 4,000 times across all criminal cases during the years the Yellow Vest protests were at their height - in 2018 and 2019. The ministry says about 3,900 people were convicted of Yellow Vest-linked offences at that time, making the 22,500 claim extremely unlikely. Read more from Reality Check Send us your questions"
Georgia election: Trump voter fraud claims and others fact-checked,"US President Donald Trump and others have made new unsubstantiated claims of voter fraud following the rerun of two crucial Senate races in the state of Georgia. With the Democrats looking likely to win both seats and with them control of the US Senate, we've debunked some of the theories that have been widely shared on social media. Since the November election, the president has repeatedly made baseless allegations that Dominion voting machines have been manipulated to engineer electoral fraud. Referring to the vote in Georgia, Mr Trump said these machines had stopped working in Republican strongholds for ""over an hour"". The official in charge of Georgia's voting systems, Gabriel Sterling, said there has been an issue in one county due to ""a programming error on security keys"" but that it was resolved hours before the president made his comments. Mr Sterling tweeted: ""The, votes of everyone will be protected and counted. Sorry you received old intel Mr President."" Georgia's Secretary of State Brad Raffensperger also clarified in a statement that there had been some issues but they did not stop people from voting, Reuters news agency reports. ""At no point did voting stop as voters continued casting ballots on emergency ballots, in accordance with the procedures set out by Georgia law,"" said Mr Raffensperger. An image that has been shared thousands of times on Twitter purported to show a pile of destroyed ballots in Georgia on election day. ""Our team is in Georgia. They took a little walk. They found shredded ballots in Dell boxes,"" the tweet said. Although the post provided no detail as to where exactly the picture had been taken, we were able to geolocate it to the absentee ballot processing centre at the Georgia World Congress Center in Fulton County, which includes Atlanta. Fulton County elections director Richard Barron told the BBC that the papers in the picture were ""definitely not ballots"", but waste from a letter-opening machine used to cut ballot envelopes. We've reported on similar claims about alleged ballot shredding in Georgia before. In November, an investigation into the shredding of papers in Cobb County concluded that it was part of a ""routine clean-up operation"" and the documents disposed of were not actual votes ""relevant to the election or the re-tally"". In a tweet generating some 300,000 likes and retweets, President Trump claimed there was a ""voter dump"" planned against Republican candidates. But there's no evidence of wrongdoing. It's not clear exactly what he means by a ""voter dump"", but he may be referring to the fact that large batches of votes are released at once. This is standard practice and a valid part of the vote-counting process. In Georgia, as in the presidential elections, larger districts, often including cities that may lean Democrat, take longer to report their results. Mr Trump has falsely claimed on multiple occasions that millions of genuine votes in November's presidential election that were counted after polls closed were ""fake"". In Georgia, election official Gabriel Sterling noted after the polls closed that some 171,000 early, in-person ballots from DeKalb County, which is Democrat-leaning, were yet to be counted. Authorities knew how many of these ""advanced"" votes were coming. A number of Republican officials and activists, including White House press secretary Kayleigh McEnany and the founder of conservative activist group Turning Point USA, claimed workers at the Chatham county count had suddenly stopped counting for the rest of the night and gone home, raising the prospect of foul play. ""They're doing this again. You can't make this up,"" Charlie Kirk tweeted. Similar claims of fraud or suspicious activity were made during the presidential election count in the county, after it took a few days for all the absentee and mail-in ballots to be tabulated. But Gabriel Sterling, Georgia's voting systems implementation manager, took to Twitter to say the count ""didn't just stop"". Workers had finished counting all the ballots they had except absentee ballots received on election day, Mr Sterling, a Republican, added. The county's board of elections chairman, Tom Mahoney, confirmed later that about 3,000 to 4,000 election day absentee ballots were left to count. Reporting by Jack Goodman, Christopher Giles, Shayan Sardarizadeh and Olga Robinson."
German elections 2021: The conspiracy theories targeting voters,"Ahead of federal elections this weekend, conspiracy theories have been spreading online, including claims the poll will be invalid because the German state is illegitimate. Followers claim neither Germany nor Austria were officially recognised as independent states by Allied force commanders after World War Two, operationally known as the Supreme Headquarters Allied Expeditionary Force (SHAEF). These baseless claims have echoes in the ReichsbÃ¼rger Movement, which rejects modern Germany's legitimacy. With links to far-right and anti-Semitic groups, it claims a German Reich still exists, with pre-War 1939 borders. But modern Germany was constituted in 1949, as the Western allies merged their post-War occupation zones into the Bundesrepublik (West Germany) while the Soviet zone became the DDR (East Germany). And these merged into the current Federal Republic in 1990, after the fall of the Berlin Wall. SHAEF conspiracy theory believers say the current German elections are invalid because they are organised by an non-existent state - and anybody taking part is committing treason. Like the QAnon conspiracy in the United States, the SHAEF theory has a ""saviour"", who will rescue Germany from disaster. While in the US, it is Donald Trump who adherents believe will eventually intervene and retake power, in Germany it is a ""Cdr Jansen"", who posts on the social media platform Telegram. Theorists say Jansen, with the aid of a reinstated President Trump, will install a ""legitimate"" government, an absurd idea that has found a home in Germany's far-right online presence. The Covid-sceptic Querdenken mass movement (roughly translated as ""lateral thinkers"") has also become a home for the spread of misinformation around the German elections. Querdenken claims to have no political affiliation, but several of its key figures have well-documented far-right connections and some of their demonstrations have ended in violence. It draws in a range of supporters - not only far-rightists and the ReichsbÃ¼rger movement but also hippies, spiritualists and evangelical Christians. A heterogenous movement from a broad background, some sections say Covid is a plot by shadowy elites to eradicate freedoms. And with links to far-right parties and organising online, there are concerns this could boost the extremist vote in the election. Facebook recently shut down a network of about 150 Querdenken-linked accounts, saying they encouraged real-world harm. A Querdenken statement claims this was ""an attack on freedom of expression ahead of the federal election"" but Facebook says the group had ""engaged in physical violence against journalists, police and medical practitioners in Germany"". Other groups such as Freiheitsboten and Die Basis also operate at local and national levels, with a membership, fact-checking organisation Logically estimates, of about 1.25% of the population. But as Logically intelligence analyst Jordan Wildon told BBC News, mass movements tend to have little effect on voting intention. ""One of the cornerstones of German politics is stability and structure, and a surge of misinformation is less likely to cause dramatic immediate changes as elsewhere in the world,"" he said. In May, state-run Russian TV channel RT DE - the German version of the channel previously known as Russia Today - was accused of smearing Green Party candidate for chancellor Annalena Baerbock. The broadcaster had aired an opinion piece criticising Ms Baerbock, following a speech in which she had praised ""our grandparents"" for bringing peace to Europe. The RT DE article, noting her grandfather had fought with the Nazi-era Wehrmacht, asked: ""Whose shoulders does the Green chancellor candidate see herself on?"" RT has often used pieces written by third parties to publish controversial views while distancing itself from the voice of these opinions. But in June, a German Interior Ministry report pointed the finger at Russia and said these interventions could ""disturb social cohesion, trust in state institutions, the political decision-making process, and electoral processes"". There are also claims being shared both in mainstream social media and alternative news platforms, casting doubt on the integrity of the postal vote, suggesting some people will be able to vote twice. The far-right Alternative for Germany (AfD) party and anti-lockdown party Die Basis both claim the postal-vote system is not secure, the latter urging supporters to vote in person. And with postal voting on the increase because of the Covid-19 pandemic, AfD in particular has been spreading, since the start of 2021, the baseless claim the mainstream parties will be using mail-in votes to rig the ballot, German broadcaster Deutsche Welle reports. But even voting in person is not without controversy, with anti-vaccine activists inaccurately claiming only people vaccinated against Covid-19 will be able to enter polling stations. Although in fact, the Federal Returning Officer has confirmed unvaccinated and untested people can vote but voters must wear a face mask. A favourite theme of conspiracy theorists, notably in the United States, has been the idea of the Great Reset - that a political elite or dark international forces have orchestrated the Covid pandemic in order to take control. And in Germany, this has surfaced as an idea these elites are planning to rig the election result. Right-wing commentators claim the election is a ""swansong for a rotten Germany"", which will see an end to freedoms and democracy. And RT called the campaign ""a uniform porridge of promises"", suggesting all the major parties are the same. But they are railing against Germany's conservative nature, according to Mr Wildon, which means disinformation and conspiracy theories have little effect. ""While there have been attempts to influence political opinion, disinformation broadly seeks to discourage people away from particular parties, rather than specifically towards another,"" he said. ""The nature of Germany's democratic process leaves people with a variety of other choices, making it more difficult to consolidate disillusioned voters in favour of one specific party."" Reporting by Alistair Coleman and Jordy Geerlings."
Ghana election: Fact-checking claims about voting day,"Voters in Ghana have gone to the polls to choose a new president and 275 members of parliament. The country is regarded as one of the most democratic in West Africa. But there have been some examples of misinformation about the voting. A video has been circulating on social media channels that purports to show a ballot with a larger fingerprint box for President Nana Akufo-Addo. The video - which is just over three minutes long - claims the ballot paper has been produced in such a way that votes for opposition candidates will be discounted because the blank boxes, where the thumb impression goes, are too small. The footage shows an individual making this claim, and placing his finger in the box of an opposition candidate to show it won't fit within the space. This claim was first highlighted by West African fact-checking site Dubawa. However, the ballot featured in the video is missing some of the features that appear on official ballots, such as a red background behind all the images and an official stamp. An official from Ghana's electoral authorities told the BBC that the ballot did not come from the commission. The video was found circulating in WhatsApp groups, but as it's a closed social media platform it's not possible to calculate the exact number of shares. However, when the BBC received the video it came with the label ""forwarded many times"". Some users have shared videos online, which they say are examples of polling day incidents where there's been police or security force involvement. On examination, these are actually taken from police training or simulation exercises in preparation for the vote, and not from polling day itself. One example is a video said to show the police shooting someone who had allegedly snatched a ballot box at a polling station in southern Ghana. But police spokeswoman Sheilla Abayie-Buckman told the BBC this particular video is from north-western Ghana and was taken back in September. She told us she recognised it because she was present at this event, which was held by local police to show their readiness for the elections to the country's police chief. A Facebook post on 5 December by a TV station called Hijrah TV News Ghana talked of security forces ""storming"" one area - Asawasi - in Kumasi district in southern Ghana and issuing warnings to local people. The Facebook post is tagged #AsawasiConstituencyTensions, and carries a Hausa-language report. The fact-checking service, Fact-Check Ghana, said this post should be disregarded for talking about the military having ""stormed"" the area. They said it was simply the military taking part in a meeting with local elders, religious figures, political representatives and others about the election on 7 December. So what was the army doing? During the TV report, the reporter talks to an army officer, who does issue a warning about people firing or brandishing weapons on election day, or attempting to steal ballot boxes. But there is no reference in the report itself to the military ""storming"" the area. The BBC's Zawadi Mudibo, who was in Kumasi on election day, says that local people told him there'd not been any unusual activity or extra presence by the military in the run-up to the vote. He was told the situation was normal, so the use of the word ""storming"" to describe the army's activities there does appear misleading. Read more from Reality Check Send us your questions Follow us on Twitter"
Google to run ads educating users about fake news,"Google plans to show ads that educate people about disinformation techniques, following a successful experiment by Cambridge University. Google Jigsaw, which tackles online security dangers, will run adverts on YouTube, TikTok, Twitter and Facebook. Researchers found the videos improved people's ability to recognise manipulative content. They will be shown in Slovakia, the Czech Republic and Poland to combat fake news about Ukrainian refugees. Google said the ""exciting"" findings showed how social media can actively pre-empt the spread of disinformation. The research was founded on a developing area of study called ""prebunking"", which investigates how disinformation can be debunked by showing people how it works - before they are exposed to it. In the experiment, the ads were shown to 5.4 million people, 22,000 of whom were surveyed afterwards. After watching the explanatory videos, researchers found: The peer-reviewed research was conducted in conjunction with Google, which owns YouTube, and will be published in the journal Science Advances. Beth Goldberg, head of research and development for Google Jigsaw, called the findings ""exciting"". ""They demonstrate that we can scale prebunking far and wide, using ads as a vehicle,"" she said. Jon Roozenbeek, the lead author on the paper, told the BBC the research is about ""reducing the probability someone is persuaded by misinformation"". ""Obviously you can't predict every single example of misinformation that's going to go viral,"" he said. ""But what you can do is find common patterns and tropes. ""The idea behind this study was - if we find a couple of these tropes, is it possible to make people more resilient against them, even in content they've never seen before?"" The scientists initially tested the videos with members of the public under controlled-conditions in a lab, before showing them to millions of users on YouTube, as part of a broader field study. The anti-misinformation campaign and prebunking campaign was run on YouTube ""as it would look in the real world"", Mr Roozenbeek said. ""We ran them as YouTube ads - just like an ad about shaving cream or whatever... before your video plays,"" he explained. Advertisers can use a feature on YouTube called Brand Lift, which tells them if, and how, an advert has raised awareness of their product. The researchers used this same feature to assess people's ability to spot the manipulation techniques they had been exposed to. Instead of a question about brand awareness, people were shown a headline and asked to read it. They were told the headline contained manipulation and asked to identify what kind of technique was being used. In addition, there was a separate control group who were not shown any videos, but were shown the headline and corresponding questions. ""What you hope to see is that the group that saw the videos is correct in their identification significantly more often than the control group - and that turned out to be the case,"" Mr Roozenbeek said. ""On average, the group that got the videos was correct about 5% more often than the control group. That's highly significant. ""That doesn't sound like a lot - but it's also true that the control group isn't always wrong. They also get a number of questions correct. ""That improvement, even in the noisy environment of YouTube, basically shows that you can improve people's ability to recognise these disinformation techniques - simply by showing them an ad."" Cambridge University said this was the first real-world field study of 'inoculation theory' on a social media platform. Professor Sander van der Linden, who co-authored the study, said the research results were sufficient to take the concept of inoculation forward and scale it up, to potentially reach ""hundreds of millions"" of social media users. ""Clearly it's important for kids to learn how to do lateral reading and check the veracity of sources,"" he said, ""but we also need solutions that can be scaled on social media and interface with their algorithms."" He acknowledged the scepticism around technology firms using this type of research, and the broader scepticism around industry-academia collaborations. ""But, at the end of the day, we have to face reality, in that social media companies control much of the flow of information online. So in order to protect people, we have come up with independent, evidence-based solutions that social media companies can actually implement on their platforms."" ""To me, leaving social media companies to their own devices is not going to generate the type of solutions that empower people to discern misinformation that spreads on their platforms."""
"Google, YouTube ban ads on climate misinformation","Google says it will stop ads running on climate change-denying YouTube videos and other content, and prohibit ads promoting these claims. The company says it is responding to concerns from advertisers. The ban will cover ads for - and the monetization of - content that contradicts the ""scientific consensus around the existence and causes of climate change"". It will be enforced by ""automated tools and human review"". The policy will apply to content ""referring to climate change as a hoax or a scam, claims denying that long-term trends show the global climate is warming, and claims denying that greenhouse gas emissions or human activity contribute to climate change"". The changes mean YouTube creators will be stopped from earning advertising revenue from content which denies climate change. A 2020 report by Avaaz - a US not-for-profit organisation which promotes activism on issues such as climate change - accused YouTube of ""incentivizing this climate misinformation content via its monetization program"". Fadi Quran, who runs Avaaz's disinformation project, told the BBC it ""could turn the tide on the climate denial economy"". ""With three weeks left for the critical Glasgow summit, and climate misinformation on the rise to undermine it, other social media platforms must quickly follow Google's leadership."" This move from Google marks a first step in trying to disincentivize those looking to profit from denying and downplaying the very real threat of climate change, on social media. Creating emotive content that's wrong about climate change attracts views, likes, and therefore money through advertising. This new policy aims to put an end to that last part - on Google platforms at least. But critics are calling for social media sites to tackle climate change disinformation in the same way - and with the same seriousness - as falsehoods about the pandemic. That would include introducing labels for false information - and demoting videos and content which mislead about climate change from the sites' algorithms - so that they aren't suggested to users. The human cost of anti-vaccine and coronavirus conspiracies appears to be in part what eventually inspired the social media sites to act. The human cost of climate change has become clear over recent months - and the question remains: will social media sites act decisively and quickly enough to combat harmful lies that could hinder efforts to save the planet? Greenpeace's Silvia Pastorelli welcomed the announcement, but told the BBC it was ""nowhere near enough to stop the overwhelming amount of climate disinformation, greenwashing and outright climate denial on big tech's platforms"". Stopping the monetization of content does not remove it or reduce its prominence. But Google says it does both, and strives to provide authoritative information, even when people search for climate-related conspiracies. The announcement by Google's advertising team follows a blog post on Wednesday by Google Chief Executive Sundar Pichai, in which he announced a range of measures to help tackle climate change including:"
Greta Thunberg: German police deny protest detainment was staged,"German police have denied being ""extras for Greta Thunberg"" after false claims that her detainment at a protest in western Germany was staged. A viral post falsely claimed the climate activist being held by police was ""all set up for the cameras"". Ms Thunberg and other activists were seeking to stop the abandoned village of LÃ¼tzerath from being demolished for the expansion of a coal mine. The video of her being removed by police has gained millions of views. ""We would never give ourselves to make such recordings,"" a spokesperson for local police told the BBC, denying allegations that Ms Thunberg's detainment was fake. But it is important that the police enable reporting and guarantee the protection of media workers, they added. The viral video shows the climate campaigner flanked by police officers on either side. Meanwhile a few photographers can be seen snapping photos and moving around her, as Ms Thunberg smiles. Several other police officers who were also standing nearby appear to be waiting with her before walking her away from the scene. Some online have jumped onto these moments of officers and Ms Thunberg waiting around, to falsely claim that it is part of a staged photo opportunity. However the interior ministry of the western state of North Rhine-Westphalia told the BBC that the police officers and Ms Thunberg were waiting for logistical reasons. ""They had to wait for a couple of minutes before they could bring her to a certain police car,"" said the spokesperson. They added that ""the whole situation has been used by those with political motives and the real reason is entirely practical and mundane."" Christian Wernicke, a journalist from German news outlet SÃ¼ddeutsche Zeitung who was there at the time, said the police officers ""were deciding how they would proceed with the identity check and waiting to take Greta to the police vehicle."" ""My impression was that there was confusion. Greta was not the first protester who had been taken away from the sit-in,"" Mr Wernicke added. ""I've seen different reactions to the video. Some say that the footage looks like the police are setting her up to embarrass her and others say that it is all part of some propaganda. ""People are interpreting and using this footage for their own motives."" Many online also falsely claimed it was a ""fake arrest"" but police clarified that Ms Thunberg had not been arrested but had been briefly detained. The group of activists were detained after they ""rushed towards the ledge"" of the Garzweiler 2 mine, police had said on Tuesday. Officers also confirmed all of those detained would not be charged. Ms Thunberg has frequently been the target of conspiracy theories and false claims online, often by those who deny the existence of man-made climate change. She tweeted: ""Yesterday I was part of a group that peacefully protested the expansion of a coal mine in Germany. We were kettled by police and then detained but were let go later that evening. ""Climate protection is not a crime"". German police have denied being ""extras for Greta Thunberg"" after false claims that her detainment at a protest in western Germany was staged. A viral post falsely claimed the climate activist being held by police was ""all set up for the cameras"". Ms Thunberg and other activists were seeking to stop the abandoned village of LÃ¼tzerath from being demolished for the expansion of a coal mine. The video of her being removed by police has gained millions of views. ""We would never give ourselves to make such recordings,"" a spokesperson for local police told the BBC, denying allegations that Ms Thunberg's detainment was fake. But it is important that the police enable reporting and guarantee the protection of media workers, they added. The viral video shows the climate campaigner flanked by police officers on either side. Meanwhile a few photographers can be seen snapping photos and moving around her, as Ms Thunberg smiles. Several other police officers who were also standing nearby appear to be waiting with her before walking her away from the scene. Some online have jumped onto these moments of officers and Ms Thunberg waiting around, to falsely claim that it is part of a staged photo opportunity. However the interior ministry of the western state of North Rhine-Westphalia told the BBC that the police officers and Ms Thunberg were waiting for logistical reasons. ""They had to wait for a couple of minutes before they could bring her to a certain police car,"" said the spokesperson. They added that ""the whole situation has been used by those with political motives and the real reason is entirely practical and mundane."" Christian Wernicke, a journalist from German news outlet SÃ¼ddeutsche Zeitung who was there at the time, said the police officers ""were deciding how they would proceed with the identity check and waiting to take Greta to the police vehicle."" ""My impression was that there was confusion. Greta was not the first protester who had been taken away from the sit-in,"" Mr Wernicke added. ""I've seen different reactions to the video. Some say that the footage looks like the police are setting her up to embarrass her and others say that it is all part of some propaganda. ""People are interpreting and using this footage for their own motives."" Many online also falsely claimed it was a ""fake arrest"" but police clarified that Ms Thunberg had not been arrested but had been briefly detained. The group of activists were detained after they ""rushed towards the ledge"" of the Garzweiler 2 mine, police had said on Tuesday. Officers also confirmed all of those detained would not be charged. Ms Thunberg has frequently been the target of conspiracy theories and false claims online, often by those who deny the existence of man-made climate change. She tweeted: ""Yesterday I was part of a group that peacefully protested the expansion of a coal mine in Germany. We were kettled by police and then detained but were let go later that evening. ""Climate protection is not a crime""."
Hawaii wildfires: 'Directed energy weapon' and other false claims go viral,"False claims about the deadly wildfires in Hawaii - including that shadowy forces orchestrated the disaster with a laser beam - have gained traction online. The misleading posts come from a variety of sources and accounts, but generally imply that ""elites"" or government agencies deliberately started the fires. Some of the most popular theories are couched in questions about a ""narrative"" and make claims that alternative views are being ""censored"", despite collecting millions of views. While there are specific rumours circulating about Maui, they fit into a general pattern repeatedly seen after extreme weather events and natural disasters -  politically motivated activists seeking to downplay the potential impact of climate change. Videos and images claiming that the wildfires were not a natural disaster - and were instead caused by a ""directed energy weapon"", a ""laser beam"" or explosion - have been viewed millions of times. One video viewed 10 million times claims to show a large explosion in Maui just before the fires. But the video was originally a viral clip shared on TikTok in May showing a transformer explosion in Chile. Chilean TV network ChilevisiÃ³n ran a report on the viral video, confirming the explosion was the result of a blown transformer caused by strong wind. An image of a church on fire in Hawaii has been viewed 9 million times, with claims it shows a laser beam striking it. But it has been digitally altered. The original image - of the Waiola Church in Lahaina in flames on 8 August - has no laser beam or ray of light visible. Two other false images have been racking up huge numbers of views. One shows a fireball and a bright streak of light rising up towards the night sky. It, too, has been accompanied by claims that wildfires are not a natural phenomenon. But a search on the internet for previous versions of this image reveals the photo shows a controlled burn at an Ohio oil refinery and was first posted online in January 2018. The streak of light, known as a ""light pillar"", is an optical illusion formed by reflections off ice crystals on a cold day. A similar image claims to show a huge beam of light in Maui just before the wildfires. But it shows the launch of a SpaceX Falcon 9 rocket in California in May 2018. There are claims circulating about videos from Maui showing some trees still standing while houses and vehicles have been burned, with people pointing to the pictures as ""evidence"" that the fires were deliberately set or that their real cause is being hidden from the public. One post on X, the platform formerly known as Twitter, includes a video of the destruction and the message: ""Everything is burnt but the trees, but don't point that out or you're a conspiracy theorist."" That post - which has been seen more than 24 million times - has been challenged by X's Community Notes feature, where users add context and facts around viral content. Dr Rory Hadden, senior lecturer and expert in fire investigations at the University of Edinburgh, told BBC Verify that it is common for trees to remain standing even after severe wildfires because ""burning through a large piece of wood takes a long time"", ""thick pieces of wood are usually not able to sustain burning on their own"" and ""the high moisture content of trees will also make them hard to burn"". Some plants, known as pyrophytes, have also adapted to survive wildfires due to thermal insulation or other means. Alongside the ""directed energy weapon"" rumours, speculation spread in viral posts that some of the island's rich inhabitants and second-home owners deliberately started the wildfires to grab valuable land in Lahaina. One viral video includes claims by a podcaster that native landowners in Maui have refused to sell land to investment management companies and rich locals. He notes the false ""directed energy weapon"" rumours before going on to speculate that there might be something to them because news outlets have called the rumours ""conspiracy theories"". Another viral thread was seen 10 million times on an X account that frequently spreads false information debunked by Community Notes. It includes a list of wealthy people who purportedly own property on Maui, a video including aerial footage of Lahaina, and claims that the pattern of destruction is suspicious. The cause or causes of the fires on Maui are still unknown, but no real evidence has emerged to suggest they were deliberately started as part of a land grab. X had not responded to a request for comment as of Monday (14 August). What do you want BBC Verify to investigate? False claims about the deadly wildfires in Hawaii - including that shadowy forces orchestrated the disaster with a laser beam - have gained traction online. The misleading posts come from a variety of sources and accounts, but generally imply that ""elites"" or government agencies deliberately started the fires. Some of the most popular theories are couched in questions about a ""narrative"" and make claims that alternative views are being ""censored"", despite collecting millions of views. While there are specific rumours circulating about Maui, they fit into a general pattern repeatedly seen after extreme weather events and natural disasters -  politically motivated activists seeking to downplay the potential impact of climate change. Videos and images claiming that the wildfires were not a natural disaster - and were instead caused by a ""directed energy weapon"", a ""laser beam"" or explosion - have been viewed millions of times. One video viewed 10 million times claims to show a large explosion in Maui just before the fires. But the video was originally a viral clip shared on TikTok in May showing a transformer explosion in Chile. Chilean TV network ChilevisiÃ³n ran a report on the viral video, confirming the explosion was the result of a blown transformer caused by strong wind. An image of a church on fire in Hawaii has been viewed 9 million times, with claims it shows a laser beam striking it. But it has been digitally altered. The original image - of the Waiola Church in Lahaina in flames on 8 August - has no laser beam or ray of light visible. Two other false images have been racking up huge numbers of views. One shows a fireball and a bright streak of light rising up towards the night sky. It, too, has been accompanied by claims that wildfires are not a natural phenomenon. But a search on the internet for previous versions of this image reveals the photo shows a controlled burn at an Ohio oil refinery and was first posted online in January 2018. The streak of light, known as a ""light pillar"", is an optical illusion formed by reflections off ice crystals on a cold day. A similar image claims to show a huge beam of light in Maui just before the wildfires. But it shows the launch of a SpaceX Falcon 9 rocket in California in May 2018. There are claims circulating about videos from Maui showing some trees still standing while houses and vehicles have been burned, with people pointing to the pictures as ""evidence"" that the fires were deliberately set or that their real cause is being hidden from the public. One post on X, the platform formerly known as Twitter, includes a video of the destruction and the message: ""Everything is burnt but the trees, but don't point that out or you're a conspiracy theorist."" That post - which has been seen more than 24 million times - has been challenged by X's Community Notes feature, where users add context and facts around viral content. Dr Rory Hadden, senior lecturer and expert in fire investigations at the University of Edinburgh, told BBC Verify that it is common for trees to remain standing even after severe wildfires because ""burning through a large piece of wood takes a long time"", ""thick pieces of wood are usually not able to sustain burning on their own"" and ""the high moisture content of trees will also make them hard to burn"". Some plants, known as pyrophytes, have also adapted to survive wildfires due to thermal insulation or other means. Alongside the ""directed energy weapon"" rumours, speculation spread in viral posts that some of the island's rich inhabitants and second-home owners deliberately started the wildfires to grab valuable land in Lahaina. One viral video includes claims by a podcaster that native landowners in Maui have refused to sell land to investment management companies and rich locals. He notes the false ""directed energy weapon"" rumours before going on to speculate that there might be something to them because news outlets have called the rumours ""conspiracy theories"". Another viral thread was seen 10 million times on an X account that frequently spreads false information debunked by Community Notes. It includes a list of wealthy people who purportedly own property on Maui, a video including aerial footage of Lahaina, and claims that the pattern of destruction is suspicious. The cause or causes of the fires on Maui are still unknown, but no real evidence has emerged to suggest they were deliberately started as part of a land grab. X had not responded to a request for comment as of Monday (14 August). What do you want BBC Verify to investigate?"
He spread conspiracies about elections. Now he oversees them,"A controversy over conspiracy theories that has engulfed a small Iowa county shows the continuing power of Donald Trump's false claims about election fraud. Like millions of other Americans, David Whipple was enraged by the 2020 election. ""The left has tried real hard to steal our nation, but no thanks. We will remain Patriots and free Americans,"" he wrote on Facebook, days after it became clear that Joe Biden would be the next president of the United States. It was just one of a string of messages that Mr Whipple shared around that time with conspiratorial themes. Others included links to QAnon and 9/11 conspiracy theory videos, and cast further doubt on the 2020 election. Those posts went almost entirely unnoticed at the time, and for more than two years afterwards - until, in June of this year, Mr Whipple was appointed as the auditor of Warren County, Iowa. Among his duties, he will now oversee elections. That has baffled and outraged many in this rural county of about 50,000 people just south of Des Moines. On Tuesday, Mr Whipple faces a special election that could remove him from office. This very local dispute raises a particularly potent political question that resonates across the United States today: does spreading conspiracy theories and election fraud allegations make someone unfit for public office? Immediately after Mr Whipple's posts came to light, local Democrats sprung into action. By law, they had two weeks from his appointment to gather enough signatures on a petition to force a special election. Democrats knocked on doors along the highways linking the county's farms, small towns and Des Moines suburbs, and fanned out around the gleaming new courthouse in Indianola, the county seat, approaching voters outside the town square's cafes and local shops. Jim Culbert, chair of the Warren County Democrats, says the petition was so popular that some eager residents didn't have to wait to be asked, instead rushing up to clipboard-toting volunteers to sign it. Mr Whipple's social media activity was the main point of contention. ""It obviously makes you question their judgment,"" Mr Culbert says of the Facebook posts. ""And if their judgment was that bad on this stuff in the past, why are we trusting them to run things in the future?"" At a restless hearing on the petition, held on a Friday afternoon just before the 4 July holiday weekend, up to 100 local residents crowded into a committee room. The fractious crowd was prepared for the petition to be denied, and the meeting's chair, county attorney Douglas Eichholz, repeatedly admonished people to remain civil. The head of the local Republican party, Steve Kirby, accused Democrats of ""passive deception"" and argued that some of the signatures on the petition should be thrown out for being illegible. But despite the opposition, the petition was accepted by a three-member panel which included Mr Whipple himself. Although he was originally appointed to serve out the rest of the auditor's term - through to the end of 2024, including next November's looming elections - he could now be out of office just months after taking up the post. Speaking to the BBC on a hot, sunny day, surrounded by stacks of paperwork in his office two blocks from the town square, Mr Whipple defended his use of Facebook. ""They weren't things that I was authoring personally,"" he says. ""I'd say, 'Hey, check this one out', and send it on to my friends and family."" He got carried away, he says, and now thinks some of the things he posted were ""ridiculous"". He says he has no doubt that Joe Biden is the legitimate president of the United States. ""It was a very emotional time for a lot of people in the world,"" he says. ""It's unfortunate that a lot of these things ended up being so much misinformation."" He deleted the posts shortly after they became news. But Democrats say he continues to traffic in unsubstantiated theories - and that makes him unsuitable for public office, particularly one that oversees elections. Warren County, like Iowa itself, was in recent memory fairly split politically - having gone narrowly for Democrat Barack Obama in the 2008 presidential election, then narrowly against him in 2012. But the mix of people here - who tend to corn and soy fields or live in the new developments on Des Moines' outskirts - have been increasingly drawn to the Republican camp ever since Mr Trump arrived on the scene. The former president won Warren County by about 17 percentage points in 2020. Democrats have also gradually lost the sway they once had locally. ""Politics here used to be much more evenly matched,"" says Amy Duncan, publisher of the local newspaper, the Indianola Independent Advocate. ""There's some Democrats around, there's even some fairly liberal Democrats around, but none of them are holding political office in the way that they did 10 years ago."" Until Mr Whipple's appointment, the auditor's position was the last county-wide post held by a Democrat. The controversial social media posts were brought to light by Kedron Bardwell, a political science professor at Simpson College. Among other things, Mr Bardwell teaches a course on misinformation and conspiracy theories on the brick-lined campus just north of Indianola's town square. His office is filled with political memorabilia from past presidential campaigns which, as per American tradition, begin in Iowa. But his students now have a local example to study. Mr Bardwell says the county's Republican leadership looked past Mr Whipple's posts because they too buy into Mr Trump's election theories. ""I think it's highly likely that [the county supervisors] didn't see them as problematic because in large part they agree,"" Mr Bardwell says. And election fraud, he noted, ""is a mainstream idea to about two-thirds of Republicans"" - a figure borne out by polls. A recent CNN survey, for example, found that 69% of Republicans believe Joe Biden's victory was illegitimate. Mr Trump himself continues to repeatedly make the same baseless allegations - that the 2020 election was stolen, and he was the rightful winner - despite facing multiple criminal charges related to those conspiracy theories. But Trump's obsession also presents a fundamental problem for Republicans nationwide. While it might enthuse the party's base, it's less popular among the general public. According to research by nonpartisan group States United, candidates who repeated election fraud themes underperformed by somewhere between 2.3 to 3.7 percentage points during last year's midterm elections - a small but potentially crucial margin. Democrats are banking that dynamic will prevail in August's special election. They are confident that they can win over independent voters and even get some Republicans to back Democrat Kim Sheets, who currently holds the position of deputy auditor. Mr Whipple retains the backing of local Republicans, who say his decades in business and his management skills make him the most qualified candidate. And far from being a demerit, argues Mr Kirby, the county Republican chairman, the controversial posts should actually count in Mr Whipple's favour. ""He's got questions about the 2020 election,"" Mr Kirby said. ""Well, a lot of people have. It also shows that he is very interested in election integrity."" Although he's thought twice about his past posts, Mr Whipple has not entirely jettisoned fraud theories. While he says he isn't aware of any large-scale voter fraud in Warren County, Mr Whipple did hint about rumours of mismanagement in the auditor's office and noted that some poll workers - many of whom are local retired volunteers - had switched their party affiliation just before previous elections. That, he suggested, might indicate there's suspicious activity going on. ""I didn't witness [this] myself,"" he says. ""But it makes me think there's smoke here. So let me go investigate the fire."" But Democrats, and election-watchers like Mr Bardwell, dismiss any suggestion of widespread voting irregularities in Warren County. ""That's crazy. I don't even know what to say about poll workers switching allegiances,"" Mr Culbert, the chair of County Democrats, says. ""I don't know how that would affect anything, even if it was true."" In the 29 August special election Mr Whipple will face voters for the first time. And, as he remains in the county auditor's post for now, he'll also oversee the election. Mr Bardwell, the political science professor, predicts that Mr Whipple will struggle to hold on to his new job. ""I've talked to several people I know around town who are not partisans,"" he says. ""They were shocked to see those posts."" He says that despite the solid Republican bloc of support, Democrats should be able to capitalise on the controversy. ""What you'll see is people in the middle rising up and saying this is a bridge too far,"" he says. ""And I think you'll see a defeat of Mr Whipple in the special election."" A controversy over conspiracy theories that has engulfed a small Iowa county shows the continuing power of Donald Trump's false claims about election fraud. Like millions of other Americans, David Whipple was enraged by the 2020 election. ""The left has tried real hard to steal our nation, but no thanks. We will remain Patriots and free Americans,"" he wrote on Facebook, days after it became clear that Joe Biden would be the next president of the United States. It was just one of a string of messages that Mr Whipple shared around that time with conspiratorial themes. Others included links to QAnon and 9/11 conspiracy theory videos, and cast further doubt on the 2020 election. Those posts went almost entirely unnoticed at the time, and for more than two years afterwards - until, in June of this year, Mr Whipple was appointed as the auditor of Warren County, Iowa. Among his duties, he will now oversee elections. That has baffled and outraged many in this rural county of about 50,000 people just south of Des Moines. On Tuesday, Mr Whipple faces a special election that could remove him from office. This very local dispute raises a particularly potent political question that resonates across the United States today: does spreading conspiracy theories and election fraud allegations make someone unfit for public office? Immediately after Mr Whipple's posts came to light, local Democrats sprung into action. By law, they had two weeks from his appointment to gather enough signatures on a petition to force a special election. Democrats knocked on doors along the highways linking the county's farms, small towns and Des Moines suburbs, and fanned out around the gleaming new courthouse in Indianola, the county seat, approaching voters outside the town square's cafes and local shops. Jim Culbert, chair of the Warren County Democrats, says the petition was so popular that some eager residents didn't have to wait to be asked, instead rushing up to clipboard-toting volunteers to sign it. Mr Whipple's social media activity was the main point of contention. ""It obviously makes you question their judgment,"" Mr Culbert says of the Facebook posts. ""And if their judgment was that bad on this stuff in the past, why are we trusting them to run things in the future?"" At a restless hearing on the petition, held on a Friday afternoon just before the 4 July holiday weekend, up to 100 local residents crowded into a committee room. The fractious crowd was prepared for the petition to be denied, and the meeting's chair, county attorney Douglas Eichholz, repeatedly admonished people to remain civil. The head of the local Republican party, Steve Kirby, accused Democrats of ""passive deception"" and argued that some of the signatures on the petition should be thrown out for being illegible. But despite the opposition, the petition was accepted by a three-member panel which included Mr Whipple himself. Although he was originally appointed to serve out the rest of the auditor's term - through to the end of 2024, including next November's looming elections - he could now be out of office just months after taking up the post. Speaking to the BBC on a hot, sunny day, surrounded by stacks of paperwork in his office two blocks from the town square, Mr Whipple defended his use of Facebook. ""They weren't things that I was authoring personally,"" he says. ""I'd say, 'Hey, check this one out', and send it on to my friends and family."" He got carried away, he says, and now thinks some of the things he posted were ""ridiculous"". He says he has no doubt that Joe Biden is the legitimate president of the United States. ""It was a very emotional time for a lot of people in the world,"" he says. ""It's unfortunate that a lot of these things ended up being so much misinformation."" He deleted the posts shortly after they became news. But Democrats say he continues to traffic in unsubstantiated theories - and that makes him unsuitable for public office, particularly one that oversees elections. Warren County, like Iowa itself, was in recent memory fairly split politically - having gone narrowly for Democrat Barack Obama in the 2008 presidential election, then narrowly against him in 2012. But the mix of people here - who tend to corn and soy fields or live in the new developments on Des Moines' outskirts - have been increasingly drawn to the Republican camp ever since Mr Trump arrived on the scene. The former president won Warren County by about 17 percentage points in 2020. Democrats have also gradually lost the sway they once had locally. ""Politics here used to be much more evenly matched,"" says Amy Duncan, publisher of the local newspaper, the Indianola Independent Advocate. ""There's some Democrats around, there's even some fairly liberal Democrats around, but none of them are holding political office in the way that they did 10 years ago."" Until Mr Whipple's appointment, the auditor's position was the last county-wide post held by a Democrat. The controversial social media posts were brought to light by Kedron Bardwell, a political science professor at Simpson College. Among other things, Mr Bardwell teaches a course on misinformation and conspiracy theories on the brick-lined campus just north of Indianola's town square. His office is filled with political memorabilia from past presidential campaigns which, as per American tradition, begin in Iowa. But his students now have a local example to study. Mr Bardwell says the county's Republican leadership looked past Mr Whipple's posts because they too buy into Mr Trump's election theories. ""I think it's highly likely that [the county supervisors] didn't see them as problematic because in large part they agree,"" Mr Bardwell says. And election fraud, he noted, ""is a mainstream idea to about two-thirds of Republicans"" - a figure borne out by polls. A recent CNN survey, for example, found that 69% of Republicans believe Joe Biden's victory was illegitimate. Mr Trump himself continues to repeatedly make the same baseless allegations - that the 2020 election was stolen, and he was the rightful winner - despite facing multiple criminal charges related to those conspiracy theories. But Trump's obsession also presents a fundamental problem for Republicans nationwide. While it might enthuse the party's base, it's less popular among the general public. According to research by nonpartisan group States United, candidates who repeated election fraud themes underperformed by somewhere between 2.3 to 3.7 percentage points during last year's midterm elections - a small but potentially crucial margin. Democrats are banking that dynamic will prevail in August's special election. They are confident that they can win over independent voters and even get some Republicans to back Democrat Kim Sheets, who currently holds the position of deputy auditor. Mr Whipple retains the backing of local Republicans, who say his decades in business and his management skills make him the most qualified candidate. And far from being a demerit, argues Mr Kirby, the county Republican chairman, the controversial posts should actually count in Mr Whipple's favour. ""He's got questions about the 2020 election,"" Mr Kirby said. ""Well, a lot of people have. It also shows that he is very interested in election integrity."" Although he's thought twice about his past posts, Mr Whipple has not entirely jettisoned fraud theories. While he says he isn't aware of any large-scale voter fraud in Warren County, Mr Whipple did hint about rumours of mismanagement in the auditor's office and noted that some poll workers - many of whom are local retired volunteers - had switched their party affiliation just before previous elections. That, he suggested, might indicate there's suspicious activity going on. ""I didn't witness [this] myself,"" he says. ""But it makes me think there's smoke here. So let me go investigate the fire."" But Democrats, and election-watchers like Mr Bardwell, dismiss any suggestion of widespread voting irregularities in Warren County. ""That's crazy. I don't even know what to say about poll workers switching allegiances,"" Mr Culbert, the chair of County Democrats, says. ""I don't know how that would affect anything, even if it was true."" In the 29 August special election Mr Whipple will face voters for the first time. And, as he remains in the county auditor's post for now, he'll also oversee the election. Mr Bardwell, the political science professor, predicts that Mr Whipple will struggle to hold on to his new job. ""I've talked to several people I know around town who are not partisans,"" he says. ""They were shocked to see those posts."" He says that despite the solid Republican bloc of support, Democrats should be able to capitalise on the controversy. ""What you'll see is people in the middle rising up and saying this is a bridge too far,"" he says. ""And I think you'll see a defeat of Mr Whipple in the special election."""
How Covid and climate misinformation spread in 2021,nan
"How Covid conspiracies, 'fake news' and misinformation spread in 2020",nan
How Kremlin accounts manipulate Twitter,"Olena Kurilo became the face of Russia's invasion of Ukraine. Bloodied and bandaged, the 53-year-old teacher said she couldn't believe what had happened to her and her town of Chuhuiv. Her picture was on the front pages of newspapers across the world. Over the next few days, Russia's government social media accounts began to post a video claiming that Olena hadn't been injured at all. ""Great photos by the way, they were all over the news,"" the Russian narrator says. The video then claims Olena was photographed two days later, uninjured. ""A couple of days later, good for her, not a scratch."" This claim is baseless, the BBC has verified the photo as genuine, as has Reuters. Wild conspiracy theories like these are not uncommon on social media. But what makes this conspiracy theory so odd is that it was shared by an official Russian government Twitter account - the Russian Mission in Geneva. Two weeks on, the tweet is still live. The Russian government has a huge network of official Twitter accounts - the BBC found more than 100 of them. They range from accounts that represent foreign missions or embassies, with a few thousand followers, to those with more than a million followers. President Putin has his own account. Many of the accounts are labelled as Russian government organisations by Twitter. Yet, while many of these accounts have spread disinformation, Twitter deals with them differently to Russian state media - like RT or Sputnik. On 28 February, Twitter announced it would prevent tweets from Russian state-affiliated media outlets from being eligible for ""amplification"" - meaning they wouldn't be recommended in the home timeline, notifications, and other places on Twitter. But Twitter has confirmed to the BBC that this policy does not include Russian government accounts. Tim Graham, a social media analyst at QUT Digital Media Research Centre in Australia, describes this as a ""loophole"" in Twitter's moderation policies, which lets the Russian government pump out misinformation. ""It's certainly a blind spot in Twitter's defences against disinformation,"" he says. Intrigued by this spider web of Russian government accounts, Mr Graham - who specialises in analysing co-ordinated activity on social media - decided to investigate further. He analysed 75 Russian government Twitter profiles which, in total, have more than 7 million followers. The accounts have received 30 million likes, been retweeted 36 million times and been replied to 4 million times. He looked at how many times each Twitter account retweeted one of the other 74 profiles within an hour. He discovered that the Kremlin's network of Twitter accounts work together to retweet and drive up traffic. This practice is sometimes called ""astroturfing"" - when the owner of several accounts uses the profiles they control to retweet content and amplify reach. ""It's a coordinated retweet network,"" Mr Graham says. ""If these accounts weren't retweeting stuff at the same time, the network would just be a bunch of disconnected dots. So what the network shows, very clearly, is that there's a very dense amount of connections to the way these accounts are retweeting. ""They are using this as an engine to drive their preferred narrative onto Twitter, and they're getting away with it,"" he says. Coordinated activity, using multiple accounts, is against Twitter's rules. ""You can't artificially amplify conversations through the use of multiple accounts,"" Twitter's rules state. But Twitter doesn't treat all accounts equally.  Tweets from government and elected officials can be given more leeway when it comes to moderation. The company says on its website that there may be a public interest in seeing tweets that would otherwise violate its rules. However, the company doesn't treat official accounts differently when it comes to coordinated behaviour - there is no exemption. The BBC put Mr Graham's research to Twitter, however the company did not respond directly to his findings. The BBC also asked the Russian Embassy in the UK about the suggestion that official Russian Twitter accounts behave in a coordinated way - and that many share misinformation. The BBC has not received a response. On 10 March, the embassy itself tweeted that the bombing of a maternity hospital in the Ukrainian city of Mariupol had been faked. The account claimed that women pictured at the scene were actors. A photo was posted of a woman being carried on a stretcher, with the words ""FAKE"" plastered over the image. The claim was false. A few days later it was reported that both she and her baby had died. Twitter deleted several tweets making the ""FAKE"" claim, after the BBC flagged them. Yet there are many other examples of Russian disinformation still up on the Russian government's Twitter accounts. The unfounded claim that Olena Kurilo wasn't really injured is still live - it has been retweeted by more than 20 separate Russian government accounts. Unfounded claims that Ukraine has bioweapons have been shared by the Russian network and are still up - as are claims of an imminent chemical attack being allegedly prepared by Ukrainians. The problem Twitter has is that proving content is false can be messy and complex in a time of war. Savvas Zannettou, who analyses social media moderation at Delft University of Technology in the Netherlands, says war makes policing social media even harder. ""To effectively moderate is impossibleÂ the information comes at a very rapid pace, and it's coming from all over the place,"" he says. It appears two things are happening here. Muddled and incomplete information on the ground means only examples of misinformation which are easy to prove are taken down on platforms such as Twitter. Added to that, Twitter's own public interest exceptions means tweets from government officials can be treated differently from other accounts. The BBC asked Twitter whether tweets from Russian ministries and embassies were included in its public interest exceptions, however the social media company did not respond to this specific question. Twitter said: ""We've taken numerous enforcement actions on Russian embassy accounts, including requiring the removal of Tweets."" Twitter also said it would also be doing more in the coming days to flag accounts linked to the Kremlin. ""We'll be expanding our government account labels to additional Russian embassies to add context for people interacting with these accounts on Twitter."" The Kremlin's social media accounts also exist on Facebook and other platforms - this isn't a headache consigned just to Twitter. In January 2021, after the Capitol Hill riots, Twitter banned Donald Trump for his role in repeating allegations of voter fraud. Twitter argued that repeated disinformation, posted from a position of power, had caused real world violence. As official Russian accounts continue to post wild misinformation during a time of war, it is perfectly possible that the Kremlin will end up facing another sanction - being frozen out of Twitter. James Clayton is the BBC's North America technology reporter based in San Francisco. Follow him on Twitter @jamesclayton5."
How Trump's allies stoked Brazil Congress attack,"The scenes in Brasilia looked eerily similar to events at the US Capitol on 6 January two years ago - and there are deeper connections as well. ""The whole thing smells,"" said a guest on Steve Bannon's podcast, one day after the first round of voting in the Brazilian election in October last year. The race was heading towards a run-off and the final result was not even close to being known. Yet Mr Bannon, as he had been doing for weeks, spread baseless rumours about election fraud. Across several episodes of his podcast and in social media posts, he and his guests stoked up allegations of a ""stolen election"" and shadowy forces. He promoted the hashtag #BrazilianSpring, and continued to encourage opposition even after Mr Bolsonaro himself appeared to accept the results. Mr Bannon, the former White House chief strategist, was just one of several key allies of Donald Trump who followed the same strategy used to cast doubt on the results of the 2020 US presidential election. And like what happened in Washington on 6 January 2021, those false reports and unproven rumours helped fuel a mob that smashed windows and stormed government buildings in an attempt to further their cause. The day before the Capitol riot, Mr Bannon told his podcast listeners: ""All hell is going to break loose tomorrow."" He has been sentenced to four months in prison for refusing to comply with an order to testify in front of a Congressional committee that investigated the attack but is free pending an appeal. Along with other prominent Trump advisers who spread fraud rumours, Mr Bannon was unrepentant on Sunday, even as footage emerged of widespread destruction in Brazil. ""Lula stole the ElectionÂ Brazilians know this,"" he wrote repeatedly on the social media site Gettr. He called the people who stormed the buildings ""Freedom Fighters"". Ali Alexander, a fringe activist who emerged after the 2020 election as one of the leaders of the pro-Trump ""Stop the Steal"" movement, encouraged the crowds, writing ""Do whatever is necessary!"" and claiming to have contacts inside the country. Bolsonaro supporters railed online about an existential crisis and a supposed ""communist takeover"" - exactly the same type of rhetoric that drove the rioters in Washington two years ago. In another parallel with the Capitol riot, some supporters of the former president attempted to shift the blame by pinning the storming of government offices on outside agitators or supporters of President Lula. Rumours about anti-fascist antifa activists or left-wing agitators sparking the Capitol riot gained traction online and on right-wing news outlets after 6 January, but subsequent criminal trials have consistently shown that the main leaders and instigators of the attack were staunch supporters of former President Trump. The links between Mr Bolsonaro and the Trump movement were highlighted by a meeting in November between the former president and Mr Bolsonaro's son at Mr Trump's Florida resort. During that trip, Eduardo Bolsonaro also spoke to Mr Bannon and Trump adviser Jason Miller, according to reports in the Washington Post and other news outlets. As in the US in 2020, partisan election-deniers focused their attention on the mechanisms of voting. In Brazil, they cast suspicion on electronic vote tabulation machines. Mr Bannon posted messages urging Brazilian authorities to ""release the machines"", echoing calls to investigate electronic voting in Colorado, Arizona, Georgia and other states. The American authorities responsible for election security said in 2020 that there was no evidence that any voting system deleted or lost votes, changed votes, or was compromised in any way. A banner displayed by the Brazilian rioters on Sunday declared ""We want the source code"" in both English and Portuguese - a reference to rumours that electronic voting machines were somehow programmed or hacked in order to foil Mr Bolsonaro. A number of prominent Brazilian Twitter accounts which spread election denial rumours were reinstated after the election and acquisition of the company by Elon Musk, according to a BBC analysis. The accounts had previously been banned. Mr Musk himself has suggested some of Twitter's own employees in Brazil were ""strongly politically biased"" without giving details or evidence. Some of Mr Trump's opponents in the US were quick to put the blame on the former president and his advisers for encouraging the unrest in Brazil. Jamie Raskin, a Democratic Party member of the US House of Representatives and a member of the committee that investigated the Capitol riot, called the Brazilian protesters ""fascists modeling themselves after Trump's Jan. 6 rioters"" in a tweet. The BBC attempted to contact Mr Bannon and Mr Alexander for comment. With reporting from the BBC's disinformation team The scenes in Brasilia looked eerily similar to events at the US Capitol on 6 January two years ago - and there are deeper connections as well. ""The whole thing smells,"" said a guest on Steve Bannon's podcast, one day after the first round of voting in the Brazilian election in October last year. The race was heading towards a run-off and the final result was not even close to being known. Yet Mr Bannon, as he had been doing for weeks, spread baseless rumours about election fraud. Across several episodes of his podcast and in social media posts, he and his guests stoked up allegations of a ""stolen election"" and shadowy forces. He promoted the hashtag #BrazilianSpring, and continued to encourage opposition even after Mr Bolsonaro himself appeared to accept the results. Mr Bannon, the former White House chief strategist, was just one of several key allies of Donald Trump who followed the same strategy used to cast doubt on the results of the 2020 US presidential election. And like what happened in Washington on 6 January 2021, those false reports and unproven rumours helped fuel a mob that smashed windows and stormed government buildings in an attempt to further their cause. The day before the Capitol riot, Mr Bannon told his podcast listeners: ""All hell is going to break loose tomorrow."" He has been sentenced to four months in prison for refusing to comply with an order to testify in front of a Congressional committee that investigated the attack but is free pending an appeal. Along with other prominent Trump advisers who spread fraud rumours, Mr Bannon was unrepentant on Sunday, even as footage emerged of widespread destruction in Brazil. ""Lula stole the ElectionÂ Brazilians know this,"" he wrote repeatedly on the social media site Gettr. He called the people who stormed the buildings ""Freedom Fighters"". Ali Alexander, a fringe activist who emerged after the 2020 election as one of the leaders of the pro-Trump ""Stop the Steal"" movement, encouraged the crowds, writing ""Do whatever is necessary!"" and claiming to have contacts inside the country. Bolsonaro supporters railed online about an existential crisis and a supposed ""communist takeover"" - exactly the same type of rhetoric that drove the rioters in Washington two years ago. In another parallel with the Capitol riot, some supporters of the former president attempted to shift the blame by pinning the storming of government offices on outside agitators or supporters of President Lula. Rumours about anti-fascist antifa activists or left-wing agitators sparking the Capitol riot gained traction online and on right-wing news outlets after 6 January, but subsequent criminal trials have consistently shown that the main leaders and instigators of the attack were staunch supporters of former President Trump. The links between Mr Bolsonaro and the Trump movement were highlighted by a meeting in November between the former president and Mr Bolsonaro's son at Mr Trump's Florida resort. During that trip, Eduardo Bolsonaro also spoke to Mr Bannon and Trump adviser Jason Miller, according to reports in the Washington Post and other news outlets. As in the US in 2020, partisan election-deniers focused their attention on the mechanisms of voting. In Brazil, they cast suspicion on electronic vote tabulation machines. Mr Bannon posted messages urging Brazilian authorities to ""release the machines"", echoing calls to investigate electronic voting in Colorado, Arizona, Georgia and other states. The American authorities responsible for election security said in 2020 that there was no evidence that any voting system deleted or lost votes, changed votes, or was compromised in any way. A banner displayed by the Brazilian rioters on Sunday declared ""We want the source code"" in both English and Portuguese - a reference to rumours that electronic voting machines were somehow programmed or hacked in order to foil Mr Bolsonaro. A number of prominent Brazilian Twitter accounts which spread election denial rumours were reinstated after the election and acquisition of the company by Elon Musk, according to a BBC analysis. The accounts had previously been banned. Mr Musk himself has suggested some of Twitter's own employees in Brazil were ""strongly politically biased"" without giving details or evidence. Some of Mr Trump's opponents in the US were quick to put the blame on the former president and his advisers for encouraging the unrest in Brazil. Jamie Raskin, a Democratic Party member of the US House of Representatives and a member of the committee that investigated the Capitol riot, called the Brazilian protesters ""fascists modeling themselves after Trump's Jan. 6 rioters"" in a tweet. The BBC attempted to contact Mr Bannon and Mr Alexander for comment. With reporting from the BBC's disinformation team"
How a fake network pushes pro-China propaganda,"A sprawling network of more than 350 fake social media profiles is pushing pro-China narratives and attempting to discredit those seen as opponents of China's government, according to a new study. The aim is to delegitimise the West and boost China's influence and image overseas, the report by the Centre for Information Resilience (CIR) suggests. The study, shared with the BBC, found that the network of fake profiles circulated garish cartoons depicting, among others, exiled Chinese tycoon Guo Wengui, an outspoken critic of China. Other controversial figures featured in the cartoons included ""whistleblower"" scientist Li-Meng Yan, and Steve Bannon, former political strategist for Donald Trump. Each of these individuals has themselves been accused of spreading disinformation, including false information about Covid-19. Some of the accounts - spread across Twitter, Facebook, Instagram and YouTube - use fake AI-generated profile pictures, while others appear to have been hijacked after previously posting in other languages. There is no concrete evidence that the network is linked to the Chinese government, but according to the CIR, a non-profit group which works to counter disinformation, it resembles pro-China networks previously taken down by Twitter and Facebook. These networks amplified pro-China narratives similar to those promoted by Chinese state representatives and state media. Much of the content shared by the network focuses on the US, and in particular on divisive issues like gun laws and race politics. One of the narratives pushed by the network paints the US as having a poor human rights record. Posts from the fake accounts cite the murder of George Floyd among examples, as well as discrimination against Asians. Some accounts repeatedly deny human rights abuses in the Xinjiang region, where experts say China has detained at least a million Muslims against their will, calling the allegations ""lies fabricated by the United States and the West"". ""The aim of the network appears to be to delegitimise the West by amplifying pro-Chinese narratives,"" said Benjamin Strick, the author of the CIR report. There are strong similarities between this network and the so-called ""Spamouflage Dragon"" propaganda network identified by social analytics firm Graphika. Commenting on the new study Ira Hubert, a senior investigative analyst at Graphika, said: ""The report shows that on US platforms, there was no 'honeymoon' in the first months of the Biden administration. ""The network put out a steady mix of anti-US content, for example cheering US 'defeat' ahead of its withdrawal from Afghanistan and painting the US as a poor ally whose aid to India was inadequate during some of its worst months battling Covid."" The CIR mapped hashtags favoured by previously identified networks, unearthing more accounts that showed signs of being part of an influence operation. Tell-tale signs included high levels of activity pushing propaganda narratives and repeated use of the same hashtags. Newly created accounts, accounts with usernames that appeared to be randomly generated, and accounts with very few followers also raised red flags. Some profiles were created to post original content, while others only shared, liked and commented on those original posts, to help them reach a wider audience. This kind of activity is often referred to as ""astroturfing"" because it is designed to create the appearance of a grass-roots campaign. Many of the fake profiles used AI generated photos - a relatively new phenomenon that allows computers to create realistic looking images of people who don't exist. Unlike stolen profile images of real people, the AI generated images, which are created by a type of machine learning framework called StyleGAN, cannot be traced using a reverse image search. The use of fake profile pictures in disinformation campaigns is becoming more common as users and platforms become more wary of suspicious accounts. The CIR used various techniques to identify fake profile pictures in the network. The synthetic images always put the eyes in the same location, so lining them all up can help identify a collection of fake profile pictures. Normally, a random collection of profile pictures would display much more variety in the cropping and the alignment of the eyes. Other signs include blurred edges around the hair, teeth at strange angles, and blurred objects around the face. Many of the Facebook accounts believed to be part of the network appeared to have Turkish names. These accounts may once have belonged to real people but were later hijacked or sold and given new profile pictures. Hijacked accounts also spread the network's pro-China narratives on YouTube. Accounts that had previously posted in English or German and then lain dormant for years suddenly started posting Chinese language content from official Chinese state broadcasters. The CIR shared its research with the social media platforms involved. Facebook has removed the accounts on its platform highlighted in the study. A Facebook spokesman said: ""In September 2019, we removed a network of spam activity that posted lifestyle and political clickbait, primarily in Chinese. This network had almost no engagement on our platform, and we continue to work with researchers and our industry peers to detect and block their attempts to come back, like those accounts mentioned in this report."" YouTube also terminated accounts in the network for violating YouTube's community guidelines. Twitter said it had also now removed almost all of the accounts identified by CIR, as well as a number of others engaged in similar behaviour. It said its investigations are still ongoing. ""When we identify information operation campaigns that we can reliably attribute to state-linked activity - either domestic or foreign-led - we disclose them to our public archive."" Over the past decade, billions of dollars have gone into funding the growth of China's presence on international platforms. But with Facebook, Twitter and YouTube blocked in the mainland, and only accessible via a VPN, the country has struggled to get such platforms recognised as viable competitors to Western juggernauts. It has needed not only Chinese voices, but foreign voices, to show that the country has ""arrived"". ""Wolf warrior diplomacy"" has emerged, with officials using Twitter accounts to fly the flag for Communist Party rhetoric. China wants to portray itself as a friend to the world - and not a repressive, authoritarian state, as it perceives Western nations make it out to be. With more than one billion internet users, China certainly has the capability to orchestrate large-scale social media campaigns, and target what it sees as anti-China voices with a wealth of opposing opinions. But with English-language skills limited in China, there are often clumsy tell-tale signs that a Chinese troll is behind such accounts. Many rely on automatic translation software to turn Chinese messages into English, meaning such messages are riddled with typos, or contain clumsy grammatical structures. And with many Western outlets inaccessible to them within China, users generally have very little knowledge of who they are meant to be targeting, so they simply piggyback off the replies of others from within the same network. Graphics by Simon Martin"
How an unproven rumour about Tyre Nichols fits a larger victim-blaming pattern,"Tyre Nichols's stepfather has denied an unproven rumour that his son was having an affair with the ex-wife of one of the police officers charged with his murder. Mr Nichols died three days after a violent encounter with police in Memphis, when officers kicked and punched him after a traffic stop. But experts say the growing volume of online chatter fits a larger pattern of speculation, rumour and completely false allegations directed towards victims of police brutality in the US. In Mr Nichols's case, a variety of activists and online accounts with varying motivations spread the rumour without any evidence. The allegation swiftly moved from fringe accounts to a level where Mr Nichols's family and leading civil rights figures felt they needed to address it directly. Social media chatter began at a low level on Friday. BBC reporters in Memphis heard similar rumours at about the same time, and chatter on far-right and ""alt-tech"" networks began later, indicating it's likely that the rumour began in the local community rather than online. Once a number of TikTok and YouTube videos and tweets addressed the subject, however, a mix of people began circulating it. The whispers grew steadily louder over the weekend, to the point where Mr Nichols's stepfather, Rodney Wells, denied them in front of a crowd at a prayer vigil on Monday night. ""The police tried to cover it up. They [are] still trying to spread rumours about my son that are not true,"" Mr Wells said, according to local news reports. ""My son was not messing around with one of the officer's wives. That's just a rumour."" No evidence has emerged that police were involved in spreading the rumour. Although some commentators have described the vicious attack as unusually personal, nothing in the bodycam videos released by Memphis authorities indicated that the officers knew Mr Nichols or specifically sought him out before they stopped him. The Reverend Al Sharpton dismissively mentioned the allegation when delivering the eulogy for Mr Nichols on Wednesday. ""Nobody mentioned nothing about no girlfriendÂ they started beating an unarmed man,"" he said. Fact checks by news organisations and Snopes, which tracks conspiracy theories and online falsehoods, laid out what's known and unknown - but had difficulty pinpointing the original source of the story. The BBC contacted several of the most popular Twitter accounts spreading the rumour, and none could provide evidence or say where the claim originated. Those spreading the unproven rumour had a variety of perspectives and possible motives. Some condemned the gossip or made the point that a personal dispute does not justify violence. Several others, including activists and influencers broadly aligned with the Black Lives Matter movement, argued that any evidence of a personal motivation would justify upgrading the criminal charges against the police officers to first-degree - or premeditated - murder. Five officers are currently charged with second-degree murder, which does not require intentional planning. In Tennessee, first-degree murder is punishable by the death penalty while second-degree murder is punishable by up to 15 to 60 years in prison. None of the officers have offered a plea, but lawyers for two of them earlier said they would contest the charges. As is often seen around high-profile news events, others spread the rumour believing they were being helpful by passing along information. Others were attempting to increase their clout and online followings. There are deeper motivations for sharing rumours, too. ""It's an attempt by some people online to rationalise why something like this would happen,"" Snopes reporter Nur Ibrahim said. Another influential group of people used the rumour to distract from larger debates and claimed that it rendered discussions of police brutality and racism irrelevant. The profiles of several of the people making this argument indicated that they supported conservative or far-right causes. Katherine Keneally, senior research director at the Institute of Strategic Dialogue, a counter-extremism think tank, said politically motivated ""bad faith actors"" are well-versed in distraction techniques. ""They're using this to try to detract from the larger problem which is police brutality and the horrible scenes in the video,"" she said. ""They will bite at any sort of rumour that they can use to advance their agenda."" Several high-profile victims of police violence in recent years have been the subject of unproven or false rumours intended to deflect from larger social issues. Sometimes the rumours start with grains of truth. For instance, following the murder of George Floyd, several online influencers focused on his criminal record or accused news outlets of ""covering up"" his history. In reality, Mr Floyd's record was well-reported, as was his involvement in religion and anti-violence causes after his release from prison. After the shooting death of Breonna Taylor by police in Louisville, Kentucky in 2020, online partisans played up her involvement in criminal activity. ""Those rumours were mostly false,"" Ms Ibrahim said. ""They took a little bit of true information and expanded and exaggerated it to the point where it became mostly false."" Ms Kennelly said the release of video footage has caused far-right and pro-police activists to scramble for a coherent story with which to push back. Other posts by some of the same people are based on facts rather than speculation - for instance highlighting that the five officers initially charged are black and that Memphis is run by Democratic Party politicians. The intent, however, is the same. ""[It's] an effort to distract from the larger problem which is police brutality and the horrible scenes in the video,"" Ms Kennelly said. ""That's why we've seen so many narratives over the past five days,"" she said. ""They are trying to get one that sticks, because it's very difficult to argue that this is something other than police brutality."" Far from harmless gossip, Ms Kennelly said the rumours have a larger, negative, impact on public debate and called for more work by social media companies to stop the spread of misleading narratives. ""Harmful misinformation and disinformation can actually have an impact on the family, the case and future efforts to combat police brutality."" Tyre Nichols's stepfather has denied an unproven rumour that his son was having an affair with the ex-wife of one of the police officers charged with his murder. Mr Nichols died three days after a violent encounter with police in Memphis, when officers kicked and punched him after a traffic stop. But experts say the growing volume of online chatter fits a larger pattern of speculation, rumour and completely false allegations directed towards victims of police brutality in the US. In Mr Nichols's case, a variety of activists and online accounts with varying motivations spread the rumour without any evidence. The allegation swiftly moved from fringe accounts to a level where Mr Nichols's family and leading civil rights figures felt they needed to address it directly. Social media chatter began at a low level on Friday. BBC reporters in Memphis heard similar rumours at about the same time, and chatter on far-right and ""alt-tech"" networks began later, indicating it's likely that the rumour began in the local community rather than online. Once a number of TikTok and YouTube videos and tweets addressed the subject, however, a mix of people began circulating it. The whispers grew steadily louder over the weekend, to the point where Mr Nichols's stepfather, Rodney Wells, denied them in front of a crowd at a prayer vigil on Monday night. ""The police tried to cover it up. They [are] still trying to spread rumours about my son that are not true,"" Mr Wells said, according to local news reports. ""My son was not messing around with one of the officer's wives. That's just a rumour."" No evidence has emerged that police were involved in spreading the rumour. Although some commentators have described the vicious attack as unusually personal, nothing in the bodycam videos released by Memphis authorities indicated that the officers knew Mr Nichols or specifically sought him out before they stopped him. The Reverend Al Sharpton dismissively mentioned the allegation when delivering the eulogy for Mr Nichols on Wednesday. ""Nobody mentioned nothing about no girlfriendÂ they started beating an unarmed man,"" he said. Fact checks by news organisations and Snopes, which tracks conspiracy theories and online falsehoods, laid out what's known and unknown - but had difficulty pinpointing the original source of the story. The BBC contacted several of the most popular Twitter accounts spreading the rumour, and none could provide evidence or say where the claim originated. Those spreading the unproven rumour had a variety of perspectives and possible motives. Some condemned the gossip or made the point that a personal dispute does not justify violence. Several others, including activists and influencers broadly aligned with the Black Lives Matter movement, argued that any evidence of a personal motivation would justify upgrading the criminal charges against the police officers to first-degree - or premeditated - murder. Five officers are currently charged with second-degree murder, which does not require intentional planning. In Tennessee, first-degree murder is punishable by the death penalty while second-degree murder is punishable by up to 15 to 60 years in prison. None of the officers have offered a plea, but lawyers for two of them earlier said they would contest the charges. As is often seen around high-profile news events, others spread the rumour believing they were being helpful by passing along information. Others were attempting to increase their clout and online followings. There are deeper motivations for sharing rumours, too. ""It's an attempt by some people online to rationalise why something like this would happen,"" Snopes reporter Nur Ibrahim said. Another influential group of people used the rumour to distract from larger debates and claimed that it rendered discussions of police brutality and racism irrelevant. The profiles of several of the people making this argument indicated that they supported conservative or far-right causes. Katherine Keneally, senior research director at the Institute of Strategic Dialogue, a counter-extremism think tank, said politically motivated ""bad faith actors"" are well-versed in distraction techniques. ""They're using this to try to detract from the larger problem which is police brutality and the horrible scenes in the video,"" she said. ""They will bite at any sort of rumour that they can use to advance their agenda."" Several high-profile victims of police violence in recent years have been the subject of unproven or false rumours intended to deflect from larger social issues. Sometimes the rumours start with grains of truth. For instance, following the murder of George Floyd, several online influencers focused on his criminal record or accused news outlets of ""covering up"" his history. In reality, Mr Floyd's record was well-reported, as was his involvement in religion and anti-violence causes after his release from prison. After the shooting death of Breonna Taylor by police in Louisville, Kentucky in 2020, online partisans played up her involvement in criminal activity. ""Those rumours were mostly false,"" Ms Ibrahim said. ""They took a little bit of true information and expanded and exaggerated it to the point where it became mostly false."" Ms Kennelly said the release of video footage has caused far-right and pro-police activists to scramble for a coherent story with which to push back. Other posts by some of the same people are based on facts rather than speculation - for instance highlighting that the five officers initially charged are black and that Memphis is run by Democratic Party politicians. The intent, however, is the same. ""[It's] an effort to distract from the larger problem which is police brutality and the horrible scenes in the video,"" Ms Kennelly said. ""That's why we've seen so many narratives over the past five days,"" she said. ""They are trying to get one that sticks, because it's very difficult to argue that this is something other than police brutality."" Far from harmless gossip, Ms Kennelly said the rumours have a larger, negative, impact on public debate and called for more work by social media companies to stop the spread of misleading narratives. ""Harmful misinformation and disinformation can actually have an impact on the family, the case and future efforts to combat police brutality."""
How fake copyright complaints are muzzling journalists,"Journalists have been forced to temporarily take down articles critical of powerful oil lobbyists due to the exploitation of US copyright law, according to a new report. At least five such articles have been subject to fake copyright claims, including one by the respected South African newspaper Mail & Guardian, according to the Organized Crime and Corruption Reporting Project (OCCRP). The claims - which falsely assert ownership of the stories - have been made by mystery individuals under the US Digital Millennium Copyright Act (DMCA), a law meant to protect copyright holders. Just last month, three separate false copyright claims were made against Diario Rombe, an investigative news outlet that focusses on Equatorial Guinea. The articles under attack are about the president of Equatorial Guinea's son, Gabriel Mbaga Obiang Lima, and his close associate, Cameroonian businessman and lawyer NJ Ayuk. The OCCRP claimed in a report published on Wednesday that the DMCA process was often abused by ""unknown parties"" who create backdated fake articles to target critical news reports. Under the US law, any online author saying that their content has been stolen can seek to have what they claim is the infringing material ""taken down"" by triggering a formal legal process through web servers who host the material. The process differs depending on the server provider, but it can mean content is removed from the web for weeks while the genuine author proves their credentials. The OCCRP is yet to discover who is behind the attacks, however all the stories were critical of NJ Ayuk. NJ Ayuk, also known as Njock Ayuk Eyong, is the CEO of African law firm Centurion Law Group and the founder of the African Energy Chamber (AEC). He is also an outspoken advocate of the oil industry in Africa. Mr Ayuk has a close relationship with the other subject of two of the stories, Gabriel Mbaga Obiang Lima. Mr Obiang Lima was Equatorial Guinea's Minister of Mines and Hydrocarbons until a recent cabinet reshuffle. Mr Ayuk has issued press releases from Centurion Law Group and the AEC which publicly attack journalists criticising his oil lobbying activities and questioning his close relationship with Mr Obiang Lima. The first known false copyright claim to target reports on Mr Ayuk was made in 2019, following the publication of an article in South Africa's Mail & Guardian (M&G) titled Fraudster named in SA's oil deal. The story examined Mr Ayuk's involvement in an oil deal between South Africa and South Sudan worth hundreds of millions of dollars. It revealed that Mr Ayuk was convicted of fraud in the US in 2007 after pleading guilty to illegally using the stationery and signature stamp of a congressman to obtain visas for fellow Cameroonians. After the story was published, the M&G's web server Linode was contacted by an ""Ian Simpson"", claiming he was the original author of the piece. Linode took down the news outlet's entire website for a morning in response to the complaint. M&G investigated and found that the US address given did not exist and that there were no other traces online of this alleged author. M&G concluded that ""Simpson"" and his article were fakes but Linode forced the newspaper to take down its article about Mr Ayuk before it would restore the rest of the M&G website. Writing about the takedown, the M&G called this a ""censorship attack"". Last November during the UN's climate summit COP27, UK-based Climate Home News published an article about Mr Ayuk launching a partnership with two UN agencies called UN gives platform to convicted fraudster lobbying for African gas. The article highlighted the role of the African Energy Chamber in the UN's flagship Team Energy Africa private investments initiative and referenced Mr Ayuk's US fraud conviction. The UN cancelled the initiative following the publication. Two weeks later, Climate Home News' server AWS received copyright claims on both articles from ""Thomas L Pierce"" and ""Marcus A Webre"". The OCCRP was unable to trace the complainants, and emails to their provided addresses went unanswered. AWS told Climate Home that it might have to take action against Climate Home News unless it could confirm that the matter had been successfully addressed. Climate Home editor Megan Darby removed the articles while addressing the false claims with AWS. It took several weeks before Climate Home was able to reinstate the articles. Ms Darby told the OCCRP: ""These bogus allegations look like a devious tactic to suppress independent journalism."" Earlier this year, unknown parties filed three complaints against independent investigative outlet Diario Rombe over articles authored by them. Two were with its server Cloudflare and one with Google. They targeted two 2021 articles published in collaboration with OCCRP which were critical of Mr Ayuk and his relationship with Mr Obiang Lima. All three complaints appear to have originated from South Africa. The OCCRP said that it could not establish whether the purported claimants ""Lavino Siqueira"" and ""Mark E Bailey"" were real people, and again, emails to their addresses went unanswered. Google removed the second article from its search results. It reinstated the piece only after Diario Rombe filed a so-called ""counter-notice"". Diario Rombe editor Delfin Mocache Massoko said: ""These copyright complaints for a small outlet without funds like Diario Rombe do huge damage to our work. I believe that the author has a single mission, to eliminate all negative information about Mr Ayuk and Lima from the internet."" When contacted by the BBC, Mr Ayuk strongly denied corruption allegations and said he, the AEC and Centurion Law Group denied the allegations made by the OCCRP including in relation to fake copyright claims. Gabriel Mgeba Obiang Lima did not respond to requests for comment at time of publication. The OCCRP contacted AWS, Google and Cloudflare for comment on the bogus copyright complaints, but they did not respond. Journalists have been forced to temporarily take down articles critical of powerful oil lobbyists due to the exploitation of US copyright law, according to a new report. At least five such articles have been subject to fake copyright claims, including one by the respected South African newspaper Mail & Guardian, according to the Organized Crime and Corruption Reporting Project (OCCRP). The claims - which falsely assert ownership of the stories - have been made by mystery individuals under the US Digital Millennium Copyright Act (DMCA), a law meant to protect copyright holders. Just last month, three separate false copyright claims were made against Diario Rombe, an investigative news outlet that focusses on Equatorial Guinea. The articles under attack are about the president of Equatorial Guinea's son, Gabriel Mbaga Obiang Lima, and his close associate, Cameroonian businessman and lawyer NJ Ayuk. The OCCRP claimed in a report published on Wednesday that the DMCA process was often abused by ""unknown parties"" who create backdated fake articles to target critical news reports. Under the US law, any online author saying that their content has been stolen can seek to have what they claim is the infringing material ""taken down"" by triggering a formal legal process through web servers who host the material. The process differs depending on the server provider, but it can mean content is removed from the web for weeks while the genuine author proves their credentials. The OCCRP is yet to discover who is behind the attacks, however all the stories were critical of NJ Ayuk. NJ Ayuk, also known as Njock Ayuk Eyong, is the CEO of African law firm Centurion Law Group and the founder of the African Energy Chamber (AEC). He is also an outspoken advocate of the oil industry in Africa. Mr Ayuk has a close relationship with the other subject of two of the stories, Gabriel Mbaga Obiang Lima. Mr Obiang Lima was Equatorial Guinea's Minister of Mines and Hydrocarbons until a recent cabinet reshuffle. Mr Ayuk has issued press releases from Centurion Law Group and the AEC which publicly attack journalists criticising his oil lobbying activities and questioning his close relationship with Mr Obiang Lima. The first known false copyright claim to target reports on Mr Ayuk was made in 2019, following the publication of an article in South Africa's Mail & Guardian (M&G) titled Fraudster named in SA's oil deal. The story examined Mr Ayuk's involvement in an oil deal between South Africa and South Sudan worth hundreds of millions of dollars. It revealed that Mr Ayuk was convicted of fraud in the US in 2007 after pleading guilty to illegally using the stationery and signature stamp of a congressman to obtain visas for fellow Cameroonians. After the story was published, the M&G's web server Linode was contacted by an ""Ian Simpson"", claiming he was the original author of the piece. Linode took down the news outlet's entire website for a morning in response to the complaint. M&G investigated and found that the US address given did not exist and that there were no other traces online of this alleged author. M&G concluded that ""Simpson"" and his article were fakes but Linode forced the newspaper to take down its article about Mr Ayuk before it would restore the rest of the M&G website. Writing about the takedown, the M&G called this a ""censorship attack"". Last November during the UN's climate summit COP27, UK-based Climate Home News published an article about Mr Ayuk launching a partnership with two UN agencies called UN gives platform to convicted fraudster lobbying for African gas. The article highlighted the role of the African Energy Chamber in the UN's flagship Team Energy Africa private investments initiative and referenced Mr Ayuk's US fraud conviction. The UN cancelled the initiative following the publication. Two weeks later, Climate Home News' server AWS received copyright claims on both articles from ""Thomas L Pierce"" and ""Marcus A Webre"". The OCCRP was unable to trace the complainants, and emails to their provided addresses went unanswered. AWS told Climate Home that it might have to take action against Climate Home News unless it could confirm that the matter had been successfully addressed. Climate Home editor Megan Darby removed the articles while addressing the false claims with AWS. It took several weeks before Climate Home was able to reinstate the articles. Ms Darby told the OCCRP: ""These bogus allegations look like a devious tactic to suppress independent journalism."" Earlier this year, unknown parties filed three complaints against independent investigative outlet Diario Rombe over articles authored by them. Two were with its server Cloudflare and one with Google. They targeted two 2021 articles published in collaboration with OCCRP which were critical of Mr Ayuk and his relationship with Mr Obiang Lima. All three complaints appear to have originated from South Africa. The OCCRP said that it could not establish whether the purported claimants ""Lavino Siqueira"" and ""Mark E Bailey"" were real people, and again, emails to their addresses went unanswered. Google removed the second article from its search results. It reinstated the piece only after Diario Rombe filed a so-called ""counter-notice"". Diario Rombe editor Delfin Mocache Massoko said: ""These copyright complaints for a small outlet without funds like Diario Rombe do huge damage to our work. I believe that the author has a single mission, to eliminate all negative information about Mr Ayuk and Lima from the internet."" When contacted by the BBC, Mr Ayuk strongly denied corruption allegations and said he, the AEC and Centurion Law Group denied the allegations made by the OCCRP including in relation to fake copyright claims. Gabriel Mgeba Obiang Lima did not respond to requests for comment at time of publication. The OCCRP contacted AWS, Google and Cloudflare for comment on the bogus copyright complaints, but they did not respond."
How high-profile scientists felt tricked by group denying climate change,"A dozen scientists, politicians, and campaigners say they have been tricked into participating in online events promoting climate-change denial. The events were organised by the Creative Society, an international activist group that denies global warming is being caused by human activity. The overwhelming majority of scientists agree greenhouse gases - which trap the Sun's heat - are causing a rise in global temperatures. But the Creative Society alleges, without any credible evidence, a conspiracy and condemns what it calls the ""CO2 fraud"". The group told BBC News it ""provides a platform for all ideas to be expressed"" and rejected allegations it tricked anyone into participating in its events. The Creative Society says it has supporters in more than 100 countries but seems to be most popular in Eastern and Central Europe. The group runs a network of more than 200 accounts - with hundreds of thousands of followers - across all major social media platforms. And through them, bad information about global warming is being spread. BBC News has seen dozens of posts denying elementary facts of climate change. The group has uploaded videos on YouTube falsely describing greenhouse gases as ""the scam of the century"". On TikTok, it links - without credible evidence - the melting of glaciers to ""cosmic pulses of galactic interactions"". And on Facebook, it has paid to promote videos wrongly describing renewable energies as a ""scam"". It also tweeted memes about ""corrupted scientists... lying about the causes of climate change"". Asked why it was using social media to promote climate denial, Alexey Prudkov, coordinator of the Creative Society project in Switzerland, told BBC News: ""Climate denialism is a very catchy and at the same time totally misleading term."" But asked whether global warming was being primarily caused by human activities - such as the burning of fossil fuels - he replied: ""No, it's not. ""CO2 is only 0.04% of the total gases in our atmosphere."" This figure is accurate but fails to show how effective carbon dioxide is in trapping the Earth's heat. ""The problem with 99% of scientific literature is that it only studies one factor,"" Mr Prudkov said. ""We call for true science that studies the problem from all angles."" TikTok, Meta, which owns Facebook and Instagram, Twitter, and Google, which owns YouTube, said they had opened investigations into Creative Society accounts, after being contacted by BBC News. On social media, the organisation drums up support for its online conferences, featuring sharp-looking volunteers speaking from their carefully lit living rooms. They also include short films depicting footage of natural disasters, played over loud, apocalyptic tracks. The group's last two conferences went on for more than 11 hours. Broadcast in dozens of languages, they have amassed thousands of views online. In these videos, the Creative Society promises to reveal ""the truth"" about the climate crisis. They offer testimonies from high-profile guests from around the world - all seemingly backing the group and its ideas. But several told BBC News they regretted participating. Some said they had been unaware of the group's views on climate change, others their interviews had been manipulated. ""I have been tricked,"" Dr Saleemul Huq, director of the International Centre for Climate Change and Development, in Bangladesh, said. Dr Huq has contributed to major reports by the Intergovernmental Panel on Climate Change, a UN body considered to set the gold standard for climate science. When Creative Society volunteers invited him for an interview, he simply ""didn't think very much about it"". He had been told the footage would be shown at an international conference, he said, but had not asked who the other contributors would be. And only after it aired, last year, did he realise something was amiss. ""I got a message from a couple of people saying, 'Do you know who these people are and what they believe in?'"" Dr Huq said. ""That's when I looked into it - and saw they were not what I had thought they were."" The Creative Society denies it deceived any of its guests. ""It was a certain lack of due diligence [from the guests],"" Mr Prudkov told BBC News. Information about the group and links to its website had been included in each invitation. ""We have been actively communicating about climate change for several years,"" he said. ""We always openly stated our position. ""Before any interview recording, we have a pre-call via Zoom where we explain what we are talking about and who the other participants are. ""We took the time to reach out to every contributor after the conferences aired, asking them to share their impressions."" BBC News has seen several of the invitations. They clearly identify climate change as one the topics of these conferences. But there is no mention of the group's views or denial of human-driven climate change. Dr Huq has asked the Creative Society to stop using his interview in online materials. In response, Mr Prudkov told BBC News, it would not include Dr Huq's footage ""in any future material"". And the interview has been removed from the group's website and most social-media accounts. Several others invited to contribute to Creative Society conferences last year told BBC News they had been unaware of the group's views on climate change when they had accepted an interview request. The office of Juraj Smatana, a State Secretary at Slovakia's Ministry of Environment, said his pre-recorded contribution had been ""manipulated"" to give the impression he agreed with the views presented at the conference. Mr Smatana is one of the ministry's highest ranking officials. It told BBC News legal action against the Creative Society was being considered. Other guests have also suggested their pre-recorded contributions were misrepresented. Portuguese Euro-MP Carlos Zorrinho said he had been ""urged several times"" during his interview to praise the work of the Creative Society. ""That did not please me,"" he told BBC News. Jeff Masters, a US meteorologist who studies extreme weather events, said: ""They were definitely selective about what I said. ""They did not include any of the parts where I talked about human-caused climate change."" The Creative Society denies accusations of manipulation or coaching. ""Media outlets edit the material to fit the time constraints and present the viewers with only the most essential information,"" Mr Prudkov said. And the group was promoting ""truthful information about the true causes"" of climate change. Anyone unhappy with their appearance on the videos should contact the society, which will ""accommodate their requests"", it says. But why would the group interview people it fundamentally disagrees with? It did not target anyone in particular and believed in allowing a platform for a wide spectrum of opinions, Mr Prudkov said. But some of the guests told BBC News its real intent was to gain credibility. ""They're drawing on the legitimate voices but then debunking what we are saying, in the overall impression that they are giving information,"" Dr Huq said. Mr Prudkov told BBC News ""thousands of people"" had been invited to Creative Society conferences. In online posts, volunteers can be seen handing invitations to Hollywood stars including Johnny Depp, Javier Bardem and Elijah Wood. None of them attended and there is no suggestion any back the group or its ideas - but it has allowed it to feature stars in its videos. Another conference is scheduled in May. The Creative Society calls itself as a ""project of all humanity"" that, Mr Prudkov said, was ""aiming to take our civilization out of this deadlock of self-destruction"". But its structure and finances are opaque. And while it claims to have no leaders, one man features prominently in the group's social-media posts. Igor Mikhailovich Danilov, a soft-spoken chiropractor, is also a leading figure in the AllatRa Ukrainian spiritual movement, whose members are among the founders of the Creative Society. Mr Prudkov told BBC News Mr Danilov described himself as a ""participant, a volunteer"" of the Creative Society. AllatRa is known for promoting pseudoscience and wild conspiracy theories involving aliens and secretive powerful elites that sacrifice children. In 2017, the Ukrainian Orthodox Church of the Kyiv Patriarchate warned against AllatRa's ""destructive activities"", describing it as an ""occult para-religious organisation"". Three years later, the Church's Chelyabinsk diocese, in west-central Russia, said it was concerned about what it considered a ""psychocult"". The AllatRa movement did not respond to BBC News requests for comment. It remains unclear how the Creative Society is funded but Mr Prudkov insists members are volunteers devoting their free time to the cause. ""We don't have any external funding,"" he said. ""This is all done by people themselves. ""There is no oil funding, or any other sources of income. ""We are not sponsored by any government or any institution."" With additional reporting from Ilona Hromliuk (BBC Ukrainian) Do you have a story for us? Get in touch."
How should you talk to friends and relatives who believe conspiracy theories?,"You're dreading the moment. As your uncle passes the roast potatoes, he casually mentions that a coronavirus vaccine will be used to inject microchips into our bodies to track us. Or maybe it's that point when a friend, after a couple of pints, starts talking about how Covid-19 ""doesn't exist"". Or when pudding is ruined as a long-lost cousin starts spinning lurid tales about QAnon and elite Satanists eating babies. The recent rules changes have upended holiday plans for many of us, but you still may find yourself grappling with such situations over the next few days - talking not about legitimate political questions and debates, but outlandish plots and fictions. So how do you talk to people about conspiracy theories without ruining Christmas? While it's important to confront falsehoods, it's never useful if things end up in a flaming row. ""My number one rule would be to not spoil Christmas,"" says Mick West, author of Escaping the Rabbit Hole. ""An angry, heated conversation will leave everyone feeling rubbish and further cement conspiracy beliefs."" Psychologist Jovan Byford, a lecturer at the Open University, notes that conspiracy theories often have a strong emotional dimension. ""They are not just about right and wrong,"" he says, ""but underpinned by feelings of resentment, anger and indignation over how the world works."" And they've boomed this year, with many searching for grand explanations for the pandemic, American politics, and huge world events. Catherine from the Isle of Wight understands that better than most. The 38-year-old used to be a big believer in conspiracies about vaccines being used to deliberately harm people. She's since rejected such claims. ""It is extremely important to remain calm at all times,"" she says. ""Whoever you're talking to is often just as passionate as you are about your own beliefs and will defend them to the grave."" And also remember - medical experts say shouting increases the chance of spreading coronavirus. Yet another reason to keep things low-key. ""Approach conversations with friends and family with empathy rather than ridicule,"" says Claire Wardle from First Draft, a not-for-profit which fights misinformation. ""Listen to what they have to say with patience."" Her golden rule is: never publicly shame someone for their views. That's likely to backfire. ""If you do decide to discuss conspiracy theories, don't be dismissive of the other person's beliefs,"" Jovan Byford agrees. ""Establish some common ground."" Remember that people often believe conspiracy theories because deep down, they're worried or anxious. Try to understand those feelings - particularly in a year like the one we've just had. People who believe conspiracy theories often say: ""I do my own research."" The problem is that their research tends to consist of watching fringe YouTube videos, following random people on Facebook, and cherry-picking evidence from biased Twitter accounts. But the spirit of doubt that pervades the conspiracy-minded internet is actually a key opening for rational thought, says Jovan Byford. ""Many people who believe in conspiracy theories see themselves as healthy sceptics and self-taught researchers into complex issues,"" he says. ""Present this as something that, in principle, you value and share. ""Your aim is not to make them less curious or sceptical, but to change what they are curious about, or sceptical of."" That's what helped Phil from Belfast. He used to be big into 9/11 conspiracies. ""I used to point out the fact that there were various experts who doubted official stories. This was very persuasive to me,"" he explains. ""Why would these experts lie?"" But then he began applying scepticism not to just ""official sources"" but also the alternative ""experts"" that was listening to. He developed a deeper understanding of the scientific method and scepticism itself. Just because one expert believes something, doesn't make it true. ""You can find experts and very intelligent people who lend credence to any position,"" he says. ""Focus on those who are pushing these ideas, and what they might be getting,"" says Claire Wardle. ""For instance, financial gain by selling health supplements, or reputational gain in building a following."" Fact-checking is important, but it's often not the right approach when someone passionately believes in conspiracies. Questions are much more effective than assertions, experts say. ""Focusing on the tactics and techniques used by people pushing disinformation is a more effective way of addressing these conversations than trying to debunk the information,"" Claire Wardle says. Think of general queries that encourage people to think about what they believe. For instance, are some of their beliefs contradictory? Do the details of the theory they're describing make much sense? Have they thought about the counter-evidence? ""By asking questions and getting people to realise the flaws, you ultimately get people to doubt their own confidence and open them up to hearing alternative views,"" says former conspiracy believer Phil. You might be hoping that a constructive conversation will end with some kind of epiphany over Christmas pudding - but don't bet on it. For those who have fallen deep down the conspiracy rabbit hole, getting out again can be a very long process. ""Be realistic about what you can achieve,"" psychologist Jovan Byford warns. ""Conspiracy theories instil in believers a sense of superiority. It's an important generator of self-esteem - which will make them resistant to change."" For fact-checker Claire Wardle, it's not just about bruised egos. This year has been scary - and for many, conspiracy theories have been a source of comfort. ""Recognise that everyone has had their lives turned upside down, and is seeking explanations,"" she says. ""Conspiracy theories tend to be simple, powerful stories that explain the world. Reality is complex and messy, which is harder for our brains to process."" But the experts agree that even if you don't see immediate results - don't give up. What did you think of this story? Email Marianna Subscribe to the BBC Trending podcast or follow us on Twitter @BBCtrending or Facebook."
How to spot false posts from Ukraine,"Russia's invasion of Ukraine has triggered a wave of falsehoods on social media and the airwaves. In a new Radio 4 podcast series, War on Truth, our specialist reporter follows the stories of people caught up by misinformation - and gives some tips about how to avoid it. Since the war began, my inbox has been flooded with messages from people telling me about misleading videos on their social media feeds and troll accounts promoting conspiracy theories. And it's not just on social media - it's also state-sponsored propaganda pushing false claims on air and beyond. In a new podcast series, I'll be reporting on the information battle being waged over Ukraine - and hearing from the ordinary people sucked into it. How can you spot bad information - and stop its spread? There are very real, distressing videos being shared of what's happening on the ground in Ukraine. But there is also footage from old conflicts going viral. Often people share it because they're shocked - or even trying to help. But it's just adding to the chaos for those in the country. The best way to figure out if a video is real or not is to look for clues - like the weather, the road signs, the languages people are speaking. Videos of Russia's invasion of Crimea and from the blast in Beirut in 2020 have been shared widely, pretending to be from the current conflict. Using Google Maps, you can figure out if the video is really from where it claims to be. And by using reverse image searches - available from a number of websites - you can see if that same video or image has been shared online before. That's a tell tale sign that it's been recycled from a previous event. It's important to examine who shared a post in the first place. Can you verify who they are - and are they a trusted source? Those who have posted misleading videos are sometimes looking for likes and shares. It's a distressing time - and posts about what's happening in Ukraine are likely to catch on. Others are sharing false claims to push certain narratives - to boost their political agendas or to sow doubt and confusion. Several young people in the country have told me about pro-Russia accounts which argue with Ukrainians, suggesting without any proof that the war is ""staged"" or Ukraine is bombing its own territory. One man I interviewed explained to me that even pictures of his home near Kyiv totally destroyed by bombs couldn't convince these trolls. Many of them have few or no followers, have taken their profile image from other places online and use generic usernames. They also only started to post after the invasion began. It's hard to tell who ultimately is running these accounts. Other accounts that have promoted false claims about the Covid pandemic have turned their attention to sharing false conspiracy theories about the war. The same false tropes - for instance that those injured by bombing are ""actors"" - have come up again and again, and have even been pushed by Russian diplomats. A lot of what's on social media about the war is frightening. It triggers a reaction - and that means people sometimes share posts before checking if they're real. Disinformation spreads because it plays on our emotions and our biases. It's not just about negative emotions - sometimes hopeful stories can also go viral. While they may boost morale, they contribute to the chaos online and make it harder to figure out what's actually happening. The information war is about more than social media. It's a battle fought by governments in both Ukraine and Russia, which are pushing out propaganda. Question why a particular source might be saying something - and whether it's backed up by evidence. Listen to War on Truth, from BBC Radio 4, out now on BBC Sounds."
How we verify social media posts from the war in Ukraine,nan
I Am Legend screenwriter dismisses anti-vax claims based on film's plot,"One of the writers of the sci-fi film I Am Legend has clarified its fictional nature amid rumours Covid-19 vaccines would turn people into zombies. The 2007 film, starring Will Smith, is about a failed attempt to genetically re-engineer measles to cure cancer, killing 99% of the world's population. Those who survive the infection turn into mutant vampiric creatures. Claims that something similar would happen to people receiving Covid jabs have been circulating on social media. Last week, the New York Times reported that the owner of an eyewear store in the Bronx, New York, was struggling to persuade some of its staff to get a Covid vaccine, with one citing the plot of I Am Legend as a concern. ""One employee said she was concerned because she thought a vaccine had caused the characters in the film I Am Legend to turn into zombies,"" the report said. Responding to the article, Akiva Goldsman, 59, who co-wrote the screenplay based on a 1954 novel of the same name, tweeted: ""Oh. My. God. It's a movie. I made that up. It's. Not. Real."" Baseless posts and memes which cite the film as a reason not to get vaccinated against Covid have appeared on social media platforms for months, with some being labelled by Facebook as containing misinformation. One meme claims in the film vaccinations cause humans to turn into zombies, both misrepresenting the plot and the fictional nature of the film. Another meme claims the film was set in 2021, which would correspond to the pandemic and the global vaccination rollout - despite the fact the plot was actually set in 2012. I Am Legend is not the only film used by activists to spread misinformation about Covid and vaccines. Other films such as Children of Men and The Matrix have appeared in similar memes and posts."
I get abuse and threats online - why can't it be stopped?,"Online abuse against women is on the rise, but why aren't the police, the government and social media companies doing more to stop it? Warning: Story contains strong language I'm the BBC's first specialist disinformation reporter - and I receive abusive messages on social media daily. Most are too offensive to share unedited. The trigger? My coverage of the impact of online conspiracies and fake news. I expect to be challenged and criticised - but misogynistic hate directed at me has become a very regular occurrence. Messages are laden with slurs based on gender, and references to rape, beheading and sexual acts. Some are a mish-mash of conspiracy theories - that I'm ""Zionist-controlled"", that I, myself, am responsible for raping babies. The C-word and F-word are repeatedly used. It's not just me - from politicians around the world and Love Island stars to frontline doctors, I've been hearing from women subjected to the same kind of hate. New research, shared with the BBC, suggests women are more likely to receive this sort of abuse than men, it's getting worse - and it's often combined with racism and homophobia. I wanted to understand why this is happening, the threat it poses - and why social media sites, the police and the government aren't doing more about it. So, I set out to make a film for the BBC's Panorama programme. We set up a fake troll account across the five most popular social media platforms to see whether they are promoting misogynistic hate to such users. Using an AI-generated photograph, we designed our fake troll to be similar to the people who sent me abuse. Our troll engaged with content recommended by the social media platforms, but did not send out any hate. As part of the programme, think-tank Demos carried out a comprehensive deep dive into abuse received by reality TV contestants, analysing more than 90,000 posts and comments about them. It was perhaps a surprising place to start, but programmes like Love Island serve almost as a microcosm for society, allowing researchers to compare the abuse directed at men and women from different backgrounds. Their popularity also generates a lot of online conversation. We discovered: Social media companies say they take online hate against women seriously - and they have rules to protect users from abuse. These include suspending, restricting or even shutting down accounts sending hate. But my experience suggests they often don't. I reported some of the worst messages I've ever received - including threats to come to my house to rape me and commit horrific sexual acts - to Facebook when I received them. But months later, the account remained on Facebook, along with dozens of other Instagram and Twitter accounts sending me abuse. It turns out my experience is part of a pattern. New research for this programme by the Centre for Countering Digital Hate, shows how 97% of 330 accounts sending misogynistic abuse on Twitter and Instagram remained on the site after being reported. Twitter and Instagram say they take action when their rules are violated, and closing accounts isn't the only option. Find out more Watch Marianna Spring's Panorama - Online abuse: Why Do You Hate Me? on the BBC iPlayer (UK only) Curious about who was running accounts sending me - and other women - abuse, I started by looking into the profiles targeting me. Most were men and based in the UK. Everything from calling me a ""daft cow"" and telling me I needed to ""get laid"" to threatening to come and find me and violently or sexually attack me, they bombard me with gender-based slurs again and again. It turns out, they are real people - not bots. One is a Spurs fan, like me. Another likes vegan cooking. One, whose account was anonymous, even gave away his location by tweeting at delivery service Ocado complaining it didn't deliver to his postcode in Great Yarmouth. I reached out to them - and one called Steve, a van driver in his 60s from the Midlands, agreed to speak to me on the phone. The messages he'd sent me were less offensive than most of the abuse I receive - mainly gender-based slurs. Like lots of account holders who sent me hate, he is deep into online conspiracy theories. But like others, the abuse he sent me also attacked me for being a woman. At first he told me he didn't think his messages were that bad - but I explained they were just some of many punctuated with abuse streaming into my inbox. ""I probably made a mistake. I'm a pretty fair bloke,"" he eventually concluded. He pointed out that he actually receives hate himself online from ""people who believe in global warming and that 9/11 happened"". They are responding to conspiracy theories that he shares on social media. I had hoped this might help him see why hate wasn't the answer. And I think by the end of our conversation he was coming around to the idea. Our conversation got me thinking about what my trolls might be seeing on their social media feeds. I wanted to see whether social media algorithms are pushing more misogyny to accounts similar to those that abuse women online. So I created a fake online persona called Barry and signed him up to the five most popular social media platforms in the UK. All the main social media companies say they don't promote hate on their platforms and take action to stop it. They each have algorithms that offer us content based on things we've posted, liked or watched in the past. But it's difficult to know what they push to each user. ""One of the only?ways to do this is to manually create a profile and seeing the kind of rabbit hole that it might be?led?down by the?platform itself, once you start to follow certain groups or pages,"" explains social media expert Chloe Colliver, who advised me on the experiment. She works for the Institute for Strategic Dialogue, looking into extremism and disinformation on social media. She has helped journalists before, and advises me on how I can set up the profiles in an ethical and realistic way - only doing what's necessary to test the algorithms. Barry's accounts were based on multiple accounts that had sent me abuse. Like my trolls, Barry was mainly interested in anti-vax content and conspiracy theories, and followed a small amount of anti-women content.  He also posted some abuse on his profile - so that the algorithms could detect from the start he had an account that used abusive language about women.  But unlike my trolls, he didn't message any women directly. Over two weeks, I logged in every couple of days and followed recommendations, posted to Barry's profiles, liked posts and watched videos. After just a week, the top recommended pages to follow on both Facebook and Instagram were almost all misogynistic. By the end of the experiment, Barry was pushed more and more anti-women content by these sites - a dramatic increase from when the account had been created. Some of this content involved sexual violence, sharing disturbing memes about sex acts, and content condoning rape, harassment and gendered violence. They also referenced extreme ideologies. That included the ""incel"" movement - an internet?subculture that encourages men to blame women for problems in their lives. It's been linked to several acts of violence, including recent shootings in Plymouth, in the UK. ""If it were a real person, [Barry] would have been brought into a hateful community full of misogynistic content very, very quickly - within two weeks,"" says Colliver. Far from stopping Barry engaging with anti-women content, Facebook and Instagram appear to have promoted it to him. By contrast, there was no anti-women content on TikTok and very little on Twitter.  YouTube suggested some videos hostile to women. Facebook, which also owns Instagram, says it tries not to recommend content that breaks its rules and is improving its technology ""to find and remove abuse more quickly"". YouTube says it has ""strict policies"" on hate and ""quickly"" removes content that breaks its rules. That wasn't the only thing in the experiment that struck me. Barry's main interest was originally conspiracy theories and I had expected him to be inundated with that sort of content at the start. But he wasn't. Social media sites have come under increasing pressure not to promote misleading information about vaccines and the pandemic. But why hasn't that happened with misogynistic content on Facebook and Instagram? ""They are driving up their bottom line by keeping people's interest in horrible, violent, often misogynistic content,"" says Colliver. Nearly three billion people worldwide use Facebook - and last year it made on average $32 (Â£23) in advertising revenue per user. The longer people stay on the platform, the more ads it sells and the more money the tech giant makes. Facebook says ""protecting"" its community is ""more important than maximising profits"". It has announced new measures to tackle sexualised hate targeting journalists, politicians and celebrities on its sites. For Panorama, researchers from think-tank Demos analysed messages of abuse directed at reality TV contestants on Love Island (ITV) and Married at First Sight (Channel 4). They found that female reality TV contestants are disproportionately targeted on social media with abuse frequently rooted in misogyny and combined with racism. While the contestants received mostly positive messages, fashion blogger Kaz Kamwi, 26, and 23-year-old medical student Priya Gopaldas, told Panorama they also got some disturbing hate-filled messages. ""The most difficult abuse to receive is any that is racially motivated. When you look at me, I am a dark skinned black woman, that's the first thing you see,"" says Kaz. ""And the fact that my family was exposed to that breaks my heart."" Ellen Judson, who led the research for Demos and focuses on social media policy, says reality TV is a great place to start looking at online hate because the genre is so popular with people expressing who they like or don't like. ""We also see that the contestants are a relatively equal mix of men and women - and from lots of different backgrounds - so it gives us an opportunity to analyse those differences in how the public are responding to them."" Demos looked at more than 90,000 online messages about Love Island and Married at First Sight contestants: ""People were using explicitly gendered slurs - women being manipulative, women being sneaky, being sexual, women being evil or stupid. Whereas what we saw with men was them being attacked for seemingly not being masculine enough - for being too weak,"" says Judson. ""We also see that women of colour are receiving more pernicious attacks as well based on their race."" I wanted to see what impact this kind of abuse is having, so I spoke to politicians and frontline doctors who use social media to do their jobs. Like me they don't mind being criticised but they do mind when it gets personal. Former leader of the Scottish Conservatives Ruth Davidson fears that abuse targeting women online could turn back the clock when it comes to equality offline. ""The attacks that have come directly to me have been about my politics, some about my physical appearance, a lot has been about the fact that I am gay and a lot of it has been about the fact that I am a woman who has opinions."" There's also concern that online abuse could lead to real world harm. ""You look at your phone and you read somebody who is telling you as an NHS doctor that they want to rape you until you need one of your own ventilators,"" explains Dr Rachel Clarke, a frontline medic based in Oxford. She's been treating Covid patients during the pandemic and sees using social media as an extension of her duty as a doctor. That means she has frequently posted warnings about the impact of coronavirus - and encouraged her followers to have a Covid vaccine. It's those tweets in particular that often sparked a wave of misogynistic hate from anti-vaccine activists, not dissimilar to the accounts sending me hate. ""Male doctors that I know will receive abuse online as well. But the volume of abuse is much less. If you're a female doctor, it'll be much more visceral, and it will target you as a woman."" I've been taking part in a major piece of research for the UN's cultural agency Unesco - which looks at the impact of online hate. Lead researcher Julie Posetti and her team asked more than 800 women, journalists like me, about their experiences of online hate. They then studied some of the accounts, including mine and that of Nobel Peace Prize winner, Maria Ressa. She's an investigative journalist from the Philippines who gets lots of online abuse and says she wears a bullet-proof vest because she fears being attacked. ""Online violence is really the new frontier of conflict that women face internationally,"" Posetti tells me. Twenty per cent of women who responded to the UN's survey, in collaboration with the International Center for Journalists (ICFJ), said they had already experienced attacks in real-life, including stalking and physical assault. I'm especially worried about some of the hate I receive online, including from a man who appears to have a prior conviction for stalking women. But I've been left frustrated at the police response. After a wave of abuse at the end of April this year, I reported the most serious threats to the police, including about sexual violence. It's a criminal offence to send messages online that are grossly offensive or obscene in order to cause distress. An officer got in touch initially and I shared my evidence of the abuse - but I only heard back from her weeks later when she told me that she was moving teams, my case was being passed on and there had been no progress. I wasn't contacted by a new liaison officer until July - when it became clear that the evidence I'd shared originally with the police had been lost, something that was later admitted. I tried to report another batch of rape threats, death threats and abusive messages at the end of July to the new officer. When we met in person in the middle of August, the officer admitted he was not the right person to handle the case - and that it should have been passed on to a specialist team. Yet more delays - and although the seriousness of the messages was acknowledged, there was little in the way of victim support. By the end of August, I was on to my third police liaison officer - who asked me to review the portfolio of evidence I had already sent in, marking which messages were from Twitter, Instagram and Facebook as he wasn't sure how to use the platforms. My latest liaison officer has requested more information from the social media sites - but still no progress. According to data from several police forces, which Panorama obtained through Freedom of Information requests, over the past five years the number of people reporting online hate has more than doubled. But over the same period, there's only been a 32% increase in the number of arrests. The victims are mainly women. This is happening in the context of increasing pressure on the Met in particular to do more to tackle violence against women on our streets after the killings of Sarah Everard and Sabina Nessa. I raised concerns that people sending me abuse might turn up at my work - but I was just told to call 999 if I felt in danger. The Metropolitan Police say they take online hate very seriously and that my case is under active investigation. The National Police Chiefs Council says the police take all reports of malicious communications seriously and will investigate but must prioritise its finite resources. It says it can take action other than making arrests. Draft proposals from the UN to get the social media companies to better protect women have been shared exclusively with Panorama. They are calling for social media platforms to introduce labels for accounts that have previously sent misogynistic abuse.  They also want to see more human moderators taking the decisions about offensive material - and an early warning system for users if they think online abuse could escalate into real world harm. ""We would like to see gender-based online violence treated at least as seriously as disinformation has been during the pandemic by the platforms,"" explains Julie Posetti, who led the research that triggered these recommendations. ""I think we have to challenge,"" says Ruth Davidson. ""I don't think that it is in anybody's interests for women who are consistently abused in a way that a man wouldn't be to let other young women who are online and seeing that abuse think that's just the way things are."" For women of all ages - myself included - that means refusing to be bullied off social media."
India Covid-19: Misleading claims shared about vaccines,"India started its Covid vaccination programme on 16 January, and in the days before and since then, various claims about vaccines have been doing the rounds on social media. The government has urged people to have the vaccines, and to ignore ""rumours and disinformation"". Here's the truth behind some widely-shared claims. A politician from the northern state of Uttar Pradesh recently claimed this - but offered no evidence at all. Ashutosh Sinha, of the opposition Samajwadi Party, has said: ""I think the vaccine may contain something which can cause harm. You can become impotent, anything can happen."" The party's leader, Akhilesh Yadav, has previously cast doubt about the jabs, describing them as the ""BJP vaccine"" - a reference to India's ruling party. But there is no proof that vaccines make you impotent, and these claims have been dubbed ""absolute rubbish"" by India's top drugs regulator. It has said that the vaccines are safe, although they may cause some side effects such as mild fever, and aches and pains. The country's Health Minister Dr Harsh Vardhan has also refuted the claim. This is not the first time impotency rumours have circulated around a vaccine programme in India. When the country was conducting its massive polio eradication drive several decades ago, some Indians were dissuaded from having a vaccine because of similar rumours. There was no truth to the claims then, and there's no evidence for them now either. Another widely-shared, but inaccurate, claim compares India favourably with both the the US and England, saying that the vaccine is free in India, while in both the US and in England you will pay. One Twitter user posted that the US vaccine would cost 5,000 rupees (Â£50; $69) and in England it would cost 3,000 rupees, apparently to show India's vaccine programme in a more favourable light compared with those in the US and England. This was picked up and tweeted by a Hindi-language TV channel, ABP News, but then taken down. The figures are not at all accurate. The US federal government has said that Covid vaccines will be free, although there may be a charge for administering the jab. But many Americans would be able to cover this charge through various health insurance schemes, and those without insurance would be covered by a special Covid relief fund. So they will not need to pay. It's also incorrect about England, which is part of the UK's National Health Service, where there are no charges for vaccines. The service is funded through taxation, and healthcare is free to the patient. It's true that in its initial phase (which covers health workers and frontline staff), India's vaccination programme will be free of charge for those getting the jabs.  The government has yet to clarify what happens after that. The Indian government has made special arrangements with vaccine suppliers to bring prices down, at least for the initial consignments. Some Islamic scholars in India have said that no Muslim should have Covid vaccines, claiming that they could contain pork products. But neither of the two vaccines being rolled out in India has such products in them. Pork gelatine has sometimes been used as a stabiliser in vaccines for some diseases - and the consumption of pork products is forbidden in Islam. The issue gained a lot of traction on Twitter after a widely-shared post advising Muslims that Covid vaccines were not certified as ""halal"" (conforms to Islamic law) - although it didn't specify which particular vaccines. There's currently only two vaccines which have been granted approval in India - Covishield (the local name for the Oxford-AstraZeneca vaccine developed in the UK) and Covaxin, locally made by Bharat Biotech. Neither uses pork gelatine. Two other major Covid vaccines, produced by Pfizer and Moderna, are similarly free of pork gelatine. Some of the claims about vaccine ingredients refer to ones made by Chinese companies, but currently there is no Chinese vaccine approved for use in India. There have been controversies over Chinese vaccines in other countries, for example in Muslim-majority Indonesia where the local Islamic authorities decided the Chinese-produced Sinovac vaccine was allowed. As in other parts of the world, conspiracy theories falsely claiming that the vaccines contain microchips have been doing the rounds on Indian social media. One short video shows a Muslim cleric saying that the vaccine has a chip in it which will control your mind. The video went viral on Facebook and Twitter earlier this month. Microchips aren't part of any vaccines, although this claim has cropped up repeatedly in conspiracy-minded groups around the world. Read more from Reality Check Send us your questions"
Ipob: Nigerian 'media warriors' call for killings on social media over Biafra,"A network of Nigerian separatists based outside the country is using social media to call for violence and incite ethnic hatred against opponents of Biafran independence, a BBC investigation has found. Warning: This article contains graphic descriptions of violence In a Facebook live broadcast to her more than 40,000 followers, Efe Uwanogho, also known as Omote Biafra, shouts hate speech directly into the camera. The front of her leather jacket features a patch of the Biafran flag, with its red, black and green tricolour and half a rising sun. ""Go after these mighty saboteursÂ Those are the people that need to be beheaded. Those are the people that need to be burnt to ashes,"" she says. She's calling for attacks against those considered enemies of the campaign for Biafran independence, which would create a breakaway state in south-east Nigeria. The campaign has a bloody history. In 1967 separatists from the mainly Igbo region declared independence for the Republic of Biafra. They fought and lost a three-year civil war against the Nigerian government in which more than a million died, mainly on the separatist side. More than half a century later, social media is a new frontline for those who are continuing the struggle. Ms Uwanogho is among them. She's a so-called ""media warrior"" for the separatist group known as the Indigenous People of Biafra (Ipob). She broadcasts from Italy, beyond the reach of Nigerian authorities. In Nigeria, Ipob has been banned and designated a terror group. Ipob insists it is a peaceful movement. The BBC's investigation revealed many other influential Ipob supporters also operating outside the country, openly promoting disinformation and inciting violence on social media from across Europe, the US, Asia and other parts of Africa. Nigerian investigative journalist Nicholas Ibekwe describes the group's online operation as an ""organised troll farm"". ""Social media has been Ipob's most successful tool in achieving most of what it wants to achieve today,"" he says. Some supporters of the group have as many as 100,000 followers on social media. We don't know if any of Ms Uwanogho's followers took action based on her online calls for violence against officials in south-eastern Nigeria. Ms Uwanogho did not respond to a request for comment on this story. But on the ground, the violence is real, with dozens of officials killed in attacks already this year in violence described by President Muhammadu Buhari as ""deeply distressing"". Nneka Igwenagu is another ""media warrior"" fighting for the Biafran cause, based in the UK. In a Facebook live broadcast from London in late 2021, she targets a youth group in Anambra, south-east Nigeria, which had been resisting pressure from Ipob for people in the region to shut down businesses and schools in solidarity with the group's detained leader Nnamdi Kanu. Mr Kanu is currently being held by Nigerian authorities and faces terror charges, which he denies. Speaking in Igbo, the most widely spoken language in south-eastern Nigeria, Ms Igwenagu refers to them as ""chickens"", saying: ""All of you are not supposed to be aliveÂ A chicken that ate its eggs, don't you see it is not supposed to live?"" A few weeks after the broadcast, the leader of the youth group she was referring to was shot and killed. Nobody has been charged over his death. We contacted Ms Igwenagu for a comment on this investigation, but received no response. One of the ways the media warriors attempt to avoid censorship is to switch into local languages that are less well moderated. This tactic is made explicit in one video we found. Okenna Okechukwu, also known as Biafran Child, speaks in Igbo when calling for the beheading of a critic, before switching to English and explaining to his followers: ""Why I am saying this in my dialect is because I don't want them to stop me. I don't want them to block me on this page."" David Ajikobi, Nigeria editor of fact-checking organisation Africa Check, says that the lack of moderation of extreme content in local languages is a major issue, not limited to Nigeria. ""We've also seen this in India, in Ethiopia, where crises are happening, people are using local language because they know that if they use English they will be flagged and will be removed from the platform."" Despite the violent nature of many of the online posts we found, moderation by social media platforms is inconsistent. In line with Facebook's own process, our team reported broadcasts by Efe Uwanogho and Nneka Igwenagu for containing violent content. We initially received a notification that the platform had decided not to take the videos down. It was only later, when the BBC shared links to the posts directly with Facebook that they were removed. But violent broadcasts from the same accounts, as well as others, remained online at the time of publication. Facebook's parent company Meta told us in a statement that calling for violence on its platform was unacceptable. It said that it had 15,000 people reviewing content in more than 70 languages - including Igbo. Our investigation also found Ipob supporters spreading disinformation to stoke tension between different ethnic groups in Nigeria. Media warriors pit ethnic Igbo people, who are mainly Christian and from the south, against those from the Fulani ethnic group, who are predominantly Muslim and from the north. In another Facebook live broadcast, Ms Igwenagu warns her followers that Fulani herders and other northerners who have moved to ""Biafraland"" are on a ""missionÂ to exterminate, kill maim, wipe [out] all of us"". Although there have been clashes between Fulani herders and communities in the south-east, there is no evidence of the sort of conspiracy that Ms Igwenagu and others are alleging. This violent rhetoric may be driven by a desire for Biafran independence, but our investigation also found evidence of financial incentives for those involved. We found videos in which media warriors admitted to being paid, either by Ipob or by supporters, for the work they do and we saw other broadcasts in which bank details for Ipob were shared to solicit donations from followers. Journalist Nicholas Ibekwe is among those who are critical of social media companies to tackle the violent threats being made on their platforms. ""It seems Facebook has really really gone to sleep. It does not think that these comments, these posts that they do on Facebook have consequences."" Meanwhile, attacks continue on the ground. On 30 April, Nigerian soldiers Audu Linus and Gloria Matthew were on their way to get married in a traditional ceremony in Imo state when they were abducted, tortured and killed by unidentified attackers. Footage showing the couple's killing, which the Nigerian president has blamed on Ipob, then went viral. A conspiracy theory was then widely shared by some Ipob supporters claiming that the footage was not real and the soldiers' deaths had been staged. The BBC has independently confirmed the deaths of the two soldiers with family members. Ipob has denied any involvement in the killing. We contacted Ipob's leadership with our findings from this investigation. The leadership replied, but did not provide a response. We contacted all of the media warriors featured in this story to ask for their comments, but had no response."
Iran accused of sowing Israel discontent with fake Jewish Facebook group,"A suspected Iranian disinformation unit ran an elaborate network on Facebook targeting nationalist and ultra-religious Jews in Israel in an attempt to stoke division and inflame tensions with Palestinians, according to research shared exclusively with the BBC. The alleged foreign interference campaign ran across multiple social media platforms posing as an ultra-Orthodox Jewish news group supportive of extreme right-wing groups. Its goal was to help fuel ""religious war"" by amplifying ""fear, hatred and chaos"", according to the Israeli disinformation watchdog FakeReporter, which uncovered the group's suspected Iranian origin. It is the latest sign of a growing disinformation battleground on social media and messaging apps in Israel. The network became active after last year's flare-up in sectarian violence in the country. In one case, the network reposted a video of a confrontation between a far-right MP, who was carrying a gun, and a Palestinian car parking attendant, adding the comment: ""It's a shame he didn't give him one in the head."" Facebook and Twitter deactivated the group's pages and associated profiles after being approached by FakeReporter. The network remains active on the messaging channel Telegram. Facebook says the accounts were part of attempts to reappear after it took down ""a small Iranian influence operation"" last March. The company sees Iran-based groups as persistent and well-resourced in trying to exploit social media platforms. The BBC approached the groups' administrator pages, asking their location and why they used copied content but they did not respond. The Iranian embassy in London did not respond to requests for comment. The ""Aduk"" - or ""strictly religious"" - group was created as a Hebrew acronym of ""Virtual religious union for the religious community"". It recirculated articles and posts supporting far-right politicians, encouraged protests and cultivated anti-government and anti-Arab sentiment. One of its profiles gathered thousands of followers. ""We see this network rise up following the events in May, when Israel was at one of the lowest points in its history in the relations between Jewish and Arab citizens,"" says FakeReporter chief executive Achiya Schatz. An Israeli security source said the online profiles had similar characteristics to Iranian activity that previously took place on the platforms. The network went to extensive lengths to look genuine, creating a page for a fictitious bakery in an ultra-Orthodox Israeli town, and in another case stealing the online identity of an ultra-religious Jewish man from Russia who died four years ago. On learning of the fake profiles his sister told the BBC that the social media platforms should be shut down (read her story below). ""It's something that we haven't seen before, creating such a backstory,"" says Mr Schatz. ""It's another concern because these networks are becoming more and more developed, to see them connecting with such extremists and violent groups... they're very fluent in Israeli politics,"" he adds. The group repeatedly backed an ultra-nationalist Israeli MP, Itamar Ben Gvir, a follower of an outlawed, racist movement which called for the expulsion of Arabs from Israel. Other posts by the suspected Iran-based network and its administrators included: Analysts draw comparisons with previous foreign interference campaigns designed to destabilise and amplify divisions in the US and Europe. When Olga Veshueva got a message from her brother Reuven she broke into a broad smile as she clicked open the photo. It was a picture of him wearing the expensive hat he had saved for weeks to buy. He had planned to wear it proudly among friends at the Jewish religious seminary he attended in St Petersburg. But that moment in 2017 is now a tragic memory for Olga. A few days later, Reuven, still in his 20s, died suddenly of heart failure. Olga cherishes the picture - the last one of Reuven ever taken. She could not have predicted the bitter blow that would come four years later. Without the family's knowledge, the picture and others were taken from Reuven's social media profile - copied by disinformation operatives believed to be in Iran to become the online face of a man calling himself ""Ariel Levi"", the administrator of the ""Aduk"" news network. Reuven's stolen identity has now appeared to thousands of Israeli social media users in posts on the group supporting extreme right-wing politicians and inflaming tensions between Jews and Arabs. Olga wept when she saw how her brother's photos had been used for the false persona on Facebook for the last eight months. ""He left his mark as a kind, gentle person. He was the greatest brother, a loving person,"" she told the BBC, speaking from her home in Kazakhstan. ""But what can I do? I have no power. All these social networks should be shut down,"" she added. Some young ultra-Orthodox Israelis may be more vulnerable to foreign interference due to low ""digital literacy"", suggests Tehilla Shwartz Altshuler of the Israel Democracy Institute think tank, who says many more are now experiencing the internet for the first time. ""This community is very conservative and doesn't have the experience of 70 years of TV,"" she says. ""Any resentfulness towards Israeli society, or far-right extremism, or anti-Arab, anti-Muslim feeling [can be exploited]. This kind of community is not prepared to cope with fake news or digital manipulation."" The ""Aduk"" network used a scattered approach to try to gain traction. Pages on some platforms were barely active and many posts gained few comments. However, the Facebook page for ""Aduk"" administrator ""Ariel Levi"" had almost 3,000 friends. This foreign interference pattern has been seen in other countries, says Simin Kargar, a non-resident fellow at the Atlantic Council's Digital Forensic Research Lab. She suggests Iran benefits from its opponents observing the disinformation campaigns themselves. ""Since the presidential elections in the US we've seen Iranian tactics getting more diverse, part of a broader and more complicated playbook... They see they're being noticed and feared,"" she says. Erez Kreimer, former head of the cyber division at Israel's Shin Bet domestic security agency, describes the ""Aduk"" network as ""unprofessional but efficient"", adding that Iran sees Israel as ""a prime target in its cyber efforts"". The case is the latest in a broader series of alleged interventions in Israel. Last month, security agencies made several arrests and the government warned about Iranian attempts to lure ordinary Israelis into low-level spying. Since late 2020, at least five cases have come to light of suspected Iranian interference on messaging apps to infiltrate and foster anti-government protests in Israel. Ms Kargar at the Atlantic Council links the attempts to the Middle East's wider shadow war, pointing to the assassination of Iran's chief nuclear scientist and mysterious explosions at its nuclear facilities. Many have attributed them to Israel, but it has never acknowledged any involvement. ""For Iran, a way of getting back at Israel is doing these more subversive campaigns or cyberattacks in order to show they're not staying silent and they're also doing things to mitigate the threat,"" she says. ""But obviously at a lower cost because the bar for entry is much lower in this [cyber] space."" Tehilla Shwartz Altshuler of the Israel Democracy Institute describes this as a cheap form of foreign intervention. ""It costs more to send missiles to Lebanon than digital bytes [to Israel],"" she says. Meanwhile, FakeReporter's researchers are calling for more robust monitoring by social media platforms. Mr Schatz says: ""We need to understand that if countries and the social networks, the big techs, won't step forward and increase security and defend the rights of users online, we are going to see more infiltration of politics and distrust between people."" Facebook's parent company, Meta, says its actions against alleged Iranian foreign intervention have ""slowed this campaign down each time and helped to keep them from rebuilding their audience on our platform"". ""Given the adversarial nature of this space and knowing that these malicious actors will always try to come back, we'll stay vigilant and take action as necessary."" A spokesman for Twitter says: ""The accounts referenced were permanently suspended for violating our platform manipulation and spam policy"". Telegram did not respond to requests for comment."
Iran's presidential election: Four claims fact-checked,"Iranians will choose a new president on Friday, after three years of economic hardship under reimposed US sanctions and two government crackdowns on nationwide protests. After a selection process that saw many would-be candidates disqualified, seven approved candidates held three televised debates. The man regarded as the favourite is hard-line cleric Ebrahim Raisi, head of Iran's judiciary. We've looked at some claims made about his record, and others. Two candidates - moderate Abdolnaser Hemmati, a former central bank governor, and reformist former vice-president Mohsen Mehralizadeh (who dropped out on Wednesday)  - claimed Mr Raisi had: Mr Raisi replied no website or newspaper had been blocked or shut down since he had become judiciary chief, in March 2019. But the encrypted messaging and voice-call app Signal, known for its high security, was blocked in January, after a huge surge in downloads by Iranian users. And Seda, a moderate weekly, was shut down in May 2019, after publishing an image of a US warship on its front cover and running an editorial about rising tensions between Tehran and Washington. Mr Raisi has been ""behind many moves that have tightened the space of online freedoms in Iran"", Mahsa Alimardani, a researcher at the Oxford Internet Institute, said. ""His judiciary has been behind arrests of administrators of Telegram channels and Instagram users who post content about the rights of minorities, LGBTQ rights, or activism about mandatory hijab,"" she added. The judiciary under Mr Raisi has also pursued the possibility of blocking or limiting access to Instagram, one of the only major social-media platforms still available to Iranians, according to Factnameh, an Iranian fact-checking service based outside the country. Mr Raisi also came in for criticism over the fate of those arrested when an increase in petrol prices sparked protests in towns and cities across Iran, in November 2019. The unrest prompted a bloody crackdown by the security forces. Amnesty International said more than 304 people had been killed, while a Reuters news agency report put the death toll at 1,500. But the Iranian authorities dismissed both figures. Official figures have not been released but the spokesman for the Iranian parliament's national security committee said, at the time, about 7,000 had been arrested. And in the final debate, Mr Mehralizadeh challenged Mr Raisi to ask Iran's Supreme Leader, Ayatollah Ali Khamenei, to pardon the remaining detainees. Mr Raisi replied most ""have been pardoned by the supreme leader, except those who had relations with other countries or had a special issue"". But he gave no figures and it is unclear whether he was referring to the protesters arrested and then freed or those who went on to face criminal proceedings. Mr Raisi also claimed the judiciary had temporarily released tens of thousands of prisoners, to reduce Covid transmission in prisons, adding: ""Nowhere else in the world has this been done."" But India, Indonesia, Turkey and Iraq have also granted temporary release to prisoners during the pandemic. Amnesty International says some of the Iranian protesters arrested have been granted pardons or temporary releases in the past year ""But the authorities have not provided any specific information about the number of people who remain detained... the charges they face or the status of their cases,"" according to Amnesty. Last September, the human rights organisation said it had recorded the names and details of more than 500 protesters subjected to criminal investigations following the unrest. Also in the final debate, Mr Mehralizadeh said Mr Raisi's campaign had held a large rally, on 9 June, with no social distancing or masks, in the city of Ahvaz, to ""show off"". Mr Raisi replied the gathering had received a relevant permit and followed official Covid protocols. But after the debate, the body in charge of Iran's Covid response released a statement saying: Hard-line candidate Mohsen Rezaei, a former Revolutionary Guards chief, said Mr Hemmati had so devalued the Iranian currency, the rial, that ""the train of the revolution has turned into a scooter"". Another candidate, hard-line MP Alireza Zakani, who dropped out in favour of Mr Raisi on Wednesday, accused Mr Hemmati of ""destroying the national currency"". But the rial has lost its value at various points during the past few years. And by July 2018, when Mr Hemmati became central-bank governor, its value against the US dollar was already plummeting. ""Iran's currency had already begun to shed value because goods imports were becoming more expensive and a lot of export revenue was getting suppressed,"" Esfandyar Batmanghelidj, of the European Council on Foreign Relations, said. And Mr Hemmati ""set up a centralised system for the country's currency market, making the purchase of foreign currency more reliable and transparent for Iranian companies"". The election of President Joe Biden also gave some hope US sanctions might be eased as part of efforts to revive the 2015 Iranian nuclear deal. But the value of the currency, also affected by the coronavirus pandemic and oil-price fluctuations, still remains far below its level of three years ago. Reporting by Jack Goodman, Christopher Giles and Shayan Sardarizadeh Read more from Reality Check"
Is this anti-vaccine conspiracy theorist the next Alex Jones?,"A film promoting an anti-vaccine conspiracy theory has been accused of helping to drive the harassment of bereaved families. In a rare interview with the BBC, the man behind it says he is ""happy"" about its influence - and believes the people responsible for Covid vaccinations should be executed. We met the film's creator, Stew Peters, in a warehouse he had rented for the occasion, on an industrial estate in Vero Beach, Florida. His crew had set up a makeshift studio and were filming us as we filmed him - to get their own message out. Mr Peters is a former bounty hunter and rapper from Minnesota who built an influential podcast and social media network through the pandemic. His film, called Died Suddenly, portrays a striking but false narrative - claiming that swathes of people are suddenly and suspiciously dropping dead in large numbers, and that Covid vaccines are to blame. The film misuses images and manipulates data to paint a persuasive picture that the vaccines are very unsafe - contrary to vast amounts of scientific research. We asked Mr Peters about the fabricated evidence within the film, including clips of blood clots and birth defects which the BBC and other researchers have traced back to medical training materials pre-dating the pandemic. But he refused to answer direct questions. ""This is an attempt to try to discredit me or the film rather than talking about the millions of people that are dying,"" he told us, going on to describe Covid vaccines as a ""bio-weaponÂ[that's] killed unprecedented, record-smashing numbers of people"". These are huge claims and so they need strong evidence to back them up - but the weight of scientific evidence is against such claims. There have been rare cases of serious Covid-19 vaccine side effects including deaths, which deserve careful investigation. But on a population level, vast amounts of data from different teams of independent scientists around the world suggest that overall, the vaccines have saved millions of lives. We asked Mr Peters why he'd included examples of people supposedly ""dying suddenly"" from Covid vaccines which were easy to disprove - including clips filmed before the pandemic or before the vaccines were available. ""I'm on a very specific mission, and that is to expose lies that are killing people,"" was his response. While the film might contradict the best evidence we have, it's super-charged a trend. Now online trolls use the keywords ""died suddenly"" to search for stories of personal tragedies and link them without evidence to Covid vaccines, often bombarding family members with unpleasant messages in the process. Look at virtually any announcement of a sudden celebrity death online and you'll now see strange messages appearing underneath, linking their passing to Covid vaccines and often using the hashtag #DiedSuddenly. You can listen to ""Ghouling: The trolls targeting bereaved people"" on BBC Sounds. Perhaps one of the most surreal moments of our interview came when we asked Mr Peters about the on-field collapse of American football player Damar Hamlin. The Died Suddenly Twitter account jumped on the news in early January, using the #DiedSuddenly hashtag and linking the player's injury to Covid vaccines. Mr Hamlin is still alive, and said recently that his doctor has put his injury down to commotio cordis - a rare condition where a blow to the chest causes cardiac arrest. But Mr Peters continues to insist Mr Hamlin ""died suddenly"". When we point out the player's multiple public appearances since his collapse, Mr Peters said: ""You ever heard of CPR? That's a thing that when somebody dies you do to save their life. They're dead. Damar Hamlin died suddenly."" He went on: ""I don't know if he's dead. I know he died on that field. We all watched itÂ Why else would they have to give him CPR?"" When we point out that death is usually irreversible, he accused us of trying to ""explain away CPR"", before suggesting Mr Hamlin was indeed dead and his public appearances had been faked. ""I don't know if it's a body double. I don't know if it's a deepfake,"" he said. It's a world where facts don't matter and anything can be spun to support your existing worldview. Mr Peters also contends that the Ukraine war and the moon landings are ""fake"". He follows the American conspiracy playbook of people like Alex Jones, who denies the reality of grieving people while promoting his own message - and products for sale. After decades of spreading conspiracy theories, Mr Jones has now been ordered to pay more than $1bn in damages for falsely claiming the Sandy Hook school shooting was a hoax. But Mr Peters' audience has so far grown with little hindrance - even attracting influential political figures to his programme. Guests have included Kelli Ward, the head of the Republican Party in Arizona and Mark Meadows, a former White House chief of staff under Donald Trump. Died Suddenly has now been watched at least 18 million times on Rumble following its release in November last year, while the film's accompanying Twitter account has more than 350,000 followers. In November of last year, Twitter stopped taking action against tweets spreading Covid misinformation. The company declined to comment. Trisha Hickman, a former army analyst, scientist and teacher, is one of the bereaved people who had her grief appropriated by Mr Peters' conspiracy theory. When she posted on Twitter last November that her husband had died unexpectedly, ""those words really opened up floodgates for people telling us what horrible people we were for getting vaccinated and how it was our fault,"" she says. She describes one of the messages she received: ""The vaccine killed your spouse. It's all your fault. You murderer"". ""It can put you down some dark holes after a while,"" she said. But when we ask Mr Peters whether he regrets the effect of his film, he shows little remorse. ""You want to know if I care that somebody got their feelings hurt? No, I don't give a damn!"" ""All we're doing is saving more lives. I think that's awesome. And I'm happy to hear you report that,"" he says. Part of what seems to make the film so seductive is, within his through-the-looking-glass logic, Mr Peters spins his far out claims around a small kernel of truth. It's true there has been a rise in the numbers of people dying in many countries across the world since Covid-19 emerged. But it's unlikely to be for the reason Mr Peters claims. Data, including that produced by the Office for National Statistics in the UK, suggests vaccinated people are dying at lower rates than unvaccinated people. When we ask him why he trusts official data when it tells us there are excess deaths, but doesn't trust the same data when it tells us those deaths are happening at a higher rate in unvaccinated people, he simply describes it as ""total nonsense"". A willingness to discard facts and pick out only the scraps of information that support a narrative has been a winning formula for attracting thousands of listeners and viewers. The tactic allows people like Stew Peters to create an alluring world view where everything can be doubted - even bereaved people's accounts of their own loved ones' deaths. You can listen to ""Ghouling: The trolls targeting bereaved people"" on BBC Sounds. A film promoting an anti-vaccine conspiracy theory has been accused of helping to drive the harassment of bereaved families. In a rare interview with the BBC, the man behind it says he is ""happy"" about its influence - and believes the people responsible for Covid vaccinations should be executed. We met the film's creator, Stew Peters, in a warehouse he had rented for the occasion, on an industrial estate in Vero Beach, Florida. His crew had set up a makeshift studio and were filming us as we filmed him - to get their own message out. Mr Peters is a former bounty hunter and rapper from Minnesota who built an influential podcast and social media network through the pandemic. His film, called Died Suddenly, portrays a striking but false narrative - claiming that swathes of people are suddenly and suspiciously dropping dead in large numbers, and that Covid vaccines are to blame. The film misuses images and manipulates data to paint a persuasive picture that the vaccines are very unsafe - contrary to vast amounts of scientific research. We asked Mr Peters about the fabricated evidence within the film, including clips of blood clots and birth defects which the BBC and other researchers have traced back to medical training materials pre-dating the pandemic. But he refused to answer direct questions. ""This is an attempt to try to discredit me or the film rather than talking about the millions of people that are dying,"" he told us, going on to describe Covid vaccines as a ""bio-weaponÂ[that's] killed unprecedented, record-smashing numbers of people"". These are huge claims and so they need strong evidence to back them up - but the weight of scientific evidence is against such claims. There have been rare cases of serious Covid-19 vaccine side effects including deaths, which deserve careful investigation. But on a population level, vast amounts of data from different teams of independent scientists around the world suggest that overall, the vaccines have saved millions of lives. We asked Mr Peters why he'd included examples of people supposedly ""dying suddenly"" from Covid vaccines which were easy to disprove - including clips filmed before the pandemic or before the vaccines were available. ""I'm on a very specific mission, and that is to expose lies that are killing people,"" was his response. While the film might contradict the best evidence we have, it's super-charged a trend. Now online trolls use the keywords ""died suddenly"" to search for stories of personal tragedies and link them without evidence to Covid vaccines, often bombarding family members with unpleasant messages in the process. Look at virtually any announcement of a sudden celebrity death online and you'll now see strange messages appearing underneath, linking their passing to Covid vaccines and often using the hashtag #DiedSuddenly. You can listen to ""Ghouling: The trolls targeting bereaved people"" on BBC Sounds. Perhaps one of the most surreal moments of our interview came when we asked Mr Peters about the on-field collapse of American football player Damar Hamlin. The Died Suddenly Twitter account jumped on the news in early January, using the #DiedSuddenly hashtag and linking the player's injury to Covid vaccines. Mr Hamlin is still alive, and said recently that his doctor has put his injury down to commotio cordis - a rare condition where a blow to the chest causes cardiac arrest. But Mr Peters continues to insist Mr Hamlin ""died suddenly"". When we point out the player's multiple public appearances since his collapse, Mr Peters said: ""You ever heard of CPR? That's a thing that when somebody dies you do to save their life. They're dead. Damar Hamlin died suddenly."" He went on: ""I don't know if he's dead. I know he died on that field. We all watched itÂ Why else would they have to give him CPR?"" When we point out that death is usually irreversible, he accused us of trying to ""explain away CPR"", before suggesting Mr Hamlin was indeed dead and his public appearances had been faked. ""I don't know if it's a body double. I don't know if it's a deepfake,"" he said. It's a world where facts don't matter and anything can be spun to support your existing worldview. Mr Peters also contends that the Ukraine war and the moon landings are ""fake"". He follows the American conspiracy playbook of people like Alex Jones, who denies the reality of grieving people while promoting his own message - and products for sale. After decades of spreading conspiracy theories, Mr Jones has now been ordered to pay more than $1bn in damages for falsely claiming the Sandy Hook school shooting was a hoax. But Mr Peters' audience has so far grown with little hindrance - even attracting influential political figures to his programme. Guests have included Kelli Ward, the head of the Republican Party in Arizona and Mark Meadows, a former White House chief of staff under Donald Trump. Died Suddenly has now been watched at least 18 million times on Rumble following its release in November last year, while the film's accompanying Twitter account has more than 350,000 followers. In November of last year, Twitter stopped taking action against tweets spreading Covid misinformation. The company declined to comment. Trisha Hickman, a former army analyst, scientist and teacher, is one of the bereaved people who had her grief appropriated by Mr Peters' conspiracy theory. When she posted on Twitter last November that her husband had died unexpectedly, ""those words really opened up floodgates for people telling us what horrible people we were for getting vaccinated and how it was our fault,"" she says. She describes one of the messages she received: ""The vaccine killed your spouse. It's all your fault. You murderer"". ""It can put you down some dark holes after a while,"" she said. But when we ask Mr Peters whether he regrets the effect of his film, he shows little remorse. ""You want to know if I care that somebody got their feelings hurt? No, I don't give a damn!"" ""All we're doing is saving more lives. I think that's awesome. And I'm happy to hear you report that,"" he says. Part of what seems to make the film so seductive is, within his through-the-looking-glass logic, Mr Peters spins his far out claims around a small kernel of truth. It's true there has been a rise in the numbers of people dying in many countries across the world since Covid-19 emerged. But it's unlikely to be for the reason Mr Peters claims. Data, including that produced by the Office for National Statistics in the UK, suggests vaccinated people are dying at lower rates than unvaccinated people. When we ask him why he trusts official data when it tells us there are excess deaths, but doesn't trust the same data when it tells us those deaths are happening at a higher rate in unvaccinated people, he simply describes it as ""total nonsense"". A willingness to discard facts and pick out only the scraps of information that support a narrative has been a winning formula for attracting thousands of listeners and viewers. The tactic allows people like Stew Peters to create an alluring world view where everything can be doubted - even bereaved people's accounts of their own loved ones' deaths. You can listen to ""Ghouling: The trolls targeting bereaved people"" on BBC Sounds."
Israel-Palestinian conflict: False and misleading claims fact-checked,"As the Israel-Palestinian conflict has escalated, posts containing misleading or false claims have been widely shared online in recent days. We've investigated examples of misinformation from both sides that have provoked intense debate on social media. A spokesperson for Israeli Prime Minister Benjamin Netanyahu shared a video on Twitter which he claimed showed Hamas firing rockets at Israel ""from populated areas"". ""1/3 of these 250+ rockets fell inside the Gaza Strip, killing Palestinians,"" Ofir Gendelman tweeted. But the video is old and the footage is from Syria, not Gaza. It was taken during a Syrian government operation against rebel groups in the city of Deraa in 2018. Twitter labelled the tweet as ""manipulated media"", adding links to fact-checks confirming the clip was from the Syrian war. After criticism, Mr Gendelman deleted the tweet. Some Twitter users spread what they claimed were screenshots of posts from the Israel Defense Forces' (IDF) Twitter account saying: ""We just love killing"" and ""Just bombed some kids"". These screenshots are fakes which can be made using freely available online tools. The IDF did not make these statements on their official Twitter account or anywhere else. The account from which the fake tweets apparently originated shows strong pro-Palestinian, anti-Israel leanings and claims to be writing satire. Some Israeli social media influencers shared a video claiming it showed Palestinians faking a funeral ceremony for an individual supposedly killed by Israeli air strikes in Gaza - in order to attract global sympathy. In the video, which was also shared by an adviser to the Israeli Foreign Ministry, a group of teenagers carry what looks like a body covered with a shroud on their shoulders. As soon as they hear the sound of sirens, they leave the body on the ground and run off. Left alone, the supposed body also gets up and runs away. We found the same video posted in March 2020, with reports at the time suggesting that it showed a group of boys in Jordan trying to avoid strict Covid-19 restrictions by pretending to hold a funeral. The clip was shared under the hashtag ""Palywood"" [Palestinian Hollywood] hundreds of times by pro-Israeli users on major social media platforms. Some pro-Palestinian users shared a video which they claimed showed al-Aqsa mosque in East Jerusalem on fire, accusing Israel of ""letting the al-Aqsa Mosque burn"". The video is real, but additional footage from other angles makes it clear that a tree near to the mosque had caught fire, not the mosque itself. The mosque complex in Jerusalem's Old City is one of Islam's most revered locations, but its location is also the holiest site in Judaism, known as the Temple Mount. In the video, a large crowd of young Jewish Israeli men can be heard singing an anti-Palestinian song behind the Western Wall, with flames visible in the distance. The cause of the blaze is disputed. Israeli police said in a statement that it was the result of fireworks thrown by Palestinian worshippers. But Palestinians say it was caused by Israeli officers throwing stun grenades. According to Reuters, the tree was only 10 metres from the mosque. The fire was subsequently put out and the mosque was not damaged by the blaze. One widely shared tweet claimed to show footage of Palestinian militant group Hamas moving truck-based missiles down a street in Gaza. A child can also be heard speaking in the video. The post, from a US-based pro-Israel account, claims: ""Once again we see Hamas using civilians as a shield to murder Jews knowing... that Israel will not retaliate due to the risk of hurting innocent people"". However, we found that the video was uploaded to Facebook on 25 November 2018, with a caption saying it was taken in the town of Abu Snan in Galilee, in Israel. Aric Toler, a researcher for open-source investigation experts Bellingcat, thinks that the footage shows decoy missile models being used for an Israeli military exercise. The Twitter account posting the video later deleted it, and apologised for their ""incorrect data"". With reporting by Alistair Coleman, Shayan Sardarizadeh, Christopher Giles and Nader Ibrahim."
Ivermectin: How false science created a Covid 'miracle' drug,"Ivermectin has been called a Covid ""miracle"" drug, championed by vaccine opponents, and recommended by health authorities in some countries. But the BBC can reveal there are serious errors in a number of key studies that the drug's promoters rely on. For some years ivermectin has been a vital anti-parasitic medicine used to treat humans and animals. But during the pandemic there has been a clamour from some proponents for using the drug for something else - to fight Covid and prevent deaths. The health authorities in the US, UK and EU have found there is insufficient evidence for using the drug against Covid, but thousands of supporters, many of them anti-vaccine activists, have continued to vigorously campaign for its use. Members of social media groups swap tips on getting hold of the drug, even advocating the versions used for animals. The hype around ivermectin - based on the strength of belief in the research - has driven large numbers of people around the world to use it. Campaigners for the drug point to a number of scientific studies and often claim this evidence is being ignored or covered up. But a review by a group of independent scientists has cast serious doubt on that body of research. The BBC can reveal that more than a third of 26 major trials of the drug for use on Covid have serious errors or signs of potential fraud. None of the rest show convincing evidence of ivermectin's effectiveness. Dr Kyle Sheldrick, one of the group investigating the studies, said they had not found ""a single clinical trial"" claiming to show that ivermectin prevented Covid deaths that did not contain ""either obvious signs of fabrication or errors so critical they invalidate the study"". Major problems included: The scientists in the group - Gideon Meyerowitz-Katz, Dr James Heathers, Dr Nick Brown and Dr Sheldrick - each have a track record of exposing dodgy science. They've been working together remotely on an informal and voluntary basis during the pandemic. They formed a group looking deeper into ivermectin studies after biomedical student Jack Lawrence spotted problems with an influential study from Egypt. Among other issues, it contained patients who turned out to have died before the trial started. It has now been retracted by the journal that published it. The group of independent scientists examined virtually every randomised controlled trial (RCT) on ivermectin and Covid - in theory the highest quality evidence - including all the key studies regularly cited by the drug's promoters. RCTs involve people being randomly chosen to receive either the drug which is being tested or a placebo - a dummy drug with no active properties. The team also looked at six particularly influential observational trials. This type of trial looks at what happens to people who are taking the drug anyway, so can be biased by the types of people who choose to take the treatment. Out of a total of 26 studies examined, there was evidence in five that the data may have been faked - for example they contained virtually impossible numbers or rows of identical patients copied and pasted. In a further five there were major red flags - for example, numbers didn't add up, percentages were calculated incorrectly or local health bodies weren't aware they had taken place. On top of these flawed trials, there were 14 authors of studies who failed to send data back.  The independent scientists have flagged this as a possible indicator of fraud. The sample of research papers examined by the independent group also contains some high-quality studies from around the world. But the major problems were all in the studies making big claims for ivermectin - in fact, the bigger the claim in terms of lives saved or infections prevented, the greater the concerns suggesting it might be faked or invalid, the researchers discovered. While it's extremely difficult to rule out human error in these trials, Dr Sheldrick, a medical doctor and researcher at the University of New South Wales in Sydney, believes it is highly likely at least some of them may have been knowingly manipulated. A recent study in Lebanon was found to have blocks of details of 11 patients that had been copied and pasted repeatedly -  suggesting many of the trial's apparent patients didn't really exist. The study's authors told the BBC that the ""original set of data was rigged, sabotaged or mistakenly entered in the final file"" and that they have submitted a retraction to the scientific journal which published it. Another study from Iran seemed to show that ivermectin prevented people dying from Covid. But the scientists who investigated it found issues. The records of how much iron was in patients' blood contained numbers in a sequence that was unlikely to come up naturally. And the patients given the placebo turned out to have had much lower levels of oxygen in their blood before the trial started than those given ivermectin. So they were already sicker and statistically more likely to die. But this pattern was repeated across a wide range of different measurements. The people with ""bad"" measurements ended up in the placebo group, the ones with ""good"" measurements in the ivermectin group. The likelihood of this happening randomly across all these different measurements was vanishingly small, Dr Sheldrick said. Dr Morteza Niaee, who led the Iran study, defended the results and the methodology and disagreed with problems pointed out to him, adding that it was ""very normal to see such randomisation"" when lots of different factors were considered and not all of them had any bearing on participants' Covid risk. But the Lebanon and Iran trials were excluded from a paper for Cochrane - the international experts in reviewing scientific evidence - because they were ""such poorly reported studies"". The review concluded there was no evidence of benefit for ivermectin when it comes to Covid. The largest and highest quality ivermectin study published so far is the Together trial at the McMaster University in Canada. It found no benefit for the drug when it comes to Covid. Ivermectin is generally considered a safe drug, though there have been some reports of side effects. Calls over suspected ivermectin poisonings in the US have increased a lot but from a very small base (435 to 1,143 this year) and most of these cases were not serious. Patients have had vomiting, diarrhoea, hallucinations, confusion, drowsiness and tremors. But indirect harm can come from giving people a false sense of security, especially if they choose ivermectin instead of seeking hospital treatment for Covid, or getting vaccinated in the first place. Dr Patricia Garcia, a public health expert in Peru, said at one stage she estimated that 14 out of every 15 patients she saw in hospital had been taking ivermectin and by the time they came in they were ""really, really sick"". Large pro-ivermectin Facebook groups have turned into forums for people to find advice on where to buy it, including preparations meant for animals. Some groups regularly contain posts about conspiracy theories of ivermectin cover-ups, as well as pushing anti-vaccine sentiment or encouraging patients to leave hospital if they aren't getting the drug. The groups often provide a gateway to more fringe communities on the encrypted app Telegram. These channels have co-ordinated harassment of doctors who fail to prescribe ivermectin and abuse has been aimed at scientists. Dr Andrew Hill, from the University of Liverpool, wrote an influential positive review of ivermectin, originally saying the world should ""get prepared, get supplies, get ready to approve [the drug]"". Now he says the studies don't stand up to scrutiny - but after he changed his view, based on new evidence emerging, he received vicious abuse. A small number of qualified doctors have had an exaggerated influence on the ivermectin debate. Noted proponent Dr Pierre Kory's views have not changed despite the major questions over the trials. He criticised ""superficial interpretations of emerging trials data"". Dr Tess Lawrie - a medical doctor who specialises in pregnancy and childbirth - founded the British Ivermectin Recommendation Development (Bird) Group. She has called for a pause to the Covid-19 vaccination programme and has made unsubstantiated claims implying the Covid vaccine had led to a large number of deaths based on a common misreading of safety data. When asked during an online panel what evidence might persuade her ivermectin didn't work she replied: ""Ivermectin works. There's nothing that will persuade me."" She told the BBC: ""The only issues with the evidence base are the relentless efforts to undermine it."" Around the world it was originally not opposition to vaccines but a lack of them that led people to ivermectin. The drug has at various points been approved, recommended or prescribed for Covid in India, South Africa, Peru and much of the rest of Latin America, as well as in Slovakia. Health authorities in Peru and India have stopped recommending ivermectin in treatment guidelines. In February, Merck - one of the companies that makes the drug - said there was ""no scientific basis for a potential therapeutic effect against Covid-19"". In South Africa, the drug has become a battleground - doctors point out the lack of evidence but many patients desperately want access as the vaccine rollout has been patchy and problematic. One GP in the country described a relative, a registered nurse, who didn't book a coronavirus vaccine she was eligible for and then caught the virus. ""When she started getting worse, instead of getting proper assessment and treatment, she treated herself with ivermectin,"" she said. ""Instead of consulting a doctor, she continued with the ivermectin and got home oxygen. By the time I heard how low her oxygen saturation levels were (66%), I begged her daughter to take her to casualty. ""At first they were reluctant, but I convinced them to go. She passed away a few hours later."" Additional reporting by Shruti Menon"
Joe Rogan: Four claims from his Spotify podcast fact-checked,"Joe Rogan has been criticised for helping spread misinformation on his podcast. Spotify reportedly paid $100m (Â£75m) in 2020 for rights to The Joe Rogan Experience, which is the streaming service's top podcast. It is reportedly downloaded almost 200 million times a month. On the show, the US broadcaster hosts a wide variety of guests who discuss their views on a range of topics - but some episodes have featured false and misleading claims. Here are four of them fact-checked. Mr Rogan said: ""This is not a vaccine, this is essentially a gene therapy."" But this is not true. None of the Covid vaccines change your genetic material or DNA - essentially the recipe book containing the instructions of how to build your body. The vaccines made by Pfizer and Moderna harness a different molecule called messenger RNA. If DNA is the blueprint, RNA is the messenger, carrying instructions to your cells. In the case of the Covid vaccine, the message to your cells is to turn the RNA into a piece of the virus's spike protein. That's what fires your immune system up to start producing antibodies and other cells to fight off the virus. When the message has been received, the RNA from the virus is broken down and disposed of. It doesn't interact with your own genetic material at all. This claim was made on an episode last year featuring Bret Weinstein, an American author and professor of biology, who said: ""Ivermectin alone is capable of driving this pathogen to extinction."" BBC Reality Check looked at a series of research papers claiming to show the effectiveness of this drug in treating Covid. Many were very low quality, and in some cases the data had been clearly manipulated. If you look only at rigorously carried out studies, there is no evidence of the drug's effectiveness. Campaigners often cherry-pick positive examples and ignore the fact that many countries which relied heavily on ivermectin, like Brazil and Peru, had some of the worst death tolls from the virus. The world-leading experts on reviewing medical evidence, Cochrane, concluded based on just these reliable trials that there was ""insufficient evidence"" to recommend the drug. One of Mr Rogan's most controversial guests has been the virologist Robert Malone. Dr Malone was banned from Twitter in December last year for violating its Covid misinformation policies. He appeared on Mr Rogan's podcast shortly afterwards. Among the misleading claims made in this podcast episode was one suggesting people who are vaccinated after having Covid-19 are at greater risk of adverse side effects. Following his appearance, more than 270 people, mostly doctors and healthcare professionals, signed a letter to Spotify, calling for Covid misinformation to be addressed. Robust studies so far have shown that a very small number of conditions - blood clots, heart inflammation - are slightly more likely after certain vaccines, although are still very rare. In one UK study, researchers found that vaccine after effects were more common in those who already had Covid. However, this study only looked at mild after effects, such as fatigue, chills and headaches. Mr Rogan said: ""I don't think it's true there's an increased risk of myocarditis from people catching Covid-19 that are young, versus the risk from the vaccine."" Myocarditis is an inflammation of the heart muscle that has been raised as a rare side effect of vaccination. However, research has shown that this condition, which can lead to shortness of breath, chest pain and in very rare cases to heart failure, is considerably more common after a Covid infection than after vaccination. - as is also the case with blood clots. It also appears that cases of myocarditis post-vaccination are generally milder and shorter-lasting. Mr Rogan later corrected himself, but has made several other comments suggesting young people shouldn't be vaccinated as they are at low risk from Covid-19. It's certainly the case that younger people are at much lower risk of serious illness from Covid, but they are not at zero risk of developing complications. Covid itself has been found to be a bigger risk than the vaccines in every age group for which they have been approved. The vaccines, particularly after a booster, can also reduce your chances of catching the virus and therefore passing it on to others. Read more from Reality Check Send us your questions"
Kenya Elections 2022: Misinformation circulating online,"Official campaigning in Kenya's elections is now under way ahead of voting in August. Already, fake endorsements for the two main presidential candidates are being shared widely online. We've been taking a look at some of the misleading social media posts and videos circulating. President Uhuru Kenyatta is standing down after two terms of office. One of those hoping to replace him is his deputy, William Ruto. A video has emerged, purporting to show the former US President, Barack Obama, announcing his support for Mr Ruto. The video has however been manipulated and has nothing to do with Kenya's election - Mr Obama has not endorsed any candidate. The widely-shared video has been doctored to show Mr Obama unveiling a large image of his chosen candidate, with fake banners across the screen suggesting it is from a BBC News story, and was originally posted on a TikTok account. The text has a grammatical error, the type faces are wrong and the colours of the banners don't match. The genuine video, used as the basis for the fake, was filmed at the Smithsonian Institute in Washington in 2018, where Mr Obama was unveiling a portrait of himself. Supporters of Raila Odinga, the other main presidential challenger, have been sharing a video which they claim shows Mr Ruto's running mate, Rigathi Gachagua, saying his coalition, Kenya Kwanza, will - if elected - break up Kenya's largest telecommunications company, Safaricom. A genuine interview, given by Mr Gachagua to a local radio station, was posted online with a sub-titled English translation which read:  ""We will kill it [Safaricom] and give that money to the people as handouts."" But speaking in the Kikuyu language, Mr Gachagua did not say this. What he actually said was:  ""Instead of having one large company called Safaricom paying taxes, if you take the money from the large company and give it out to many people... the tax from the many put together will be 30 times greater than that of the large company."" It was a proposal to redistribute profits to support smaller enterprises, and clearly not one to ""kill"" corporate business. In a curious twist to this story, a press release appeared online shortly after the video, supposedly from Safaricom, condemning the sentiments expressed in the interview, which amounted, said the document, to ""shutting down [Safaricom] and other major corporate firms"". The statement went on: ""We wish to condemn these remarks [by Mr Gachagua] in the strongest possible terms."" However, the press release was a fake and Safaricom subsequently released its own genuine statement on Twitter to confirm this. Both leading presidential candidates are seeking support from the vote-rich Kikuyu ethnic group.  (Ruto is from the Kalenjin community and Odinga is Luo). So, an endorsement from the son of Kenya's former President Mwai Kibaki - a Kikuyu - would be a highly coveted prize. A fake Twitter account has appeared, purporting to be owned by Jimmy Kibaki, the former president's eldest son. The account, which has since changed its name, was created in February and recently tweeted support for William Ruto's candidacy. This account is just one of many fake accounts using Jimmy Kibaki's name, and he has issued a statement calling on Kenyans to ignore them. The constitution limits a president to two terms, which means Mr Kenyatta cannot stand for election again this year. However, some online users, including at least one leading politician, have been suggesting that he could stand as the deputy-presidential candidate. ""Thinking out loud yet again :- article 137(1) of the Kenyan Constitution does not disqualify the current president from running as a deputy president!"" Senator Ledama Ole Kina tweeted. While it is true that this article of the constitution doesn't explicitly prohibit this, there is another article that does rule him out. Article 148 (1) says the person nominated as a deputy-president must be ""qualified for nomination for election as President."" Having served for two terms, Mr Kenyatta is not eligible under this condition. Read more from Reality Check Send us your questions"
Kenya election 2022: Raila Odinga corruption claims fact-checked,"Former prime minister Raila Odinga has been campaigning to take over as president of Kenya from Uhuru Kenyatta. He has made corruption a major focus of his rallies and speeches. We've previously fact-checked the other leading candidate, William Ruto. Here we look at some of the claims made by Mr Odinga. Mr Gachagua, who's campaigning to be deputy president alongside Mr Ruto, was ordered by a court on 28 July to return more than 200m Kenya shillings (Ksh) ($1.7m, Â£1.4m) because he'd failed to explain how he had acquired it. Mr Gachagua says he was not given the chance to challenge the evidence against him and that he will appeal against the decision. Raila Odinga has called for him to withdraw from the election, saying that under the Kenyan constitution, ""you cannot contest for presidency or be a presidential running mate if you have been indicted of a crime"". ""He says he is going to appeal"" added Mr Odinga, ""but as things stand today he is convicted, guilty as charged."" However, the case involving Mr Gachagua was a civil one brought by a government agency responsible for recovering the proceeds of corruption. It was not a criminal case, and the distinction is important. The constitution states that a person is disqualified from standing as president, deputy president or a member of parliament if they have been: But it also says you are not disqualified ""unless all possibility of appeal or review of the relevant sentence or decision has been exhausted"". Constitutional lawyer Bobby Mkangi told us he believes this allows someone to continue to run for public office ""while this [appeal] process is under way"", Mr Gachagua is facing a related criminal corruption case, but this isn't due to be heard in court until September. He denies the charges. Mr Odinga said this in an interview broadcast on 21 July, but we don't know how he arrived at the figure of Ksh100m ($840,000, Â£690,000) a month. Mr Ruto has taken part in many fundraising events in recent years, but there is no legal requirement in Kenya for donors to declare their contributions. Once election campaigning is under way, no candidate is permitted to make further donations. We've asked Mr Odinga's office how he arrived at the figure for how much Mr Ruto has contributed to these harambees and when he made them, but we have not had a reply. As for the figure given for Mr Ruto's monthly salary, the official Kenya Gazette lists his pay as Ksh1.2m ($10,000, Â£8,300). Mr Ruto is also known to have private sources of income from investments and business interests, but it's not known what he earns from these. Mr Odinga made this claim in a recent BBC interview when asked about his time as prime minister from 2008 to 2013. In 2010, a corruption scandal broke involving a subsidised maize programme. A report by the global financial auditors PricewaterhouseCoopers (PwC) recommended an investigation into a number of government officials, and this included two working within the prime minister's office. Kenya's anti-corruption commission carried out its own probe and concluded there was no evidence to bring charges against these two. It recommended the cases against them should be closed. The staff members were reinstated later that year. Subsequently, a fresh controversy arose over a World Bank-supported project to tackle youth unemployment. The project faced criticism from MPs over the way it was run, amid allegations that money intended for unemployed youths was being siphoned off by officials in Mr Odinga's office. At the time, the World Bank did raise concerns about the management of the project, and had asked the prime minister's office to clarify what had happened to more than Ksh33m (Â£229,000, $277,000) But it did not publicly accuse any officials of wrongdoing. Mr Odinga later told parliament ""not a single penny [had] been lost in the programme""."
"Kenya elections 2022: While Kenya waits, unfounded election claims spread","In the uneasy period between Kenya's presidential election last week and the much anticipated declaration of the final official result, social media platforms have been flooded with conflicting claims over who has won. It's a country where political twists and turns are very much guided by influential online pundits with large followings on platforms such as Twitter and Facebook. With concrete information hard to come by, misinformation and exaggeration has been the order of the day particularly as it's a very tight race between Deputy President William Ruto and long-time opposition leader Raila Odinga. So in the world of social media speculation, both candidates have already been declared the winner. Twitter has placed labels on some posts warning users to wait for the official result. There have already been claims of politicians losing their seats only for them later to be announced as winners. As in many countries, influential bloggers and politicians in Kenya help political parties bypass mainstream media channels and connect directly with potential supporters. For many, this has been the main source of information during the election campaigns and a means of mobilising support. Election observers and monitoring groups have expressed concern at the scale of the false and misleading information being spread. Some posts are falsely claiming fraud at polling stations, such as this one from a Ruto supporter suggesting a voter turnout of over 100% in an area with strong traditional support for Raila Odinga. The Tweet is partially correct. There is indeed a discrepancy on the returning officer's declaration form. However, referring back to the official voter registration data shows that the number of registered voters should be 632 and not 362. The error at the local level makes no difference to the number of votes recorded, and indicates that the turnout at this polling station was about 62%. On the other side, Mr Odinga's supporters have been having a go at their opponents online. In this Tweet, for example, a long-standing disagreement over the use of an electronic system is highlighted by pointing out that Mr Ruto's running mate, Rigathi Gachagua (whose coalition opposed the use of a manual register) had difficulties registering at a polling station using the electronic method. While the electronic kit initially had problems identifying Mr Gachagua, it eventually worked after he rubbed his finger on his hair allowing him to vote. For those trying to locate reliable sources of election information it's all too easy to fall into the trap of fake accounts pretending to be those of official electoral bodies. A Twitter account calling itself IEBC Tabulation has been posting election results and using the Independent Electoral and Boundaries Commission's official logo as the profile picture and cover image. To confuse further, the account linked directly to the authentic election website.  However, a deeper look quickly revealed not only clear political bias, but also that it had recently been posting a stream of sexually explicit content. This account has now been suspended for violating Twitter rules. One attempt at misleading voters appeared on election day itself, suggesting that votes had already been tallied in an overseas polling station in Sydney, Australia and that Mr Odinga had received the most votes. Variations of this message, presumably designed to energise supporters to get out and vote, circulated on WhatsApp, Twitter and Facebook. However, it was all made up. There were no Kenyan diaspora polling stations in Australia. The electoral commission says voting by the diaspora was taking place in 12 locations: Burundi, Tanzania, Rwanda, Uganda, South Africa, United Kingdom, Canada, USA, South Sudan, Qatar, UAE, and Germany. Australia wasn't one of them."
Liverpool: Protesters disrupt meeting over non-existent policy,"About 30 people gathered at Liverpool Town Hall on Tuesday, loudly opposing the idea of a ""15-minute city"". However it was not being discussed by the neighbourhoods committee, nor has it ever been a Liverpool City Council policy. As councillors went inside they were accused of ""betraying"" the city. The council's leader, Liam Robinson, said he did not know whether the protesters had genuinely or deliberately confused the issues. Committee members were denounced as ""treacherous traitors"" and the meeting had to be suspended after members of the public tried to address it. They were told they could not and removed by security staff. Mr Robinson said he found it ""concerning"" that protesters had turned up at a meeting to oppose an idea that was not on the agenda. A 15-minute city is an urban planning idea that recently gained traction in Paris, in which neighbourhood amenities are all within 15 minutes by foot, bicycle or public transport. The neighbourhood system - which was on the agenda - is essentially an administrative change dividing the city into 13 new areas. It is designed to improve the delivery of public services. Mr Robinson said: ""I don't want to speculate too much, as we are aware that different groups might be involved in... these conspiracy theories. Possibly some elements of the far right and others. ""There might be reasons people might want to hijack a protest."" Under the real scheme, each area will have a manager to highlight and tackle issues, such as housing, waste management, potholes, parking or anti-social behaviour. It is designed to help taxpayers access council services and create joined-up council departments. However, some protesters told our reporter they believed it would lead to greater surveillance, monitoring of their behaviour and limits on their movement. Mr Robinson dismissed this completely, adding that the reality was mundane. ""The neighbourhood plan is a model that most councils and cities have."" Mr Robinson said: ""[The 15-minute city] is not something we've ever adopted as a policy in Liverpool. ""There's obviously some benefits to the theory behind it. But it's something that's been twisted [by] conspiracies [suggesting] that people wouldn't be able to go to other cities and communities - which is completely false."" He criticised social media companies for allowing the spread of fake news. ""When things are getting out that are completely wrong, that needs to be dealt with,"" he said. He added that there were only 30 protesters on Tuesday, whereas the city's population is just under half a million. It was this larger group that he hoped would support the new service-delivery model that was on the meeting's agenda. Why not follow BBC North West on Facebook, Twitter and Instagram? You can also send story ideas to northwest.newsonline@bbc.co.uk About 30 people gathered at Liverpool Town Hall on Tuesday, loudly opposing the idea of a ""15-minute city"". However it was not being discussed by the neighbourhoods committee, nor has it ever been a Liverpool City Council policy. As councillors went inside they were accused of ""betraying"" the city. The council's leader, Liam Robinson, said he did not know whether the protesters had genuinely or deliberately confused the issues. Committee members were denounced as ""treacherous traitors"" and the meeting had to be suspended after members of the public tried to address it. They were told they could not and removed by security staff. Mr Robinson said he found it ""concerning"" that protesters had turned up at a meeting to oppose an idea that was not on the agenda. A 15-minute city is an urban planning idea that recently gained traction in Paris, in which neighbourhood amenities are all within 15 minutes by foot, bicycle or public transport. The neighbourhood system - which was on the agenda - is essentially an administrative change dividing the city into 13 new areas. It is designed to improve the delivery of public services. Mr Robinson said: ""I don't want to speculate too much, as we are aware that different groups might be involved in... these conspiracy theories. Possibly some elements of the far right and others. ""There might be reasons people might want to hijack a protest."" Under the real scheme, each area will have a manager to highlight and tackle issues, such as housing, waste management, potholes, parking or anti-social behaviour. It is designed to help taxpayers access council services and create joined-up council departments. However, some protesters told our reporter they believed it would lead to greater surveillance, monitoring of their behaviour and limits on their movement. Mr Robinson dismissed this completely, adding that the reality was mundane. ""The neighbourhood plan is a model that most councils and cities have."" Mr Robinson said: ""[The 15-minute city] is not something we've ever adopted as a policy in Liverpool. ""There's obviously some benefits to the theory behind it. But it's something that's been twisted [by] conspiracies [suggesting] that people wouldn't be able to go to other cities and communities - which is completely false."" He criticised social media companies for allowing the spread of fake news. ""When things are getting out that are completely wrong, that needs to be dealt with,"" he said. He added that there were only 30 protesters on Tuesday, whereas the city's population is just under half a million. It was this larger group that he hoped would support the new service-delivery model that was on the meeting's agenda. Why not follow BBC North West on Facebook, Twitter and Instagram? You can also send story ideas to northwest.newsonline@bbc.co.uk"
Lumpy skin disease: Viral cattle disease sends rumours flying in India,"Misinformation about a viral disease that infects cattle is spreading on social media in India. Lumpy skin disease has already infected over 2.4 million animals and has led to over 110,000 cattle deaths in India, according to latest data from the government. India is the world's largest milk producer and has the world's largest cattle population, but the infection is threatening livelihoods of farmers in the country. Meanwhile, misinformation has made some people wary of consuming milk. We debunk three false claims about the disease. Many viral social media posts falsely claim that milk has become unsafe for human consumption due to the spread of lumpy skin disease, and that drinking milk from an infected animal will lead to the development of a skin disease in humans as well. The posts are often accompanied by images of visibly diseased human bodies covered in lesions, meant to create fear. ""I have seen many such claims in social media groups of the dairy industry. Those who circulate such claims are not responsible - they share it as though it is information that only they possess,"" Poras Mehla, general secretary of an association of 6,000 dairy farmers in the northern Indian state of Haryana, told the BBC. Dairy farmers are suffering due to the false claim. ""I noticed this claim on social media and even heard that some people who believe it are throwing away milk,"" says Manav Vyas, a dairy farmer and the manager of a cattle shelter in the western Indian state of Rajasthan. ""Dairy farmers who are already under economic stress after losing cattle to lumpy skin disease are now facing the added burden of stigma from people who refuse to buy milk."" Searches for ""can we drink milk of lumpy skin disease cow"" grew by more than 5,000% in the past 30 days according to data from Google Trends. In reality, lumpy skin disease is not a zoonotic disease - which means it is not naturally transmissible from animals to humans. In a 2017 report, the UN's Food and Agricultural Organisation (FAO) confirmed that lumpy skin disease does not affect humans. This has also been confirmed by the Indian government's Indian Veterinary Research Institute (IVRI). ""Till date there is no evidence of any animal to human transmission,"" Dr KP Singh, Joint Director of the IVRI told the BBC. ""However, a suckling calf can get the infection from the milk of an infected cow."" As for the images of human bodies covered in lesions that usually accompany the false posts, the disease can be accurately identified by collecting samples and sending them to a diagnostic laboratory, according to Dr Singh. ""We cannot pinpoint the disease on the basis of symptoms or lesions, as there are many diseases which have similar symptoms."" Misinformation about the origin of the lumpy skin disease is also doing the rounds on social media. This includes the false claim that lumpy skin disease has entered India from Pakistan, and that it is part of a Pakistani conspiracy against India's cows. Cows are considered sacred by India's majority Hindu population. In reality, lumpy skin disease first originated in Zambia in 1929. For a while it remained endemic to sub-Saharan Africa, but it has since spread to countries in North Africa, the Middle East, Europe, and Asia. In Asia, the disease was first observed in July 2019 in Bangladesh, China and India, according to a report by the FAO. At the time this FAO report was published in 2020, the disease had not yet been detected in Pakistan - so it can be concluded that the disease was detected in India before it was detected in Pakistan, and that the claim that the disease spread from Pakistan to India is false. This was further confirmed by Dr KP Singh, Joint Director of the IVRI. ""The disease entered India from Bangladesh - not from Pakistan - due to natural animal movement and transport at the border. Cases in Bangladesh were reported earlier than cases in India. In Pakistan, cases were reported later, after being reported in India,"" he told the BBC. Misinformation about lumpy skin disease has been compounded with anti-vaccine conspiracies on social media. A video of cattle carcasses in a dumping ground is viral on social media platforms, with the claim that tens of thousands of cattle ""suddenly started to die after being given a vaccine by the Indian government."" These claims have thousands of retweets and have been viewed over a hundred thousand times. While the video is genuine, the accompanying claim - that cattle are dying after being administered the vaccine - is false. Large-scale vaccinations are the most effective way of limiting the spread of the lumpy skin disease, according to the FAO. A cattle vaccination programme is currently underway in several states across India, and the goat pox vaccine is currently being used as it provides cross protection against lumpy skin disease. Indian researchers have also developed a vaccine against lumpy skin disease, which they have been working on since the virus was first detected in India in 2019. This vaccine is yet to become commercially available. Millions of animals have already been vaccinated and recovered across India. ""The only solution currently available is the goat pox vaccine. It is a very good vaccine and gives 70-80% protection against lumpy skin disease without any side effects. We are observing this impact in the field and getting good feedback,"" Dr KP Singh told the BBC."
Marianna Vyshemirsky: 'My picture was used to spread lies about the war',"A photo of a heavily pregnant woman fleeing a bombed maternity hospital became one of the most iconic images of the war in Ukraine. But its subject was targeted by an extraordinary Russian disinformation campaign and she received hate from both sides. Wrapped in a duvet with her forehead bloodied, Marianna Vyshemirsky's image was seen around the world. The photo above was taken in the aftermath of a Russian airstrike in Mariupol. It circulated online, on newspaper front pages, and was argued about at the UN Security Council. But, having survived one attack, Marianna faced another onslaught - of disinformation and hate aimed at her and her family. As Russia attempted to sow falsehoods about the attack, 29-year-old Marianna was falsely accused of ""acting"". Russian diplomats even claimed that she had ""played"" not one, but two different women. I've spoken extensively to her friends and relatives, but have been trying to interview my namesake for weeks. So when she finally appears on my screen on a video call, it feels a little surreal. She tells me about her harrowing escape, and about the online abuse that came after. ""I received threats that they would come and find me, that I would be killed, that my child would be cut into pieces,"" she says. This is her first interview with a major western media outlet after being evacuated to her hometown in a part of Donbas controlled by Russian-backed separatists. Marianna seems at ease, and is speaking to me without any preconditions, but a pro-separatist blogger is with her. She tells me what it's like to find herself inside an information battle - all while giving birth to her daughter Veronika in a war zone. ""She chose to show up at a difficult time,"" she explains, ""but it's better she arrived under these circumstances than not at all."" Life in Mariupol was very different before the war. Marianna promoted beauty products on social media, while her husband Yuri worked at the Azovstal steel works. ""We had a quiet and simple life,"" she says, ""and then, of course, things were turned upside down."" Her Instagram account shows her excitement at the prospect of becoming a mother. But by the time Marianna was admitted to hospital, Mariupol had become the most bombed city in Ukraine. On 9 March, she was chatting with other women on the ward when an explosion shook the hospital. She pulled a blanket over her head. Then a second explosion hit. ""You could hear everything flying around, shrapnel and stuff,"" she says. ""The sound was ringing in my ears for a very long time."" The women sheltered in the basement with other civilians. Marianna suffered a forehead cut and glass fragments lodged in her skin, but a doctor told her she didn't need stitches. What she did need, she explains, was to retrieve her possessions from the ruins of the hospital. She asked a police officer to help her back inside. ""Everything I had prepared for my baby was in that maternity ward,"" she says. While she stood outside the hospital, waiting to recover her things, she was photographed by journalists from the Associated Press. They snapped her again as she descended the stairs exiting the building. Those images quickly went viral. And that's when false allegations that the pictures were ""staged"" first appeared on a pro-Kremlin Telegram channel. Marianna's beauty blogging was used to suggest she was an ""actor"" who had used makeup to fake injuries. These falsehoods were repeated and amplified by senior Russian officials and state media. They even claimed that a photo of another pregnant woman on a stretcher was also Marianna, even though it's clear that the photos are of different people. The woman on the stretcher and her unborn child later died from their injuries. Fleeing and without internet access, Marianna didn't see those images until days later. By that point, her Instagram was inundated with accusatory and threatening messages. She found both the trolling and the false allegations shocking. ""It was really offensive to hear that, because I actually lived through it all,"" she says. But she refrains from directly criticising the Russian officials who spread the false information about her. Instead, she criticises the Associated Press. ""I was offended that the journalists who had posted my photos on social media had not interviewed other pregnant women who could confirm that this attack had really happened."" She suggests this may help explain why some people ""got the impression that it was all staged"". But by Marianna's own account she was one of the last patients to be evacuated, and that was when the AP journalists arrived. The journalists interviewed other people at the scene. And they had nothing to do with the subsequent false story spread by Russian officials. We approached the AP for comment. In the days after the attack, Marianna gave birth to Veronika in another hospital. Like thousands of others, Marianna and Yuri were desperately trying to escape Mariupol. For weeks, it was largely impossible to make contact with them. Eventually Marianna's relatives told me the couple had got out of the city, but their whereabouts were unclear. Then in early April, they resurfaced in the Donbas region. She filmed an interview with Denis Seleznev, a blogger who is a vocal supporter of Russian-backed separatists. There was speculation how free she was to say what she wanted. Marianna says to me: ""I had to describe the whole situation, as I saw it with my own eyes."" My conversation with her was also arranged via Denis. Marianna speaks to me from his home. He is present throughout our chat but doesn't interrupt. Marianna's relatives and friends have assured me she is now safe. Much of what she says in her interview with me undermines the Russian government's mistruths. The Kremlin wrongly and repeatedly suggested the hospital that was attacked was Mariupol's hospital number one, and that it was no longer operational. But the BBC's disinformation team identified the hospital where Marianna was - hospital number three. We contacted the Russian Embassy in London for comment. Marianna confirms that the hospital was definitely treating her and other patients - contrary to Russian claims that it was not functioning as a health care facility. Russia also claimed that the hospital had been taken over by the Azov regiment - the controversial Ukrainian nationalist group that has been linked with neo-Nazis, allegations they themselves deny. Comments Marianna made in her interview with Denis were cherry-picked by Russian officials to claim soldiers forced Marianna and the other pregnant women to act as human shields. But Marianna told me there were no Ukrainian military stationed in the building where she was. She says she saw Ukrainian soldiers in the oncology unit in the building opposite the maternity unit. It's unclear whether they were based there or not. Nevertheless, Marianna's interview with Denis Seleznev was used by the Kremlin to suggest further falsehoods. Russian officials have seized on her comments that she doesn't believe the explosions at the hospital were caused by an airstrike, implying that the damage was Ukrainian shelling. ""The typical sound a plane makes when it flies overhead is impossible to miss,"" Marianna tells me, saying that she did not hear one. But here she is mistaken. The AP journalists documented evidence it was an airstrike, including video where a plane can be heard. At the scene both a soldier and a police officer say the attack was an airstrike. Also visible in photos is a huge crater which munition experts say could only have been caused by an airstrike. ""I personally did not see this crater, but I saw the video of it,"" Marianna says. ""In reality I can't blame anyone - because I didn't see with my own eyes where for certain [the explosions] came from."" This fresh controversy sparked a new wave of online vitriol. ""Some people said that I was an actress, others said that I was lying about the fact that there were no air raids,"" she says. Even some she regarded as friends don't believe her. Fellow beauty blogger Yaroslava lives in Russia and continues to believe state TV claims that Marianna was acting. ""I think that Marianna played her part. That Ukraine needed the Ukrainian military to blame everything on Russia."" Yaroslava told me. She's since unfollowed Marianna on Instagram - and doesn't want to speak to her again. ""It's a pity when people I know believe in something that I haven't done,"" Marianna says. But she brightens whenever the conversation turns to baby Veronika. Marianna has returned to blogging and in a recent post told readers to stick around if they were interested in ""cosmetics, nappies and the everyday life of a new mum"". Her message to those who want to send her hate was ""go in peace"". But unwillingly finding herself at the centre of an information war - as the military conflict continues - has changed Marianna's life forever. ""You know, for now I'm not thinking about my hopes or making plans, because we don't know what tomorrow will bring."" Listen to War on Truth on BBC Sounds"
Marjorie Taylor Greene: Twitter bans congresswoman over Covid misinformation,"Twitter has permanently suspended the personal account of the US Congresswoman Marjorie Taylor Greene for repeated violations of its rules around coronavirus misinformation. The action against the Republican lawmaker came under Twitter's strike system, which identifies posts about the virus that could cause harm. The company had previously suspended the Georgia congresswoman four times. Rep Greene said the ban proved that the company is ""an enemy to America"". In a lengthy statement posted to the social media outlet, Telegram, the 47-year-old said ""social media platforms can't stop the truth from being spread far and wide"" and accused Twitter of aiding unidentified enemies in ""a Communist revolution"". Her official congressional account, which staffers appear to post on infrequently, remains active. The congresswoman's ban comes after she had tweeted on Saturday, falsely, about ""extremely high amounts of Covid vaccine deaths"" in the US. In a statement issued to the BBC, a Twitter spokesperson said that Rep Greene has been banned for ""repeated"" violations of its coronavirus misinformation policy, which allows four ""strikes"" with varying suspensions from the platform, before issuing a permanent ban. The social media giant had issued her with a fourth strike in August after she falsely posted that coronavirus vaccines were ""failing"" and called on regulators not to approve new shots. ""We've been clear that, per our strike system for this policy, we will permanently suspend accounts for repeated violations of the policy,"" the spokesperson said. Since her election in 2020, Rep Greene has become one of Washington's most controversial politicians. She has been a vocal supporter of former President Donald Trump's unsubstantiated claims that the 2020 presidential election was rigged and has in the past been associated with the QAnon conspiracy theory. Despite the US struggling to contain the coronavirus, from which more than 825,000 people now died, she has been a determined opponent of measures designed to tackle the virus. She has frequently called into question the efficacy of vaccines and has regularly been fined for refusing to follow Covid guidelines in Congress, including those regarding mask-wearing on the House floor."
Mayday: How the White Helmets and James Le Mesurier got pulled into a deadly battle for truth,"The British man behind the Syrian civil defence group, the White Helmets, found himself at the centre of a battle to control the narrative of the Syrian war. Russian and Syrian propagandists accused his teams of faking evidence of atrocities - and convinced some in the West. The battle for truth formed a backdrop to James Le Mesurier's sudden death in Istanbul in November 2019. With the setting sun reflecting in the water and the lights of Istanbul twinkling on the horizon, the wedding guests sat around lantern-lit tables: diplomats from several countries, military officers, journalists and activists who had flown in from around the world to see James Le Mesurier get married. A dashing former army officer in his 40s, Le Mesurier had made his name as the co-founder of the White Helmets - the group of several thousand young Syrian men and women who pulled survivors and bodies from the rubble of bombed-out buildings in rebel-held areas of the war-ravaged country. The woman he was marrying, Emma Winberg, once worked for the UK Foreign Office but had latterly been helping him manage the White Helmets. She was his third wife. The couple lived in a traditional white wooden house overlooking the Marmara Sea on Buyukada island, off the coast of Istanbul. The small island once had a reputation for hosting subversives and spies - Trotsky lived there in a similar wooden house a few years before his fateful meeting with the icepick in Mexico. These days it's popular with journalists, artists and those wanting to escape the chaos of the city. The wedding party, in summer of 2018, was held in the garden of the couple's home with the bride and groom dressed like old-fashioned movie stars. Le Mesurier was carried on the shoulders of his Syrian guests as they bounced him around in a traditional arada sword dance - his face flushed and glowing. It was a romantic setting and it was obvious the couple was very much in love. But if you had been able to listen in to the guests, you wouldn't have heard the usual wedding chatter - the main topic of conversation among the champagne and canapes was the ongoing conflict in Syria. The war was always present - even on their wedding day. They found it impossible to separate their work and their private lives. Emma knew their future together wouldn't be stress-free. ""We often said, as bad as it gets, we will have each other. We knew it would be an adventure,"" she says. And after the fairy-tale wedding things did get bad - far worse than Emma could have imagined. In just 18 months, James was dead. Spoiler alert: This is the story told in the BBC's 11-part Mayday podcast - if you prefer to listen to the audio please click here, otherwise read on (this story is a 23-minute read) On 11 November 2019 at around 05:00, a worshipper on his way to morning prayers discovered James Le Mesurier's crumpled body lying on the cobblestones in a narrow alleyway in Istanbul. He had apparently fallen from the apartment above his office, three floors up. Emma was still asleep in their bed when the police banged on the door and woke her. Turkish detectives questioned her and took her DNA and fingerprints before forensically scouring the scene. There were concerns that Le Mesurier had also been murdered by foreign agents, like the Saudi journalist, Jamal Khashoggi a year earlier, almost to the day. As the news of the 48-year-old's death broke around the world, lots of people - including many friends and associates - assumed he had been murdered. The White Helmets were a thorn in the side of the Syrian and Russian governments, bearing witness to the bombing and killing of innocents and posting the videos online. In Moscow the television news described his death as a ""purely English murder"" claiming he had been finished off by his ""MI6 handlers"" when he stopped being useful. Syria's President Bashar al-Assad later gave an interview where he likened Le Mesurier's death to that of Jeffrey Epstein, saying both men knew too many secrets to be allowed to live. The British government was quick to dismiss such allegations. ""The Russian charges against him that came out of the Foreign Ministry that he was a spy - categorically untrue,"" said Karen Pierce, the UK ambassador to the UN. ""He was a real humanitarian, and the world and Syria in particular is poorer for his loss."" Digging into his past it seems that at one point Le Mesurier did want to be a spy. After leaving the army he applied to join MI6 and - on paper at least - he looked a perfect fit. He aced the application process, but he was turned down at vetting; it took him months to recover from the disappointment. An old friend, Alistair Harris, describes Le Mesurier as ""Lawrence of Arabia-esque"" - an image friends say he liked to cultivate. He had a taste for the finer things in life, and lived in a series of homes on islands. During several years living in the Gulf, he would regularly travel into town from his home on Futaisi island, Abu Dhabi, standing at the wheel of a boat wearing a suit and brogues, his tie flapping in the wind. But he was never in the Security and Intelligence Services says Harris, a former UK diplomat who worked with Le Mesurier on several projects in the Middle East. The son of a decorated colonel, Le Mesurier earned a degree in international politics and strategic studies before graduating top of his class from Sandhurst military academy. Friends from that time describe him as an incredibly talented soldier, head and shoulders above the others in strategy and communications but ""too much of a nice guy for anyone to begrudge him it"". He spent the next decade in the Army but left after becoming disillusioned with the failures of the West to prevent atrocities in Kosovo, where he served as an officer. By 2004 he was working as an adviser to the new Iraqi government, but again he became exasperated by what he saw as wasted opportunities and money squandered on projects which failed to rebuild the country or win the support of its people. So when, in 2011, he was invited by Alistair Harris to move to Turkey and manage civil society projects across the border in Syria, he jumped at the chance. A democratic uprising, which the Syrian government had attempted to crush by force, had become a civil war, and government-run services were absent in rebel-held areas. As head of the Istanbul office of Harris's organisation, Ark, one of the projects Le Mesurier's took on focused on training young Syrians to act as firefighters, ambulance drivers and rescuers. Young men and women were already rushing in to help their relatives and neighbours whenever a bomb landed on a residential area, flattening apartments and trapping the residents inside - but often without the necessary skills. Le Mesurier felt that here at last was an inspiring Western-funded project. In a dark complex war, these were heroes: local people, instinctively trusted by their own communities, doing what they could in a time of crisis. He brought them all together in one organisation and got them professionally trained by the Turkish earthquake rescue specialists, Akut. One of Le Mesurier's colleagues at Ark, Shiyar Mohammed, remembers that before this vital training, volunteers would rush into a bomb site wanting to help, but without any idea what they were doing - which sometimes made things considerably worse. ""They hadn't even heard of things like maintaining an open airway,"" says Mohammed. ""Somebody with a neck injury would get picked up from his arms and legs and put on the back of a pickup truck."" Le Mesurier and his team pulled in funding from the British, French, Dutch, Japanese, German and Canadian governments: one of his talents was persuading diplomats to part with their country's money. Once the trainees returned to their neighbourhoods with their new civil defence skills, Le Mesurier began securing funding for equipment - shovels, medical supplies and hard hats. There weren't enough of the red helmets meant for firefighters, so they ordered white ones - and these helmets would eventually earn the rescuers their nickname. But at Ark the White Helmets were just one of many projects and Le Mesurier wanted to focus on them exclusively, so in 2014 - with Harris's blessing - he set up his own not-for-profit organisation, Mayday Rescue. Speaking to the BBC in 2014, Le Mesurier described the rescuers as ordinary people: ""Former bakers, former builders, former students who... chose to stay with very little equipment, and at the beginning with no training whatsoever, to respond to bomb attacks, respond to shellings and to try to save their fellow Syrian civilians."" While rescue operations were taking place in Syria, Le Mesurier was in Istanbul, hundreds of miles away. The only way he could find out what was happening on the ground was by watching videos of the new trainees in action. So he equipped the White Helmets with Go-Pro cameras attached to their hard hats. Before long, films of the White Helmets' daring rescues were going viral on social media. You can still find them on their Facebook page: hundreds of videos showing men and women in fleece jackets digging, sometimes for hours, through rubble and blocks of concrete, to the sound of cries from those trapped below. Often they pull out corpses - many of them dead children, whose parents are seen wailing over their tiny bodies. Sometimes they manage to pull people out alive, dusty and blood-splattered, who are rushed into ambulances. Much of the footage showed the destruction caused by Syrian and Russian war planes. The Syrian Air Force's weapons of choice were oil barrels stuffed with explosives - barrel bombs - which were dropped from helicopters on to rebel neighbourhoods. Occasionally the rescuers themselves can be seen weeping - a reminder that they are local people and that the victims were probably people they knew. One incident in Aleppo in 2014 was filmed in detail: It's night and a lot of people are panicking, frantically digging for their neighbours who are buried under concrete following an aerial attack. A woman caught in the rubble is rescued relatively quickly, but her two-month-old baby is still trapped under layers of debris. The White Helmets are filmed removing the concrete piece by piece until they can see the baby's head, but they continue to dig until finally they can access the baby's body and a rescuer called Khaled Omar Harrah is able to pull him out. ""We saved a baby. It was an incredible accomplishment for all of us,"" says Shiyar Mohammed. He remembers it as a moment of elation, feeling that all their hard work and the training sessions had been worth it. But their joy was tempered by the realities of war. ""This was just one baby out of thousands and thousands of other babies who have died, who couldn't be reached,"" he says. That scene of the baby's rescue had a huge impact in the West. It was the first time that a lot of people had seen the work of the White Helmets, and many were very moved. Le Mesurier explained to the BBC that Khaled was a former painter and decorator, who became a civil defence volunteer after his own street was heavily bombed. The baby was under seven feet of concrete and the rescue took 19 hours to complete. ""The work that they do is absolutely humbling,"" he said. But for cynics, the baby-rescue drama seemed a little too slick. Could the whole thing have been stage-managed by Le Mesurier and the White Helmets to gain support and extra funding, they wondered? And in some more radical circles - where everything financed by the West was seen as tainted by an imperialist agenda - the White Helmets started being accused of producing propaganda to push for intervention in the war. The videos were not stage-managed but the rescuers were deliberately documenting what they believed were war crimes, including the indiscriminate bombing of civilian apartment buildings, markets, schools and hospitals. And while the White Helmets were not calling for Western boots on the ground, they were pushing for the declaration of a no-fly zone enforced by foreign governments. There is also no doubt that the videos were tremendously helpful for fund-raising. By the time a Netflix documentary about the rescuers won an Oscar in 2017 Le Mesurier's organisation, Mayday Rescue, was receiving millions of dollars from states around the world including the USA, France, Britain, Germany, Holland, Japan and Qatar. The money was used to run training camps for the rescuers and to send equipment across the border into Syria, including fire trucks and ambulances. But the Syrian and Russian governments insisted that James Le Mesurier and the White Helmets were manipulating the truth. According to their account the Syrian state, with Russia's help, was protecting a loyal and grateful population from evil jihadists, some of whom were dressed as White Helmets. The Syrian president, Bashar al-Assad repeated these accusations in televised interviews and Russian diplomats began publishing what they said was evidence of the White Helmets using film sets to produce faked rescues. Two injured children - Omran and Aya - found themselves at the heart of this upside-down story of the war. In the summer of 2016 a Russian bomb fell on the Al-Qaterji neighbourhood in rebel-held East Aleppo. When it exploded it took out the home of the Dagnish family. When the White Helmets arrived on the scene they pulled five-year-old Omran from the debris along with his parents and baby brother. His older brother didn't survive. There's footage of little Omran, being carried by a White Helmet and put into the back of an ambulance. He's tiny and monochrome - covered head to toe in brick dust like a little grey ghost. He sits there, expressionless, utterly dazed. Omran's photo was on the front page of newspapers around the globe. Another child whose face appeared on our TVs here in the West, was a little girl called Aya. The eight-year-old was filmed in a hospital in Homs, in western Syria. She had been hiding under a table when the ceiling of her home collapsed on her. A week after Aya's story was broadcast on CNN, the Syrian president gave an interview to Swiss TV where he was confronted with a photo of Omran. Unflustered, he replied that Omran and Aya were just props, siblings being used by the White Helmets in fake videos. And he claimed the rescuers had used them not just once, but several times in different videos. When journalists (including Channel 4 and France 24) looked into the claims, they found that they were false. Aya was confused with another child, pictured in the arms of three different people, but that was at a single rescue event where the pictures were taken moments apart. Journalists also tracked down witnesses, including Omran's father, who confirmed they had been involved in real bombings. In another ""discovery"" of fake videos, the Russian Embassy in South Africa tweeted a photograph purporting to show the White Helmets mid-shoot, with dressing rooms in the background and a clapper board in front of the camera. The photograph was quickly identified as having been lifted from the set of a real film, called Revolution Man. In a bizarre twist, the feature film, financed by the Syrian Ministry of Culture, was about a corrupt Western journalist who travels to rebel-held areas of Syria and finds himself helping the White Helmets to fake videos. The White Helmets in the photograph weren't actors working to discredit the Syrian state, they were actors working for the Syrian state. What the Russian and Syrian governments say about the war is unlikely to have much influence on most people in the UK, but they are not alone in spreading these stories about the White Helmets - a network of sympathetic Western bloggers and activists have amplified their ideas. The most prolific among them is Vanessa Beeley, a British diplomat's daughter who quit her job in manufacturing about a decade ago in order to highlight what she saw as injustices in the Middle East. Beeley began travelling to Gaza to report on the suffering of ordinary people there. She set up a citizen journalist blog and began posting articles about what she saw. When the war in Syria began in earnest she, along with a small group of other pro-Palestinian activists, became convinced that the uprising had been instigated by Western proxies. She soon turned her attention to the White Helmets, accusing the organisation of being a Western-created disinformation operation masterminded by a British spy - James Le Mesurier. She took up the allegation that they were faking videos, and also put great emphasis on the idea that they were jihadists, who had been taking part in executions. The Syrian state granted her visas and offered her government-guided tours of recently captured areas, where Islamist logos on the walls of White Helmets premises were pointed out to her. What Beeley's videos show is evidence that a variety of groups, some of them jihadists, have operated in the same areas as the White Helmets and possibly used the same buildings - not that the rescuers and Islamists ever worked together. Nevertheless, there are other photographs and videos online that seem to show individual White Helmets supporting jihadists - from the so-called Islamic State group or the al-Nusra Front (al-Qaeda's representatives in Syria) - either cheering their arrival in an area, or appearing to assist in an execution by removing the body afterwards. ""There's no way to deny it,"" says Nur (not his real name) who helps manage the White Helmets' media online. ""Former volunteers were in pictures waving flags."" In the early days, in a few isolated cases, rescuers joined the White Helmets having left jihadist organisations, he says. In other cases individuals might have seen the jihadists as a possible solution to the bombs that were raining down on them from Syrian government aircraft - but he says the organisation quickly sacked anyone who showed such sympathies. Le Mesurier helped put a code of conduct in place which required independence from all armed groups, among other things, and all the rescuers were trained to understand its importance. As for the executions, Nur explains, one of the jobs of the White Helmets is to replace undertakers in rebel-controlled areas. ""Someone has to respectfully deal with the bodies and get them to their families,"" he says, adding that they were just informed when and where an execution would take place The White Helmets say their impartiality and adherence to humanitarian principles has been the secret to their survival as an organisation through so many years of war and in so many different areas with different groups in control. ""There have been multiple different examples of White Helmets teams, responding to buildings, not knowing who is trapped inside, and they continue regardless,"" James Le Mesurier told Dutch TV in 2015. ""They have rescued regime soldiers from under piles of rubble, and they do so neutrally and they do so impartially. For them what is important is saving a life. It doesn't matter who that life belongs to."" One video in 2016 left the White Helmets wide open to Vanessa Beeley's accusations of fakery. The mannequin challenge was an online fad where people pretended to be mannequins - frozen mid-action before suddenly starting to move, like a mannequin coming to life. The White Helmets had filmed a mannequin challenge of their own. In it they are frozen mid-rescue about to pull a young man out of the rubble. For their detractors this was further proof that the organisation were expert fakers. Speaking on the Russian state-funded channel Russia Today (RT), shortly after her first visit to Moscow, Vanessa Beeley called the video bizarre. ""Whatever reason the White Helmets had for doing this extraordinary event, we've seen a reaction that I believeÂ massively backfired on them,"" she said, adding that the stunt made a mockery of the suffering of the Syrian people. Listen to the 11-part Mayday podcast with Chloe Hadjimatheou on BBC Sounds When the whole scandal broke James Le Mesurier was furious. His wife, Emma, says she had never seen him so angry. ""He just thought it was the most stupid own goal. James was very frustrated because this would keep getting used and recycled on a routine basis by the White Helmets' antagonists."" I managed to track down the young Syrian who filmed the video. He wasn't a White Helmet - he was a media activist. He hoped the mannequin challenge might help people in the West connect to what was going on in Syria. It never occurred to him that it would be used as proof that the White Helmets' videos were fake. Vanessa Beeley is so convinced that the White Helmets are working for Western intelligence (and with Islamist militant groups) that she has even argued they are legitimate targets for the Syrian military. ""The White Helmets cannot be considered a humanitarian organisation, when they are embedded with a designated terrorist organisation al-Qaeda, and of course, ISIS and various other armed groups... They do not behave in any way like a humanitarian organisation inside Syria, and thereforeÂ they themselves are a legitimate target in a war situation,"" she said in an interview to UK Column News in October 2020, repeating a view she had expressed before. James Le Mesurier was horrified when he saw her tweet this idea. ""I don't really have words for it. It was clearly legitimising the targeting of civilians,"" says his wife, Emma. ""And the fact that Beeley was a UK national, and was hosted on Russia Today as an independent investigative journalist, put them at even greater risk."" Even before Vanessa Beeley's comments, Syrian and Russian states had begun employing double and triple-tap strikes in what appear to be deliberate efforts to bomb the rescuers. After a bomb falls the planes circle around waiting for the rescuers to arrive at the site before bombing a second time and sometimes delaying again before bombing a third time. Almost a quarter of all the White Helmets - there were around 4,300 at the height of the war in 2016/17- have been killed or seriously injured in the course of their work; it's one of the most dangerous jobs in the world. But perhaps Vanessa Beeley's most bizarre claim is that James Le Mesurier was involved in an organ-harvesting racket. In 2018 she was invited to speak at a joint Russian and Syrian presentation at the United Nations, sharing the floor with a Russian researcher. Apparent witnesses were shown in videos being interviewed by the researcher and saying that they had seen the White Helmets return the bodies of injured victims back to their families with all their organs missing. It is impossible to know whether the people who provided these accounts were speaking freely, and no other evidence was presented. The White Helmets say they have never heard any such claims from anyone in the areas where they operate. The accusation that Le Mesurier was involved in murder and organ theft might sound far-fetched but the fact that the ideas were presented at the UN gave them the veneer of officialdom. Misinformation about the Syrian war has become so ubiquitous it has resulted in what psychologists have called the ""illusionary truth effect"" where most people end up absorbing some of the false narratives, even on an unconscious level. When I first began looking into the White Helmets I had a feeling they were a bit dodgy, but I wouldn't have been able to tell you why or where I had heard that. All this was beginning to have a real effect on Le Mesurier. At one point, his colleagues say, when he tried to open a new bank account he was turned down because of concerns he might be involved in organ-trafficking. His wife Emma says he worried that after the war was over his reputation might be so damaged that he would never work again. Vanessa Beeley has denied being pro-Assad despite singing the praises of the presidential couple and the Syrian Army on social media. These days she lives in Damascus and drives around the city in a bright pink 1970s VW Beetle with a picture of Bashar al-Assad pasted in the back window. She declined to give me an interview but we did exchange emails. She told me she is not incentivised by any government, that she is self-funded and that her concern is getting to the truth. She also made it clear that she believes the BBC is a mouthpiece for the British government and is engaged in deliberate anti-Assad propaganda. Beeley sometimes claims to have been a finalist for the prestigious Martha Gellhorn Prize for Journalism. But when I contacted a member of the prize committee, James Fox, he told me: ""There are no finalists of the Gellhorn Prize for Journalism, and no 'runners up'. The prize does not draw up or publish such a list. The judges publish only winners or special commendations."" There are other British Assad sympathisers. One is Peter Ford, the UK ambassador to Syria from 2003 to 2006, who says the White Helmets have faked all but a handful of rescues, have been involved in beheadings, and played a crucial role in the faking of chemical attacks - all of which he believes were hoaxes. He argues that the Syrian revolution was instigated by Western governments with the intention of toppling President Assad. Ford co-chairs the British Syrian Society with Assad's father-in-law, Fawaz Akhraz, who lives in London and has recently come under US sanctions as one of the state's ""enablersÂ in perpetuating their atrocities"". These days the organisation is seen by many as a propaganda operation for the Syrian leadership, though Peter Ford is at pains to make it known that he isn't paid by the society. He has also made it clear he believes the BBC was commissioned ""by Le Mesurier's handlers"" to whitewash the White Helmets. Ford has shared a platform with The Working Group on Syria Propaganda and the Media, led by a group of British professors from some of the country's top universities, which also argues that chemical attacks in Syria have probably been faked. In 2020 three members of the Working Group gave a presentation at Portcullis House, part of the Houses of Parliament complex, focusing on a chemical attack in the Damascus suburb of Douma in April 2018. It argued that dead bodies and gas canisters had been moved and manipulated in photographs that had been presented as evidence of a chemical attack, and that this staging would have required the active participation of the White Helmets. The Douma attack is one of the most contested events in the Syrian war, with both the Syrian government and their Russian allies claiming it was a ""false-flag"" attack, perpetrated by the rebels against their own side, so that the Syrian government would be blamed - and on this occasion the US, France and the UK did in fact respond with a punitive missile strike. (In the view of the Russian and Syrian governments, all the chemical attacks Syria has been accused of are Western-sponsored fakes. The Russian Embassy in London says the White Helmets ""have performed a number of cynical actions aimed at discrediting the Syrian authorities and promoting the Western narrative centred around a regime change in Damascus. This includes fake and false-flag chemical attacks."") An investigation into the Douma incident by the Organisation for the Prohibition of Chemical Weapons (OPCW) concluded - in characteristically careful language - that there were reasonable grounds to believe chlorine gas was used and that it was delivered from the sky, which would indicate it had been dropped by Syrian or Russian government forces, as no other parties to the conflict possess aircraft. But two members of the OPCW investigation team rejected this report, alleging that the US had pressured the organisation to reach this conclusion. They questioned whether the limited amount of gas that had apparently been dropped would have killed people where they lay, and also whether the canisters could have crashed through a concrete ceiling without showing more damage. The OPCW said these former employees had not been involved in the full investigation and had not had access to all the facts and independent reports. Despite this, the Working Group found the whistleblowers' arguments convincing - but then had to explain how the more than 40 victims who had been filmed at the location of the attack had died at the same time from the same cause. One of the Working Group's members, Prof Paul McKeigue of Edinburgh University - whose area of expertise is genetic epidemiology and statistical genetics - suggested that the most likely scenario was that the victims had been executed in a gas chamber and then carried to the apartment building and posed to look as if they had died there. I contacted the spokesman of the Working Group - a former professor from Sheffield University, Piers Robinson - who told me they did not accept that their assertions were conspiracy theories. He said their output was objective and rigorous and that they consulted widely when expertise outside their own research areas was needed. James Le Mesurier's wife, Emma, says attacks like these made during his lifetime were putting him under a great deal of stress. She believes it is likely that he was also suffering from trauma after years of watching distressing videos of the White Helmets' rescues. Most of those they pulled out of the rubble were already dead, including a disproportionate number of children. In making the podcast series Mayday I ended up watching dozens of these videos - there are hundreds on their Facebook page. This stuff sticks with you, and it left people like Le Mesurier's colleague at Ark, Shiyar Mohammed, traumatised. ""Because I was subjected to so much graphic footage and so much violence. I ended up with sort of basically horrific scenes stuck in my head. Instead of the victims, I'm imagining myself to be in their place,"" he says. There was a macho culture, Mohammed says, in which Le Mesurier and his colleagues saw themselves as too tough to be affected by all the horror of the war. Mohammed admits he was naive. By the time he left Ark he was no longer able to function in his daily life, suffering from panic attacks for three or four minutes every couple of hours. How close was Le Mesurier to experiencing this kind of trauma? I asked Emma about that and instead of answering me she showed me the photos and videos he had on his mobile phone when he died. There are happy times at home on Buyukada island, hanging out with his dog Balloo, and weekends spent entertaining his two young daughters from his previous marriage. But interspersed with all these domestic scenes are images the White Helmets sent him, of tiny shroud-wrapped dead children, videos of parents wailing over corpses, a lot of horrifying images of cruelty and death. And it wasn't just the horror of the war - it was the denial of all that horror that got to him. The Syrian and Russian governments were flipping everything on its head, as he saw it, and turning the war's heroes into villains. That's why, among all those awful images on Le Mesurier's phone at the end of his life there were also countless screenshots of online messages doubting whether any of it was true and calling him a liar, an organ harvester and a jihadist. In the end, though, it was misinformation from inside his own organisation that was apparently the final straw. Although Le Mesurier excelled in wooing donors, finances proved to be his Achilles' heel. He had never been across the books at Mayday Rescue, which was dealing with tens of millions of dollars a year - he left that to his colleagues. And it was the financial fallout following a major rescue mission that proved his undoing. This time the people being rescued were the White Helmets themselves. In the summer of 2018, rescuers in the south of the country were caught between President Assad's forces and the Islamic State group. In a daring plan dubbed Operation Magic Carpet Le Mesurier organised the evacuation of 800 White Helmets and their families through three border crossings into Israel - a country which had been at war with Syria for decades. To make this happen he helped orchestrate high-level discussions with the governments of Canada, Britain, Germany and the Netherlands, as well as Jordan and Israel. The discussions continued at his and Emma's wedding, attended by some of the key players - a detailed plan was cooked up among the canapes and lamb shanks. Emma crafted a clever seating arrangement for the reception, grouping together people who needed to speak to each other. Five days later, Le Mesurier flew to Amman, Jordan, to help oversee the huge operation. He was in his element - all his talents in strategising, learned at Sandhurst and honed over his decade in the military, came into play. White Helmets and their families had been hiding for days in a town near the razor-wire fences and concrete watch towers that marked the disputed border with Israel on the Golan Heights. They had fled their homes as the Syrian military advanced on their towns. Fear of arrest and torture - they had seen videos of ""confessions"" colleagues had been forced to make - had them running with only the clothes on their backs, carrying crying, hungry children. Le Mesurier was determined to get them out. Finally, on 21 July 2018, just as the sun was setting, the Israeli military cranked open the huge metal gates at two of the border crossings to let the families through. It had taken just a few weeks to mobilise the huge international operation but it wasn't fast enough. One exit route had already become too dangerous - in the previous days it had fallen under the control of Islamic State - and half of those they hoped to rescue didn't make it out. It is not clear what happened to these 400 people, but they were advised to burn their uniforms and hide. Senior members of the White Helmets told me they believe many of those left behind were captured and tortured or killed. Le Mesurier had managed to save 400 White Helmets, but at a huge political cost. Now he and the whole organisation appeared directly connected to Israel and his detractors - ever prone to see conspiracies involving the hidden hand of Zionism - had more fuel than ever. ""It was extremely frustrating, not just that there was this relentless personal attack on him, but that some people would believe it. I remember him saying, 'Will I ever work again after this?' So I think it was a huge strain on him,"" says Robin Wettlaufer, then Canada's Special Representative to Syria and one of the people who made the rescue happen. Le Mesurier returned to Istanbul utterly depleted. He hadn't slept for days and in this exhausted state he made a fatal mistake. To cover any expenses during the rescue mission Le Mesurier had withdrawn $50,000 in cash from Mayday Rescue's safe. In the event, he only spent around $9,000. Months after his return to Istanbul his head of finance, a Dutchman named Johan Eleveld, asked where the remaining cash had gone. James Le Mesurier couldn't remember. ""He might have lost it, he might have left it at the airport. He couldn't remember,"" admits his wife Emma. ""James had made a mistake."" He would make an even bigger one. At a meeting with several senior staff members, including Eleveld, Le Mesurier took the decision to repay the missing cash out of his salary. But fearing he would look unprofessional if he publicly admitted he had misplaced such a large amount, he also decided to fake a receipt making it look as if he had replaced the unspent cash as soon as had returned from Jordan. In November 2019 an audit firm was checking operational changes at Mayday Rescue, with Johan Eleveld assisting them with their work. At some point they turned their attention to the organisation's cash books and came across the faked receipt. When they questioned Le Mesurier about it he immediately confessed. The audit firm also flagged loans and advances that had been taken by his wife, Emma, and warned Le Mesurier that he was leaving himself open to some difficult financial questions. Emma Le Mesurier says that their relationship with Johan Eleveld had been deteriorating for some time and he was avoiding their calls. Meanwhile, colleagues at Mayday Rescue say Eleveld was telling them the loan Emma had taken, which she had paid back within days, and the faked receipt amounted to fraud - and that there was a high chance Le Mesurier would face a prison sentence. Johan Eleveld said a non-disclosure agreement prevented him from talking to me, but in an email he denied saying that James might be jailed. Two nights before his death Le Mesurier wrote to the governments supporting the White Helmets saying that he took responsibility for any financial wrongdoing and offering to resign. The donors did not accept his resignation but said they would need a forensic audit and that would involve freezing Mayday Rescue's operations until a full investigation had been concluded. This meant the White Helmets' salaries, training and equipment would be withheld at a time when they were facing an escalating bombing campaign. Emma says Le Mesurier spent three tortured days believing that a stupid mistake he had made would result in harm and suffering to the most vulnerable people in Syria - those he had spent years trying to protect. He also believed that he would be publicly humiliated, and thought it was true that he might go to prison. Perhaps after years of fighting an increasingly personal disinformation campaign and seeing the brutality of war close up, James Le Mesurier was too tired to fight any more. The couple spent the evening of 10 November in their flat above the Mayday Rescue offices in central Istanbul. They had a difficult night. James went to bed and left Emma pacing the flat thinking. Around 04:00 he got up and offered her a sleeping pill and stood by the window smoking a cigarette, waiting for her to fall asleep. An hour later Emma was woken by police banging on her door. In the end, the Turkish police concluded that James's death was suicide. The detective in charge of the investigation told me a high-tech security system meant no-one else could have entered the apartment, and they found no evidence of a struggle. Six months later, an extensive independent financial investigation by Grant Thornton would conclude that Mayday Rescue's book-keeping was shoddy - but they could find no evidence of financial mismanagement or fraud by either Emma or James Le Mesurier. Trawling through years of correspondence, they unearthed emails from Le Mesurier to the finance department in the summer of 2018, soon after he had returned from the rescue mission. It turned out the money had never been missing. The emails show he kept the cash and asked the accountants to offset it from his salary. But he was so tired he had completely forgotten what he had done. Mayday Rescue went into administration in July 2020 and these days the White Helmets' finances are all managed by an American organisation called Chemonics - but as a commercial operation they charge considerably more for their services than Mayday Rescue did so the White Helmets get less of the funds. When someone kills themselves, that single act, that one moment in the thousands of moments that made up their life, ends up colouring everything. It inverts their biography so we look back at all they did through the lens of their death. And that is not always fair. James Le Mesurier was a man who lived several lives. He was a soldier, he was a Middle East traveller and an island dweller, a father and a husband and he was a humanitarian. And, like the people of Syria, he was a victim of disinformation. These days his wife Emma lives alone in Amsterdam, in an apartment they bought together on an island in the centre of the city. She spends hours sitting by a shrine she has built for James; a photograph of him, holding a bottle of wine with a cheeky lopsided smile, sits on top of the wooden box containing his ashes, surrounded by flowers and candles. ""I talk to him, and he talks back,"" she says, her voice breaking. ""He was an extraordinarily robust and resilient person. But he was exhausted and we were on the losing side. But I don't want to speculate on what James was thinking [in his final moments]. I don't think anyone has the right to do that."""
Media and tech firms join forces to tackle harmful Covid vaccine myths,"A coalition of news providers and tech companies has pledged to work together to tackle harmful misinformation about Covid-19 vaccines. The Trusted News Initiative's members include the BBC, Reuters, Facebook, Google/YouTube and Twitter. The project was set up last year to combat fake news around elections. BBC director general Tim Davie said: ""Whether it's a threat to our health or a threat to our democracy, there is a human cost to disinformation."" He said 2020 had seen ""the rapid spread of harmful disinformation and a growing number of conspiracy theories online"". The project would not prevent ""legitimate concerns"" about vaccines being aired, but would attempt to stop ""harmful disinformation myths"", Mr Davie added. False claims about the vaccines have been rife on social media. The World Health Organization has said the world is fighting an ""infodemic"" as well as a pandemic, with an overload of information - some of it false - making it difficult for people to make decisions about their health. The Trusted News Initiative said its members would alert each other to ""disinformation which poses an immediate threat to life so content can be reviewed promptly by platforms, whilst publishers ensure they don't unwittingly republish dangerous falsehoods"". YouTube, Facebook and Twitter already say they will remove harmful and misleading claims, and the companies are part of another group with fact-checkers, governments and researchers to come up with a new way of tackling misinformation. The roll-out of Covid-19 vaccines began in the UK this week. The TNI members have already been working together in an attempt to tackle harmful false news around coronavirus and about elections in the UK, US, Myanmar and Taiwan. The organisation has also announced a year-long research project into the effectiveness of different initiatives to prevent the spread of health disinformation. The other members of the TNI are the Associated Press, Agence France Presse, CBC/Radio-Canada, European Broadcasting Union, Financial Times, First Draft, The Hindu, Microsoft, Reuters Institute for the Study of Journalism and The Washington Post."
Meta requires political advertisers to mark when deepfakes used,"Meta will require political advertisers to flag when they have used AI or digital manipulation in adverts on Facebook and Instagram. The social media company already has policies on using deepfakes in place, but says this goes a step further. From January, adverts related to politics, elections or social issues will have to declare any digitally altered image or video. The worldwide policy will be moderated by a mix of human and AI fact checkers. In an announcement, Meta said this would include changing what somebody has said in a video, altering images or footage of real events, and depicting real-looking people who do not exist. Users will be notified when adverts have been marked as being digitally changed. Meta told the BBC that it would add this information to the ad but didn't go into detail on how it would be presented. Advertisers do not have to declare when small changes have been made, such as cropping or colour correction, ""unless such changes are consequential or material to the claim, assertion, or issue raised in the ad"". Meta already has policies for all users - not just advertisers - about using deepfakes in videos. Deepfakes are removed if they ""would likely mislead an average person to believe a subject of the video said words that they did not say"". The new rules require adverts relating to politics, elections or social issues to disclose any kind of digital alteration, whether done by a human or AI, before the ad goes live on Facebook or Instagram. Meta's other social media platform, Threads, follows the same policies as Instagram. It says that if advertisers do not declare this when they upload adverts, ""we will reject the ad and repeated failure to disclose may result in penalties against the advertiser."" Google recently announced a similar policy on its platforms. TikTok does not allow any political advertising, General elections are expected in 2024 in some of the world's biggest democracies, including India, Indonesia, the US and the UK. Russia, South Africa and the EU also have elections scheduled for next year. Deepfakes - where AI is used to changed what someone says or does in a video - are a growing concern in politics. In March, a fake picture of former US President Donald Trump falsely showing him being arrested was shared on social media. The image was created by AI tools. The same month, a deepfake video circulated of Ukrainian President Volodymyr Zelensky talking of surrendering to Russia. However in July, false claims that a video of US President Joe Biden was a deepfake were debunked, with the video proven to be authentic. Meta will require political advertisers to flag when they have used AI or digital manipulation in adverts on Facebook and Instagram. The social media company already has policies on using deepfakes in place, but says this goes a step further. From January, adverts related to politics, elections or social issues will have to declare any digitally altered image or video. The worldwide policy will be moderated by a mix of human and AI fact checkers. In an announcement, Meta said this would include changing what somebody has said in a video, altering images or footage of real events, and depicting real-looking people who do not exist. Users will be notified when adverts have been marked as being digitally changed. Meta told the BBC that it would add this information to the ad but didn't go into detail on how it would be presented. Advertisers do not have to declare when small changes have been made, such as cropping or colour correction, ""unless such changes are consequential or material to the claim, assertion, or issue raised in the ad"". Meta already has policies for all users - not just advertisers - about using deepfakes in videos. Deepfakes are removed if they ""would likely mislead an average person to believe a subject of the video said words that they did not say"". The new rules require adverts relating to politics, elections or social issues to disclose any kind of digital alteration, whether done by a human or AI, before the ad goes live on Facebook or Instagram. Meta's other social media platform, Threads, follows the same policies as Instagram. It says that if advertisers do not declare this when they upload adverts, ""we will reject the ad and repeated failure to disclose may result in penalties against the advertiser."" Google recently announced a similar policy on its platforms. TikTok does not allow any political advertising, General elections are expected in 2024 in some of the world's biggest democracies, including India, Indonesia, the US and the UK. Russia, South Africa and the EU also have elections scheduled for next year. Deepfakes - where AI is used to changed what someone says or does in a video - are a growing concern in politics. In March, a fake picture of former US President Donald Trump falsely showing him being arrested was shared on social media. The image was created by AI tools. The same month, a deepfake video circulated of Ukrainian President Volodymyr Zelensky talking of surrendering to Russia. However in July, false claims that a video of US President Joe Biden was a deepfake were debunked, with the video proven to be authentic."
Monkeypox wasnÂt created in a lab - and other claims debunked,"Since cases of monkeypox began to emerge in Europe, beliefs about the virus have been shared widely on social media that appear to be recycled from the Covid-19 pandemic. A common fear shared online is that restrictions on movement are being planned. One account told followers to get ready for ""monkeypox lockdowns"" and ""monkeypox tyranny"". While fears about the monkeypox outbreak are understandable, scientists say this virus is not like Covid, and most experts think its spread will be limited. It is much harder to pass on than Covid, we already have available vaccines and treatments, and people appear to be infectious only once symptoms appear - making it easier to spot and isolate. So restrictions such as lockdowns or mass vaccinations are ""really not going to be the way to respond to this"", says Prof Peter Horby, director of the Pandemic Sciences Centre at the University of Oxford. Instead, isolation measures and vaccines are currently being targeted at infected people or their close contacts. Dr Rosamund Lewis, of the World Health Organization (WHO) Emergencies Programme, confirmed there was no need for mass vaccination, and the WHO has also recommended against any travel restrictions. It's no surprise people's minds now turn to Covid when news of an unfamiliar virus breaks. But the Institute for Strategic Dialogue has noted that recent outbreaks of monkeypox were also ""reviving the spread of a set of cut-and-paste... conspiracies"" which have been used over the past two years to mislead people during the Covid pandemic Social media accounts and news outlets in Ukraine, Russia, China and the US have all made accusations that the outbreak was the result of a laboratory leak, or the use of monkeypox as a biological weapon. It's possible to identify where a virus is likely to have come from by sequencing its DNA. Geneticist Fatima Tokhmafshan likens this to scanning a barcode on a parcel to ""map the different paths [it] has taken"". The genetic sequences we have so far for the virus all trace it back to the strain of monkeypox which commonly circulates in West Africa: ""That tells us this is not something manufactured"". There were a handful of cases in the UK in 2018 and in 2021, and a larger outbreak in the US, also in 2021, each brought over by human travellers or imported animals. ""So it's entirely plausible that that's exactly what's happened this time, ""says Prof Horby, ""and it's by far the most likely scenario."" The earliest case identified in the UK in the current outbreak was traced to someone who had travelled from Nigeria. As for the idea that monkeypox escaped from a lab, ""there is absolutely no basis for that claim at all"", Prof Horby says. There are those claiming online that the current monkeypox outbreak was deliberately planned - with many pointing the finger at Bill Gates or Anthony Fauci, in an echo of Covid conspiracies. This unfounded assertion is being shared across Russia media, on the Chinese social app Weibo, and on Instagram. It can also be found on Facebook in Romanian, German, English, Arabic, French, Slovenian, Hungarian and Punjabi. The claims point to a document prepared by a US-based biosecurity organisation, the Nuclear Threat Initiative (NTI). In 2021, NTI conducted a workshop to encourage leaders from around the world to plan for the possibility of future pandemics. The participants were asked to work through a fictional scenario - a ""deadly, global pandemic involving an unusual strain of monkeypox virus... [that] spread globally"". ""The risks posed by monkeypox"", according to the NTI, ""have been well documented for years"" and cases have been on the increase, making it an obvious virus to choose for this workshop. Outbreaks of infection are a fact of life, so an organisation predicting and planning for them is not in itself suspicious. This claim has taken two forms - some point to the fact the AstraZeneca vaccine uses a virus found in chimpanzees, modified so it cannot replicate and spread. These social media posts then suggest a link between vaccines employing that chimp virus and the monkeypox outbreak. However, monkeypox is caused by a totally different type of virus to the one found in the AstraZeneca vaccine - and is actually thought to be mostly found in rodents, not monkeys. The second type of claim spreading online is that the Covid vaccine somehow suppresses your immune system, making you more vulnerable to other infections. This claim has no basis in reality. Vaccines stimulate - not deplete - your immune system, making it more effective at targeting a particular infection. While there are a very small number of cases of people having autoimmune reactions to vaccines, where your body starts attacking itself (the cause of rare blood clots after AstraZeneca), there is no evidence of vaccines suppressing the immune system or altering your ability to fight other diseases. Additional reporting by Olga Robinson and BBC Monitoring. Read more from Reality Check Send us your questions"
Myanmar coup: Does the army have evidence of voter fraud?,"A military coup fuelled by allegations of electoral fraud has led to the removal and arrest of Myanmar's democratically-elected leaders. The army's move has been condemned inside and outside Myanmar, also known as Burma, but do its claims about voter fraud stand up to scrutiny? In the days before the coup, the military declared that more than eight million cases of potential voting fraud had been uncovered relating to the 8 November election. Aung San Suu Kyi's National League for Democracy (NLD) won a landslide victory with more than 80% of the seats at stake. ""There was terrible fraud in the voter list during the democratic general election,"" General Min Aung Hlaing announced on TV after seizing power. The country's election commission failed to address their findings, says the army. Independent observers agree there may have been significant errors in the voter rolls, but no evidence that people actually committed electoral fraud has been presented. The commission has also pushed back, saying there is no evidence to support the army's claims. The US-based Carter Center, which had more than 40 observers visiting polling stations on election day itself, said voting had taken place ""without major irregularities being reported by mission observers"". Central to the military's claims are the voter lists, on which a person's name must appear so they can take part in the election. These are compiled by local administrators and are based on previous election lists and other official data. A draft was released in the summer of 2020 and an amended one again in October, which led to a period for corrections to be issued. The final lists were posted outside polling stations. The military claims to have found widespread inconsistencies and many cases of ineligible voters. In the evidence it has presented so far, it says there are nearly 10.5 million instances of irregularities. The military says it aggregated lists from different towns and then identified entries where the national registration number had been repeated - either under the same or a different name. It says it found others without a national registration number at all. We have not been able to verify this data independently because the final voter lists were removed from public view after the election, and the election commission has withheld the data, citing privacy concerns. The army claims these lists reveal instances where it is possible the same person could have voted more than once - by being registered in different places. However, the national election commission says this would not have been possible because there were effective safeguards in place. ""These persons could not cast their votes many times in a single day,"" it said in a statement, pointing to the indelible ink administered to voters' fingers, which lasts at least a week. Indelible ink is used in many elections around the world, and in Myanmar was provided by the United Nations and Japan. The dye contains silver nitrate which stains the skin on exposure to sunlight and is described as ""resistant to attempts to remove it using water, soap, liquids, home-cleansing, detergents, bleaching product, alcohol, acetone or other organic solvents"". The election commission also pointed to strict Covid-19 travel restrictions, which would have made it particularly hard to vote in multiple locations. These restrictions may also have distorted the lists in some areas, with voters registering outside their usual locality, unable to return home. Myanmar begin implementing restrictions on travel as Covid cases began to increase in the second half of 2020. This, says one local election monitoring group, Phan Tee Eain, may have resulted in ""inflated"" lists in some areas because ""they couldn't go back due to Covid"". It could have meant names appearing more than once on the overall voter lists. But there is no evidence that this led to deliberate acts of multiple voting. The military has also claimed that the voter lists contain almost five million names without associated national registration cards. This was used to cast doubt on people's right to vote, although it's not been clarified how this might have happened. It's possible to get on the voter list without official ID on the recommendation of local officials in an area, according to the election commission. These officials must certify in a letter that someone is a local resident. However, it's unlikely this would by itself account for 4.6 million discrepancies. The ID card itself is also not required at the polling station if citizenship can be demonstrated with another form of documentation. It's important to note that the national registration card is not available to everyone in the country, like the Rohingya minority in Rakhine state, who were largely disenfranchised. Voting was cancelled in some areas here, and in other regions which are home to minority groups, with officials citing security issues. It's not the first time there have been issues over voter lists in Myanmar. In 2015, when Aung San Suu Kyi's NLD also won a big majority, there were questions raised about the integrity of the voter lists, including people whose names were missing just a week before the vote. It was also known that in the months before this latest election in Myanmar, there were mistakes on the electoral roll. But clear weaknesses in voter registration in a poor country with fractured bureaucratic systems do not amount to deliberate fraud on the scale alleged by the military. Additional reporting by the BBC Burmese Service Read more from Reality Check Send us your questions"
Neil Young wants to quit Spotify over Joe Rogan's vaccine misinformation,"Neil Young has demanded that Spotify removes his music, due to vaccine misinformation spread by podcaster Joe Rogan on the streaming service. ""They can have Rogan or Young. Not both,"" wrote the star in a letter to his management and record label. Rogan has been criticised for airing vaccine-sceptical views, and promoting debunked claims about treating Covid-19 with the anti-parasite drug ivermectin. Spotify, which paid $100m for rights to the podcast in 2020, is yet to comment. Young's comments came in an open letter, which was briefly posted to his Neil Young Archives website before being removed. ""I want you to let Spotify know immediately TODAY that I want all my music off their platform,"" he wrote. ""I am doing this because Spotify is spreading fake information about vaccines - potentially causing death to those who believe the disinformation being spread by them. Please act on this immediately today and keep me informed of the time schedule. ""With an estimated 11 million listeners per episode, JRE [the Joe Rogan Experience] which is hosted exclusively on Spotify, is the world's largest podcast and has tremendous influence,"" Young continued. ""Spotify has a responsibility to mitigate the spread of misinformation on its platform, though the company presently has no misinformation policy."" Young is not the first person to raise concerns over the content of Rogan's podcast. Last month, 270 doctors, scientists and healthcare professionals signed an open letter requesting that Spotify implement a policy for dealing with misinformation because of Rogan's ""concerning history"" in discussing the Covid-19 pandemic. The letter cited an episode in which Rogan interviewed Dr Robert Malone, a virologist who worked on early research into the mRNA technology behind several Covid-19 vaccines, but who is now critical of the treatments. Both men were criticised for promoting conspiracy theories, including the false claim that hospitals are financially incentivised to falsely diagnose deaths as having been caused by Covid-19. Malone also incorrectly stated that getting vaccinated puts people who have already had Covid-19 at higher risk, and claimed world leaders had hypnotised the public into supporting vaccines, drawing parallels between the pandemic and the rise of the Nazi party in 1930s Germany. Last year, before that episode was recorded, Rogan clarified that he was ""not an anti-vax person"". ""I believe they're safe and encourage many people to take them,"" he said, while refusing to back down on claims that young people did not ""need"" the vaccine. The stand-up and TV personality also stressed that he should not be regarded a source of scientific advice. ""I'm not a doctor,"" he said. ""I'm not a respected source of information, even for me."" Spotify has removed controversial content in the past, including several episodes of Rogan's podcast featuring right-wing personalities, which were recorded before he signed his exclusivity deal with the service in 2020. It has also removed music by bands with affiliations to neo-Nazi and white supremacist hate groups. In 2018, the service announced a new policy around ""hateful conduct,"" which led to music by artists accused of physical and sexual abuse being removed from its editorial and algorithmic playlists. But the company reversed that policy three weeks later, stating in a blog post that while the policy against hate content would remain, it would not ""play judge and jury"" over artist's conduct. The company has faced further criticism in recent months, after owner Daniel Ek revealed he had invested 100 million euros (Â£85.2 million) in the defence firm Helsing, which is said to be developing AI software to support military operations identify targets on the battlefield. Several artists, including UK psychedelic musician Darren Sangita and German techno producer Skee Mask have pulled their music from Spotify, spearheading a small ""Boycott Spotify"" movement that has yet to be endorsed by any major artists. As for Young, he has removed his songs from Spotify before - quitting the service, along with Apple Music and other streaming sites, in 2015 after stating their audio quality was not good enough. At the time of writing, his music - including classic albums like Harvest and After The Gold Rush - is still available on Spotify. Follow us on Facebook, or on Twitter @BBCNewsEnts. If you have a story suggestion email entertainment.news@bbc.co.uk."
New UK centre will help fight information war,"A new centre aims to boost the UK's security through building expertise in cutting-edge technology. The Centre for Emerging Technology and Security (CETaS) will be based at the Alan Turing Institute, the UK's centre for data science and artificial intelligence. UK officials say it will help develop expertise outside government, including in publicly available information. This is proving vital in combating Russian disinformation over Ukraine. But concerns are also being raised about the government's current ""fragmented"" use of this type of open-source intelligence. There has been a widespread view that Moscow enjoyed the upper hand in using technology to fight an ""information war"" in recent years. The West appeared to be on the back foot since Russia weaponised social media to influence public opinion, most famously using fake accounts in the 2016 US presidential election. But the Ukraine conflict has revealed a shifting balance, officials say. ""In the current phase of the conflict, the balance of advantage is with those who seek the truth about progress in Russia's campaign,"" two anonymous government officials wrote in a paper issued to mark the launch of the new government-funded CETaS. A key reason has been what's called open-source intelligence. This relies on analysing publicly available data, like videos on social media, in contrast to ""secret"" intelligence that spies obtain through covert means like intercepting communications or running agents. ""The Ukrainian conflict has shown us the importance of data analysis and technology for exposing Russian disinformation campaigns,"" Paul Killworth, deputy chief scientific adviser for national security, told the BBC. ""Centres such as [CETaS] provide another tool in the armoury of open societies. It gives us more teams of specialists able to investigate claims."" US and UK governments have been active in using open-source information to be able to talk publicly about what their secret sources are indicating. But this type of information is most powerfully used by those outside government to reveal what is really happening on the ground. On the evening of 23 February, graduate students in Monterey, California, who had been using publicly available satellite imagery to watch Russian tanks on the border with Ukraine, saw Google Maps showing a traffic jam inching towards the Ukrainian border. They tweeted that a war seemed to have started, long before any official announcement. Since the conflict started, others have used data to investigate possible war crimes and to contest Russian narratives. The extent to which investigations have been pioneered by citizen-journalists and investigative groups like Bellingcat is a positive, according to Mr Killworth. ""If we went back perhaps a decade or so, if you were looking at advanced analytical capabilities, the ability to manage large amounts of data and conduct cutting-edge analysis, this was the preserve of government,"" he said. ""It was carried out behind barbed wire in very, very tightly controlled circumstances. A few decades on and the amount of cutting-edge, IT tools and analytics and open-source data available to investigative journalists, to citizens groups, to academics has grown dramatically."" Harnessing new technology to maintain an edge is part of the new centre's mission. This could include fields like automated recognition of military vehicles from satellite imagery or social media, allowing human experts to spend their time on trickier problems. Tools are already allowing greater translation and interpretation of foreign language material. Artificial Intelligence can also be used to reveal patterns in behaviour or language that indicate the presence of an organised disinformation network on social media. Dealing with these challenges at speed is one of the ambitions for the centre which aims to build a community that can keep pace with the growing amount of data and tools to exploit it. Another paper issued as part of the centre's launch, and jointly authored with the think tank RUSI, raises questions about whether government is organised to adequately exploit open-source intelligence. It warns of current ""fragmentation"" of activity within government and says it needs to be elevated to become a ""core"" intelligence discipline. One official told the authors that even though 35% of intelligence comes from open source, it receives only 1% of funding relative to classified sources. More focus needs to be made on building up the skills and breaking down barriers, with government analysts sometimes unable to access open-source information because of regulatory and technical constraints. A crucial problem is cultural bias. Intelligence agencies have often been reluctant to makes use of open-source information and decision makers are more likely to pay attention to a piece of information with ""SECRET"" stamped across it than something found online, even if it is just as relevant, the paper says. Experts also warn Russia is likely to adapt and up its game. This might mean spending more time amplifying real voices in the West which support its message, something which is harder for governments and social media companies to counter, or by developing better ""deepfake"" technology. Russia's narrative has also not been challenged within its own borders because it closed down its information space, and the government authors of the CETaS report say Moscow's messages may also be more effective beyond the West. ""Outside the Western ""information theatre"", Russia is having more success: audiences in China, India, Africa and the Middle East have a more sympathetic view of Russia's actions,"" they warn."
Nicaragua accused of running internet troll farm,"The company behind Facebook and Instagram has removed more than 1,000 fake accounts in Nicaragua which it says were part of a disinformation campaign by the government. Meta said those who ran the accounts included staff at the telecoms regulator and the Supreme Court. It comes ahead of presidential elections this weekend with the president's main challengers jailed. The United States has described the election as a sham. The accounts were controlled by Daniel Ortega's government and the FSLN ruling party, Ben Nimmo, threat intelligence lead for Facebook parent company Meta, told the AFP news agency. Facebook closed 937 accounts, 140 pages and 24 groups, as well as 363 Instagram accounts, he said. All accounts were shut down last month. The disinformation campaign allegedly began in 2018 as an effort to denigrate the opposition.  It spread to other platforms, including TikTok and Twitter. In 2018, Mr Ortega's regime cracked down on protests, killing more than 300 people. Tens of thousands of have since fled into exile. ""The goal was to flood the online conversation in Nicaragua with pro-government and anti-opposition messages,"" he said. Facebook said in a statement the network was ""a coordinated effort... to corrupt or manipulate public discourse by using fake accounts to build personas across platforms and mislead people about who's behind them"". Analysis suggests that people were posting on the accounts as their day job, with a break for lunch. The government has been arresting opponents and critics since June on charges of treason or money-laundering. Many say the charges are baseless and designed to facilitate Mr Ortega's re-election. The EU's foreign policy chief recently called Nicaragua ""one of the worst dictatorships in the world""."
Nigeria elections 2023: How influencers are secretly paid by political parties,"A BBC investigation has discovered that political parties in Nigeria are secretly paying social media influencers to spread disinformation about their opponents ahead of general elections in February. The BBC's Global Disinformation Team has spoken to whistle-blowers working for two of Nigeria's political parties, and prominent influencers who have described it as ""an industry"". The whistle-blowers say parties give out cash, lavish gifts, government contracts and even political appointments for their work. We changed their names to protect their identity. ""Yemi"" is a prominent strategist and ""Godiya"" a politician. ""We've paid an influencer up to 20m naira ($45,000; Â£37,000) for delivering a result. We've also given people gifts. Other people prefer to hear: 'What do you want to do in government, be a board member, be a special assistant?',"" says Godiya. Situation rooms are commonplace in the run-up to an election. It's where political parties strategise, develop plans and monitor their campaigns' success. But in the rooms the whistle-blowers described to us, there was another function: following how false narratives assigned to influencers were performing. Strategist Yemi says fake stories are developed to improve their candidates' chances: ""You can deliberately misinform in a suitable way for you."" The BBC has spoken to multiple influencers who have confirmed that payment in exchange for false political posts is widespread. One influencer who asked not to be named - with almost 150,000 Facebook followers - told us he is paid by political parties to post completely false stories about political opponents. He says he does not do it openly but rather plants false stories through other micro-influencers he hires. Separately, Rabi'u Biyora is a major influencer known for supporting the governing All Progressives Congress (APC) party. He told us he was ""wooed"" by an opposition party to stop promoting the APC's candidate, and give his support to their candidate instead. Posts on his Facebook timeline confirm he did just that. He told us he did not receive gifts of any kind to do so. But we discovered a Facebook post from 2019 in which he said he received a car and money from a party in exchange for his support on social media. We put this finding to him, but he stopped responding to us. With an estimated 80 million Nigerians online, social media plays a huge role in national debates about politics. Our investigation uncovered different tactics used to reach more people on Twitter. Many play on divisive issues such as religious, ethnic and regional differences. In July, influencers widely shared posts associating Kashim Shettima, the APC's candidate for vice-president, with members of the Islamist militant group Boko Haram. This false narrative gained momentum on Twitter and was shared thousands of times, spilling onto WhatsApp and other platforms. Using reverse image search, we found that those in the picture with Mr Shettima were nomadic Fulani parents whose children he had enrolled in secular schools in 2017, not members of Boko Haram. A month later, influencers promoted a claim without evidence that Labour Party presidential candidate Peter Obi was linked to, and following orders from, the Indigenous People of Biafra (Ipob) - a separatist movement designated in Nigeria as a terror group. His party denies this. Those who shared this information included Reno Omokri - special assistant to former opposition President Goodluck Jonathan - who has more than two million followers on Twitter. When approached for a comment, Reno Omokri said he stands by his accusations, but insists he has not been paid by the main opposition People's Democratic Party (PDP) to campaign on their behalf. Meanwhile, false claims that the PDP presidential candidate, Atiku Abubakar, fell ill and was rushed out of the country have been shared several times on Twitter. Godiya, the politician we interviewed, says political parties tell influencers to elicit as much emotion as they can with their paid posts. ""We use images that may not even be relevant to the story we are trying to spin. We can take pictures from East Africa in the 1990s in warzones and attach them to a tweet about how my ethnic group is being killed. When people get emotional they retweet, they like, and it gets traction,"" she says. According to the whistle-blowers, the hired influencers are sometimes given an idea that they should frame in their own words. At other times, they are given the actual tweets that need to be published at specific times. They say influencers are paid based on the number of followers they have. They also say payment happens mostly in cash to avoid a paper trail. It is not illegal for political parties to hire social media influencers in Nigeria, but spreading disinformation on social media is a breach of the country's laws and Twitter's policy. The BBC has asked Nigeria's main political parties, APC, PDP, and the Labour Party, about the whistle-blowers' allegations. They did not reply to our request for comment. In response to our findings, Twitter has taken down some of the accounts we reported to them and said it had a responsibility to protect electoral conversations from interference, manipulation, and false information. However, there are concerns about the platform's capacity to tackle misinformation in Africa after Elon Musk's takeover of the company, when its continental headquarters in Ghana was closed and nearly all its staff fired. The BBC has reached out to Twitter again after these changes, but received no response. Idayat Hassan, director at the Centre for Democracy and Development, says the activities of these influencers amounted to ""political interference"". ""It is undermining trust in democracy, undermining trust in the electoral system, and it is instigating conflict,"" she says. But politician Godiya sees it a different way, and defends the tactic: ""It is a game. Somebody had to win, and God help me, I will not be on the losing side."" A BBC investigation has discovered that political parties in Nigeria are secretly paying social media influencers to spread disinformation about their opponents ahead of general elections in February. The BBC's Global Disinformation Team has spoken to whistle-blowers working for two of Nigeria's political parties, and prominent influencers who have described it as ""an industry"". The whistle-blowers say parties give out cash, lavish gifts, government contracts and even political appointments for their work. We changed their names to protect their identity. ""Yemi"" is a prominent strategist and ""Godiya"" a politician. ""We've paid an influencer up to 20m naira ($45,000; Â£37,000) for delivering a result. We've also given people gifts. Other people prefer to hear: 'What do you want to do in government, be a board member, be a special assistant?',"" says Godiya. Situation rooms are commonplace in the run-up to an election. It's where political parties strategise, develop plans and monitor their campaigns' success. But in the rooms the whistle-blowers described to us, there was another function: following how false narratives assigned to influencers were performing. Strategist Yemi says fake stories are developed to improve their candidates' chances: ""You can deliberately misinform in a suitable way for you."" The BBC has spoken to multiple influencers who have confirmed that payment in exchange for false political posts is widespread. One influencer who asked not to be named - with almost 150,000 Facebook followers - told us he is paid by political parties to post completely false stories about political opponents. He says he does not do it openly but rather plants false stories through other micro-influencers he hires. Separately, Rabi'u Biyora is a major influencer known for supporting the governing All Progressives Congress (APC) party. He told us he was ""wooed"" by an opposition party to stop promoting the APC's candidate, and give his support to their candidate instead. Posts on his Facebook timeline confirm he did just that. He told us he did not receive gifts of any kind to do so. But we discovered a Facebook post from 2019 in which he said he received a car and money from a party in exchange for his support on social media. We put this finding to him, but he stopped responding to us. With an estimated 80 million Nigerians online, social media plays a huge role in national debates about politics. Our investigation uncovered different tactics used to reach more people on Twitter. Many play on divisive issues such as religious, ethnic and regional differences. In July, influencers widely shared posts associating Kashim Shettima, the APC's candidate for vice-president, with members of the Islamist militant group Boko Haram. This false narrative gained momentum on Twitter and was shared thousands of times, spilling onto WhatsApp and other platforms. Using reverse image search, we found that those in the picture with Mr Shettima were nomadic Fulani parents whose children he had enrolled in secular schools in 2017, not members of Boko Haram. A month later, influencers promoted a claim without evidence that Labour Party presidential candidate Peter Obi was linked to, and following orders from, the Indigenous People of Biafra (Ipob) - a separatist movement designated in Nigeria as a terror group. His party denies this. Those who shared this information included Reno Omokri - special assistant to former opposition President Goodluck Jonathan - who has more than two million followers on Twitter. When approached for a comment, Reno Omokri said he stands by his accusations, but insists he has not been paid by the main opposition People's Democratic Party (PDP) to campaign on their behalf. Meanwhile, false claims that the PDP presidential candidate, Atiku Abubakar, fell ill and was rushed out of the country have been shared several times on Twitter. Godiya, the politician we interviewed, says political parties tell influencers to elicit as much emotion as they can with their paid posts. ""We use images that may not even be relevant to the story we are trying to spin. We can take pictures from East Africa in the 1990s in warzones and attach them to a tweet about how my ethnic group is being killed. When people get emotional they retweet, they like, and it gets traction,"" she says. According to the whistle-blowers, the hired influencers are sometimes given an idea that they should frame in their own words. At other times, they are given the actual tweets that need to be published at specific times. They say influencers are paid based on the number of followers they have. They also say payment happens mostly in cash to avoid a paper trail. It is not illegal for political parties to hire social media influencers in Nigeria, but spreading disinformation on social media is a breach of the country's laws and Twitter's policy. The BBC has asked Nigeria's main political parties, APC, PDP, and the Labour Party, about the whistle-blowers' allegations. They did not reply to our request for comment. In response to our findings, Twitter has taken down some of the accounts we reported to them and said it had a responsibility to protect electoral conversations from interference, manipulation, and false information. However, there are concerns about the platform's capacity to tackle misinformation in Africa after Elon Musk's takeover of the company, when its continental headquarters in Ghana was closed and nearly all its staff fired. The BBC has reached out to Twitter again after these changes, but received no response. Idayat Hassan, director at the Centre for Democracy and Development, says the activities of these influencers amounted to ""political interference"". ""It is undermining trust in democracy, undermining trust in the electoral system, and it is instigating conflict,"" she says. But politician Godiya sees it a different way, and defends the tactic: ""It is a game. Somebody had to win, and God help me, I will not be on the losing side."""
Nigerian elections 2023: False claims and viral videos debunked,"False claims about Nigeria's electoral commission sparked concern as voters cast their ballots on Saturday. Videos containing old and misleading footage filmed in previous polls were also circulating. While Nigerians await the official election results we have looked into some of these claims. Social media in Nigeria, especially Twitter, has played a huge role in the dissemination of credible election-related news but at the same time it has been a major source of disinformation and misinformation. One disinformation trend we monitored was the sharing of videos purporting to show ballot-stuffing during the elections. In Nigeria, people vote by putting their thumb print beside the logo of the party of their choice. Using reverse-image search tools, the BBC traced some of the videos of people thumb-printing ballots to elections in 2021 and 2019. Another viral clip showed people being coached on the best way to print their thumb on ballot papers while voting for a particular party. Both sets of videos had strong regional and religious undertones and were widely shared on WhatsApp groups and Twitter. A popular politician in Nigeria was one of the people who shared the video of people being coached on how to thumb print. The video appears to be voter sensitisation projects carried out by the opposition Labour Party in parts of Nigeria. The BBC has contacted the party for comment but they are yet to respond. The BBC could not establish where the videos were recorded. But we know that the ballots shown in at least one of these viral videos were not real. They are clearly marked ""specimen"" and bear little resemblance to the standard electoral commission ballot papers, seen below on the left. A bold claim that has gained traction, pushed largely by influencers on social media, alleges that Nigeria's Independent National Electoral Commission (Inec) is rigging the election count to favour the governing All Progressives Congress (APC) party. Videos shared by accounts with large followings also suggested that Inec's server had been breached and unknown people were inputting fabricated election results. Checks showed that the alleged website was not that of the electoral commission and was, in fact, a fake website that replicated the interface of Inec's election results viewing portal. The web address has inconsistencies typical of a phishing website, such as having numbers instead of an actual website name. Inec released a statement saying that although its server was ""slow and unsteady"" due to the amount of activity going on, it was not compromised. There were also claims that Inec used the Bimodal Voter Accreditation (BVAS) machine to add votes to the tally of a particular candidate. Inec denies this. In 2021 Nigeria's electoral commission introduced the BVA machine to simplify the verification and accreditation of voters on election day. But it was also to be used in uploading results on the commission's result viewing portal. Some social media users claimed without evidence that machine failures had happened because Inec was deliberately sabotaging the electoral process. But Inec, in a statement it released to counter the viral allegation, said some machines failed to accredit voters or upload election results in some areas because of technical problems or the absence of an internet connection. Some political parties, including those of the three leading opposition contenders, have called for the polls to be cancelled because of the issues relating to the BVAS, among other complaints. Social media influencers and politicians with hundred of thousands of followers shared fake and misleading results. This has contributed to the questioning of the official results released by Inec. Bashir Ahmad, a spokesman for President Muhammadu Buhari, was one of those who shared results later confirmed to be fake when Inec released the official results. Mr Ahmad has since deleted his tweet. One person who featured prominently in disinformation messages shared online was former Nigerian President Olusegun Obasanjo, who was a member of the Peoples Democratic Party (PDP) but has since thrown his support behind Peter Obi of the Labour Party. In the lead up to the election, allegations of Mr Obasanjo intervening to stop a lorry load of Chadians who were allegedly coming to vote in the election was shared widely using WhatsApp. The message said a junior immigration officer alerted the former president of 1.5 million Chadians with Nigerian voter cards travelling to Kaduna in north-west Nigeria in 100 trucks, but that Mr Obasanjo had instructed his personal security to block all roads and capture the foreigners. Checks in Nigeria show no reports of arrests of Chadians trying to enter the country. As a former president, Mr Obasanjo does not have the power to block roads or instruct security agencies to intercept people or goods coming into the country. Moreover, a reverse image search confirms that one of the pictures used to spread the story was in fact from the News Agency of Nigeria in May 2021 - when it reported that the Nigeria Security and Civil Defence Corps stopped Fulani herders from entering Kwara state. Another picture was from 2021, when the security network, Amotekun, detained another set of Fulani herders. Popular musician and activist Charles Oputa, also known as Charly Boy, shared this false story to his Instagram handle. He has since deleted it. Another false claim trending on social media and messaging apps such as WhatsApp is that Mr Obasanjo had ""stormed"" the Inec collation centre in Abuja with the ""real results"" of the elections, which he had supposedly gotten from the servers. But there is no credible possibility that Mr Obasanjo could have intercepted results that were yet to be uploaded to Inec's server. BBC reporters at the collation centre did not see any evidence of such an event happening. False claims about Nigeria's electoral commission sparked concern as voters cast their ballots on Saturday. Videos containing old and misleading footage filmed in previous polls were also circulating. While Nigerians await the official election results we have looked into some of these claims. Social media in Nigeria, especially Twitter, has played a huge role in the dissemination of credible election-related news but at the same time it has been a major source of disinformation and misinformation. One disinformation trend we monitored was the sharing of videos purporting to show ballot-stuffing during the elections. In Nigeria, people vote by putting their thumb print beside the logo of the party of their choice. Using reverse-image search tools, the BBC traced some of the videos of people thumb-printing ballots to elections in 2021 and 2019. Another viral clip showed people being coached on the best way to print their thumb on ballot papers while voting for a particular party. Both sets of videos had strong regional and religious undertones and were widely shared on WhatsApp groups and Twitter. A popular politician in Nigeria was one of the people who shared the video of people being coached on how to thumb print. The video appears to be voter sensitisation projects carried out by the opposition Labour Party in parts of Nigeria. The BBC has contacted the party for comment but they are yet to respond. The BBC could not establish where the videos were recorded. But we know that the ballots shown in at least one of these viral videos were not real. They are clearly marked ""specimen"" and bear little resemblance to the standard electoral commission ballot papers, seen below on the left. A bold claim that has gained traction, pushed largely by influencers on social media, alleges that Nigeria's Independent National Electoral Commission (Inec) is rigging the election count to favour the governing All Progressives Congress (APC) party. Videos shared by accounts with large followings also suggested that Inec's server had been breached and unknown people were inputting fabricated election results. Checks showed that the alleged website was not that of the electoral commission and was, in fact, a fake website that replicated the interface of Inec's election results viewing portal. The web address has inconsistencies typical of a phishing website, such as having numbers instead of an actual website name. Inec released a statement saying that although its server was ""slow and unsteady"" due to the amount of activity going on, it was not compromised. There were also claims that Inec used the Bimodal Voter Accreditation (BVAS) machine to add votes to the tally of a particular candidate. Inec denies this. In 2021 Nigeria's electoral commission introduced the BVA machine to simplify the verification and accreditation of voters on election day. But it was also to be used in uploading results on the commission's result viewing portal. Some social media users claimed without evidence that machine failures had happened because Inec was deliberately sabotaging the electoral process. But Inec, in a statement it released to counter the viral allegation, said some machines failed to accredit voters or upload election results in some areas because of technical problems or the absence of an internet connection. Some political parties, including those of the three leading opposition contenders, have called for the polls to be cancelled because of the issues relating to the BVAS, among other complaints. Social media influencers and politicians with hundred of thousands of followers shared fake and misleading results. This has contributed to the questioning of the official results released by Inec. Bashir Ahmad, a spokesman for President Muhammadu Buhari, was one of those who shared results later confirmed to be fake when Inec released the official results. Mr Ahmad has since deleted his tweet. One person who featured prominently in disinformation messages shared online was former Nigerian President Olusegun Obasanjo, who was a member of the Peoples Democratic Party (PDP) but has since thrown his support behind Peter Obi of the Labour Party. In the lead up to the election, allegations of Mr Obasanjo intervening to stop a lorry load of Chadians who were allegedly coming to vote in the election was shared widely using WhatsApp. The message said a junior immigration officer alerted the former president of 1.5 million Chadians with Nigerian voter cards travelling to Kaduna in north-west Nigeria in 100 trucks, but that Mr Obasanjo had instructed his personal security to block all roads and capture the foreigners. Checks in Nigeria show no reports of arrests of Chadians trying to enter the country. As a former president, Mr Obasanjo does not have the power to block roads or instruct security agencies to intercept people or goods coming into the country. Moreover, a reverse image search confirms that one of the pictures used to spread the story was in fact from the News Agency of Nigeria in May 2021 - when it reported that the Nigeria Security and Civil Defence Corps stopped Fulani herders from entering Kwara state. Another picture was from 2021, when the security network, Amotekun, detained another set of Fulani herders. Popular musician and activist Charles Oputa, also known as Charly Boy, shared this false story to his Instagram handle. He has since deleted it. Another false claim trending on social media and messaging apps such as WhatsApp is that Mr Obasanjo had ""stormed"" the Inec collation centre in Abuja with the ""real results"" of the elections, which he had supposedly gotten from the servers. But there is no credible possibility that Mr Obasanjo could have intercepted results that were yet to be uploaded to Inec's server. BBC reporters at the collation centre did not see any evidence of such an event happening."
"No, Damar Hamlin was not replaced by a body double","Activists who blamed NFL star Damar Hamlin's on-field collapse this month on Covid-19 vaccines have concocted another baseless conspiracy theory - that the player has been replaced by a ""body double"" or even a ""clone"". It's an escalation of rumours that circulated after Mr Hamlin's injury. The latest allegations claim the player is dead and has been ""replaced"". The anti-vaccination activists stoking the wild claims on Twitter have provided no proof. On Sunday, Mr Hamlin attended an NFL playoff game pitting his team, the Buffalo Bills, against the Cincinnati Bengals. His face was covered as he walked into the stadium, and snow showers in a frigid stadium near Buffalo meant that live TV shots of him urging on the crowd from a booth far above the field were fuzzy. After the Bills lost, 27-10, ending their season, several influential online accounts opposed to Covid-19 vaccines began to spread rumours and innuendo about the player based on the TV footage - despite the fact that Mr Hamlin had posted a clear picture from his hospital bed two weeks earlier. Tweets and posts on fringe video sites and messaging apps were seen millions of times. Some simply cast doubt on whether Mr Hamlin had attended the game, while others went further and claimed he had died on the pitch or even, bizarrely, that he had been cloned. Among those spreading the rumours was Stew Peters, one of the people behind a documentary called Died Suddenly, an online hit in anti-vaccination circles that includes a number of dubious and false claims. An account linked to the documentary was among the first to start trying to link Mr Hamlin's injury to vaccines, despite the fact that he had taken a hit to the chest just seconds before collapsing. Mr Hamlin's injury, which resulted in the unprecedented cancellation of a primetime American football matchup between two top teams, was quickly seized upon by anti-vaccination activists to further their cause. Other influential accounts spreading the most recent rumours include a former reporter for fringe right-wing news outlets and Juanita Broaddrick, a woman who once accused Bill Clinton of rape and later became a supporter of Donald Trump. In a tweet viewed more than 2.7m times, she declared: ""Everyone thinks Damar Hamlin is dead... the whole thing smells."" She did not respond to a request for comment, nor did Mr Peters. Conspiracy theory expert Mike Rothschild, author of a book on the QAnon phenomenon, said some of those spreading the rumours had financial motives - promoting their websites, books, podcasts and unproven cures. ""It's the same antivaxxers and conspiracy influencers who have spent the last three years spreading conspiracy theories about Covid-19 for money,"" he said. ""Once there was a vaccine, they quickly added it to the grand conspiracy, saying it was poisonous, untested, and killed whoever took it,"" he added. ""They were desperate to link Hamlin's injury to the vaccine, and when that didn't work, they just changed some of the details."" One online video viewed tens of thousands of times showed a shot of a data-scraping website as ""proof"" that a death report had been filed in Mr Hamlin's name in his hometown in Pennsylvania. However, Mr Hamlin's injury occurred in Cincinnati, in the state of Ohio. Furthermore, current Pennsylvania death records are not searchable online and a spokesman for the Pennsylvania Department of Health told the BBC such records are not made public until 50 years after a person's death. Despite the outlandishness of the false claims, the online chatter reached such a volume by Tuesday that Mr Hamlin's teammate, Bills quarterback Josh Allen, was asked about it on an American football podcast. His reply was blunt. ""That's stupid,"" he said. ""There's absolutely zero chance. That's the Damar Hamlin, that's our guy, our brother. He was with us pre-game, post-game, he was up in the suite with his family, his little brother, one hundred percent. ""So people need to stop it."" He ended his answer with an expletive. Hamlin himself poked fun at the rumours, posting with a selfie outside a mural painted in his honour in Buffalo. Activists who blamed NFL star Damar Hamlin's on-field collapse this month on Covid-19 vaccines have concocted another baseless conspiracy theory - that the player has been replaced by a ""body double"" or even a ""clone"". It's an escalation of rumours that circulated after Mr Hamlin's injury. The latest allegations claim the player is dead and has been ""replaced"". The anti-vaccination activists stoking the wild claims on Twitter have provided no proof. On Sunday, Mr Hamlin attended an NFL playoff game pitting his team, the Buffalo Bills, against the Cincinnati Bengals. His face was covered as he walked into the stadium, and snow showers in a frigid stadium near Buffalo meant that live TV shots of him urging on the crowd from a booth far above the field were fuzzy. After the Bills lost, 27-10, ending their season, several influential online accounts opposed to Covid-19 vaccines began to spread rumours and innuendo about the player based on the TV footage - despite the fact that Mr Hamlin had posted a clear picture from his hospital bed two weeks earlier. Tweets and posts on fringe video sites and messaging apps were seen millions of times. Some simply cast doubt on whether Mr Hamlin had attended the game, while others went further and claimed he had died on the pitch or even, bizarrely, that he had been cloned. Among those spreading the rumours was Stew Peters, one of the people behind a documentary called Died Suddenly, an online hit in anti-vaccination circles that includes a number of dubious and false claims. An account linked to the documentary was among the first to start trying to link Mr Hamlin's injury to vaccines, despite the fact that he had taken a hit to the chest just seconds before collapsing. Mr Hamlin's injury, which resulted in the unprecedented cancellation of a primetime American football matchup between two top teams, was quickly seized upon by anti-vaccination activists to further their cause. Other influential accounts spreading the most recent rumours include a former reporter for fringe right-wing news outlets and Juanita Broaddrick, a woman who once accused Bill Clinton of rape and later became a supporter of Donald Trump. In a tweet viewed more than 2.7m times, she declared: ""Everyone thinks Damar Hamlin is dead... the whole thing smells."" She did not respond to a request for comment, nor did Mr Peters. Conspiracy theory expert Mike Rothschild, author of a book on the QAnon phenomenon, said some of those spreading the rumours had financial motives - promoting their websites, books, podcasts and unproven cures. ""It's the same antivaxxers and conspiracy influencers who have spent the last three years spreading conspiracy theories about Covid-19 for money,"" he said. ""Once there was a vaccine, they quickly added it to the grand conspiracy, saying it was poisonous, untested, and killed whoever took it,"" he added. ""They were desperate to link Hamlin's injury to the vaccine, and when that didn't work, they just changed some of the details."" One online video viewed tens of thousands of times showed a shot of a data-scraping website as ""proof"" that a death report had been filed in Mr Hamlin's name in his hometown in Pennsylvania. However, Mr Hamlin's injury occurred in Cincinnati, in the state of Ohio. Furthermore, current Pennsylvania death records are not searchable online and a spokesman for the Pennsylvania Department of Health told the BBC such records are not made public until 50 years after a person's death. Despite the outlandishness of the false claims, the online chatter reached such a volume by Tuesday that Mr Hamlin's teammate, Bills quarterback Josh Allen, was asked about it on an American football podcast. His reply was blunt. ""That's stupid,"" he said. ""There's absolutely zero chance. That's the Damar Hamlin, that's our guy, our brother. He was with us pre-game, post-game, he was up in the suite with his family, his little brother, one hundred percent. ""So people need to stop it."" He ended his answer with an expletive. Hamlin himself poked fun at the rumours, posting with a selfie outside a mural painted in his honour in Buffalo."
Oxford residents dubbed 'guinea pigs' over traffic policy,"A trial scheme to reduce car traffic in central Oxford has drawn the ire of activists promoting conspiracy theories online. But why exactly? Oxford residents may have been surprised when they opened their post boxes in the last week. ""Hello Guinea Pig"" said a leaflet delivered to many homes across the city. It appeared to be decorated with the Oxford coat of arms, but instead of depicting an ox crossing a river at the centre, this version showed a guinea pig instead. The leaflet, produced by activist group Not Our Future, criticises an Oxfordshire County Council scheme aimed at stopping local drivers from using busy city routes at peak times. It alleges that councillors have been ""duped into thinking this is for the good of the people"" and told ""to make it happen"". Asked about evidence to back those claims, Not Our Future directed the BBC to the group's website. There, a local media article is referenced as a source, despite not including any such allegations. The group also falsely links the traffic reduction scheme to the United Nations and its policies on tackling climate change - a problem which it sees as non-existent. ""The climate is changing as it always does,"" it says in its leaflet. ""It's a natural cycle. The planet isn't 'on fire'."" In response to the leaflet, Oxfordshire County Council said it respects the right of anyone to voice opposition to its policies. But it also said that ""some of the information being circulated by the group is demonstrably false"". At first glance, Not Our Future would appear to be a group of concerned Oxford residents. The group, founded last year, has the support of a number of media personalities and social media influencers. Many of them are known for spreading conspiracy theories and misinformation about Covid vaccines, climate change or the war in Ukraine. Its website lists several of these supporters, but only a few appear to have any substantial links to Oxford. Several are based abroad. ""This is a national and international issue, with Oxford being one of the first high-profile examples,"" Not Our Future said in a statement. ""Of course this is of international interest."" But the campaign appears to be meant to resonate with local residents unhappy about the council's policies. Last November, Oxfordshire County Council approved the creation of traffic filters, enforced through cameras, in six key locations across the city. Under this trial scheme, private cars will not be allowed through without a permit (which they can use up to 100 days per year), but all other vehicles will be exempt. While the scheme is not expected to start before 2024, thousands of local residents and businesses have voiced their concerns over the impact the measures might have on them. Soon after the council's decision was announced, rumours about the scheme began spreading online, aided by other blogs and fringe media outlets known for spreading misinformation. Among other things, it was falsely claimed that the scheme amounted to a ""climate lockdown"" and that Oxford residents would soon be forced to stay at home to protect the environment. The scheme was also wrongly linked to a separate council proposal to ensure that every Oxford resident has shops, healthcare and parks within a 15-minute walk of their home. The concept was dubbed ""15-minute neighbourhoods"" and, for many of the users sharing these distortions online, it was part of a sinister plan to limit people's freedom of movement. There is no evidence to back any such claims, and Oxfordshire County Council vehemently denies residents will ever be confined to their local area. As these falsehoods spread online, councillors soon began receiving abusive messages and threats, some of which have been reported to Thames Valley Police. There is no evidence to suggest that Not Our Future or its supporters played a part in any of this. In a statement released in December, Oxfordshire County Council condemned the abuse, which it said was ""due to inaccurate information being circulated online"". Despite the council's repeated attempts to set the record straight, these narratives appear to have found a willing audience in conspiracy-focused pages and channels on social media, both in the UK and abroad. The BBC has seen dozens of posts (some of which were shared thousands of times) describing the measures as ""dystopian"" and ""totalitarian"". For its part, Not Our Future claims its mission is ""to fight for the survival of our way of life as we know it"". But references to common conspiratorial tropes can also be found on the group's website and social media accounts, including baseless claims about Covid 19, the World Economic Forum and climate change. ""What do you consider to be a conspiracy theory?"" asked the group in response to the BBC's questions. ""All we want to do is inform the public,"" it said, adding that it won't be leafleting Oxford again in the near future. A trial scheme to reduce car traffic in central Oxford has drawn the ire of activists promoting conspiracy theories online. But why exactly? Oxford residents may have been surprised when they opened their post boxes in the last week. ""Hello Guinea Pig"" said a leaflet delivered to many homes across the city. It appeared to be decorated with the Oxford coat of arms, but instead of depicting an ox crossing a river at the centre, this version showed a guinea pig instead. The leaflet, produced by activist group Not Our Future, criticises an Oxfordshire County Council scheme aimed at stopping local drivers from using busy city routes at peak times. It alleges that councillors have been ""duped into thinking this is for the good of the people"" and told ""to make it happen"". Asked about evidence to back those claims, Not Our Future directed the BBC to the group's website. There, a local media article is referenced as a source, despite not including any such allegations. The group also falsely links the traffic reduction scheme to the United Nations and its policies on tackling climate change - a problem which it sees as non-existent. ""The climate is changing as it always does,"" it says in its leaflet. ""It's a natural cycle. The planet isn't 'on fire'."" In response to the leaflet, Oxfordshire County Council said it respects the right of anyone to voice opposition to its policies. But it also said that ""some of the information being circulated by the group is demonstrably false"". At first glance, Not Our Future would appear to be a group of concerned Oxford residents. The group, founded last year, has the support of a number of media personalities and social media influencers. Many of them are known for spreading conspiracy theories and misinformation about Covid vaccines, climate change or the war in Ukraine. Its website lists several of these supporters, but only a few appear to have any substantial links to Oxford. Several are based abroad. ""This is a national and international issue, with Oxford being one of the first high-profile examples,"" Not Our Future said in a statement. ""Of course this is of international interest."" But the campaign appears to be meant to resonate with local residents unhappy about the council's policies. Last November, Oxfordshire County Council approved the creation of traffic filters, enforced through cameras, in six key locations across the city. Under this trial scheme, private cars will not be allowed through without a permit (which they can use up to 100 days per year), but all other vehicles will be exempt. While the scheme is not expected to start before 2024, thousands of local residents and businesses have voiced their concerns over the impact the measures might have on them. Soon after the council's decision was announced, rumours about the scheme began spreading online, aided by other blogs and fringe media outlets known for spreading misinformation. Among other things, it was falsely claimed that the scheme amounted to a ""climate lockdown"" and that Oxford residents would soon be forced to stay at home to protect the environment. The scheme was also wrongly linked to a separate council proposal to ensure that every Oxford resident has shops, healthcare and parks within a 15-minute walk of their home. The concept was dubbed ""15-minute neighbourhoods"" and, for many of the users sharing these distortions online, it was part of a sinister plan to limit people's freedom of movement. There is no evidence to back any such claims, and Oxfordshire County Council vehemently denies residents will ever be confined to their local area. As these falsehoods spread online, councillors soon began receiving abusive messages and threats, some of which have been reported to Thames Valley Police. There is no evidence to suggest that Not Our Future or its supporters played a part in any of this. In a statement released in December, Oxfordshire County Council condemned the abuse, which it said was ""due to inaccurate information being circulated online"". Despite the council's repeated attempts to set the record straight, these narratives appear to have found a willing audience in conspiracy-focused pages and channels on social media, both in the UK and abroad. The BBC has seen dozens of posts (some of which were shared thousands of times) describing the measures as ""dystopian"" and ""totalitarian"". For its part, Not Our Future claims its mission is ""to fight for the survival of our way of life as we know it"". But references to common conspiratorial tropes can also be found on the group's website and social media accounts, including baseless claims about Covid 19, the World Economic Forum and climate change. ""What do you consider to be a conspiracy theory?"" asked the group in response to the BBC's questions. ""All we want to do is inform the public,"" it said, adding that it won't be leafleting Oxford again in the near future."
Parler: Amazon to remove site from web hosting service,"Amazon is removing ""free speech"" social network Parler from its web hosting service for violating rules. If Parler fails to find a new web hosting service by Sunday evening, the entire network will go offline. Parler styles itself as an ""unbiased"" social media and has proved popular with people banned from Twitter. Amazon told Parler it had found 98 posts on the site that encouraged violence. Apple and Google have removed the app from their stores. Launched in 2018, Parler has proved particularly popular among supporters of US President Donald Trump and right-wing conservatives. Such groups have frequently accused Twitter and Facebook of unfairly censoring their views. While Mr Trump himself is not a user, the platform already features several high-profile contributors following earlier bursts of growth in 2020. Texas Senator Ted Cruz boasts 4.9 million followers on the platform, while Fox News host Sean Hannity has about seven million. The move comes after Apple suspended Parler from its app store. The suspension will remain in place for as long as the network continued to spread posts that incite violence, it said. Google removed the app from its store on Friday. Responding to Google's move earlier, Parler's chief executive John Matze said: ""We won't cave to politically motivated companies and those authoritarians who hate free speech!"" He also warned that Parler could be offline for up to a week while ""we rebuild from scratch"". It briefly became the most-downloaded app in the United States after the US election, following a clampdown on the spread of election misinformation by Twitter and Facebook. In a letter obtained by CNN, Amazon's AWS Trust and Safety team told Parler's Chief Policy Officer Amy Peikoff that the social network ""does not have an effective process to comply with the AWS terms of service"". ""AWS provides technology and services to customers across the political spectrum, and we continue to respect Parler's right to determine for itself what content it will allow on its site"", the letter said. ""However we cannot provide services to a customer that is unable to effectively identify and remove content that encourages or incites violence against others."". Parler will be removed from Amazon's web hosting service shortly before midnight on Sunday Pacific Standard Time (07:59 GMT on Monday). On Saturday, Apple removed Parler from its app store after warning the network to remove content that violated its rules or face a ban. ""Parler has not taken adequate measures to address the proliferation of these threats to people's safety"", it said in a statement announcing the app's suspension on Saturday evening. By Shayan Sardarizadeh, BBC Monitoring For months, Parler has been one of the most popular social media platforms for right-wing users. As major platforms began taking action against viral conspiracy theories, disinformation and the harassment of election workers and officials in the aftermath of the US presidential vote, the app became more popular with elements of the fringe far-right. This turned the network into a right-wing echo chamber, almost entirely populated by users fixated on revealing examples of election fraud and posting messages in support of attempts to overturn the election outcome. In the days preceding the Capitol riots, the tone of discussion on the app became significantly more violent, with some users openly discussing ways to stop the certification of Joe Biden's victory by Congress. Unsubstantiated allegations and defamatory claims against a number of senior US figures such as Chief Justice John Roberts and Vice-President Mike Pence were rife on the app. Google and Apple say they are taking necessary action to ensure violent rhetoric is not promoted on their platforms. However, to those increasingly concerned about freedom of speech and expression on online platforms, it represents another example of draconian action by major tech companies which threatens internet freedom. This is a debate which is certain to continue beyond the Trump presidency."
Pastor Paul Mackenzie: What did the starvation cult leader preach?,"The leader of a Christian cult in Kenya is to remain in police custody for another month, as the exhumation of bodies found in mass graves on his land continues. At least 130 have been discovered so far. Pastor Paul Nthenge Mackenzie has said he closed down his Good News International Church four years ago after nearly two decades of operation. But the BBC has uncovered hundreds of his sermons still available online, some of which appear to have been recorded after this date. What picture do they paint of a man whose followers have starved themselves to death? In a passionate, raspy voice, Pastor Mackenzie delivers his sermons to large congregations in thrall to his apocalyptic themes. ""We are about to win the battleÂ let no-one turn backÂ the journey is about to be accomplished,"" reads a banner across the screen. One series of videos on his church's YouTube channel has the caption: ""End Time Kids"" and shows groups of young children delivering messages to the camera. Others culminate in exorcisms in which followers - often women - writhe around on the ground while he ""torments"" the demonic forces within them. These YouTube channels have thousands of subscribers and a Facebook page set up by his church links to many of the videos. The channels, which the BBC flagged to YouTube after Pastor Mackenzie's arrest, remain active. The BBC has observed several monetised videos on the channels, meaning YouTube makes money from the videos via online ads. Google and Meta have not responded to a BBC request for comment. It's not clear when the sermons were filmed, but there is reference to an upcoming preaching event by Pastor Mackenzie in Nairobi in January 2020, which contradicts his claim to have ended his preaching activities the previous year. Former members of the church have claimed that they were forced to fast as part of their adherence to its teachings. There is no direct evidence in the dozens videos we've seen of Pastor Mackenzie directly ordering people to fast, but there are many references to followers sacrificing what they hold dear, including their lives. ""There are people who don't even want to preach [about] Jesus. They say their children are crying because they are hungry, let them die. Is there a problem there?"" In an interview with the Kenyan Nation newspaper a few weeks ago, Pastor Mackenzie denied he forced his followers to fast. ""Is there a house maybe or an enclosure or a fence somewhere that has been found [at the farm] where people might have been locked in?"" he replied when the reporter asked him about this. Another theme of Pastor Mackenzie's sermons has been the idea that formal education is satanic and used to extort money. ""They know education is evil. But they use it for their own gains"" he says in one sermon. ""Those who sell uniforms, write booksÂthose who make pensÂ all kinds of rubbish. They use your money to enrich themselves while you become poor."" In 2017 and again in 2018, he was arrested for encouraging children not to go to school as he claimed education was ""not recognised in the Bible"". Pastor Mackenzie has also condemned education for promoting homosexuality through sex education programmes. ""I told people education is evilÂ. Children are taught gayism and lesbianism,'' he told the Nation newspaper. He has also encouraged mothers to avoid seeking medical attention during childbirth and not to vaccinate their children. In one of the videos, a woman narrates how she helped to deliver a baby through prayer and without the need for a caesarean section, adding that she later received a ""prompting"" from the holy spirit to warn her neighbour against vaccinating her child. The pastor then echoes her sentiments that vaccines are not necessary, claiming that doctors ""serve a different God"". He also discourages women from plaiting their hair, wearing wigs and wearing ornaments. Much of Pastor Mackenzie's preaching relates to the fulfilment of Biblical prophecies about Judgement Day. The church's online content also features posts about the end of the world, impending doom and the supposed dangers of science. And there are frequent warnings of an omnipotent satanic force that has supposedly infiltrated the highest echelons of power around the world. He repeatedly references ""New World Order"" - a conspiracy theory about a plot by global elites to bring about an authoritarian world government, replacing nation states - falsely claiming the Catholic Church, the UN and the US are behind it. He is also highly sceptical of modern technology, previously claiming a plan by the Kenyan government to establish a unique identity number for citizens to access government services was the 'mark of the beast'. Additional reporting by Paul Brown, Shayan Sardarizadeh and Jemimah Herd The leader of a Christian cult in Kenya is to remain in police custody for another month, as the exhumation of bodies found in mass graves on his land continues. At least 130 have been discovered so far. Pastor Paul Nthenge Mackenzie has said he closed down his Good News International Church four years ago after nearly two decades of operation. But the BBC has uncovered hundreds of his sermons still available online, some of which appear to have been recorded after this date. What picture do they paint of a man whose followers have starved themselves to death? In a passionate, raspy voice, Pastor Mackenzie delivers his sermons to large congregations in thrall to his apocalyptic themes. ""We are about to win the battleÂ let no-one turn backÂ the journey is about to be accomplished,"" reads a banner across the screen. One series of videos on his church's YouTube channel has the caption: ""End Time Kids"" and shows groups of young children delivering messages to the camera. Others culminate in exorcisms in which followers - often women - writhe around on the ground while he ""torments"" the demonic forces within them. These YouTube channels have thousands of subscribers and a Facebook page set up by his church links to many of the videos. The channels, which the BBC flagged to YouTube after Pastor Mackenzie's arrest, remain active. The BBC has observed several monetised videos on the channels, meaning YouTube makes money from the videos via online ads. Google and Meta have not responded to a BBC request for comment. It's not clear when the sermons were filmed, but there is reference to an upcoming preaching event by Pastor Mackenzie in Nairobi in January 2020, which contradicts his claim to have ended his preaching activities the previous year. Former members of the church have claimed that they were forced to fast as part of their adherence to its teachings. There is no direct evidence in the dozens videos we've seen of Pastor Mackenzie directly ordering people to fast, but there are many references to followers sacrificing what they hold dear, including their lives. ""There are people who don't even want to preach [about] Jesus. They say their children are crying because they are hungry, let them die. Is there a problem there?"" In an interview with the Kenyan Nation newspaper a few weeks ago, Pastor Mackenzie denied he forced his followers to fast. ""Is there a house maybe or an enclosure or a fence somewhere that has been found [at the farm] where people might have been locked in?"" he replied when the reporter asked him about this. Another theme of Pastor Mackenzie's sermons has been the idea that formal education is satanic and used to extort money. ""They know education is evil. But they use it for their own gains"" he says in one sermon. ""Those who sell uniforms, write booksÂthose who make pensÂ all kinds of rubbish. They use your money to enrich themselves while you become poor."" In 2017 and again in 2018, he was arrested for encouraging children not to go to school as he claimed education was ""not recognised in the Bible"". Pastor Mackenzie has also condemned education for promoting homosexuality through sex education programmes. ""I told people education is evilÂ. Children are taught gayism and lesbianism,'' he told the Nation newspaper. He has also encouraged mothers to avoid seeking medical attention during childbirth and not to vaccinate their children. In one of the videos, a woman narrates how she helped to deliver a baby through prayer and without the need for a caesarean section, adding that she later received a ""prompting"" from the holy spirit to warn her neighbour against vaccinating her child. The pastor then echoes her sentiments that vaccines are not necessary, claiming that doctors ""serve a different God"". He also discourages women from plaiting their hair, wearing wigs and wearing ornaments. Much of Pastor Mackenzie's preaching relates to the fulfilment of Biblical prophecies about Judgement Day. The church's online content also features posts about the end of the world, impending doom and the supposed dangers of science. And there are frequent warnings of an omnipotent satanic force that has supposedly infiltrated the highest echelons of power around the world. He repeatedly references ""New World Order"" - a conspiracy theory about a plot by global elites to bring about an authoritarian world government, replacing nation states - falsely claiming the Catholic Church, the UN and the US are behind it. He is also highly sceptical of modern technology, previously claiming a plan by the Kenyan government to establish a unique identity number for citizens to access government services was the 'mark of the beast'. Additional reporting by Paul Brown, Shayan Sardarizadeh and Jemimah Herd"
Paul Pelosi: Examining the false claims about the attack on Nancy Pelosi's husband,"Paul Pelosi, the husband of US House of Representatives Speaker Nancy Pelosi, was attacked by a hammer-wielding intruder at the couple's San Francisco home in the early hours of Friday. Within hours of the attack, a series of unsubstantiated claims began circulating in fringe far-right circles that contradicted the official police account of how the attack unfolded. Those misleading claims have since gone viral after being amplified by new Twitter chief Elon Musk and a number of conservative influencers. BBC News examines some of the claims about the attack. One of the most viral false claims about the attack suggests that Mr Pelosi, 82, and his attacker David DePape, 42, were in a same-sex relationship and had a drunken quarrel. A series of baseless assumptions that do not match official accounts of the incident have been used to support the narrative. These claims started to trend in the US after Elon Musk tweeted an article from a website featuring similar claims to his 112 million followers on Sunday, before deleting his tweet without any explanation hours later. ""There is a tiny possibility there might be more to this story than meets the eye,"" Mr Musk had said in response to a tweet by former Democratic presidential nominee Hillary Clinton. The website Mr Musk linked to has a history of publishing inaccurate stories, including an article from 2016 that claimed Hillary Clinton was dead. One of the claims made online is that both Mr DePape and Mr Pelosi were in just their underwear as police arrived at the scene. But the FBI complaint against Mr DePape quotes a witness as saying he was dressed ""in all black"" carrying a large black bag on his back. Another claim seized on to support this narrative is that the two men knew each other before the attack and were friends. Republican Congresswoman Marjorie Taylor Greene repeated the claim in a tweet yesterday. According to the FBI complaint, Paul Pelosi did not know Mr DePape. Mr Pelosi used coded language as he made a 911 call from the bathroom, and an experienced operator worked out what was happening in his house. Another rumour supporting the idea that the two men knew each other claimed that the shattered glass door of the house was broken from the inside, suggesting Mr Pelosi or a third person had let Mr DePape in. This was mentioned by former President Donald Trump in a recent interview, who claimed ""it wasn't a break in, it was a break out"". The FBI complaint quotes Mr DePape as saying that he ""broke into the house through a glass door, which was a difficult task that required the use of a hammer"". There is no evidence in any of the police accounts that a third person was either in the house or involved in the attack. Two personal blogs and a Facebook account in the suspect's name were found on the internet after police revealed his name following the attack, all of which were subsequently taken down. His writings, viewed by the BBC, suggest he was a man radicalised by far-right conspiracy theories. His posts cover a range of subjects, including unsubstantiated theories that the 2020 election was stolen, the 6 January Capitol riot, claims that Covid vaccines were harmful, support for the QAnon conspiracy theory, as well as racist and anti-Semitic posts. Some online posts suggested the blogs were fake and only created on the day of the attack to support the narrative that he believed in far-right conspiracy theories. But the BBC has screenshots of the blogs which show he had made posts as early as August, weeks before the attack. Some have also claimed the attack was not motivated by politics or Mr DePape's beliefs. Conservative commentator Matt Walsh said it was ""absurd"" to portray the attacker as ""a militant right winger"". Texas Senator Ted Cruz echoed Mr Walsh's words, simply tweeting ""truth"". However, the police complaint clarifies the attack was not a random act. According to San Francisco's district attorney Brooke Jenkins, the attack was likely ""politically motivated"". In his police interview, Mr DePape described Nancy Pelosi as the ""leader of the pack of lies told by the Democratic Party"", adding that he wanted to ""break her kneecaps"". Conservative figures, including Congressman Steve Scalise and Supreme Court Justice Brett Kavanaugh, have also been targets of violent attacks by political opponents in recent years. Baseless theories in the aftermath of the attack weren't confined to the right. Some liberal influencers seized on a tweet by Congresswoman Marjorie Taylor Greene, posted a day prior to the attack, which read: ""Just wait until tomorrow."" A number of accounts with large liberal followings claimed that Ms Taylor Greene's tweet could be a hint that she was in on the attack on Mr Pelosi. There is no evidence whatsoever to support this theory."
Pfizer CEO Albert Bourla: My wife's vaccine death is fake news,nan
Protests lead to social media misinformation warning,"West Midlands Police have asked people to be mindful of misinformation and rumour on social media after two protests took place. About 50 people gathered near a Hindu temple in Coventry on Thursday. Earlier, 150 people met in Smethwick which resulted in minor disorder. The reasons surrounding the protests are complex, police said, but added it was working with community leaders. Unsubstantiated claims on social media can have a serious impact, it warned. A spokesman said there had been several instances of fake news and unsubstantiated claims being spread on social media and messaging services. These include: ""We have local officers on the streets, and are engaging with faith leaders and other key stakeholders in our communities, to keep us informed and better understand how people are feeling,"" a police spokesman said. ""We have appropriate policing plans in place to deal with any further incidents should they occur, and will continue to closely monitor what is happening."" Follow BBC West Midlands on Facebook, Twitter and Instagram. Send your story ideas to: newsonline.westmidlands@bbc.co.uk"
Putin's mysterious Facebook 'superfans' on a mission,"Russia's invasion of Ukraine has been widely condemned in many parts of the world, but a network of Facebook groups run by people with obscure motivations would like to change perceptions of the country's leader. Millions of people have viewed posts committed to portraying President Vladimir Putin as smiling, benevolent and peace-loving. These are Putin's superfans - and we've been tracking what they do and where they come from. The BBC has been investigating these huge pro-Putin groups with the help of researchers from the Institute for Strategic Dialogue (ISD). ISD experts identified 10 pro-Putin public groups, boasting names such as Vladimir Putin - Leader of the Free World. The groups have more than 650,000 members between them. Content includes photos and messages praising the Russian leader, written in a number of languages, including English, Russian, Farsi, Arabic and Khmer. Not only are they popular, but they are very active. Over the past month, researchers counted 16,500 posts, receiving more than 3.6 million interactions. The overall aim of the groups seems to be to promote Mr Putin as a hero standing up to the West, with overwhelming international support. The images often show the Russian leader ""walking confidently, holding puppies, staring longingly into the camera, saluting troops, and riding an array of wild animals, including bears and lions"". These groups have gained more than 100,000 new members since the start of the invasion on 24 February. Digging into the details of the people driving most of the content, it emerged that many of the fans listed as administrators of the groups have duplicate accounts under the same name. The researchers found at least 100 such accounts in the network. These accounts generally follow each other and sometimes post heart-warming messages or send heart emojis to each other. And they administer these pro-Putin accounts alongside others pretending to be the Russian Federation or the Russian security services, which are clearly fake. Running duplicate accounts is a potential violation of Facebook's rules on inauthentic behaviour, the ISD says. Lead researcher Moustafa Ayad calls the practice an example of ""astroturfing"" - an online operation involving multiple accounts that falsely gives something the impression of wider grassroots support. The campaign ""creates the appearance of widespread support for Putin and the Kremlin in the shadow of the invasion and relies on... inauthentic accounts to accomplish its goal"", according to the ISD report. A closer examination of some of the group admins shows some unusual activity. One, named Marine, who says her location is Syria, uses three separate accounts to generate support for the president. Her three accounts, in Arabic, post at the same time every day. Another moderator, Victoria, from Cambodia, has been pushing content in a Khmer language group. Since 4 February, her posts have generated more than 34,000 reactions and have been shared more than 4,000 times. And Marine and Victoria jointly run a Khmer-language Facebook page, part of a wider pattern of co-ordination between some of the accounts. Posts are widely shared across different groups. For instance, another account listed as located in Bulgaria posted the same Putin image 12 times in the space of a couple of minutes. We tried to contact the people behind all of these accounts for comment, but didn't have much luck. But a man in Kenya, called Raj, who's in several of these groups and includes ""Putin"" at the end of his name on Facebook, did answer the phone when we rang. In a brief conversation, he called the president a ""great leader"" but said he didn't want to discuss the war. We emailed him further questions about his interest in Russia, but he didn't respond. Hasmik, from Armenia, says she's a journalist and now helps to run six pro-Putin groups. We asked who invited her to do it. She told us it was the people already running the groups and said that she wasn't paid for her efforts. It's difficult to glean the motivations of the people behind the accounts. There is no obvious link to the Russian government and unlike other well-known Russian disinformation campaigns, the network isn't subtle; nor do the people involved hide their intentions. But we can't rule out the possibility that the network has some links to the Russian authorities or pro-Putin elements inside Russia. Many people around the world are drawn to Mr Putin and his anti-West view of the world. We contacted Facebook, which says it has policies against fake accounts and has suspended a number of accounts based on information from the report and their own investigations. ""We're continuing to take strong action to prevent the spread of misinformation relating to the crisis in Ukraine,"" says a spokesman for parent company Meta. In the course of our research, we came across another interesting phenomenon - Vladimir Putin impersonation accounts. Mr Putin is one of the few world leaders who doesn't use social media, and there's no official Facebook account in his name. He reputedly doesn't even have a smartphone. According to his spokesman, Mr Putin simply ""does not need"" social media as it ""doesn't give him anything he doesn't have already"". But some have filled the gap left by his online absence. The page on Facebook displayed above had more than three million followers until it was taken down for impersonation shortly after the invasion at the end of February. A significant number of its subscribers - more than 700,000 - joined during the pandemic, when the page was talking up Russian-made Covid vaccines. More recently, the page was posting messages amplifying the Kremlin's view of the war, and many commenting on it appeared to believe it contained the genuine words of the Russian president. Shortly after the invasion, a post on the page declared the goal of the ""operation"" was ""peacekeeping... aimed only at the demilitarisation of a neighbouring country"". This message was shared and liked more than 200,000 times. And the page also had a habit of tagging people in its messages about Mr Putin, including users identified by researchers as having duplicate accounts. In other words, it was interacting with the Putin superfans. We don't know who's behind this account. The people managing it are based in Russia and Latvia, according to the page's transparency section. Fan pages are fertile ground to drum up support for the Kremlin internationally, says Nika Aleksejeva, a researcher at the Digital Forensic Research Lab (DFRLab), part of the Atlantic Council think tank. ""They may help to build public support in foreign countries for Russia's so-called 'military operation in Ukraine' unless taken down by mainstream social media platforms,"" she says. DFRLab documented how one Putin-impersonator account posting in Arabic had paid for adverts targeting users in several countries, including Algeria, Libya, Egypt, Yemen, Morocco, Lebanon, and Tunisia. The page had more than one million followers, but has since been deleted. Another prominent Putin page, posted in Arabic, used to be managed by a man who is also a big fan of Syrian leader Bashar al-Assad. It attracted almost a million followers before recently disappearing."
QAnon: What's the truth behind a pro-Trump conspiracy theory?,"A sprawling, endlessly complicated pro-Trump conspiracy theory has jumped from fringe social media sites to mainstream attention. The signs, shirts and banners at a rally in support of President Trump on Tuesday were, to the uninitiated, baffling. ""We are Q,"" read one sign at the event in Florida. ""WHERE WE GO ONE WE GO ALL,"" read another. Others wore T-shirts with the letter ""Q"" and slogans such as ""The Great Awakening"". All are references to a conspiracy theory gripping fringe pro-Trump activists - albeit a growing number of them, including celebrities, media personalities and influential social media accounts. It's nebulous and continuously changing to adapt to current events, but the overarching conspiracy theory has been given a name: ""QAnon"". The story began in October 2017, when an anonymous user posted a series of messages on 4chan - a very loosely moderated message board which has been a breeding ground of a number of online movements, including the alt-right. The unidentified user, who signed off as ""Q"", claimed to have top security clearance within the US government. The baseless core of the QAnon story is that  the Mueller investigation into alleged collusion between the Trump campaign and Russia is actually an investigation into global elites, and that the president is masterminding a secret plan to arrest top politicians and Hollywood stars for corruption and child abuse. For some reason, this plan is being revealed to niche internet message boards, via Q, through cryptic messages that frequently do not appear to make any sense (or are open to countless interpretations). For example: ""Do you believe in coincidences? ""'Blunt & Direct Time' ""BDT. ""Think currency. ""Think fireworks."" Despite the farfetched, open-ended and inscrutable nature of Q's messages, they quickly gained a cult following. Other users began to interpret the clues - or ""breadcrumbs"" - and elaborated on the theory. The resulting QAnon conspiracy theory - also known as ""The Storm"" - is a collection of these interpretations. The ""Anon"" part of the name comes from the fact that 4chan posters are, by default, anonymous. It echoes the debunked ""pizzagate"" saga - which resulted in a man opening fire in a Washington pizza restaurant in 2016. He believed a Democratic Party-run paedophile ring was based there. Despite there being no real evidence that Q has any special insight into the inner workings of the government, the conspiracy theory has been pushed by various celebrities in the US. The actress Roseanne Barr, former baseball player and current Breitbart podcast host Curt Schilling, and Infowars host Alex Jones - who has spread other conspiracy theories, including one which claimed that a massacre at a Connecticut school was staged by the government - have all promoted the theory. It's not always clear whether the people pushing the conspiracy theory really believe that the contents of Q's cryptic messages are meaningful, or whether they are using it to provoke political opponents and the media. Many alt-right and far-right social media figures have been known to ironically latch onto conspiracy theories - including ""pizzagate"" and others - to bash liberals and mainstream conservatives, or mock legitimate news outlets. But it's also clear that QAnon has hooked some true believers. A man recently blocked a bridge near the Hoover Dam in Arizona using a homemade armoured truck, and held up a QAnon-related sign to the window. Since being arrested on terrorism charges, he has written letters to President Trump peppered with various QAnon slogans. You may also be interested in: The cryptic messages from Q have now migrated over to 8chan - another anonymous forum with extremely light moderation rules - but the theory has also filtered into more mainstream platforms including Twitter, Facebook, YouTube and Reddit. And according to NBC, the QAnon conspiracy app ""QDrops"" made the top seller list in Apple's App Store and Google's Play Store when it launched in April. Will Sommer, a journalist at the Daily Beast who writes a newsletter about right-wing media, says QAnon supporters tend to be older people who are ""a little less sceptical about what they see on the Internet"". He covered a small QAnon rally in Washington, which was made up mostly of middle-aged Americans, some of whom had travelled from hundreds or thousands of miles away. It wasn't a crowd, he says, that you would normally associate with niche message boards. ""It's really taking off, at least within the American right, and amongst Trump supporters,"" says Sommer. The timing of the conspiracy theory's origins, he says, is no accident. During the Mueller investigation, ""people were really looking for reasons to not think that the president is somehow in the employ of Russia, or that something nefarious had happened during the campaign."" Q acolytes pay close attention to President Trump's speeches, and although he has never directly referenced the theory, the president has promoted conspiracy theories to his supporters in the past - most notably the false idea that former President Obama was not born in the United States. Joseph Uscinski, associate professor at the University of Miami, says Trump built his support amongst ""more conspiratorially inclined Republicans"". During the 2016 election campaign, Trump suggested that Rafael Cruz, the father of his main opponent Ted Cruz, was connected to the man who killed President John F Kennedy. Although there was no evidence for the claim, Uscinski says that Trump ""had to keep going with these conspiracy theories to keep his prime constituency motivated."" The incident in Arizona, the tweets by Rosanne, and the prominence of Q signs at Tuesday's rally in Tampa has led to more coverage of QAnon in the media. Whitney Phillips, assistant professor of communication, culture and digital technologies at Syracuse University, says that media outlets need to be careful they are not drawing more people into conspiracy theories. She says ""if a particular conspiracy only exists within a particular community, all reporting will do is amplify that concept so that more and more people are exposed to it."" Phillips acknowledges that ""at this point, not reporting on the story (of QAnon) could be framed as being irresponsible, because it is happening and people are responding"". However, she argues that conspiracy theories ""don't occur in a vacuum"" and warns that even articles debunking theories can legitimise their ideas. ""Not only do these individuals tend to follow mainstream media coverage very closely, they tend to cater their messages to maximize media exposure,"" she says. ""They love it when they're in the news."" Certainly Q - whoever it is behind the messages - is lapping up the attention. In recent days Q has posted links to media stories and has claimed the coverage is ""right on schedule"". On Thursday the account published a new message: ""Welcome to the mainstream. ""We knew this day would come."" Do you have a story for us? Email BBC Trending. More from Trending: Giuliani's 'you' tweet inspires song lyrics It doesn't take much to tickle the social media fancy - in fact one word was all Donald Trump's lawyer Rudy Giuliani needed to spark a new wave of internet gags. READ NOW You can follow BBC Trending on Twitter @BBCtrending, and find us on Facebook.  All our stories are at bbc.com/trending."
Researchers warn of rise in extremism online after Covid,"Researchers across the world are increasingly finding ways in which the coronavirus pandemic changed us. As more data comes in, what impact have lockdowns and their aftermath had on the spread of extremism? The United Nations painted a sobering picture of how the pandemic has fuelled terrorism and violent extremism, in a report last year. Heavy-handed enforcement of Covid restrictions, growing economic inequalities and an ""erosion of trust in government"", coupled with a diversion of resources away from fighting terrorism, were among the factors driving the change, according to the UN. Jacob Davey, a researcher at the Institute for Strategic Dialogue (ISD), a UK counter-extremism think tank, also identified ""quite significant spikes in extremist activity and also conspiracy theories"" during the pandemic. ""It might be people spending more time on their computer,"" he says, but there was also ""a heightened sense of anxiety"". Conspiratorial views and talking points ""provide easy answers"" to people who are worried, he argues. He singles out messaging app and social network Telegram - which grew rapidly during the pandemic and claims to have more than 500,000 members around the world - as a hub for ""disinformation through to conspiracy theories, through to terrorist activity"". Easily searchable groups on Telegram mean more extreme networks can feed into seemingly innocent groups. ""There's still a large amount of extremist content, still a large amount of disinformation content, enforcement is not great, but we have seen them over the past 10 years start to take a bit more action,"" he says. ""High-profile influencers are slowly but surely being kicked off Telegram."" ""Telegram's very unmoderated approach has meant that it functions as a centralising hub for a lot of different groups and individuals,"" says Dr Tim Squirrell, who also works at the ISD, ""you can get kicked off Facebook or the mainstream social and video sharing platforms,"" but ""you can still maintain your audience on Telegram"". Dr Squirrell says accounts which were removed over the QAnon conspiracy theory on Twitter rapidly ""flooded over to Telegram"". But, he warns, for those using Telegram thinking it's a secure and encrypted app, he says it isn't. When Telegram decides to take action, such as against Islamic State group accounts, ""it's actually pretty effective,"" and those accounts have ""found it really difficult to re-establish a foothold"". Mr Davey says there are ""hundreds"" of right-wing extremist groups operating in English language channels, with users from Australia, the US and Britain. One group, he says, saw themselves ""as essentially resistance against Covid measures,"" including vaccines. It has 247 affiliated regional groups on Telegram, 45 of which focus on the UK, the main channel has over 62,000 subscribers. ""At last count,"" Mr Davey says, ""my list of white supremacist channels was at something like 650, reaching hundreds of thousands of people"". ""We've seen pandemic related spikes,"" Mr Davey says, most of these extremist groups saw a sudden rise during the pandemic. Telegram itself, however, has become a battleground in the Russian invasion of Ukraine, because the app is heavily used in both countries, and due to their lax moderation standards, disinformation is rife. A spokesperson for the app told us ""Telegram is a platform for free speech, including that we do not agree with. It is for this reason that Telegram is used to organize pro-democracy protests in places like Hong Kong, Belarus and Iran. ""However, calls to violence are explicitly forbidden by Telegram's terms of service. Our moderators proactively monitor public parts of the app as well as accepting user reports in order to remove content that breaches of our terms."" The pandemic might have eased up, but the online conspiracy movement that boomed during it - including here in the UK - has far from disappeared. Instead, those who thought Covid-19 was a hoax and that the vaccine was part of a genocidal plot - false claims different from legitimate concerns and political criticisms - have turned their energy elsewhere. Now, climate change and the war are a hoax, too - and terror attacks and tragedies never really happened. They all employed crisis actors. Violent rhetoric about treason and hangings continues to accompany these conspiracies, directed at public figures, experts and anyone who disagrees with the new narrative. Far-right groups have sought to exploit this sizeable, captive online audience - sharing their beliefs on what were once the most prominent Covid-19 conspiracy channels on Telegram. Protests linked to these groups haven't disappeared, either. Rallies this summer have attracted many of the same conspiracy influencers who were present at anti-lockdown marches. This time they're promoting disinformation about child grooming, while being applauded by far-right figures online. The UK's conspiracy movement isn't going anywhere - and it has a real-world impact. It harms those who are victims of this disinformation and hate, but it also poses a threat to its followers, now deep down a rabbit hole and vulnerable to extreme, false ideas. ""More than 97%"" of news traffic during the pandemic ""went to trustworthy sites,"" Rasmus Nielsen, the Director of the Reuters Institute for the Study of Journalism, says the BBC alone benefited from a ""30% increase in web visits"". He thinks sometimes people think there is a ""tsunami of misinformation, and there's no question that it's out there, there is plenty of misinformation. But when we look at what people actually engage with, our data suggests that the vast majority of it is from trustworthy sources"". ""There are people who publish things that are at best misleading and tenuous, and at worse, outright fabrications or false,"" he continues, ""anyone can do it if they put their minds to it"". Even in America, he says, where the problem is more pronounced, ""average Americans spend about 100 times more time with actual news as they do with identified false or fake news"". Latest Counter Terrorism data seems to show a trend upwards in children being exposed to extremist grooming. This is happening at the same time, they say, that referrals to the Prevent programme have reduced largely due to schools being closed during the pandemic. In 2020, 25 children were arrested in relation to terrorism offending, the highest number ever recorded in a 12-month period. Counter Terrorism Policing, an organisation headed by the Metropolitan Police, allowing police forces to co-operate on the threat of terrorism, said they were ""working around the clock to tackle the proliferation of content of the internet... every day, investigators from the Counter Terrorism International Referral Unit trawl the internet, identifying terrorist material and working with service providers to ensure it's removed."" They said the pandemic ""has undoubtedly changed the landscape when it comes to radicalisation, particularly in the online world, as well as exacerbating challenging circumstances and grievances within society that terrorists use to promote their brands of hatred, or extremism - it has made us all more isolated."" Researchers across the world are increasingly finding ways in which the coronavirus pandemic changed us. As more data comes in, what impact have lockdowns and their aftermath had on the spread of extremism? The United Nations painted a sobering picture of how the pandemic has fuelled terrorism and violent extremism, in a report last year. Heavy-handed enforcement of Covid restrictions, growing economic inequalities and an ""erosion of trust in government"", coupled with a diversion of resources away from fighting terrorism, were among the factors driving the change, according to the UN. Jacob Davey, a researcher at the Institute for Strategic Dialogue (ISD), a UK counter-extremism think tank, also identified ""quite significant spikes in extremist activity and also conspiracy theories"" during the pandemic. ""It might be people spending more time on their computer,"" he says, but there was also ""a heightened sense of anxiety"". Conspiratorial views and talking points ""provide easy answers"" to people who are worried, he argues. He singles out messaging app and social network Telegram - which grew rapidly during the pandemic and claims to have more than 500,000 members around the world - as a hub for ""disinformation through to conspiracy theories, through to terrorist activity"". Easily searchable groups on Telegram mean more extreme networks can feed into seemingly innocent groups. ""There's still a large amount of extremist content, still a large amount of disinformation content, enforcement is not great, but we have seen them over the past 10 years start to take a bit more action,"" he says. ""High-profile influencers are slowly but surely being kicked off Telegram."" ""Telegram's very unmoderated approach has meant that it functions as a centralising hub for a lot of different groups and individuals,"" says Dr Tim Squirrell, who also works at the ISD, ""you can get kicked off Facebook or the mainstream social and video sharing platforms,"" but ""you can still maintain your audience on Telegram"". Dr Squirrell says accounts which were removed over the QAnon conspiracy theory on Twitter rapidly ""flooded over to Telegram"". But, he warns, for those using Telegram thinking it's a secure and encrypted app, he says it isn't. When Telegram decides to take action, such as against Islamic State group accounts, ""it's actually pretty effective,"" and those accounts have ""found it really difficult to re-establish a foothold"". Mr Davey says there are ""hundreds"" of right-wing extremist groups operating in English language channels, with users from Australia, the US and Britain. One group, he says, saw themselves ""as essentially resistance against Covid measures,"" including vaccines. It has 247 affiliated regional groups on Telegram, 45 of which focus on the UK, the main channel has over 62,000 subscribers. ""At last count,"" Mr Davey says, ""my list of white supremacist channels was at something like 650, reaching hundreds of thousands of people"". ""We've seen pandemic related spikes,"" Mr Davey says, most of these extremist groups saw a sudden rise during the pandemic. Telegram itself, however, has become a battleground in the Russian invasion of Ukraine, because the app is heavily used in both countries, and due to their lax moderation standards, disinformation is rife. A spokesperson for the app told us ""Telegram is a platform for free speech, including that we do not agree with. It is for this reason that Telegram is used to organize pro-democracy protests in places like Hong Kong, Belarus and Iran. ""However, calls to violence are explicitly forbidden by Telegram's terms of service. Our moderators proactively monitor public parts of the app as well as accepting user reports in order to remove content that breaches of our terms."" The pandemic might have eased up, but the online conspiracy movement that boomed during it - including here in the UK - has far from disappeared. Instead, those who thought Covid-19 was a hoax and that the vaccine was part of a genocidal plot - false claims different from legitimate concerns and political criticisms - have turned their energy elsewhere. Now, climate change and the war are a hoax, too - and terror attacks and tragedies never really happened. They all employed crisis actors. Violent rhetoric about treason and hangings continues to accompany these conspiracies, directed at public figures, experts and anyone who disagrees with the new narrative. Far-right groups have sought to exploit this sizeable, captive online audience - sharing their beliefs on what were once the most prominent Covid-19 conspiracy channels on Telegram. Protests linked to these groups haven't disappeared, either. Rallies this summer have attracted many of the same conspiracy influencers who were present at anti-lockdown marches. This time they're promoting disinformation about child grooming, while being applauded by far-right figures online. The UK's conspiracy movement isn't going anywhere - and it has a real-world impact. It harms those who are victims of this disinformation and hate, but it also poses a threat to its followers, now deep down a rabbit hole and vulnerable to extreme, false ideas. ""More than 97%"" of news traffic during the pandemic ""went to trustworthy sites,"" Rasmus Nielsen, the Director of the Reuters Institute for the Study of Journalism, says the BBC alone benefited from a ""30% increase in web visits"". He thinks sometimes people think there is a ""tsunami of misinformation, and there's no question that it's out there, there is plenty of misinformation. But when we look at what people actually engage with, our data suggests that the vast majority of it is from trustworthy sources"". ""There are people who publish things that are at best misleading and tenuous, and at worse, outright fabrications or false,"" he continues, ""anyone can do it if they put their minds to it"". Even in America, he says, where the problem is more pronounced, ""average Americans spend about 100 times more time with actual news as they do with identified false or fake news"". Latest Counter Terrorism data seems to show a trend upwards in children being exposed to extremist grooming. This is happening at the same time, they say, that referrals to the Prevent programme have reduced largely due to schools being closed during the pandemic. In 2020, 25 children were arrested in relation to terrorism offending, the highest number ever recorded in a 12-month period. Counter Terrorism Policing, an organisation headed by the Metropolitan Police, allowing police forces to co-operate on the threat of terrorism, said they were ""working around the clock to tackle the proliferation of content of the internet... every day, investigators from the Counter Terrorism International Referral Unit trawl the internet, identifying terrorist material and working with service providers to ensure it's removed."" They said the pandemic ""has undoubtedly changed the landscape when it comes to radicalisation, particularly in the online world, as well as exacerbating challenging circumstances and grievances within society that terrorists use to promote their brands of hatred, or extremism - it has made us all more isolated."""
Russia Ukraine conflict: Fact-checking Russian TV's Ukraine claims,"Russia has played down accusations of a military build-up near Ukraine's border - a view amplified by a state television channel, which has broadcast misleading footage about US tanks and planes. We've fact-checked claims from one of the country's most well-known pro-government news shows - Vesti Nedeli (""News of the week""). The weekly news programme on Rossiya 1, Russia's most popular TV channel, is presented by Dmitry Kiselyov, a controversial media personality known for his anti-Western views. A recent report on the programme detailed the alleged build-up of Nato military hardware in Ukraine. ""Never before has there been so much of the alliance's military equipment on Ukrainian soil,"" said the narrator over footage of an American C-17 military transport plane landing on an airstrip. But the aircraft did not, in fact, land in Ukraine. The footage - apparently taken from the website of the US Department of Defense - actually shows the C-17 landing at Joint Base Elmendorf-Richardson in Alaska. In the original version of the clip, mountains can be seen faintly in the background, but in the Russian version, they are not visible at all. The Russian news report was sourced to a YouTube channel which says it broadcasts ""US military news"". That channel posted a slightly different and longer version of the plane landing. And the clip appears to have been brightened - an effect that obscured the mountains in the background. But other details in the clip align exactly with the US Department of Defense video from Alaska. For instance, a white building, a small shack with a green roof, and other small details are visible in both pieces of footage. There's no doubt the video clips came from the same source material - shot in Alaska, not Ukraine. The Vesti Nedeli report went on to suggest that American tanks have been delivered to Ukraine. It showed a clip of a US M1 Abrams tank being unloaded from a military transport plane, with a voiceover suggesting that the footage was either from the capital, Kyiv, or Lviv, in western Ukraine. In fact, the footage is from Burgas, Bulgaria, site of a military exercise called Operation Speed and Power in 2015. Again, it's US Department of Defence footage - a  video and still images of the unloading were published by the American military. We managed to find the original footage by searching through lists of details of the military hardware in the clip. And again the details in the two clips match up, proving the falsehood beyond a doubt. Both the original video and the footage shown on Russian TV contain identical details such as a Lukoil truck and a man wearing a high-viz jacket. The high profile show also featured discussion about how the US was allegedly ""pushing"" Ukraine towards war with Russia. Mr Kiselyov, once dubbed Russia's ""chief propagandist"", referenced a quote from an unlikely source to lament his country's plight: Lord Palmerston, British Prime Minister during the Crimean War in the 1850s. The presenter quoted him saying: ""It's so difficult to live when no-one wages war on Russia."" It was a useful historical argument for Mr Kiselyov's views, with one problem - there's no evidence that Lord Palmerston ever said it. BBC Monitoring's Russia specialists went in search of the quote but were unable to find a credible record of the former prime minister ever saying it. The University of Southampton, which holds an extensive Palmerston collection, also found no record of him making these comments. According to the university's archivist, there are no references to it in Palmerston: A Biography by David Brown. In Russia, Lord Palmerston's observations have been reported as part of a speech he made in the House of Commons on 1 March 1848. But the quote is not in the official transcript of that address. The earliest mention of the remarks that we've found attributed to Lord Palmerston are contained in a work of historical fiction - published in 2011. The same phrase appeared in a blog post of another Russian fiction writer two years later. The BBC has attempted to contact Vesti Nedeli for comment. The main impression being transmitted on Russian state TV seems be that Ukraine and the West are somehow responsible for the upsurge in tensions. But the programmes offer little in the way of details as to what exactly they did to spark the tension. The gap has been filled by various, at times conflicting theories- a tactic used in the past by Russian state media when Moscow is accused of something, such as during the Salisbury poisonings. At times, a West bent on weakening Russia is cast as egging Ukraine on, at other times, it is a supposedly bloodthirsty Ukraine trying to drag the West into a war of revenge against Moscow. There has also been an emphasis on emotional coverage of victims of alleged Ukrainian aggression in the conflict area. Ukraine alleges that Russia is to blame for most ceasefire violations. Another claim is that Ukraine and the West are massing forces in the region. But again, details are sketchy, and the footage used to illustrate this has at times been out of date. So Ukraine says any military activity on its side is a response to the recent Russian military build-up in the region. Read more from Reality Check Send us your questions"
Russia laws ban 'disrespect' of government and 'fake news',"Russia's parliament has passed two bills outlawing ""disrespect"" of authorities and the spreading of what the government deems to be ""fake news"". The first ban refers to ""blatant disrespect"" of the state, its officials and Russian society, and repeat offenders face up to 15 days in jail. The second bill prohibits sharing ""false information of public interest, shared under the guise of fake news,"" the Tass state news agency reported. Both new crimes carry heavy fines. President Vladimir Putin is expected to sign the bills into law once they have received approval from Russia's upper house, the Federation Council. The body will consider both bills on 13 March. Journalists, human rights campaigners and even government ministers have voiced their opposition. Nikolai Svanidze, a journalist and member of Russia's Civic Chamber, said the ""barbaric"" legislation would ""make journalists fearful of speaking and writing"". Business newspaper Vedomosti also criticised the measures, saying they could threaten online news sites and blogs that quote anonymous sources critical of the government. But lawmakers for the governing United Russia party, whose members proposed the bills, defended the legislation. MP Pavel Krasheninnikov said the laws would ""ensure protection against so-called web-based terrorists"", while his colleague Anatoly Vyborny praised efforts to ""discipline our citizens"" and promote ""greater accountability"". Steve Rosenberg, BBC Moscow correspondent If you believe the pro-Kremlin MPs behind this legislation, tackling fake news and online insults benefits the Russian people and the state. But the headline in today's edition of the newspaper Vedomosti tells a different story: ""Fake concern about society"", declared its front page. Critics of the legislation believe the draft laws are part of a growing Kremlin-inspired crackdown on Internet freedom. They point to another bill under debate to create a ""Sovereign Internet"". Under the plan, Russian cyber space could operate independently of the world wide web. Many see this as Russia's version of the Great Firewall of China: an Internet Iron Curtain. As for the draft law on disrespect, earlier this week popular tabloid Moskovsky Komsomolets summed up concern in a stark cartoon. It depicted a police officer talking to a man who is brandishing an axe, with bodies lying all around. Pointing to the weapon, the policeman says: ""Don't worry about that. Just make sure you don't write anything bad online about the authorities."" For showing ""disrespect"", first-time offenders face fines up to 100,000 roubles (Â£1,150; $1,500). Repeated violations could bring double or even triple the amount in fines, or a 15-day jail sentence. Sanctions for publishing so-called fake news will vary. Individuals, officials and businesses will face fines of 300,000, 600,000 or 1 million roubles respectively if the spread information affects ""functioning of critical infrastructure"" like transport or communications. Any online article containing ""blatant disrespect"" for the government or ""public morality"" will have to be deleted within 24 hours. Traditional media registered with the Justice Ministry will face fines under the fake news bill, while originally they had been threatened with losing their licenses. News sites without a licence could be blocked without warning by the state media regulator."
Russia threatens YouTube ban for deleting RT channels,"Russia has threatened to ban YouTube if it does not reinstate two German-language channels backed by the Russian state that were deleted for violating Covid misinformation guidelines. Russian media watchdog Roskomnadzor accused YouTube of censorship. The agency ??ÂdemandedÂ that the channels be restored. It comes as YouTube also expanded its misinformation policies to cover all effective vaccines, not just Covid ones. The tech firm said the measles, mumps and rubella (MMR) vaccine being falsely attributed to causing autism, was one example of the types of content the new policy will cover which had previously been allowed. In the Russian argument, RT DE had already received a warning from YouTube for breaching coronavirus misinformation guidelines. It was given a week-long suspension from posting on the platform. During this time, RT used a second channel - Der Fehlende Part - to upload content which also violated these policies. As a result, both were deleted by YouTube. But the move may have repercussions. Internet service providers in Russia can limit or block the flow of data to websites, as instructed by the government. The state used these powers in March to restrict access to Twitter after Roskomnadzor said it failed to remove around 3,000 posts allegedly involving banned content. In May, it also threatened to slow down YouTube for failing to remove videos it said were ÂunlawfulÂ. ÂYouTube has always had clear community guidelines that outline what is allowed on the platform,Â a spokesperson for the platform said. In August, Sky News Australia was suspended on the platform for a week after posting videos that denied the existence of Covid and encouraged the use of unproven and potentially dangerous treatments hydroxychloroquine and ivermectin. Russia's information war Analysis by Alistair Coleman, BBC Monitoring The Russian YouTube channels were taken down for posting misinformation about Covid and trying to evade a YouTube-imposed ban. Previously, they've been accused by Germany of 'manipulative' reporting on anti-lockdown protests, and for spreading divisive content ahead of last week's election. YouTube's move to suspend the Russian state-operated channels has been met by predictable outrage from Moscow, which portrays itself as an innocent victim of US-backed 'Russophobia', trying to silence its voice abroad. The affair is being portrayed by the Russian government as information warfare instigated by Germany, calling this incident ""Operation Media Barbarossa"", a reference to the Nazi invasion of Russia in 1941. And it's expressing its anger through predictable means - suggesting that retaliatory measures are in the pipeline not only against YouTube, but also German broadcasters in Russia. We can expect at least some sort of action from Moscow. RT's editor-in-chief Margarita Simonyan - a close friend of Vladimir Putin - says that she was looking forward to Moscow ""banning Deutsche Welle and other German media outlets"". It's a predictable dance faced by governments and - increasingly - the big tech companies. How far can they tolerate misinformation from foreign broadcasters if their own media organisations get caught in the retaliatory crossfire? YouTube's new rules on misinformation, meanwhile, mean any videos containing misinformation about any vaccine that has been approved by health authorities will be removed. Under its previous guidelines, these videos would not be promoted by the website - meaning fewer views - but would not be deleted outright. YouTube said it has removed 130,000 pieces of content related to Covid vaccine misinformation since last year, as part of a total of one million videos removed by the platform for spreading Covid-related misinformation."
RussiaÂs new schoolbook aims to justify war on Ukraine,"Authorities in Moscow have unveiled a new schoolbook which aims to justify the war on Ukraine and accuses the West of trying to destroy Russia. According to excerpts published by Russian media, schoolchildren will now be taught that human civilisation could have come to an end had Vladimir Putin not started his ""special military operation"" against Ukraine. The textbook, called ""Russian History, 1945 - early 21st century"", was co-authored by presidential adviser Vladimir Medinsky, formerly Russian culture minister. This is the first officially approved history book to be used in Russian schools which mentions events as recent as the full-scale invasion of Ukraine, which started in February 2022. From September, it will be studied in the last year of secondary education in Russia - the 11th year - which is attended by pupils aged 17-18. The textbook claims that ""the West is fixated on destabilising the situation within Russia"" and to achieve this aim, Western powers spread ""undisguised Russophobia"". Then, it goes on, they started ""dragging"" Russia into various conflicts. The West's ultimate objective is to destroy Russia and take control of its mineral wealth, the schoolbook says. It repeats numerous clichÃ©s from Kremlin propaganda, portraying Ukraine as an aggressive state run by nationalist extremists and manipulated by the West, which allegedly uses the country as a ""battering ram"" against Russia. According to the book, Ukraine is little more than a Western invention created to spite Russia, and even Ukraine's blue-and-yellow flag was supposedly invented by the Austrians keen to convince Ukrainians that they are different from Russians. The textbook is also rife with distortion and manipulation. For example, it describes Russia's initial attack on Ukraine in 2014 as a popular uprising of eastern Donbas residents who ""wanted to stay Russian"" and who were joined by ""volunteers"" from Russia. It makes no mention of the military hardware and personnel Russia sent to Donbas at the time or over the next eight years. It argues that one key reason for the full-scale invasion in 2022 was the possibility of Ukraine joining Nato. If Ukraine had joined the alliance and then ""provoked a conflict in Crimea or Donbas"", the textbook says, Russia would have been forced to wage war against the whole of the Nato alliance. ""This would have possibly been the end of civilisation. This could not be allowed to happen,"" the schoolbook says. However, Ukraine's accession to Nato was, back then - and remains now - a distant prospect. The textbook also falsely claims that before Russia's annexation of Crimea in 2014, Ukraine had plans to turn Sevastopol - the seat of Russia's Black Sea Fleet -  into a Nato base and that later Kyiv said it wanted to acquire nuclear weapons. Another false assertion in the textbook is that until 2014, 80% of Ukraine's population considered Russian as their mother tongue. According to a poll published by the reputable Razumkov Centre in 2006, only 30% of residents of Ukraine named Russian as their mother tongue, while 52% said Ukrainian was their native language. In an apparent reference to the abundance of online material implicating Russian forces in atrocities committed in Ukraine, the textbook warns schoolchildren to be mindful of ""a global industry manufacturing staged clips and fake photos and videos"". ""Western social networks and media all too enthusiastically spread fake information,"" the textbook says in a chapter about the ""special military operation"". Authorities in Russia have previously jailed activists who have accused Russian troops of targeting civilians in Ukraine. For example, Kremlin critic Ilya Yashin was jailed for eight-and-a-half years in December 2022 after discussing suspected Russian war crimes in the Ukrainian town of Bucha in an online live stream. The textbook is critical of Western sanctions imposed on Russia in the wake of its invasion of Ukraine and presents them as an attempt to ""destroy Russia's economy"". It also wrongly argues that these sanctions ""violate all the norms of international law which the West is so fond of quoting"". At the same time, the exodus of Western businesses from Russia in the wake of the full-scale invasion is presented as a ""fantastic opportunity"" for Russian businesspeople. Authorities in Moscow have unveiled a new schoolbook which aims to justify the war on Ukraine and accuses the West of trying to destroy Russia. According to excerpts published by Russian media, schoolchildren will now be taught that human civilisation could have come to an end had Vladimir Putin not started his ""special military operation"" against Ukraine. The textbook, called ""Russian History, 1945 - early 21st century"", was co-authored by presidential adviser Vladimir Medinsky, formerly Russian culture minister. This is the first officially approved history book to be used in Russian schools which mentions events as recent as the full-scale invasion of Ukraine, which started in February 2022. From September, it will be studied in the last year of secondary education in Russia - the 11th year - which is attended by pupils aged 17-18. The textbook claims that ""the West is fixated on destabilising the situation within Russia"" and to achieve this aim, Western powers spread ""undisguised Russophobia"". Then, it goes on, they started ""dragging"" Russia into various conflicts. The West's ultimate objective is to destroy Russia and take control of its mineral wealth, the schoolbook says. It repeats numerous clichÃ©s from Kremlin propaganda, portraying Ukraine as an aggressive state run by nationalist extremists and manipulated by the West, which allegedly uses the country as a ""battering ram"" against Russia. According to the book, Ukraine is little more than a Western invention created to spite Russia, and even Ukraine's blue-and-yellow flag was supposedly invented by the Austrians keen to convince Ukrainians that they are different from Russians. The textbook is also rife with distortion and manipulation. For example, it describes Russia's initial attack on Ukraine in 2014 as a popular uprising of eastern Donbas residents who ""wanted to stay Russian"" and who were joined by ""volunteers"" from Russia. It makes no mention of the military hardware and personnel Russia sent to Donbas at the time or over the next eight years. It argues that one key reason for the full-scale invasion in 2022 was the possibility of Ukraine joining Nato. If Ukraine had joined the alliance and then ""provoked a conflict in Crimea or Donbas"", the textbook says, Russia would have been forced to wage war against the whole of the Nato alliance. ""This would have possibly been the end of civilisation. This could not be allowed to happen,"" the schoolbook says. However, Ukraine's accession to Nato was, back then - and remains now - a distant prospect. The textbook also falsely claims that before Russia's annexation of Crimea in 2014, Ukraine had plans to turn Sevastopol - the seat of Russia's Black Sea Fleet -  into a Nato base and that later Kyiv said it wanted to acquire nuclear weapons. Another false assertion in the textbook is that until 2014, 80% of Ukraine's population considered Russian as their mother tongue. According to a poll published by the reputable Razumkov Centre in 2006, only 30% of residents of Ukraine named Russian as their mother tongue, while 52% said Ukrainian was their native language. In an apparent reference to the abundance of online material implicating Russian forces in atrocities committed in Ukraine, the textbook warns schoolchildren to be mindful of ""a global industry manufacturing staged clips and fake photos and videos"". ""Western social networks and media all too enthusiastically spread fake information,"" the textbook says in a chapter about the ""special military operation"". Authorities in Russia have previously jailed activists who have accused Russian troops of targeting civilians in Ukraine. For example, Kremlin critic Ilya Yashin was jailed for eight-and-a-half years in December 2022 after discussing suspected Russian war crimes in the Ukrainian town of Bucha in an online live stream. The textbook is critical of Western sanctions imposed on Russia in the wake of its invasion of Ukraine and presents them as an attempt to ""destroy Russia's economy"". It also wrongly argues that these sanctions ""violate all the norms of international law which the West is so fond of quoting"". At the same time, the exodus of Western businesses from Russia in the wake of the full-scale invasion is presented as a ""fantastic opportunity"" for Russian businesspeople."
Shinzo Abe killing: Hideo Kojima threatens to sue over false posts,"A legendary video game developer has threatened to sue over hoax posts portraying him as Shinzo Abe's killer. Metal Gear creator Hideo Kojima was linked to the shooting of Japan's former prime minister in pictures on website 4chan. The images were shared by a French politician and reportedly broadcast by Greek and Iranian news outlets. Kojima Productions said it ""strongly condemns the spread of fake news and rumours that convey false information"". The 4chan post used a photo of Kojima and falsely labelled him as a ""left-wing extremist"" with a criminal record. It also included a picture of him wearing a type of Ushanka, or fur hat, worn by soldiers in communist Russia, and another of him standing next to a picture of Marxist revolutionary Che Guevara. Screenshots on social media showed Damien Rieu, a French politician associated with the country's nationalist movement, had tweeted out images of Kojima with text translated to: ""The far-left kills"". He has since deleted his tweet and issued an apology to Kojima, saying he ""naively took a joke for information"" and ""was wrong not to check before sharing"". In response, the game director's company tweeted a statement warning it would consider legal action over the spread of false information. Mr Abe died last Friday after he was shot with a homemade gun. Police say the suspect, named as Tetsuya Yamagami, 41, has admitted the killing. By Shayan Sardarizadeh, BBC Disinformation journalist In the immediate aftermath of a tragedy, details are often murky and emotions run high. In the absence of reliable information, misleading claims fill the gap, and Mr Abe's assassination wasn't an exception. False claims that the assassination was staged, that Mr Abe wasn't bleeding in pictures, that the man arrested was not the real suspect, and that he was Korean or Chinese, were posted on Japanese social media. But in other parts of the world, the focus was on Mr Kojima and a play on a racist trope about Asians. Arguably the biggest hub of internet subculture, 4chan has been responsible for many false claims and memes. This isn't the first time Mr Kojima has been the target of online misinformation. Posts falsely accusing him of ""aborting and mummifying a baby"" went viral just a few weeks ago in the context of abortion debate in the US. As always, the best practice is to wait for reliable information from relevant authorities and trusted news sources, and avoid sharing unverified claims, no matter how viral they may be. Japan's longest-serving prime minister, who served for a year in 2006 and then again from 2012 to 2020, before stepping down due to health reasons. Abe later revealed that he had suffered a relapse of ulcerative colitis, an intestinal disease. While he was in office, he pushed more assertive policies on defence and foreign policy and wanted to amend Japan's pacifist post-war constitution. On Japanese social media, the hashtag ""We want democracy, not violence"" was trending throughout Friday, with many users expressing their horror and disgust over Mr Abe's killing. Follow Newsbeat on Instagram, Facebook, Twitter and YouTube. Listen to Newsbeat live at 12:45 and 17:45 weekdays - or listen back here."
Should bad science be censored on social media?,"How do you solve a problem like bad information? When it comes to understanding science and making health decisions, it can have life-or-death consequences. People dissuaded from taking vaccines as a result of reading misleading information online have ended up in hospital or even died. And inaccurate or completely made-up claims about 5G and the origins of Covid-19 have been linked to violence and vandalism. But completely removing information can look a lot like censorship, especially for scientists whose careers are based on the understanding that facts can and should be disputed, and that evidence changes. The Royal Society is the world's oldest continuously operating scientific institution, and it is attempting to grapple with the challenges posed by our newest ways of communicating information. In a new report, it advises against social media companies removing content that is ""legal but harmful"". Instead, the report authors believe, social media sites should adjust their algorithms to prevent it going viral - and stop people making money off false claims. But not everyone agrees with that view - especially researchers who are experts in tracking the way misinformation spreads online, and how it harms people. The Center for Countering Digital Hate (CCDH) maintains there are cases when the best thing to do is to remove content when it is very harmful, clearly wrong and spreading very widely. The team points to Plandemic - a video that went viral at the start of the pandemic, making dangerous and false claims designed to scare people away from effective ways of reducing harm from the virus, like vaccines and masks, and was eventually taken down. Social media companies were better primed for the video's sequel Plandemic 2, which fell flat after being restricted on major platforms, having nothing like the same reach as the first video. ""It's a political question...what balance we see between individual liberties and some form of restrictions on what people can and cannot say,"" says Prof Rasmus Kleis Nielsen, director of the Reuters Institute for the Study of Journalism at the University of Oxford. Prof Nielsen acknowledges that, although it's a relatively small part of people's media diets, science misinformation can lead to disproportionate harm. But, he adds, given a lack of trust in institutions is a big driver of misinformation: ""I imagine that there are quite a lot of citizens who would have their worst suspicions confirmed about how society works, if established institutions took a much more hands-on role in limiting people's access to information."" Echoing this concern, the Royal Society says: ""Removing content may exacerbate feelings of distrust and be exploited by others to promote misinformation content."" This ""may cause more harm than good by driving misinformation content...towards harder-to-address corners of the internet."" The fact that those corners are ""harder to reach"", though, is arguably part of the point. It reduces the risk that someone who is not already committed to potentially harmful beliefs, and isn't seeking them out, will be exposed to them by chance. Some of the violent protests that were driven at least in part by conspiracies had their origin not in obscure corners of the internet, but on Facebook. And there is little clear evidence that removing content drives people further into harmful beliefs. Scientific misinformation is nothing new. The incorrect belief in a link between the MMR vaccine and autism came from a published (and later retracted) academic paper, while widespread unevidenced beliefs in the harm of water fluoridation were driven by the print media, campaign groups and word of mouth. What's changed is the speed at which false facts travel, and the huge numbers of people who can end up reading them. Rather than removing content, one way suggested by the report's authors of tackling misinformation is making it harder to find and share, and less likely to appear automatically on someone's feed. This, Prof Gina Neff, a social scientist at the Oxford Internet Institute explained, was to ""ensure that people still can speak their mind"" - they just aren't guaranteed an audience of millions. ""They can still post this information, but the platforms don't have to make it go viral."" The Institute for Strategic Dialogue (ISD), a think tank which monitors extremism, points out a substantial proportion of misinformation relies on the appropriation and misuse of genuine data and research. ""This is sometimes more dangerous than outright false information, because it can take substantially longer to debunk by explaining how and why this is a misreading or misuse of the data,"" its spokesperson says. That's where fact-checking comes in - another tool which the Royal Society supports. One of the most common pieces of vaccine misinformation over the past year - which the BBC has repeatedly fact-checked - was the notion that people are being harmed in high numbers by the jab. This claim is based on a misinterpretation of real figures. The ISD says research has shown that a small group of accounts spreading misinformation had a ""disproportionate influence on the public debate across social media"". ""Many of these accounts have been labelled by fact-checkers as sharing false or misleading content on multiple occasions, yet remain live."" The Royal Society did not investigate removing the accounts of ""influencers"" who are especially prolific spreaders of harmful misinformation. But this is seen as an important tool by many disinformation experts, and research into ISIS and the far-right suggests it can be successful. When David Icke, a prolific spreader of Covid misinformation as well as anti-Semitic conspiracy theories, was removed from YouTube, research from the CCDH found his ability to reach people was considerably reduced. While his videos remained on alternative video-hosting platform BitChute, their views fell from 150,000 on average before the YouTube ban to 6,711 afterwards. On YouTube, 64 of his videos had been viewed 9.6 million times. Research from Cardiff University, found that the de-platforming of Kate Shemirani, a former nurse and prolific spreader of Covid misinformation, decreased her reach in the short term. ""Part of the issue is that current models of de-platforming need to be developed. It's not enough to just take down a piece of content, or a small number of accounts,"" one of the paper's authors - Prof Martin Innes - explains. Research from organised crime and counter-terrorism shows the need to disrupt the whole network, he says. But he believes ""this level of sophistication isn't embedded yet"" in the way we tackle disinformation that could put people in danger."
Sixth-form students use art to explore fake news,"An online exhibition by sixth-form students from 58 different colleges in England features artists expressing their interpretation of fake news. The exhibition has been co-ordinated by the Sixth Form Colleges Association (SFCA) and features the work of more than 250 students. ""The Fake News exhibition highlights how young people feel about having to navigate the vast amount of news and information that is available in the modern world, and at the same time, to discern what is the truth,""  said Bill Watkin, chief executive of the SFCA. ""Art has always played an important role in social and political commentary. ""The exhibition is a celebration of the arts and a recognition of the excellence in sixth-form colleges, which are a vital supply pipeline of talented artists."" Here is a selection of work from the exhibition. Fake News runs until 22 July. All photographs subject to copyright"
Spotify removes Neil Young after he calls for Joe Rogan to go,"Neil Young's music is being removed from Spotify after the rock star called for the streaming platform to choose between him and podcaster Joe Rogan. Accusing him of Covid misinformation, Young told Spotify this week: ""They can have Rogan or Young. Not both."" Rogan has been criticised for interviewing an infectious disease specialist who opposes Covid-19 vaccines for children. Spotify said it ""regrets"" the move and hopes he returns to the platform soon. The Canadian-American musician behind classic rock hits such as Harvest Moon and Heart of Gold publicly accused Spotify on Monday of ""spreading fake information about vaccines - potentially causing death to those who believe the disinformation being spread by them"". In another statement posted to his website on Wednesday he called the music streaming giant ""the home of life-threatening Covid misinformation"", adding: ""Lies being sold for money."" He also thanked his record label, Warner Brothers-owned Reprise Records, for supporting his decision, saying that around 60% of all of his streamed music comes from Spotify listeners. ""Thank you Warner Brothers for standing with me and taking the hit - losing 60% of my worldwide streaming income in the name of Truth,"" he wrote online. Spotify reportedly paid $100m (Â£75m) for rights to The Joe Rogan Experience podcast in 2020. The programme is the top podcast on Spotify, and is reportedly downloaded almost 200 million times a month. On Wednesday, Spotify replied to the singer's ultimatum. ""We want all the world's music and audio content to be available to Spotify users. With that comes great responsibility in balancing both safety for listeners and freedom for creators,"" it said. ""We have detailed content policies in place and we've removed over 20,000 podcast episodes related to Covid since the start of the pandemic."" Spotify has more than 300m monthly listeners, including more than 170m who pay for a subscription to the service. It has defended Rogan in the past, including after an episode in 2020 that featured the conspiracy theorist Alex Jones. ""We want creators to create,"" chief executive Daniel Ek told The Financial Times at the time. ""It's what they do best. We're not looking to play a role in what they should say."" At the time of writing, no other artists have followed Young's lead. Steve Sladkowski, the guitarist for Canadian rock band Pup, gave one explanation why, tweeting, ""It rocks that Neil can take his music off [Spotify] but the fact remains that the vast majority of us can't afford to do that because the (very meagre) royalties are one of the few ways to cobble together any semblance of a living."" Young is not the first person to raise concerns over the content of Rogan's podcast. In early January, a group of doctors, scientists and healthcare professionals signed an open letter to Spotify citing Rogan's ""concerning history"" in discussing the Covid-19 pandemic. The letter referred to an episode in which Rogan interviewed Dr Robert Malone, a virologist who worked on early research into the mRNA technology behind several Covid-19 vaccines, but who is now critical of the treatments. Fact-checkers have fiercely disputed Dr Malone's claim that vaccination puts people who have already had Covid-19 at higher risk. He also said world leaders had hypnotised the public into supporting vaccines, drawing parallels between the pandemic and the rise of the Nazi party in 1930s Germany. Twitter banned Dr Malone, accusing him of spreading misinformation. Last year, before that episode was recorded, Rogan clarified that he was ""not an anti-vax person"". ""I believe they're safe and encourage many people to take them,"" he said, while refusing to back down on claims that young people did not ""need"" the vaccine. Rogan has also been criticised in the US for touting the anti-parasite drug ivermectin as a treatment for coronavirus. As for Young, the singer is no stranger to serious medical issues. He is a survivor of the polio virus, catching the infection as a child four years before a vaccine was made available in 1955. Young described the moment he was diagnosed with polio as his ""first big trauma"" and recalled how other children were warned to avoid him while he recovered in quarantine. The rock star has removed his songs from Spotify before - quitting the service, along with Apple Music and other streaming sites, in 2015 after stating their audio quality was not good enough. Follow us on Facebook, or on Twitter @BBCNewsEnts. If you have a story suggestion email entertainment.news@bbc.co.uk."
Sri Lanka: The fake ÂinvasionsÂ of a broadcaster and Central Bank,"Mass protests over Sri Lanka's worst economic crisis in decades have escalated this past week after crowds breached official buildings. But while protesters did in fact force their way into the Sri Lankan presidential residence and break into the prime minister's office in Colombo, misleading claims of other break-ins spiralled on social media. We've looked at a viral claim that the island's national broadcaster had been ""taken over"", as well as a video alleging that protesters had broken through to Sri Lanka's Central Bank. On Wednesday, major global media outlets mistakenly reported that Sri Lanka's national broadcaster Rupavahini was taken over by protesters. Some social media posts wrongly suggested that protesters had taken over anchoring duties for the national broadcaster. The BBC reached out to directors at Rupavahini to understand what happened at their premises on Wednesday. According to Rupavahini's Assistant Director and Head of Foreign News Prasad Kaushalya Dodangodage, the protesters arrived at the premises uninvited on Wednesday afternoon with a list of demands. After a discussion with directors at the national broadcaster, they were provided an interview slot. During the interview one of the protesters made a misleading claim in Sinhala that Rupavahini will only broadcast programmes of the Jana Aragalaya, or the protesters' movement against the government. ""Aragalaya"" in Sinhala means ""struggle"". Rupavahini does not subscribe to this, Mr Prasad told the BBC. The protesters left the premises after being granted 15 minutes of airtime. While broadcasts were briefly suspended, they later resumed, and the broadcaster returned to routine programming. By then, the misleading claim that protesters ""took over"" Sri Lanka's national broadcaster had been widely shared on social media by verified handles and by major news outlets, including some with millions of followers. A viral video on Twitter with over 1.5 million views claimed that protesters had stormed into Sri Lanka's Central Bank. The video was posted by a handle which claims to belong to an independent news agency. The video showed a large crowd of protesters - many of them dressed in black, some wearing helmets and some carrying the Sri Lankan flag - cheering as they opened a large gate and entered the premises of a building. In reality, protesters did not storm the Central Bank. The BBC analysed images from the viral video. They show protesters breaking through gates located on Janadhipathi Mawatha - the road where the Central Bank is based. But the video does not show protesters entering the Central Bank itself. This was confirmed by the BBC with local sources and by a Sri Lankan fact-checking service called WatchDog, which said their team members on the ground confirmed that no protesters entered the Central Bank. The presidential residence is 400 metres away from the Central Bank, according to Google Maps. The false claim was widely shared on social media. The BBC reached out to Twitter for comment. The company added a ""False Context"" label in accordance to their policies to one of the tweets sharing the misleading claim. On Wednesday, the Indian government denied reports that it helped Sri Lankan President Gotabaya Rajapaksa and former Finance Minister Basil Rajapaksa flee the country. President Rajapaksa fled to the Maldives on Wednesday. On Thursday, he, his wife, and personal bodyguards left the Maldives for Singapore. The Indian High Commission in Sri Lanka described the reports of the Indian government helping the Rajapaksas flee as ""baseless and speculative."" This is not the first time the Indian government has issued a statement to deny helping Sri Lankan politicians flee. In May, the day after then Prime Minister Mahinda Rajapaksa resigned, the Indian High Commission in Sri Lanka denied reports that ""certain political persons and their families"" have fled to India. On Sunday, the Indian government also denied reports that it sent troops to Sri Lanka. The same statement was issued by the Indian government in May as well. There were also rumours about India supplying a water cannon vehicle to Sri Lanka which India denied. Additional reporting by Josh Cheetham and Maryam Azwer"
Staged videos fuel religious hate and misogyny in India,"In a video shared and watched by millions of people in India, a man is seen attacking a person who is wearing a black burka and holding a child. He then forcibly removes the burka to reveal a man. The message accompanying the clip warns in Hindi that people should ""be aware"" of criminals using the burka - a veil used by Muslim women around the world - to disguise themselves and ""kidnap children"". The video, published on YouTube earlier this year, has been viewed more than 29 million times before it was deleted. But it did not show real events. It was a dramatisation - a scripted performance with amateur actors. Scripted videos, apparently created for entertainment, are increasingly being shared on social media as true events in India. Often accompanying the videos are false claims that stoke religious hatred and misogyny. India has witnessed growing tension among religious communities, particularly between Hindus and Muslims, since Prime Minister Narendra Modi's Hindu-nationalist Bharatiya Janata Party (BJP) came to power in May 2014. Many of the false narratives that target these communities also encourage moral policing against women. This trend of dramatised videos has reached multiple Indian languages, including Hindi, Tamil, Malayalam, Gujarati, Marathi and Telugu. Sometimes, local media outlets have also mistaken staged videos for news. Many of the staged videos show people wearing burkas in order to kidnap children. This could have real-life consequences - over the past few years, authorities in many Indian states have had to issue warnings against fake news after several people were attacked by mobs believing them to be kidnappers. These dramatised videos are accompanied by disinformation tactics which may confuse viewers on social media. Some have disclaimers but they may be hidden in the middle or the end of the videos. Most times, the text is in English, which is not always understood by viewers. According to a fact-check by Alt News, the original clip of the man wearing a burka - which was later deleted by its creator - actually had a disclaimer stating it was ""a work of fiction"". But it was visible only for a second. Other creators add CCTV templates to make the videos seem more realistic. One such video, which went viral in December 2021, was shared alongside claims without evidence in multiple languages that Muslim men were trying to intoxicate Hindu girls by spiking their food. In the comment section below the video, many users appeared to believe it was true, making Islamophobic remarks. ""Beware of love jihad,"" commented a user. ""Love jihad"" refers to a conspiracy theory which claims that Muslim men are wooing Hindu women to convert them to Islam. Most videos made by Hyderabad-based creator Venkat Seepana feature a recording sign and time-stamp like CCTV clips. His YouTube channel has over 1.2 million subscribers and more than 400 videos. One clip depicted a tailor misbehaving with a woman. It was shared multiple times on Twitter and Facebook with claims that it showed a Muslim man mistreating a Hindu woman: ""Hindu sisters and daughters are requested not to go to the shops of Muslims, they are people with a bad mentality."" Seepana told the BBC that he made these videos to ""spread awareness and show real-life situations"". Alishan Jafri, a journalist and disinformation researcher, says that dramatisations that go viral may not lead to physical violence. But they deepen existing religious biases. ""These videos are adding fuel to the fire in the society that is already divided and polarised. Most of these videos are targeted against certain communities, particularly Muslims, and when they go viral, they contribute to structural violence against the minority community,"" he says. Sometimes, these scripted videos - which spread confusion in the first place - are used to sow even more disinformation online. Some of them portray illicit relationships between friends, family members and people with a huge age difference. Two such staged videos were widely shared in May with false claims attacking the Hindu community. The first one depicted a man dressed in saffron - a colour associated with Hinduism - who claims he is marrying his sister. In the second video, the same woman is shown standing next to him in a burka and he says he is marrying her to convert her to Hinduism. On Twitter the clips were used by some to claim that this was a Hindu man who was making his sister pretend to be a Muslim woman. Both the man and woman seen in the two videos appear in several other videos portraying different characters. The original clips can be found on a YouTube channel with more than 400,000 followers which commonly posts scripted videos. When the BBC asked Vikram Mishra, the channel's owner, if he was aware that his videos were perceived as real, he replied: ""We all want to become a hit. I make videos that do well according to the trends of society."" He said the videos are created only for ""entertainment and views, as our team of 12 people earn their livelihood from our YouTube channel"". The BBC also reached out to social media platforms with questions about their policies on dramatised videos shared out of context. A Meta spokesperson said they have ""clear rules prohibiting content on Facebook that incites violence"" and that they remove anything that breaks these rules. YouTube too said the platform has ""strict policies prohibiting violent or graphic content"", misinformation, and ""misleading or deceptive content with serious risk of egregious harm"". X, formerly known as Twitter, sent an auto-reply that they would ""get back"" soon. Many of the videos look and feel staged, and they are also produced and shared in other countries. But they are believed by Indians and go viral in the country because they ""cater to more conservative audiences"", says Harish Nair, managing editor of Fact Crescendo, which operates in India and other Asian countries. He also believes Indians ""share videos which they believe are issued in the public interest"". According to him, staged videos are not the prevailing misinformation trend in India. But they have ""a huge impact on society as they validate their pre-existing beliefs and sentiments"". Prateek Waghre, policy director of Internet Freedom Foundation, a Delhi-based digital rights advocacy group, agrees. ""Low media literacy is one aspect of the problem, but this is happening in a society where there are existing social divisions and people are already primed to think like that."" But there are ways to check if a video is actually scripted. Ruby Dhingra, managing editor of India-based multilingual fact-check media Newschecker, said viewers should be wary of camera angles, locations, reactions and the language used in the video. They can reveal if the people caught in action are hiding from the camera or posing for it, and if they are speaking naturally or being loud and overacting. Dhingra also notes that it is ""highly unlikely"" that an incident will be captured by multiple cameras for its entire length and without any disruption, like the scripted videos. In a video shared and watched by millions of people in India, a man is seen attacking a person who is wearing a black burka and holding a child. He then forcibly removes the burka to reveal a man. The message accompanying the clip warns in Hindi that people should ""be aware"" of criminals using the burka - a veil used by Muslim women around the world - to disguise themselves and ""kidnap children"". The video, published on YouTube earlier this year, has been viewed more than 29 million times before it was deleted. But it did not show real events. It was a dramatisation - a scripted performance with amateur actors. Scripted videos, apparently created for entertainment, are increasingly being shared on social media as true events in India. Often accompanying the videos are false claims that stoke religious hatred and misogyny. India has witnessed growing tension among religious communities, particularly between Hindus and Muslims, since Prime Minister Narendra Modi's Hindu-nationalist Bharatiya Janata Party (BJP) came to power in May 2014. Many of the false narratives that target these communities also encourage moral policing against women. This trend of dramatised videos has reached multiple Indian languages, including Hindi, Tamil, Malayalam, Gujarati, Marathi and Telugu. Sometimes, local media outlets have also mistaken staged videos for news. Many of the staged videos show people wearing burkas in order to kidnap children. This could have real-life consequences - over the past few years, authorities in many Indian states have had to issue warnings against fake news after several people were attacked by mobs believing them to be kidnappers. These dramatised videos are accompanied by disinformation tactics which may confuse viewers on social media. Some have disclaimers but they may be hidden in the middle or the end of the videos. Most times, the text is in English, which is not always understood by viewers. According to a fact-check by Alt News, the original clip of the man wearing a burka - which was later deleted by its creator - actually had a disclaimer stating it was ""a work of fiction"". But it was visible only for a second. Other creators add CCTV templates to make the videos seem more realistic. One such video, which went viral in December 2021, was shared alongside claims without evidence in multiple languages that Muslim men were trying to intoxicate Hindu girls by spiking their food. In the comment section below the video, many users appeared to believe it was true, making Islamophobic remarks. ""Beware of love jihad,"" commented a user. ""Love jihad"" refers to a conspiracy theory which claims that Muslim men are wooing Hindu women to convert them to Islam. Most videos made by Hyderabad-based creator Venkat Seepana feature a recording sign and time-stamp like CCTV clips. His YouTube channel has over 1.2 million subscribers and more than 400 videos. One clip depicted a tailor misbehaving with a woman. It was shared multiple times on Twitter and Facebook with claims that it showed a Muslim man mistreating a Hindu woman: ""Hindu sisters and daughters are requested not to go to the shops of Muslims, they are people with a bad mentality."" Seepana told the BBC that he made these videos to ""spread awareness and show real-life situations"". Alishan Jafri, a journalist and disinformation researcher, says that dramatisations that go viral may not lead to physical violence. But they deepen existing religious biases. ""These videos are adding fuel to the fire in the society that is already divided and polarised. Most of these videos are targeted against certain communities, particularly Muslims, and when they go viral, they contribute to structural violence against the minority community,"" he says. Sometimes, these scripted videos - which spread confusion in the first place - are used to sow even more disinformation online. Some of them portray illicit relationships between friends, family members and people with a huge age difference. Two such staged videos were widely shared in May with false claims attacking the Hindu community. The first one depicted a man dressed in saffron - a colour associated with Hinduism - who claims he is marrying his sister. In the second video, the same woman is shown standing next to him in a burka and he says he is marrying her to convert her to Hinduism. On Twitter the clips were used by some to claim that this was a Hindu man who was making his sister pretend to be a Muslim woman. Both the man and woman seen in the two videos appear in several other videos portraying different characters. The original clips can be found on a YouTube channel with more than 400,000 followers which commonly posts scripted videos. When the BBC asked Vikram Mishra, the channel's owner, if he was aware that his videos were perceived as real, he replied: ""We all want to become a hit. I make videos that do well according to the trends of society."" He said the videos are created only for ""entertainment and views, as our team of 12 people earn their livelihood from our YouTube channel"". The BBC also reached out to social media platforms with questions about their policies on dramatised videos shared out of context. A Meta spokesperson said they have ""clear rules prohibiting content on Facebook that incites violence"" and that they remove anything that breaks these rules. YouTube too said the platform has ""strict policies prohibiting violent or graphic content"", misinformation, and ""misleading or deceptive content with serious risk of egregious harm"". X, formerly known as Twitter, sent an auto-reply that they would ""get back"" soon. Many of the videos look and feel staged, and they are also produced and shared in other countries. But they are believed by Indians and go viral in the country because they ""cater to more conservative audiences"", says Harish Nair, managing editor of Fact Crescendo, which operates in India and other Asian countries. He also believes Indians ""share videos which they believe are issued in the public interest"". According to him, staged videos are not the prevailing misinformation trend in India. But they have ""a huge impact on society as they validate their pre-existing beliefs and sentiments"". Prateek Waghre, policy director of Internet Freedom Foundation, a Delhi-based digital rights advocacy group, agrees. ""Low media literacy is one aspect of the problem, but this is happening in a society where there are existing social divisions and people are already primed to think like that."" But there are ways to check if a video is actually scripted. Ruby Dhingra, managing editor of India-based multilingual fact-check media Newschecker, said viewers should be wary of camera angles, locations, reactions and the language used in the video. They can reveal if the people caught in action are hiding from the camera or posing for it, and if they are speaking naturally or being loud and overacting. Dhingra also notes that it is ""highly unlikely"" that an incident will be captured by multiple cameras for its entire length and without any disruption, like the scripted videos."
Tech Tent: Did social media inspire Congress riot?,"It was the most violent assault on the US Capitol since the British Army set it ablaze in the war of 1814. This week's Tech Tent asks what role social media played in preparing the ground for the riots which saw Donald Trump's supporters storm Congress. The BBC's disinformation specialist, Marianna Spring, told the programme that the roots of the anger on display amongst Trump supporters can be traced back to before the presidential  election. ""President Trump, on his own Twitter feed, amplified and suggested that this election was going to be rigged, that there was going to be fraudulent voting,"" she said. Then, after the election, she saw lots of Facebook groups spring up using the term ""stop the steal"", echoing Trump's own language. Facebook removed many of the groups, but by then the damage was done - just as it was with the social media giant's belated move to remove content about the QAnon conspiracy theory. ""When the roots of these conspiracies are so deep, it comes as little surprise that the threats continued, the disinformation continued,"" Spring said. ""A lot of people who attended Capitol Hill felt so passionate about this - and really genuinely believed these false claims spreading online about voter fraud."" Disinformation researcher Dr Alexi Drew, of King's College London, said this ""is something that a lot of us have been saying has been a real risk for quite some time"". She added: ""It's just tragic that it's taken the realisation of that risk for others to listen, and actually realise that we weren't exaggerating what we've been trying to say for the past four years or more."" Many of the conspiracy theorists have moved on to far-right platforms such as Parler, when they have been banned from Facebook or Twitter. But Dr Drew says the social media giants have no excuse for not moving more rapidly against groups which are spreading dangerous lies. And she reserves her strongest criticism for Facebook, which has encouraged people to join such groups through its algorithm. ""They've had the controls and the ability to stamp down on group recommendations and these closed groups - and the content in these groups - since they were created. ""They've just not done it until now."" The question is what happens next. You might think that with both Democrats and Republicans extremely critical of social media, tighter regulation is a surefire bet under the Biden administration. But what that will look like remains to be seen. Will it, for instance, involve the repeal of section 230, which protects online platforms from legal action over user comments? The danger is that tighter rules will be more expensive for tech companies - which could just reinforce the dominance of the existing wealthy players, shutting out newcomers. And is it even clear that social media bears most of the responsibility for spreading the lies and hatred that led to the assault on the Capitol? Remember, Fox News, talk radio stations and more recently TV channels such as OANN and NewsMax have fed their audiences a Trump-shaped view of the world for a long time. Last year, Harvard University's Berkman Klein Center published a study of how misinformation spread about the amount of fraud in postal voting. The researchers found that social media activity around the subject surged when mainstream news reports carried speeches about it by President Trump, peaking last April when Fox News ran numerous segments about its dangers. Ever since the Reagan administration abolished the Fairness Doctrine in the 1980s, television news channels have been free to offer a partisan view. The result today is that viewers of Fox News and MSNBC might as well occupy two very different countries. It is hard to see how tighter regulation of social media will change that."
Texas shooting: How false rumours spread that gunman was trans,"Minutes after Tuesday's tragic shooting at the Robb Elementary School in Uvalde, Texas, false rumours began spreading about the identity of the gunman. Images of three separate trans women were shared online purporting to be of the gunman, and leading to a barrage of abuse. The inaccurate claims were also amplified by US politicians and political influencers, some of whom also more broadly linked transgenderism to violence. Almost immediately after the shooting, pictures of the gunman, Salvador Ramos, 18, appeared online. Ramos didn't have a huge social media footprint - but one photo in particular was widely circulated. Taken from his Instagram and TikTok accounts, it showed him looking into a mirror wearing a dark grey hoodie. The rumour that he was trans appears to have started on the fringe message board 4chan, and in particular the /pol/ or ""Politically Incorrect"" board, which has for years been associated with the far-right and mass shootings. A controversial hub of internet subculture, 4chan has been the birthplace of many harassment and trolling campaigns. Users posted an image of a trans woman who slightly resembled Ramos, along with a link to her Reddit profile, and baselessly claimed she was the gunman. It didn't take long for the claim to migrate to other, larger social platforms, and it began to be repeated by far-right and right-wing activists and politicians. Conservative activist Candace Owens claimed there were photos of the gunman ""cross-dressing"", and claimed this was evidence that ""there were plenty of signs that he was mentally disturbed"". Republican congressman Paul Gosar, of Arizona, repeated the trans claim in a tweet that he later deleted. Mr Gosar also called the gunman, who was born in the United States, an ""illegal alien"", although Texas governor Greg Abbott, also a Republican, stated that Ramos was a US citizen. We contacted Ms Owens, and Mr Gosar's spokesperson, for comment. Another congressman, Pete Sessions, claimed in an interview on the Today Programme on Thursday that Ramos ""wore dresses"". Sam, the transgender woman targeted by the 4chan campaign, posted on Reddit saying that she didn't live in Texas and was alive after the shooting, even though Ramos was shot dead. But Sam - not her real name - wasn't the only trans person targeted by false stories. Images of Sabrina, another trans woman, appeared in photo collages alongside the actual photo of the gunman, with similar false claims. She posted an image of herself holding her phone with the time and date visible to prove she was alive after the shooting. And another trans person's image which also appeared on 4chan later popped up in far-right spaces, including conspiracy theorist Alex Jones's Infowars website. This is not the first time that trans and other LGBT individuals have been the targets of misinformation, says Mallory Moore, a researcher with the Trans Safety Network, a UK-based organisation. She says the organisation advised Sabrina on how to put social media safeguards in place following the attack and online abuse - something she described as ""pre-emptive"". ""As things tend to spiral, people will pick through someone's social media and dump it online,"" she says. ""Getting ahead of that is a sensible precaution."" As often happens after mass shootings, a number of other false rumours spread in the wake of the attack. BBC News observed at least a dozen fake accounts claiming to belong to the gunman in the aftermath, most of which were attempts to copy his removed, genuine account on Instagram. Most have been removed."
The 'ninjas' fighting climate change denial on Twitter,"Secretive internet vigilantes have made it their mission to fight climate change denial on Twitter. But, as a vicious information war rages online, do they risk becoming the very trolls they claim to be targeting? I meet Maria and Arthur at the top of a hill overlooking the Mediterranean Sea, in a small coastal town in Spain. They ask me not to reveal their real names or their exact whereabouts. Over the years, they have made countless enemies on the internet, and they believe stepping out of the shadows could prove dangerous. ""For you to be able to do your work, and not be scared of the consequences, you really have to fly under the radar,"" Maria tells me. In 2019, she helped set up Team Ninja Trollhunters, a group of 25 people from around the world who came together to fight climate change denial on Twitter. ""For me, it was a necessity to show that many things that are being tweeted are wrong,"" Maria says. Like some of her fellow vigilantes, she has a background in science, which comes in handy when looking through complex research. But, with her blue Snoopy t-shirt, Maria does not immediately strike me as a ""ninja"" - and neither does her softly spoken partner, Arthur, whom she recruited into the group. ""We fought many battles together and we also had a lot of fun,"" he says. When the group first came together in 2019, part of its time was spent fact-checking false or misleading claims they found on Twitter. The ""ninjas"" spotted claims going viral and responded to them with links to factual information - academic papers or scientific reports. ""But after a couple of months, you realise you don't make an impact because, for most of these people, facts are irrelevant,"" Maria says. It was time to come up with new tactics. The ""ninjas"" began keeping tabs on prominent Twitter accounts which disputed the basic science of climate change. Whenever those users tweeted something which broke the platform's rules, they would report them. Climate change denial is not forbidden on Twitter, but some other types of content are - like threats, harassment, or hate speech. Until November last year, posting misleading claims about Covid-19 could also lead to tweets being removed or accounts being suspended. ""At the end of the day,  it doesn't matter whether they get suspended because of Covid-19 misinformation or Nazi symbols,"" Maria tells me. ""When they're gone, they're gone."" You can listen to ""Twitter 'ninjas' against climate denial"" on BBC Sounds. Thousands of hours of slow, painstaking work paid off - or so the ""ninjas"" like to believe. They claim that, as a result of their actions, about 600 Twitter accounts promoting climate change denial were suspended. I cannot independently verify this claim. But I have seen links to hundreds of offending tweets that the ""ninjas"" reported , as well as a detailed list of suspended accounts. One of those accounts was Mike's. He is an Australian engineer with more than 23,000 followers on Twitter - many of whom believe in conspiracy theories. In April last year, his account was permanently suspended from Twitter, after posting an unfounded claim about Covid vaccines. Up until that point, the ""ninjas"" had been keeping watch on his feed, reporting dozens of his tweets. In a private forum, they added Mike's handle to their list of claimed scalps. ""I'm not surprised in the slightest,"" Mike says. Over the years, he claims to have been repeatedly targeted by groups like this one, which he accuses of ""trolling"" users like him. The ""ninjas"" share a set of rules laid out in a document called ""The Resistor's Guide to Effective Trollhunting"". In it, members are advised ""not to engage"" with their targets. And yet, by their own admission, each member of the group has their own way of operating. Maria insists she always played by the rules and that she ""knew where the line was"". But Arthur's methods led to him getting temporarily suspended from Twitter ""a couple of times"". ""When I engaged climate change deniers, I noticed some of them got agitated. So I continued to do it, until the point they showed harassing behaviour [against me], which is not allowed,"" he told me. ""Then you can get rid of them."" I suggest to Arthur that his behaviour may not be dissimilar to that of an online troll. ""You could say that, because it is partially true,""  he replies. But I point out to him that, by provoking his targets into crossing a line, he could be causing real-world harm. ""I can't see any real-world damage worse than what they are doing,"" he says. ""When they are trying to convince people climate change is a myth, they are inflicting damage upon all of us."" But the ""ninjas""' efforts have been somewhat hampered by Elon Musk's takeover of Twitter. Last November, the billionaire announced the platform would reinstate thousands of previously suspended accounts. Mike's account was among them. ""That was a slap in the face,"" Maria says. ""If Twitter decided that these people should be suspended, there was a good reason for it."" Twitter did not respond to requests for comment. Maria and Arthur have now left Twitter, but other members of the group have stayed there. Their online battle continues. I have spoken to several of the group's current members, and they described a recent ""uptick"" in climate misinformation circulating on Twitter. For Arthur, this proves just how relevant the ""ninjas"" continue to be. ""If just a fraction of regular people would do what we did, we would be much louder than all deniers together."" You can listen to Twitter 'ninjas' against climate denial on BBC Sounds. Secretive internet vigilantes have made it their mission to fight climate change denial on Twitter. But, as a vicious information war rages online, do they risk becoming the very trolls they claim to be targeting? I meet Maria and Arthur at the top of a hill overlooking the Mediterranean Sea, in a small coastal town in Spain. They ask me not to reveal their real names or their exact whereabouts. Over the years, they have made countless enemies on the internet, and they believe stepping out of the shadows could prove dangerous. ""For you to be able to do your work, and not be scared of the consequences, you really have to fly under the radar,"" Maria tells me. In 2019, she helped set up Team Ninja Trollhunters, a group of 25 people from around the world who came together to fight climate change denial on Twitter. ""For me, it was a necessity to show that many things that are being tweeted are wrong,"" Maria says. Like some of her fellow vigilantes, she has a background in science, which comes in handy when looking through complex research. But, with her blue Snoopy t-shirt, Maria does not immediately strike me as a ""ninja"" - and neither does her softly spoken partner, Arthur, whom she recruited into the group. ""We fought many battles together and we also had a lot of fun,"" he says. When the group first came together in 2019, part of its time was spent fact-checking false or misleading claims they found on Twitter. The ""ninjas"" spotted claims going viral and responded to them with links to factual information - academic papers or scientific reports. ""But after a couple of months, you realise you don't make an impact because, for most of these people, facts are irrelevant,"" Maria says. It was time to come up with new tactics. The ""ninjas"" began keeping tabs on prominent Twitter accounts which disputed the basic science of climate change. Whenever those users tweeted something which broke the platform's rules, they would report them. Climate change denial is not forbidden on Twitter, but some other types of content are - like threats, harassment, or hate speech. Until November last year, posting misleading claims about Covid-19 could also lead to tweets being removed or accounts being suspended. ""At the end of the day,  it doesn't matter whether they get suspended because of Covid-19 misinformation or Nazi symbols,"" Maria tells me. ""When they're gone, they're gone."" You can listen to ""Twitter 'ninjas' against climate denial"" on BBC Sounds. Thousands of hours of slow, painstaking work paid off - or so the ""ninjas"" like to believe. They claim that, as a result of their actions, about 600 Twitter accounts promoting climate change denial were suspended. I cannot independently verify this claim. But I have seen links to hundreds of offending tweets that the ""ninjas"" reported , as well as a detailed list of suspended accounts. One of those accounts was Mike's. He is an Australian engineer with more than 23,000 followers on Twitter - many of whom believe in conspiracy theories. In April last year, his account was permanently suspended from Twitter, after posting an unfounded claim about Covid vaccines. Up until that point, the ""ninjas"" had been keeping watch on his feed, reporting dozens of his tweets. In a private forum, they added Mike's handle to their list of claimed scalps. ""I'm not surprised in the slightest,"" Mike says. Over the years, he claims to have been repeatedly targeted by groups like this one, which he accuses of ""trolling"" users like him. The ""ninjas"" share a set of rules laid out in a document called ""The Resistor's Guide to Effective Trollhunting"". In it, members are advised ""not to engage"" with their targets. And yet, by their own admission, each member of the group has their own way of operating. Maria insists she always played by the rules and that she ""knew where the line was"". But Arthur's methods led to him getting temporarily suspended from Twitter ""a couple of times"". ""When I engaged climate change deniers, I noticed some of them got agitated. So I continued to do it, until the point they showed harassing behaviour [against me], which is not allowed,"" he told me. ""Then you can get rid of them."" I suggest to Arthur that his behaviour may not be dissimilar to that of an online troll. ""You could say that, because it is partially true,""  he replies. But I point out to him that, by provoking his targets into crossing a line, he could be causing real-world harm. ""I can't see any real-world damage worse than what they are doing,"" he says. ""When they are trying to convince people climate change is a myth, they are inflicting damage upon all of us."" But the ""ninjas""' efforts have been somewhat hampered by Elon Musk's takeover of Twitter. Last November, the billionaire announced the platform would reinstate thousands of previously suspended accounts. Mike's account was among them. ""That was a slap in the face,"" Maria says. ""If Twitter decided that these people should be suspended, there was a good reason for it."" Twitter did not respond to requests for comment. Maria and Arthur have now left Twitter, but other members of the group have stayed there. Their online battle continues. I have spoken to several of the group's current members, and they described a recent ""uptick"" in climate misinformation circulating on Twitter. For Arthur, this proves just how relevant the ""ninjas"" continue to be. ""If just a fraction of regular people would do what we did, we would be much louder than all deniers together."" You can listen to Twitter 'ninjas' against climate denial on BBC Sounds."
The (almost) complete history of 'fake news',"In record time, the phrase morphed from a description of a social media phenomenon into a journalistic cliche and an angry political slur. How did the term ""fake news"" evolve - and what's next in the world of disinformation? It was mid-2016, and Buzzfeed's media editor, Craig Silverman, noticed a funny stream of completely made-up stories that seemed to originate from one small Eastern European town. ""We ended up finding a small cluster of news websites all registered in the same town in Macedonia called Veles,"" Silverman recalls. He and a colleague started to investigate, and shortly before the US election they identified at least 140 fake news websites which were pulling in huge numbers on Facebook. The young people in Veles may or may not have had much interest in American politics, but because of the money to be made via Facebook advertising, they wanted their fiction to travel widely on social media. The US presidential election - and specifically Donald Trump - was (and of course still is) a very hot topic on social media. And so the Macedonians and other purveyors of fakery wrote stories with headlines such as ""Pope Francis Shocks World, Endorses Donald Trump for President"" and ""FBI Agent Suspected in Hillary Email Leaks Found Dead in Apparent Murder-Suicide"". They were completely false. And thus began the modern - and internet-friendly - life of the phrase ""fake news"". Misinformation, spin, lies and deceit have of course been around forever. But what Silverman and others uncovered was a unique marriage between social media algorithms, advertising systems, people prepared to make stuff up to earn some easy cash and an election that gripped a nation and much of the world. In the wake of President Trump's victory, BBC Trending delved into the huge world of pro-Trump Facebook groups. Inside those hyper-partisan spaces there were some outright falsehoods circulating. But most of the content was more traditional political communication: puffery, drumbeating, and opponent-slagging. There were memes showing Trump as a fearless leader, support for his pledges to deport illegal immigrants, and potted biographies describing the candidate as ""the very definition of the American success story."" It was hardly balanced stuff - but nor did much of it qualify as ""fake news"". But pundits scrambling to explain the shock result (and in many cases, their own follies) turned to ""fake news"" as one possible explanation. The phrase now evokes much more than those get-rich-quick Macedonian teenagers. President Trump even gave out ""Fake News Awards"" to reporters who had made errors or poor predictions - with a special nod to all reporting on the ongoing and very real investigations into collusion between the Trump campaign and Russia. But to say that President Trump was the first politician to deploy the term would itself be, well, ""fake news"". On 8 December 2016, Hillary Clinton made a speech in which she mentioned ""the epidemic of malicious fake news and false propaganda that flooded social media over the past year."" ""It's now clear that so-called fake news can have real-world consequences,"" she said. ""This isn't about politics or partisanship. Lives are at riskÂ lives of ordinary people just trying to go about their days, to do their jobs, contribute to their communities."" Some journalists at the time interpreted her remarks as a reference to ""Pizzagate"", a bonkers conspiracy theory which sprouted and grew to tremendous proportions online. It started with a rumour that sex slaves were being held under a Washington pizza restaurant, and ended a couple of days before Clinton's speech, when a man entered the busy family-friendly restaurant with a rifle. Nobody was injured, and the man was arrested and sentenced to four years in jail. But in that speech, Clinton also asked her audience to help ""protect our democracy"". Other reporters interpreted that more broadly as a reference to the election. President-elect Trump took up the phrase the following month, in January 2017, a little over a week before taking office. In response to a question, he said ""you're fake news"" to CNN reporter Jim Acosta. Around the same time he started repeating the phrase on Twitter. ""That signalled to the many people out there who were supporting Trump and running websites supportive of him, that he was saying 'OK, we're going to take this term and make it ours',"" Silverman says. The fake news horse had not just bolted from the stable, it was off and running. Since then phrase has been used more or less continuously by Trump and other world leaders, as well as by countless political operatives, journalists and ordinary people. As a rough guide, a Google News search of ""fake news"" throws up 5 million results, and already in 2018 the phrase has been used about two million times on Twitter. And, contrary to the conventional wisdom, it's no longer a stream of falsehoods eagerly swallowed solely by Trump supporters and/or those with little education. By April 2017, Trending was reporting on the phenomenon of left-wing, anti-Trump fakery. Experts say highly-educated people can be duped by lies as well - and can often be more stubborn when presented with information that challenges their views. But within months the sheer ubiquity of the phrase ""fake news"" had perhaps rendered the term meaningless. All sorts of things - misinformation, spin, conspiracy theories, mistakes, and reporting that people just don't like - have been rolled into it. ""We did this to ourselves, and by 'we', I mean the media,"" says Alexios Mantzarlis, director of the Poynter Institute's International Fact-Checking Network. ""Right after the election, in editorials, in news articles, we started calling 'fake news' a bit of everything. ""We should be conscious that our industry is partly to blame for the confusion we're at."" And some experts with huge experience in the field have started to back away from the fake news fire altogether. ""The reason I don't like the phrase now is it's used as a term to describe everything,"" says Clare Wardle of First Draft News, a truth-seeking non-profit based at Harvard's Shorenstein Centre. ""Whether it's a sponsored post, an ad, a visual meme, a bot on Twitter, a rumour - people just use it against any information they don't like."" ""This is a really complex problem,"" she says. ""If we're going to start thinking of ways we can intervene, we're going to have to have clear definitions."" Wardle says that an obsession with the phrase (and yes, this story admittedly might be a part of that) is actually hurting the credibility of otherwise credible news outlets. ""My concern now is the kind of reporting we see on disinformation,"" says Clare Wardle. ""People are saying, 'I don't know who to believe or who to trust, everything's broken.' My concern is the way that we're talking about some of these issues is actually doing more than the original misinformation did in the first place."" Mantzarlis says that while he's concerned about language creep, he isn't ready to abandon it altogether - although he would like to see ""fake news"" restricted to descriptions of spammy made-up stories wrecking Facebook news feeds. ""Just because someone else is using the term to mean something different doesn't mean it loses its value,"" he says. ""If someone starts calling a telephone a banana, and has a very big megaphone, doesn't mean that the rest of us should stop calling a telephone a telephone."" Clearly the enabler of the modern form of ""fake news"" - or, if you like, misinformation - has been the explosive growth of social media. ""In the early days of Twitter, people would call it a 'self-cleaning oven', because yes there were falsehoods, but the community would quickly debunk them,"" Wardle says. ""But now we're at a scale where if you add in automation and bots, that oven is overwhelmed. ""There are many more people now acting as fact-checking and trying to clean all the ovens, but it's at a scale now that we just can't keep up."" So what to do about it? Fact-checking works, says Alexios Mantzarlis, but automated solutions are probably not the answer. ""We're been heralding robotic fact checking for about 20 years and we're nowhere near it,"" he says. ""What we can do is help humans and journalists find fishy claims faster, and get access to the stats that they need to verify a claim faster."" ""I see an enormous potential in technology as an assistant and turbocharger of fact-checking,"" he says. ""I see very little use in technology as a one-size-fits all universal fixer of this problem."" But all the fact-checking institutions in the world will never be able to beat down every rumour or fake ""fact"". And while some media reports have  cast doubt on the efficacy of fact-checking, Mantzarlis is convinced that his work has an impact. ""What we've seen over the past two years is that consistently, across the board, regardless of partisanship, when people get told a falsehood and get presented with a correction, their belief in the falsehood goes down,"" he says. People might be ""fact resistant"", but very few are ""fact immune"", he says. In the future, the term ""fake news"" might come to be seen as a relic of a febrile 2017 (if we're lucky). But the fight against misinformation won't go away. Companies and governments are now starting to take concrete action, the consequences of which will be felt for some time. ""Google and Facebook have both said that they are going to be hiring a lot of people to review content and enforce their terms of service and keep fake and illegal stuff off their platform. I'm interested to see how that is actually done,"" Buzzfeed's Silverman says. ""The opaqueness of these platforms and their power and the fact that so much speech has moved on to them is something that we need to pay attention to and make sure that we don't turn them from places where misinformation is running rampant to places that are so locked down that they are inhibiting speech,"" he says. Alongside worries about the power of the social media companies, the experts also have concerns about the power of governments. ""Sometimes well-intentioned but ill-informed legislators will overreach and do more harm that the problem they are trying to fix, with legislation on fake news,"" Mantzarlis says, noting that legislation is being proposed in several countries across Europe. The most sweeping such legislation came into effect on 1 January in Germany. The law demands that social media sites quickly remove hate speech, fake news and illegal material or face fines up to 50m euro (Â£44.3m, $61.1m). And beyond viral political text news stories, there are new frontiers which fact-checkers are trying to delve into. ""I really think we need to be thinking of visuals more. Visuals are very powerful vehicles of disinformation,"" Claire Wardle says. Often photos are travelling with rapid speed on closed messaging apps such as WhatsApp or Viber. And while the discussion about ""fake news"" has focused on the West, a lot of misinformation like this is circulating about health, religion and society outside of the US, in developing countries. ""The power of something like WhatsApp is that it's travelling between very close networks of peers who are much more likely to trust each other,"" Wardle says. There's one essential question - what impact does misinformation really have in the minds of voters? Ever since the debate over the issue really took off a little over a year ago, there's been enormous disagreement as to whether false stories spread online actually have any impact on people's politics or voting patterns. In one of the first academic studies about the consumption of fake news, researchers at Princeton, Dartmouth and the University of Exeter estimated that about 25 percent of Americans visited a fake news website in a six-week period around the time of the 2016 US election. But the researchers also found that the visits were highly concentrated - 10% of readers made 60% of the visits. And crucially, the researchers concluded ""fake news does not crowd out hard news consumption."" ""The reach was relatively wide, but not so deep,"" Mantzarlis says. ""It's quite a big step further to say, are people voting on this, making decisions on it."" ""To say it's poisoning our democracy or it won this guy or the other guy an election, we need a lot more research to be able to say that."" Do you have a story for BBC Trending? Email us. You can follow BBC Trending on Twitter @BBCtrending, and find us on Facebook.  All our stories are at bbc.com/trending."
The 65 days that led to chaos at the Capitol,"Many were taken by surprise by the events in Washington, but to those who closely follow conspiracy and extreme right groups online, the warning signs were all there. At 02:21 Eastern Standard Time on election night, President Trump walked onto a stage set up in the East Room of the White House and declared victory. ""We were getting ready to win this election. Frankly, we did win this election."" His speech came an hour after he'd tweeted: ""They are trying to steal the election"". He hadn't won. There was no victory to steal. But to many of his most fervent supporters, these facts didn't matter, and still don't. Sixty five days later, a motley coalition of rioters stormed the US Capitol building. They included believers in the QAnon conspiracy theory, members of ""Stop the Steal"" groups, far-right activists, online trolls and others. On Friday 8 January -  some 48 hours after the Washington riots - Twitter began a purge of some of the most influential pro-Trump accounts that had been pushing conspiracies and urging direct action to overturn the election result. Then came the big one - Mr Trump himself. The president was permanently banned from tweeting to his more than 88 million followers ""due to the risk of further incitement of violence"". The violence in Washington shocked the world and seemed to catch the authorities off guard. But for anyone who had been carefully watching the unfolding story - online and on the streets of American cities - it came as no surprise. The idea of a rigged election was seeded by the president in speeches and on Twitter, months before the vote. On election day, the rumors started just as Americans were going to the polls. A video of a Republican poll watcher being denied entry to a Philadelphia polling station went viral. It was a genuine error, caused by confusion about the rules. The man was later allowed into the station to observe the count. But it became the first of many videos, images, graphics and claims that went viral in the days that followed, giving rise to a hashtag: #StopTheSteal. The message behind it was clear - Mr Trump had won a landslide victory, but dark forces in the establishment ""deep state"" had stolen it from him. In the early hours of Wednesday 4 November, while votes were still being counted and three days before the US networks called the election for Joe Biden, President Trump claimed victory, alleging ""a fraud on the American public"". Mr Trump did not provide any evidence to back up his claims. Studies carried out for previous US elections have shown that voter fraud is extremely rare. By mid-afternoon a Facebook group called ""Stop the Steal"" was created and quickly became one of the fastest-growing in the platform's history. By Thursday morning, it had added more than 300,000 members. Many of the posts focused on unsubstantiated allegations of mass voter fraud, including manufactured claims that thousands of dead people had voted and that voting machines had somehow been programmed to flip votes from Mr Trump to Mr Biden. But some of the posts were more alarming, speaking of the need for a ""civil war"" or ""revolution"". By Thursday afternoon, Facebook had taken down Stop the Steal, but not before it had generated nearly half a million comments, shares, likes, and reactions. Dozens of other groups quickly sprang up in its place. The idea of a stolen election continued to spread online and take hold. Soon, a dedicated Stop the Steal website was launched in a bid to register ""boots on the ground to protect the integrity of the vote"". On Saturday 7 November, major news organisations declared that Joe Biden had won the election. In Democratic strongholds, throngs of people took to the streets to celebrate. But the reaction online from Mr Trump's most ardent supporters was one of anger and defiance. They planned a rally in Washington DC for the following Saturday, dubbed the Million MAGA (Make America Great Again) March. Trump tweeted that he might try to stop by the demonstration and ""say hello"". Previous pro-Trump rallies in Washington had failed to attract large crowds. But thousands gathered at Freedom Plaza that sunny morning. One extremism researcher called it the ""debut of the pro-Trump insurgency"". As Trump's motorcade drove through the city, supporters screaming with delight rushed to catch a glimpse of the president, who beamed at them wearing a red MAGA hat. While mainstream conservative figures were present, the event was dominated by far-right groups. Dozens of members of the far-right, anti-immigrant, all-male group Proud Boys, who have repeatedly been involved in violent street protests and were among those who would later break into the US Capitol, joined the march. Militia groups, far-right media figures and promoters of conspiracy theories were also there. As night fell, clashes between Trump supporters and counter-protesters broke out, including a brawl about five blocks from the White House. The violence - although largely contained by police on this occasion - was a clear sign of things to come. By now, President Trump and his legal team had invested their hopes in dozens of legal cases. Although a number of courts had already dismissed fraud allegations, many in the pro-Trump online world became fascinated with two lawyers with close ties to the president - Sidney Powell and L Lin Wood. Ms Powell and Mr Wood promised they were preparing cases of voter fraud so comprehensive that when released, they would destroy the case for Mr Biden having won the presidency. Ms Powell, 65, a conservative activist and former federal prosecutor, told Fox News that the effort would ""release the Kraken"" - a reference to a gigantic sea monster from Scandinavian folklore that rises up from the ocean to devour its enemies. The ""Kraken"" quickly became an internet meme, representing sprawling, unsubstantiated claims of widespread election fraud. Ms Powell and Mr Wood became heroes to followers of the QAnon conspiracy theory - who believe President Trump and a secret military intelligence team are battling a deep state made up of Satan-worshipping paedophiles in the Democratic Party, media, business and Hollywood. The lawyers became a conduit between the president and his most conspiracy-minded supporters - a number of whom ended up inside the Capitol on 6 January. Ms Powell and Mr Wood were successful in whipping up sound and fury online, but their legal efforts came to nothing. When they released almost 200 pages of documents in late November, it became clear that their lawsuit consisted predominantly of conspiracy theories and debunked allegations that had already been rejected by dozens of courts. The filings contained simple legal errors - and basic misspellings and typos. Still, the meme lived on. The terms ""Kraken"" and ""Release the Kraken"" were used more than a million times on Twitter before the Capitol riot. As courts rejected Mr Trump's legal cases, far-right activists increasingly targeted election workers and officials. Death threats were made against a Georgia election worker, and Republican officials in the state - including Governor Brian Kemp, Secretary of State Brad Raffensperger and the official in charge of the state's voting systems, Gabriel Sterling - were branded ""traitors"" online. Mr Sterling issued an emotional and prescient warning to the president in a press conference on 1 December. ""Someone's going to get hurt, someone's going to get shot, someone's going to get killed, and it's not right,"" he said. In Michigan in early December, Secretary of State Jocelyn Benson, a Democrat, had just finished trimming her Christmas tree with her four-year-old son when she heard a commotion outside her Detroit home. About 30 protesters with banners stood outside, shouting ""Stop the steal!"" through megaphones. ""Benson, you are a villain,"" one person yelled. ""You're a threat to democracy!"" called another. One of the demonstrators live-streamed the protest on Facebook, stating that her group was ""not going away"". It was just one of a rash of protests targeting people involved in the vote. In Georgia, a constant stream of Trump supporters drove past Mr Raffensperger's home, honking their horns. His wife received threats of sexual violence. In Arizona, demonstrators gathered outside of the home of Secretary of State Katie Hobbs, a Democrat, at one point warning: ""We are watching you."" On 11 December, the Supreme Court rejected an attempt by the state of Texas to throw out election results. As the president's legal and political windows continued to close, the language in pro-Trump online circles became increasingly violent. On 12 December, a second Stop the Steal rally was held in the capital. Once again, thousands attended, and once again prominent far-right activists, QAnon supporters, fringe MAGA groups and militia movements were among the demonstrators. Michael Flynn, Mr Trump's former national security advisor, likened the protesters to the biblical soldiers and priests breaching the walls of Jericho. This echoed the rally organisers' call for ""Jericho Marches"" to overturn the election result. Nick Fuentes, the leader of Groypers, a far-right movement that targets Republican politicians and figures they deem too moderate, told the crowd: ""We are going to destroy the GOP!"" The march once again turned violent. Then two days later, the Electoral College certified Mr Biden's victory, one of the final steps required for him to take office. On online platforms, supporters were becoming resigned to the view that all legal avenues were dead ends, and only direct action could save the Trump presidency. Since election day, alongside Mr Flynn, Ms Powell and Mr Wood, a new figure had rapidly gained prominence among pro-Trump circles online. Ron Watkins is the son of Jim Watkins, the man behind 8chan and 8kun - message boards filled with extreme language and views, violence and extreme sexual content. They gave rise to the QAnon movement. In a series of viral tweets on 17 December, Ron Watkins suggested President Trump should follow the example of Roman leader Julius Caesar, and capitalise on ""fierce loyalty of the military"" in order to ""restore the Republic"". Ron Watkins encouraged his more than 500,000 followers to make #CrossTheRubicon a Twitter trend, referring to the moment when Caesar launched a civil war by crossing the Rubicon river in 49BC. The hashtag was also used by more mainstream figures - including the chairwoman of Arizona Republican Party, Kelli Ward. In a separate tweet, Ron Watkins said Mr Trump must invoke the Insurrection Act, which empowers the president to deploy the military and federal forces. Mr Trump met Ms Powell, Mr Flynn and others at a strategy meeting at the White House the following day, 18 December. During the meeting, according to the New York Times, Mr Flynn called on Mr Trump to impose martial law and deploy the military to ""rerun"" the election. The meeting further stoked online chatter about ""war"" and ""revolution"" in far-right circles. Many came to see the joint session of Congress on 6 January, normally a formality, as a last roll of the dice. A wishful story began to take hold among QAnon and some MAGA supporters. They hoped that Vice-President Mike Pence, who was set to preside over the 6 January ceremony, would ignore the electoral college votes. The president, they said, would then deploy the military to quell any unrest, order the mass arrest of the ""deep state cabal"" who had rigged the election and send them to Guantanamo Bay military prison. Back in the land of reality, none of this was remotely feasible. But it launched a movement for ""patriot caravans"" to organise ride shares to help transport thousands from around the country to Washington DC on 6 January. Long processions of vehicles flying Trump flags and sometimes towing elaborately decorated trailers gathered in car parks in cities including Louisville, Kentucky, Atlanta, Georgia, and Scranton, Pennsylvania. ""We are on our way,"" one caravaner posted on Twitter with a picture of about two dozen supporters. At an Ikea parking lot in North Carolina, another man showed off his truck. ""The flags are a little tattered - we'll call them battle flags now,"" he said. As it became clear that Mr Pence and other key Republicans would follow the law and allow Congress to certify Mr Biden's win, the language towards them became vicious. ""Pence will be in jail awaiting trial for treason,"" Mr Wood tweeted. ""He will face execution by firing squad."" Online discussion reached boiling point. References to firearms, war and violence were rife on self-styled ""free speech"" social platforms such as Gab and Parler, which are popular with Trump supporters, as well as on other sites. In Proud Boys groups, where members had once supported police, some turned against authorities, whom they deemed to no longer be on their side. Hundreds of posts on a popular pro-Trump site, TheDonald, openly discussed plans to cross barricades, carry firearms and other weapons to the march in defiance of Washington's strict gun laws. There was open chatter about storming the Capitol and arresting ""treasonous"" members of Congress. On Wednesday 6 January, Mr Trump addressed a crowd of thousands at the Ellipse, a park just south of the White House, for more than an hour. Early on he encouraged supporters to ""peacefully and patriotically make your voices heard"", but he ended with a warning. ""We fight like hell, and if you don't fight like hell, you're not going to have a country anymore. ""So we're going to, we're going to walk down Pennsylvania AvenueÂ and we're going to the Capitol."" To some observers, the potential for violence that day was clear from the outset. Michael Chertoff, former secretary of homeland security under President George W Bush, blamed the Capitol Police, who reportedly turned down offers of assistance from the much larger National Guard ahead of time. He characterised it as ""the worst failure of a police force I can think of"". ""I think it was a very foreseeable potential negative turn of events,"" Mr Chertoff said. ""To be blunt, it was obvious. If you read the newspaper and were awake, you understood that you've got a lot of people who have been convinced there was a fraudulent election. Some of them are extremists, and violent. Some of the groups openly said, 'Bring your guns'."" Still, many Americans were astonished by Wednesday's scenes, like James Clark, a 68-year-old Republican from Virginia. ""I find it absolutely shocking. I didn't think it would come to this,"" he told the BBC. But the signs were there for weeks. A hodgepodge of extreme and conspiratorial groups were convinced that the election was stolen. Online, they repeatedly talked about arming themselves, and violence. Perhaps the authorities didn't think their posts were serious, or specific enough to investigate. They now face pointed questions. For Joe Biden's inauguration on 20 January, Mr Chertoff is expecting a ""much stronger showing"" by security services than last Wednesday night. But that hasn't stopped many on extreme platforms calling for further violence and disruption on the day. There are questions, too, for the major social media platforms, which enabled conspiracy theories to reach millions of people. Late on Friday, Twitter deleted the accounts of Mr Flynn, the former Trump advisor, the ""Kraken"" lawyers Ms Powell and Mr Wood, and Mr Watkins. Then Mr Trump himself. Arrests of those who stormed the Capitol continue. But most of the rioters still live in a parallel online universe - a subterranean world filled with alternative facts. They have already come up with fanciful explanations to dismiss Mr Trump's video statement, posted on Twitter the day after the riots, in which he acknowledged for the first time that ""a new administration will be inaugurated on 20 January"". He can't possibly be giving up, they contend. Among their new theories - it's not really him in the video but a computer-generated ""deep fake"". Or perhaps the president is being held hostage. Many still believe Mr Trump will prevail. There's no evidence behind any of this, but it does prove one thing. No matter what happens to Donald Trump, the rioters who stormed the US Capitol are not backing down anytime soon. Additional reporting: Olga Robinson and Jake Horton All photographs subject to copyright"
The Brazilian doctor offering bogus Covid remedies for social media likes,"A Brazilian state representative and doctor is trading social media subscriptions and likes for medicines that have not been proved to be safe or effective against Covid-19. Brazil has been hit hard by Covid, and many people are looking for help. Dr Albert Dickson, an ophthalmologist in Brazil's north-east region, offers prospective patients ""free medical consultations"" as well as prescribing ""prophylactic measures"" against the virus. The catch? You have to subscribe to his YouTube channel. ""How are you going to be entitled to the consultation? You will subscribe to our channel... You will make a screenshot and send it to my WhatsApp. When you send it, you will start to have access,"" he said in a video published on Facebook in March. ""The secret is to send the screenshot."" In addition to being an ophthalmologist, Dr Dickson is a Brazilian state representative from the minor Pros party, which supports President Jair Bolsonaro. In his consultations, he prescribes drugs such as ivermectin. That's a treatment for lice and scabies which he and others say prevents Covid - but according to several leading health authorities, there's no evidence to back up those claims. BBC News Brasil interviewed a number of patients who contacted Dr Dickson on WhatsApp, and each confirmed they received a stock response reiterating the process and encouraging them to follow him on Instagram. We contacted Dr Dickson via email. He says he ""suggests"" signing up for his Instagram and YouTube channels because he puts ""up-to-date research there and explains the disease in detail and our experience with it, in addition to answering questions live"". ""It is not mandatory to subscribe to the channel to get a consultation,"" he says. ""We just suggest it. Many don't comply and we continue to respond. The virtual consultation is free, I have never charged."" Dr Dickson also said he was ""above all a doctor"" and said that the Federal Council of Medicine in Brazil, which regulates doctors, gives him the right to ""medicate against Covid-19"". His YouTube channel has more than 200,000 subscribers. He has around 140,000 followers on two Instagram profiles, along with 50,000 on Facebook. YouTube recently told BBC Brasil that, under a new rule, it had removed 12 of the doctor's videos for spreading medical disinformation, such as stating there is a guaranteed cure for Covid and recommending the use of ivermectin or another drug, hydroxychloroquine. The channel itself was not taken down, however, because the videos had been published prior to 12 April, when the new rule came into force. A spokesman for Facebook, which owns Instagram, said it ""removes proven false claims about the disease"". However, a claim by the doctor that ivermectin can prevent Covid was still live on Facebook at the time of publication of this story. Dr Dickson is not the only Brazilian doctor who advocates drugs unproven to treat Covid or even proven to be ineffective against the virus. Some call it ""early treatment"", and the drugs they prescribe include hydroxychloroquine, which has not been proven to be effective against Covid in several studies. President Bolsonaro has hailed hydroxychloroquine, ivermectin and ""early treatment"" in public several times. More than 439,000 people have died with Covid in Brazil. Dr Dickson told us via email that he's been an ""advocate of 'early treatment' since the beginning of the pandemic"" and said he would continue to suggest it. His service appears to be very popular. In one of his videos, the doctor says he helps 500 people a day ""from Sunday to Sunday, from 07:00 to 03:00 every day"". At a meeting in Brazil's Congress in July last year, Dickson said he had tended to ""31,000 patients from all over the world"" and had followed up by email with more than 6,000 others. Two had died, he said. We asked the doctor how many people he had ""treated"" for Covid since the beginning of the pandemic, but he declined to give us a figure. In May last year, Dr Dickson introduced two bills on ""early treatment"" at the Legislative Assembly of Rio Grande do Norte, where he is a representative. One of the bills proposed the ""free availability of drug kits with hydroxychloroquine, ivermectin and azithromycin drugs"". The other bill proposed the distribution of these drugs by health insurance companies. BBC News Brasil has seen three prescriptions sent by Dr Dickson. All three contain his signature and a religious expression (""God be exalted! Read the Bible""). One of Dickson's prescriptions for Covid lists ivermectin, but a cocktail of other drugs: azithromycin (an antibiotic), prednisone (a steroid), dutasteride (which treats prostate enlargement), spironolactone (a diuretic), bromhexine (used in cough syrup), apixaban (an anticoagulant), and vitamin D. ""There is no proof that any of this works against Covid,"" says AndrÃ© Bacchi, professor of pharmacology at the Federal University of RondonÃ³polis, who was shown the list by BBC Brasil. The Anti-Vax Files: from BBC Trending and the BBC World Service. Download the podcast or listen online ""The idea of '??supplementing', taking increased doses of various substances to give someone a 'superimmunity' is fallacious, and unfortunately it is widespread in general society as well as among specialists,"" Dr Bacchi says. BBC News Brasil has spoken directly to a number of Dr Dickson's patients - one of whom has been taking ivermectin weekly since last year. Not only are there no robust studies that show the drugs recommended in Dr Dickson's prescription regime have any effect against Covid, Dr Bacchi says, but taking them pre-emptively could cause serious harm. By taking an anticoagulant like apixaban, he says, ""you put yourself at risk of unnecessary adverse effects, such as an increased risk of bleeding."" ""It is not a medication to be used prophylactically for anyone,"" he says. ""And corticosteroids such as prednisone taken in the early stages of the disease can actually decrease immunity."" Hydroxychloroquine, touted by both former US President Donald Trump and Brazilian President Jair Bolsonaro over the last year, has been shown to be ineffective against Covid. In March this year, a panel of international experts from the WHO made a ""strong recommendation"" not to use it in treating the disease. The same is true of azithromycin. In December 2020, a large-scale randomised clinical trial found the antibiotic had no beneficial effect in patients hospitalised with Covid. Some studies have shown an association between vitamin D and better Covid outcomes. But these studies only observed what happens to people with higher and lower levels of the vitamin, without controlling for other factors - the evidence is not yet definitive. Sergio Rego is a physician, and professor of bioethics at the Fiocruz National School of Public Health. He says that doctors who prescribe ""early treatment"" can be held responsible for any adverse effects resulting from it. A section of Brazilian law, Dr Rego says, forbids ""exposing the life or health of others to direct and imminent danger"", with a penalty of three months to one year in prison. ""The doctor has autonomy, but that does not exempt him from the consequences of his actions,"" says Dr Rego. ""It is not a carte blanche."" Listen to The Anti-Vax Files from BBC Trending, on the World Service. Download the podcast or listen online."
The Matrix's real-world legacy - from red pill incels to conspiracies and deepfakes,"""I don't know the future... I didn't come here to tell you how this is going to end, I came here to tell you how it's going to begin."" The closing monologue of 1999's The Matrix saw Keanu Reeves' heroic character Neo deliver a stark warning to the world's controlling machines, having discovered that humanity was trapped in a simulated reality. Released as society lay on the cusp of the internet revolution and fretted over the millennium bug, the film not only tapped into technological developments of the time, but posed far-flung questions about the internet, consciousness and social control that have since come to shape society. As a fourth instalment, Matrix Resurrections, hits cinemas - 18 years on from the original trilogy drawing to a close - we look at the saga's enduring and often prophetic legacy. The Matrix's co-creator siblings Lana and Lilly Wachowski loosely based their dystopian vision on the work of French academic philosopher Jean Baudrillard. Long before Reeves donned Neo's trench coat and shades, they asked that he read Baudrillard's 1981 book Simulacra and Simulation to prepare for the role. It pondered a ""desert of the real"" - a world where true reality had been replaced by the illusions of capitalism. The film took the concept, with rebel leader Morpheus using the exact phrase when introducing Neo to the ruins of the outside world, and rewired it. Where for Baudrillard there was no escape from the simulation, the Wachowskis offered hope in the ""promise of a true natural world 'unplugged' and separate from the Matrix"", explains Prof Richard Smith, editor of The Baudrillard Dictionary. Baudrillard was not a fan of the change. ""The Matrix is surely the kind of film about the matrix that the matrix would have been able to produce,"" he said. Either way, the rabbit hole had been opened. Here are four main ways it has hacked our reality. One of the most iconic scenes in The Matrix sees Morpheus offer Neo (then still living as curious hacker Thomas Anderson) a central choice of blue pill or red pill. Pop the blue pill and return to life as Mr Anderson blissfully unaware of the matrix, the simulated world created to covertly enslave humanity. Or swallow the red pill and become enlightened to reality and the tyranny of the machines. For Prof Smith, the film's Marxist narrative evokes Plato's allegory of chained prisoners in a cave ""who mistake the shadows on the wall for reality"". As Morpheus puts it: ""The Matrix is the world that has been pulled over your eyes to blind you from the truth."" The pill scene ""urges human beings to free themselves from the world of appearances"", says Prof Smith. But over time the film's cultural prominence has seen the red pill metaphor rebranded online for causes far removed from its original meaning. This includes its adoption by misogynistic online groups, notably the incel movement - young men describing themselves as ""involuntarily celibate"" - part of a ""manosphere"" closely tied to a hatred of women. Reddit forum TheRedPill (TRP) was launched in 2012 with the aim of providing men with a ""sexual strategy"" to defeat what it described as a manipulative ""feminist culture"" that solely empowers women. By the time it was ""quarantined"" by Reddit in 2018 (given a content warning and only made accessible via direct links), in a community clean-up drive that eventually saw incel forum r/braincels shut completely, it had more than 400,000 followers. Research on the measure from the Australian National University suggested that rather than limit hate speech, it had simply pushed many users off-site on to self-moderated platforms. In some cases the philosophy has moved offline with deadly consequences. Plymouth gunman Jake Davison spoke of ""consuming the black pill overdose"" in YouTube videos before his August killing spree - the incel community's own term for nihilistic red pill extremism. Journalist, author and social media creator Sophia Smith Galer says the offline transition reflects how at its most basic, red pill theory appeals as a readily accessible answer and misguided outlet for life's frustrations. ""The epicentre of their problems often becomes women, rather than real, systemic failings or stereotypes in society that hurt all of us - and then many share misogynist, violent or self-harming ideas about how to improve their lives,"" she told the BBC. The ""free your mind"" ethos exploited by red pill theory has also fed into politics - a byword for the modern age of far-right populism that positions itself as anti-establishment. As a product of the alt-right, whose members are generally outspoken in their attacks on multiculturalism, globalisation and immigration, the red pill becomes ""a verb"", wrote broadcaster Danny Leigh. It opened ""the eyes of new recruits to their hated oppressors - feminists, people of colour and progressives"", he said. ""Morpheus became the face of memes that asked: 'What If I Told You Hitler Was A Socialist?'."" Fuelled by a distrust of government, the media and the status quo, the alt-right was most evidently brought into mainstream Western politics by former US President Donald Trump and his supporters. His own daughter, Ivanka, then a White House senior adviser, proudly quote-tweeted billionaire Elon Musk to say she had ""taken"" the red pill. The tweet represented a complete reversal of Morpheus's red pill reality, says author James Ball. ""In the film, taking the red pill is to accept an alien and horrifying truth rather than stay in a comfortable delusion,"" he said. ""And yet red-pilling, as beloved by far-right and niche online groups, is to accept vile but comfortable groupthink, to suit your own preconceptions, and see the world in a framing that suits yourself."" Lilly Wachowski responded curtly, with a blunt two-word condemnation. Actor Hugo Weaving, who played Agent Smith in the original Matrix trilogy, has also said he is ""befuddled"" by the hijacking of the film's message. ""It just goes to show how people don't read below surfaces,"" he told The Daily Beast. The fact it is now so easy to fortify yourself in an online media echo chamber - a space devoid of balanced opinion - has led to claims we are living in a ""post-truth"" era. The term was even declared word of the year by Oxford Dictionaries after the Brexit and US presidential campaigns of 2016. Messaging apps and social media have helped this climate flourish, with promotion of fake news and by using algorithms that build a version of reality tailored to our tastes - rewarding partisan news content. This year's Reuters Institute Digital News Report found that while audiences increasingly value truth, only 44% believe the news they read. Platforms like Instagram and TikTok have continued to attract more young people, but frequently offer personality and opinion-led content devoid of fact-checks, the study added. Together this can provide fertile ground for a spiral into a tailspin of misinformation and conspiracy theories. This means that the red/blue pill debate is blurring, and is today threatening to transform into a uniform purple pill of bias and distrust. Ciaran O'Connor, of the Institute for Strategic Dialogue, says this is underpinned by confirmation bias, our tendency to prioritise or remember new information that supports our pre-existing opinions. ""Platforms such as Facebook are designed to profit from engagement and time spent on their platforms - and one way platforms engineer this is through algorithms. But we've seen how algorithms can inadvertently direct people to spaces where they are exposed and incentivised to engage in conspiracy content,"" he said. He points to the evolution of the QAnon conspiracy as one of the best examples of this in action. Its momentum eventually snowballed into January's US Capitol riots, fuelled in part by former President Trump's false claims of widespread election interference. Despite intensified efforts to ban QAnon content on YouTube, Facebook and elsewhere, the once niche online conspiracy had already ""gone global"", says Mr O'Connor. The irony is that although conspiracy theory followers believe they are emulating Neo by following the white rabbit and ""unplugging"" in search of truth, in fact the opposite is happening - they are being distracted within the very system they think they are exposing. However, digital information sharing has not solely reinforced mistruth and protected the establishment. The original WikiLeaks data dump and Edward Snowden's mass surveillance revelations, while controversial in their practice, uncovered widespread government wrongdoing. Social media has equally shown it can act as a liberating, uniting force, empowering democratic coups and social justice initiatives. Beyond shifting perceptions of truth, our increasingly interconnected online presence, known as a digital footprint, realises elements of the original Matrix film in ways that felt pure science fiction at the time of release. Our willingness, tacitly or otherwise, to share personal information and agree to monitoring via technology, from mobile phones apps to machine learning tools like smart speakers, has allowed a very detailed picture of our personal lives and habits to be generated. The Cambridge Analytica data scandal showed how this information can be used to target, influence, and potentially swing voters in political systems. Elsewhere, the overlap between our digital and real life profiles has been increased by augmented reality and virtual reality, which mirror the way the rebels in the original film plug in and out of the simulation. Facebook recently announced long-term plans to create a virtual metaverse - allowing more of life to be lived out immersively online. By the same token, the way Morpheus's freedom fighters hack the matrix system to install programmes, scenarios or different appearances reflects today's real-world rise of deepfake videos - a computer-generated copy that aims to impersonate someone. Transhumanism, the belief that humans can improve beyond their physical and mental limitations and ""upgrade"" their bodies by incorporating technology, also matches the way characters in the film can download skillsets and learn to manipulate physics laws within the simulation. The film's nod to identity and the body as malleable has been strengthened by Lilly Wachowski, who retrospectively described it as a trans allegory when speaking to Netflix last year. ""That was the original intention but the corporate world wasn't quite ready,"" said the filmmaker, who came out as trans along with her sister Lana after the original trilogy was released. So where does all this leave The Matrix as we look to the future? Some believe full-circle. In 2016, a group of physicists suggested it is likely that our universe is not real and is instead a giant simulation run by a higher power. Technologists in Silicon Valley, including Tesla boss Elon Musk, have supported the idea. As implausible as it sounds, it fits the legacy of The Matrix. As Neo warned the machines in 1999: ""I'm going to show them a world without you, a world without rules and controls, without borders and boundariesÂ a world where anything is possible"". Follow us on Facebook, or on Twitter @BBCNewsEnts. If you have a story suggestion email entertainment.news@bbc.co.uk."
The YouTubers who blew the whistle on an anti-vax plot,"A mysterious marketing agency secretly offered to pay social media stars to spread disinformation about Covid-19 vaccines. Their plan failed when the influencers went public about the attempt to recruit them. ""It started with an email"" says Mirko Drotschmann, a German YouTuber and journalist. Mirko normally ignores offers from brands asking him to advertise their products to his more than 1.5 million subscribers. But the sponsorship offer he received in May this year was unlike any other. An influencer marketing agency called Fazze offered to pay him to promote what it said was leaked information that suggested the death rate among people who had the Pfizer vaccine was almost three times that of the AstraZeneca jab. The information provided wasn't true. It quickly became apparent to Mirko that he was being asked to spread disinformation to undermine public confidence in vaccines in the middle of a pandemic. ""I was shocked,"" says Mirko ""then I was curious, what's behind all that?"" In France, science YouTuber LÃ©o Grasset received a similar offer. The agency offered him 2000 euros if he would take part. Fazze said it was acting for a client who wished to remain anonymous. ""That's a huge red flag"" says LÃ©o. Both LÃ©o and Mirko were appalled by the false claims. They pretended to be interested in order to try to find out more and were provided with detailed instructions about what they should say in their videos. In stilted English, the brief instructed them to ""Act like you have the passion and interest in this topic."" It told them not to mention the video had a sponsor - and instead pretend they were spontaneously giving advice out of concern for their viewers. Social media platforms have rules that ban not disclosing that content is sponsored. In France and Germany it's also illegal. Fazze's brief told influencers to share a story in French newspaper Le Monde about a data leak from the European Medicines Agency. The story was genuine, but didn't include anything about vaccine deaths. But in this context it would give the false impression that the death rate statistics had come from the leak. The data the influencers were asked to share had actually been cobbled together from different sources and taken out of context. It presented the numbers of people who had died in several countries some time after receiving different Covid vaccines. But just because someone dies after having a vaccine doesn't mean they died because they had the vaccine. They could have been killed in a car accident. In the countries the statistics were from, greater numbers of people had received the Pfizer vaccine at that time, so a higher number of people dying after having a Pfizer jab was to be expected. ""If you don't have any scientific training, you could just say, 'oh, there are these numbers, they are really different. So there must be a link.' But you can make any spurious correlation as you want really,"" LÃ©o says. The influencers were also provided with a list of links to share - dubious articles which all used the same set of figures that supposedly showed the Pfzer vaccine was dangerous. When LÃ©o and Mirko exposed the Fazze campaign on Twitter all the articles, except the Le Monde story, disappeared from the web. By any measure the disinformation campaign was bungled. Since LÃ©o and Mirko blew the whistle at least four other influencers in France and Germany  have gone public to reveal they also rejected Fazze's attempts to recruit them. But German journalist, Daniel Laufer, has identified two influencers who may have taken up the offer. Indian YouTuber Ashkar Techy usually makes jokey videos about cars and dating and Brazilian prankster Everson Zoio, has more than three million Instagram followers. Each of them posted uncharacteristic videos in which they pushed the same message as the Fazze campaign and shared the fake news links from the agency's brief. Both had also participated in previous Fazze promotions. After Daniel Laufer contacted them, Everson Zoio and Ashkar Techy removed their videos but didn't answer his questions. The BBC tried to contact both influencers, but they didn't respond. We tried emailing the people who approached Mirko and LÃ©o. The emails bounced back, not from Fazze, but from the domain of a company called AdNow. Fazze is a part of AdNow, which is a digital marketing company, registered in both Russia and the UK. The BBC has made multiple attempts to contact AdNow by phone, email and even a letter couriered to their Moscow headquarters, but they have not responded. Eventually we managed to contact Ewan Tolladay, one of two directors of the British arm of AdNow - who lives in Durham. Mr Tolladay said he had very little to do with Fazze - which he said was a joint venture between his fellow director - a Russian man called Stanislav Fesenko - and another person whose identity he didn't know. He said that he hadn't been a part of the disinformation campaign. He said he hadn't even known Fazze had taken on the contract before the story broke. He couldn't enlighten us on who the mystery client was. He said that in light of the scandal  ""we are doing the responsible thing and shutting down AdNow here in the UK"". He said Fazze was also being shut down. We have tried to get Mr Fesenko to talk to us but had no success. Both the French and German authorities have launched investigations into Fazze's approaches to influencers. But the identity of the agency's mystery client remains unclear. There has been speculation about the Russian connections to this scandal and the interests of the Russian state in promoting its own vaccine - Sputnik V. Omid Nouripour, the foreign policy spokesman for the German Green party has suggested looking to Moscow for the motivation behind the Fazze campaign. He said: ""Bad-mouthing vaccines in the West undermines trust in our democracies and is supposed to increase trust in Russia's vaccines, and there is only one side that benefits and that is the Kremlin."" But in a statement the Russian embassy in London said: ""We treat Covid-19 as a global threat and, thus, are not interested in undermining global efforts in the fight against it, with vaccinating people with the Pfizer vaccine as one of the ways to cope with the virus."" While Fazze's campaign was a flop, LÃ©o Grasset believes it won't be the last attempt to use the power of social influencers to spread disinformation. ""If you want to manipulate public opinion, especially for young people, you don't go to TV"" says French YouTuber LÃ©o Grasset. ""Just spend the same money on TikTok creators, YouTube creators. The whole ecosystem is perfectly built for maximum efficiency of disinformation right now."" Listen to BBC Trending: The anti-vax influencer plot that flopped on the World Service. Download the podcast or listen online. Follow Charlie and Flora on Twitter."
The anti-vax movement targeting German children,"A German anti-lockdown, anti-vaccine movement with links to the far right has recruited hundreds of children into a private online group, reports Jessica Bateman. The girl with the loudspeaker doesn't look much older than 15. ""I've spoken at these demonstrations [before],"" she says, before launching into a tirade against the German government's lockdown restrictions and vaccination programme. ""They say, 'We have to lock them up! Have them vaccinated! Only then will they be allowed out again!'"" she bellows, adding that she was escorted from her school by police for refusing to comply with restrictions. The girl was speaking at one of a series of demonstrations organised by Querdenken, Germany's anti-lockdown movement. Roughly translated as ""lateral thinkers"", it's a loose-knit coalition that pushes baseless conspiracy theories - such as the idea masks are deadly or that vaccines will alter your DNA. And YouTube videos like this one, and others of other teenagers speaking at events, are frequently shared on social media. How have children become so heavily involved in a controversial movement? We've been investigating a private group for under-18s on the chat app Telegram, run by one of Querdenken's most popular figures. The Querdenken movement first sprung up last summer and gained international notoriety when one of its Berlin demonstrations ended with protestors attempting to storm the German parliament. The group claims to have no party political affiliation, but several of its key figures have well-documented far-right connections. Querdenken draws in a range of supporters - not only from the far-right, but a motley crew of hippies, spiritualists and some evangelical Christians. It has spawned a new crop of social media celebrities who push disinformation, sell branded merchandise and solicit donations from their followers. One of these is Samuel Eckert, a former evangelical preacher, who runs a public Telegram channel with more than 120,000 subscribers. According to computer scientist Josef Holnburger, who has studied the movement's rise, it's one of the most popular Telegram channels in Germany. And Eckert also regularly promotes a second, private channel called SE Youngsters, which he says is for children and teenagers aged 10 to 17 - even though the minimum age for using Telegram is 16. On Eckert's website, there's a sign-up page and a verification process to ensure the interested child really is under 18. Telegram did not respond to our questions about the group. The Anti-Vax Files: A new series from BBC Trending, on the World Service from 05:30 GMT Saturday. Download the podcast or listen online The BBC spoke to an online activist who gained access to the channel via an insider. He describes an echo chamber of increasingly extreme Covid conspiracy theories, alongside talk of deteriorating mental health, school exclusion and bullying. Our source remains anonymous for safety reasons and goes by the name DatenLiebe (""Data Love"") online. He's been accessing the group - which has more than 300 members - since last autumn. ""What surprised me was that the children were having very casual conversations, they were talking about the weather, or about their petsÂ like totally undangerous stuff,"" he says. ""But they are also forwarding content from dangerous Telegram channels, like QAnon."" According to DatenLiebe, practically ""every type"" of anti-vax or anti-Covid conspiracy you can think of is circulating in the group. ""They say pretty clearly that they either don't think that coronavirus exists, or that it's just the flu,"" he says. He also says the members have ""a strong distrust in state institutions"" and most believe Covid-19 vaccines either don't work or are more harmful than the disease itself. And he's also tracked stories of the children's beliefs causing them trouble in their personal lives. Several members of the group have said that they dropped out of school because they can't handle the pressure around mask regulations, or have been bullied by their classmates. We spoke to the mother of two girls who are members of the group. Like her daughters, she also believes Covid-19 is no more dangerous than flu, even though overwhelming evidence indicates it's both more deadly and can result in long-term health problems. The mother also says she doesn't plan to take a Covid-19 vaccine. However, she's adamant that her daughters came to their views independently and aren't being influenced by her or exploited by Samuel Eckert and the Querdenken movement. ""We always taught them to think for themselves,"" she says. She says her children changed schools - which she describes as a ""traumatic"" experience for them - after disputes over masks and their involvement in Querdenken demos. The safety of children has long been a powerful narrative in conspiracy theories, from the anti-Semitic ""blood libel"" which falsely accused Jews of murdering children, to the present day QAnon which claims world leaders are involved in child sex trafficking. At the same time, many parents have legitimate concerns about how lockdown measures, including school closures and social distancing, have affected their children's mental health and education. Journalist Marc RÃ¶hig, from the German magazine Der Spiegel, believes Eckert is trying to exploit these fears. ""His main target is concerned parents,"" he says. ""You can have two narratives. One is to fight for your own freedomÂ But you can also say, let's fight for our children and for their future."" Eckert did not respond to any of our requests for comment. However, he says on his social media accounts that the Telegram group is simply for Covid-sceptic young people to meet and support one another. He's not shy about using them for his own content, too. He set up a dedicated YouTube channel for videos of their speeches, and the children often appear with him at events or on his video livestreams. While experts say the Querdenken movement doesn't appear to be getting much bigger, it may be becoming more radical. Officials in the state of Baden WÃ¼rttemberg, in Germany's south-west, have put the group under surveillance as a potential security threat. And protestors are becoming more extreme in their actions, attacking journalists at demonstrations and even targeting vaccination centres. ""I'm really concerned about it, because those are real kids,"" says DatenLiebe, the inside source. ""And they go to real schools and they feel physical pain from a reality that doesn't exist."" Listen to The Anti-Vax Files from BBC Trending, on the World Service. Download the podcast or listen online."
The casualties of this year's viral conspiracy theories,"Conspiracy theories ripped through the internet this year, destroying relationships and endangering lives. The flurry of online falsehoods about coronavirus began as soon as the pandemic hit. Misleading pictures suggesting tanks were rolling down village streets and lists of false diagnostic tips were frantically forwarded on WhatsApp. As luck would have it, I had just begun my job reporting on the impact of online disinformation. With the help of a BBC team of experts, I got to work looking into the spread of one really viral post. At first glance, the post seemed legitimate, because the information was attributed to a trusted source: a doctor, an institution, or well-educated ""uncle"". It hopped across Facebook profiles around the world, translated into Italian, Arabic and a dozen other languages. A special programme from the BBC Trending team. Listen now on BBC Sounds. But along with useful information like ""wash your hands"", it listed false cures and phony diagnostic tests. One of the people most responsible for its online spread was an 84-year-old pensioner from Buckinghamshire. Peter Lee Goodchild assured me that he did not intend to share bad information - but his version of the dodgy post accumulated more than 400,000 shares in early spring. Have his online habits changed since he went super viral? Not a whole lot. ""Four times I've been pulled up by Full Fact or one of the others who vet Facebook to say 'No that's incorrect' or 'That wasn't said' or 'That didn't happen',"" Peter explained when I spoke to him later. He told me he posts on Facebook now more than ever. Peter may have had good intentions, and although some of the information in his viral post was wrong, it wasn't critically dangerous. That's not always the case when it comes to online falsehoods. Our team found numerous links around the world between misleading and false posts online and serious real world harm. False claims about 5G technology inspired arsons attacks on phone masts and assaults on telecommunications workers. We catalogued mass poisonings and overdoses of hydroxychloroquine - a drug that world leaders like Donald Trump and Jair Bolsonaro falsely claimed cures or prevents Covid-19. There were riots and poisonings - all because of bad online information. But Brian's story stood out. He's a 46-year old taxi driver from Florida who I first interviewed in May. Because of posts he had seen on Facebook, he believed a variety of false claims: that coronavirus was not real, not serious, or somehow linked to 5G technology. He didn't wear a mask or worry too much about social distancing. But then Brian and his wife Erin fell seriously ill with Covid-19 and ended up in hospital. As his wife remained in a critical condition, he regretted not trusting expert advice. ""We just can't be playing around anymore,"" he lamented. ""This thing is real."" In August, Erin died due to heart complications linked to the virus. I caught up with Brian at the end of what has, understandably, been a difficult year for him. He's now being careful about following health advice - and keeping his online habits in check. Conspiracies closer to home As the year progressed, we watched as the nature of bad information changed. As we learned more about the virus, the rumours about societal collapse, martial law, and straw-grasping health ""tips"" mostly disappeared. What took their place were conspiracy theories - pushed by highly motivated individuals. Newly-emerged influencers gained huge online followings by promoting baseless claims about the pandemic. That includes denying the virus existed or suggesting the outbreak was planned and managed as some sort of sinister plot. Their theories were often blatantly inconsistent - for instance, accusing authorities of incompetence in one breath, and in the next alleging they managed legendary logistical feats. My inbox quickly flooded with pleas for help from people with friends or family members under the spell of these influencers. The most striking email was from the son of a leader of Britain's conspiracy community. Sebastian Shemirani got in touch because of his fears about his mother's impact on public health - and their relationship. Sebastian's mum Kate Shemirani has collected tens of thousands of followers with false claims - including denying coronavirus exists, blaming the symptoms of Covid-19 on 5G radio waves and likening the NHS to Nazi Germany. She's spoken to crowds of thousands at protests in London. ""This is her five minutes of fame and when this is over, people will forget about it,"" Sebastian told me. ""But you know the disaster that goes on within my family and the relationships that she's losing now - that stuff stays forever."" In response to her son's interview at the time, Kate Shemirani told us: ""From what I can see it would appear Â a ""conspiracy theorist"" is actually now anyone who believes something other than what your controllers want them to believe. I find this deeply disturbing."" I've spoken to psychologists, experts and even people who used to believe the Earth was flat about how to repair relationships ravaged by cult-like online conspiracies. ""There is no silver bullet, there is no argument you can present to someoneÂ that will change their mind,"" explains psychologist Jovan Byford. ""The point is to infuse their thinking with counter arguments so the next time they approach a conspiracy theory in a different way."" The vaccine lies ahead The embers of 2020's blaze of bad viral information are still glowing as we head into 2021. People around the world are starting to receive coronavirus vaccines - and conspiracy theorists will be focusing on this in the months ahead. Just as the vaccine roll-out began, I investigated how the feet of a Texas woman named Patricia were used to fuel anti-vaccine propaganda online. Patricia came down with an unexplained skin condition - but a misunderstanding about what might have caused it set off a chain of events that turned her foot into fodder for anti-vaccine activists. She joins a long list of casualties of viral conspiracies in 2020. Do you have a story to tell? Email Marianna Subscribe to the BBC Trending podcast or follow us on Twitter @BBCtrending or Facebook."
The climate change-denying TikTok post that won't go away,"Earlier this year, TikTok vowed to clamp down on climate change denial. But a BBC investigation tracked one video that has been viewed millions of times - and found the company is struggling to stop false climate information from spreading across the platform. If you searched for ""climate change"" on TikTok in recent months, you might have come across a video featuring Dan PeÃ±a, a self-styled ""business success coach"" with thousands of followers on social media. The video, shot during the 2017 London premiere of a documentary film about Mr PeÃ±a, shows a heated exchange between the American businessman and a member of the audience. Asked what ""the people with the money"" will do about climate change, he replies: ""The financial institutions and the banks know [climate change] is not going to happen."" He adds, without providing any credible evidence: ""It's the greatest fraud that has been perpetrated on mankind this century."" Contacted by the BBC, Mr PeÃ±a stood by these comments, saying climate change was actually a ""historical norm"" over thousands of years and ""not new"".  He questioned whether it was a ""genuine threat"" as well as the effectiveness of measures proposed by climate change activists in the face of growing emissions from China. The overwhelming weight of scientific evidence has found that world temperatures are rising because of human activity, leading to rapid climate change and threatening every aspect of human life. But while Mr PeÃ±a's statements conflict with that scientific evidence, this clip appears to have been edited and re-uploaded by other users from different TikTok accounts dozens of times, racking up more than nine million views in the process. Under new community guidelines unveiled by TikTok last April, content that ""undermines well-established scientific consensus"" on climate change will not be allowed on the platform. And yet, the clip depicting Mr PeÃ±a is far from an isolated occurrence: the BBC identified 365 different videos in English denying the existence of man-made climate change. TikTok itself deems climate change denial to be ""harmful misinformation"". Using tools available to any TikTok user, we reported those videos to the platform under that category. We then waited for at least a day to find out whether they would be taken down. The company did not remove almost 95% of the posts we flagged up - videos that, having been watched almost 30 million times, appeared to be attracting significant attention. In a statement to the BBC, TikTok said it is working ""to empower informed climate discussions"", and that it is working with fact-checkers to tackle misinformation. The company also pointed out that, when users search for videos about climate change, they are being shown a link to a United Nations website on the topic. But the video of Mr PeÃ±a demonstrates how ""bad arguments can spread really fast on TikTok"", says Roshan Salgado D'Arcy, a science communicator who uses social media to debunk viral videos that contain false claims about climate change. ""There are no real checks and balances to make sure that the information is accurate."" The problem is not exclusive to English-speaking TikTok either: BBC Monitoring found dozens of other climate change-denying videos in Spanish, Turkish, Arabic, Portuguese, and Russian. ""As a member of the public on social media, it must be very easy to get the wrong idea about how certain we are about climate change,"" says Dr Doug McNeall, a scientist from the Met Office's Hadley Centre for Climate Prediction and Research. ""Misinformation can really damage our discussion about what to do about climate change."" TikTok is aware of the problem - which is why, to mark Earth month in April, it announced it would begin actively removing content that contradicts basic climate science. In a blog post published at the time, it listed as examples of rule-breaking content posts ""denying the existence of climate change or the factors that contribute to it"". But the reach of videos like those featuring Mr PeÃ±a raises questions about how successfully this new policy is being enforced. ""Rules become irrelevant, if they're not applied consistently, accurately and fairly,"" says Jennie King, head of climate research and policy at the Institute for Strategic Dialogue, a UK counter-extremism think tank. Ms King said this emboldens people to try ""to game the system even more, because they know they can ultimately act with impunity"". Paul Scully MP, the minister for technology and the digital economy, told the BBC that the government's proposed Online Safety Bill would guarantee that the responsibility of social media platforms to tackle disinformation was ""taken seriously"". After we shared the findings of our investigation with TikTok, 65 accounts that had been posting wrong information about climate change in breach of the platform's guidelines were permanently removed. The company also removed most of the remaining videos that were still online - including several that featured Dan PeÃ±a's 2017 talk. However, at the time of writing, several copies of the clip featuring Dan PeÃ±a describing climate change as the ""greatest fraud"" can still be found on the app. At the Met Office, Dr McNeall welcomes TikTok's efforts against misinformation, but he questions whether this is a battle the company can win. ""As a scientist I'm happy to be challenged,"" he says. ""Maybe we should focus on promoting good climate science information, rather than just removing the content that we perhaps don't like."" Earlier this year, TikTok vowed to clamp down on climate change denial. But a BBC investigation tracked one video that has been viewed millions of times - and found the company is struggling to stop false climate information from spreading across the platform. If you searched for ""climate change"" on TikTok in recent months, you might have come across a video featuring Dan PeÃ±a, a self-styled ""business success coach"" with thousands of followers on social media. The video, shot during the 2017 London premiere of a documentary film about Mr PeÃ±a, shows a heated exchange between the American businessman and a member of the audience. Asked what ""the people with the money"" will do about climate change, he replies: ""The financial institutions and the banks know [climate change] is not going to happen."" He adds, without providing any credible evidence: ""It's the greatest fraud that has been perpetrated on mankind this century."" Contacted by the BBC, Mr PeÃ±a stood by these comments, saying climate change was actually a ""historical norm"" over thousands of years and ""not new"".  He questioned whether it was a ""genuine threat"" as well as the effectiveness of measures proposed by climate change activists in the face of growing emissions from China. The overwhelming weight of scientific evidence has found that world temperatures are rising because of human activity, leading to rapid climate change and threatening every aspect of human life. But while Mr PeÃ±a's statements conflict with that scientific evidence, this clip appears to have been edited and re-uploaded by other users from different TikTok accounts dozens of times, racking up more than nine million views in the process. Under new community guidelines unveiled by TikTok last April, content that ""undermines well-established scientific consensus"" on climate change will not be allowed on the platform. And yet, the clip depicting Mr PeÃ±a is far from an isolated occurrence: the BBC identified 365 different videos in English denying the existence of man-made climate change. TikTok itself deems climate change denial to be ""harmful misinformation"". Using tools available to any TikTok user, we reported those videos to the platform under that category. We then waited for at least a day to find out whether they would be taken down. The company did not remove almost 95% of the posts we flagged up - videos that, having been watched almost 30 million times, appeared to be attracting significant attention. In a statement to the BBC, TikTok said it is working ""to empower informed climate discussions"", and that it is working with fact-checkers to tackle misinformation. The company also pointed out that, when users search for videos about climate change, they are being shown a link to a United Nations website on the topic. But the video of Mr PeÃ±a demonstrates how ""bad arguments can spread really fast on TikTok"", says Roshan Salgado D'Arcy, a science communicator who uses social media to debunk viral videos that contain false claims about climate change. ""There are no real checks and balances to make sure that the information is accurate."" The problem is not exclusive to English-speaking TikTok either: BBC Monitoring found dozens of other climate change-denying videos in Spanish, Turkish, Arabic, Portuguese, and Russian. ""As a member of the public on social media, it must be very easy to get the wrong idea about how certain we are about climate change,"" says Dr Doug McNeall, a scientist from the Met Office's Hadley Centre for Climate Prediction and Research. ""Misinformation can really damage our discussion about what to do about climate change."" TikTok is aware of the problem - which is why, to mark Earth month in April, it announced it would begin actively removing content that contradicts basic climate science. In a blog post published at the time, it listed as examples of rule-breaking content posts ""denying the existence of climate change or the factors that contribute to it"". But the reach of videos like those featuring Mr PeÃ±a raises questions about how successfully this new policy is being enforced. ""Rules become irrelevant, if they're not applied consistently, accurately and fairly,"" says Jennie King, head of climate research and policy at the Institute for Strategic Dialogue, a UK counter-extremism think tank. Ms King said this emboldens people to try ""to game the system even more, because they know they can ultimately act with impunity"". Paul Scully MP, the minister for technology and the digital economy, told the BBC that the government's proposed Online Safety Bill would guarantee that the responsibility of social media platforms to tackle disinformation was ""taken seriously"". After we shared the findings of our investigation with TikTok, 65 accounts that had been posting wrong information about climate change in breach of the platform's guidelines were permanently removed. The company also removed most of the remaining videos that were still online - including several that featured Dan PeÃ±a's 2017 talk. However, at the time of writing, several copies of the clip featuring Dan PeÃ±a describing climate change as the ""greatest fraud"" can still be found on the app. At the Met Office, Dr McNeall welcomes TikTok's efforts against misinformation, but he questions whether this is a battle the company can win. ""As a scientist I'm happy to be challenged,"" he says. ""Maybe we should focus on promoting good climate science information, rather than just removing the content that we perhaps don't like."""
The dead professor and the vast pro-India disinformation campaign,"A dead professor and numerous defunct organisations were resurrected and used alongside at least 750 fake media outlets in a vast 15-year global disinformation campaign to serve Indian interests, a new investigation has revealed. The man whose identity was stolen was regarded as one of the founding fathers of international human rights law, who died aged 92 in 2006. ""It is the largest network we have exposed,"" said Alexandre Alaphilippe, executive director of EU DisinfoLab, which undertook the investigation and published an extensive report on Wednesday. The network was designed primarily to ""discredit Pakistan internationally"" and influence decision-making at the UN Human Rights Council (UNHRC) and European Parliament, EU DisinfoLab said. EU DisinfoLab partially exposed the network last year but now says the operation is much larger and more resilient than it first suspected. There is no evidence the network is linked to India's government, but it relies heavily on amplifying content produced on fake media outlets with the help of Asian News International (ANI) - India's largest wire service and a key focus of the investigation. EU DisinfoLab are an independent NGO ""focused on tackling sophisticated disinformation campaigns targeting the EU, its member states, core institutions, and core values"". Their researchers, who are based in Brussels, believe the network's purpose is to disseminate propaganda against India's neighbour and rival Pakistan. Both countries have long sought to control the narrative against the other. Last year, the researchers uncovered 265 pro-Indian sites operating across 65 countries, and traced them back to a Delhi-based Indian holding company, the Srivastava Group (SG). Wednesday's report, titled Indian Chronicles, reveals that the operation, run by SG, is spread over at least 116 countries and has targeted members of the European Parliament and the United Nations - raising questions about how much EU and UN staff knew about SG's activities, and whether they could have done more to counter those activities, especially after last year's report. Mr Alaphilippe said the EU DisinfoLab researchers had never encountered such co-ordination between different stakeholders to spread disinformation. ""During the last 15 years, and even after being exposed last year, the fact that this network managed to operate so effectively shows the sophistication and the drive of the actors behind Indian Chronicles,"" he said. ""You need more than a few computers to plan and sustain such an action,"" he said. The researchers cautioned against ""definitively attributing Indian Chronicles to some specific actors such as Indian intelligence services"" without further investigation. Ben Nimmo, a disinformation network expert, told the BBC the uncovered network was ""one of the most persistent and complex operations"" he had seen, but he too was wary of attributing it to a specific actor. Mr Nimmo, who is director of investigations at digital monitoring firm Graphika, cited previous examples of privately-run large-scale troll operations. ""Just because they're big, it doesn't necessarily mean they're directly run by the state,"" he said. The BBC approached the Indian government for comment but had received no response by the time of publication. One of the most important findings of the open-source investigation was establishing direct links between the Srivastava Group (SG) and at least 10 UN-accredited NGOs, along with several others, which were used to promote Indian interests and criticise Pakistan internationally. ""In Geneva, these think tanks and NGOs are in charge of lobbying, of organising demonstrations, speaking during press conferences and UN side-events, and they were often given the floor at the UN on behalf of the accredited organisations,"" the report says. The investigation shows that the operation led by SG began in late 2005, a few months after the UNHRC was founded in its current form. One particular NGO which caught the eye of the researchers was the Commission to Study the Organisation of Peace (CSOP). The CSOP was founded in the 1930s and won UN-accreditation in 1975 but became inactive later in the 1970s. The investigation found that a former chairman of the CSOP - Prof Louis B Sohn, one of the 20th Century's leading international law scholars and a Harvard Law faculty member for 39 years - was listed under the name Louis Shon as a CSOP participant at the UNHRC session in 2007 and at a separate event in Washington DC in 2011. The listings shocked the researchers because Prof Sohn died in 2006. The authors dedicated their investigation to the professor's memory, writing that his name had been ""usurped by the malicious actors in this report"".  They said CSOP ""had been resurrected, and its identity hijacked in 2005 by the same actors depicted in our first investigation"". The investigation also shows there were several hundred pro-Indian interventions by the non-accredited NGOs, which were repeatedly given the floor at the UNHRC on behalf of the accredited organisations, pursuing the same agenda of maligning Pakistan. On other occasions, NGOs and organisations which seemingly had nothing to do with Pakistan or India according to their stated objectives would get the opportunity to speak at the UNHRC and target Pakistan. In March 2019, during the UNHRC's 40th session, United Schools International (USI), another UN-accredited organisation with direct links to SG, allowed its slot to be used by Yoana Barakova, a research analyst with an Amsterdam-based think-tank called the European Foundation for South Asian Studies (EFSAS). Ms Barakova spoke about ""atrocities committed by Pakistan"" during the session. She told the BBC that EFSAS was a partner with USI and she was ""not responsible for organisational logistics"". The BBC received no reply when it contacted the director of EFSAS, who also represented USI at the same session to criticise Pakistan. The primary news agency re-packaging and boosting pro-India content related to SG appears to be ANI, established in 1971, which describes itself as ""South Asia's leading multimedia news agency, with more than 100 bureaus in India, South Asia and across the globe"". Indian news media, especially broadcast media, thrive on content provided by ANI. EU DisinfoLab found at least 13 instances of ANI re-publishing mostly anti-Pakistan and sometimes anti-China op-eds by Members of the European Parliament (MEPs), originally published on EU Chronicle, one of the fake news sites linked to SG. EU Chronicle was born in May this year when EP Today, a site flagged in the previous disinformation report, was simply discontinued and renamed. The EU DisinfoLab report said: ""The actors behind the operation hijacked the names of others, tried to impersonate regular media such as the EU Observer... used the letterhead of the European Parliament, registered websites under avatars with fake phone numbers, provided fake addresses to the United Nations, created publishing companies to print books of the think-tanks they owned. ""They used layers of fake media that would quote and republish one another. They used politicians who genuinely wanted to defend women or minority rights to ultimately serve geopolitical interests and gave a platform to far-right politicians when convergent objectives could be reached."" Mr Alaphilippe said the news agency ANI was being used to give legitimacy to the entire ""influence operation"", which relied ""more on ANI than on any other distribution channel"" to give it ""both credibility and a wide reach to its content"". ANI's news reports have found space in many mainstream Indian news outlets and publishers. Its content was further reproduced on more than 500 fake media websites across 95 countries, the researchers found. Websites identified by the report as fake media outlets include those owned by Big News Network, which describes itself as a ""leading provider of news headlines with over 400 distinct categories of latest news"". In an e-mail to the BBC a Big News Network spokesman said that they are not associated with ANI, other than as a client which has for many years been a subscriber to their service. They add that their sites ""take news disseminated from the Big News Network database which comprises numerous sources"" including ANI and other agencies. Demonstrations in Europe conducted by organisations linked to the Srivastava Group have also been covered by ANI, as well as by fake media websites linked to SG. According to the findings of the investigation, the disinformation network had a two-pronged strategy to spread influence. In Geneva, the think-tanks and NGOs were in charge of lobbying and protesting, and taking the floor at the UNHRC on behalf of accredited organisations. In Brussels, the focus was on the MEPs, who were taken on international trips and solicited to write ""exclusive"" op-eds for fake outlets like EU Chronicle, which would then be amplified using ANI, the researchers found. A group of MEPs appear regularly in the investigation. One of them, French MEP Thierry Mariani, has written two op-eds for EU Chronicle and was also part of a controversial visit to Indian-administered Kashmir last year. ""If the Indian government is behind the newspaper [EU Chronicle], it is not my problem,"" Mr Mariani, a member of France's far-right National Rally, told the BBC. ""I sign what I want and I feel, it is my opinion. I have connections in [India's governing] Bharatiya Janata Party (BJP) and I support the government of [Narendra] Modi,"" he said. Two other MEPs named in the report - Angel Dzhambazki from Bulgaria and Grzegorz Tobiszowski from Poland - denied having written op-eds that were published on EU Chronicle. The articles under their names were also reproduced on ANI. Asked what the EU is doing to fight disinformation networks, EU spokesperson on foreign affairs Peter Stano pointed to the action taken to expose EP Today last year. ""Exposing the disinformation and those who spread it is one of our main instruments,"" he told the BBC. ""We will continue to identify them and call them out."" But he said questions about finances and transparency of NGOs registered in Brussels were for Belgian authorities to answer. Rolando Gomez, a spokesperson for the UNHRC, told the BBC that it was the prerogative of NGOs to raise whichever issue they wish to address and whoever they grant space to speak on the floor. ""There are no rules stating that an NGO must speak to specific issues. Doing so would amount to infringing on their freedom of speech,"" Mr Gomez said. Gary Machado, managing director of EU DisinfoLab, said he thought the muted reaction to the revelation of the disinformation network was partly because it was ""clearly managed by Indian stakeholders"". ""Imagine if the same operation was run by China or Russia. How do you think the world would have reacted? Probably with international outrage, leading to public inquiries and probably sanctions,"" he told the BBC. But the activities of MEPs named in the report prompted criticism from some of their colleagues. MEP Daniel Freund from the Greens said fellow members needed to declare their activities. ""There have been at least 24 breaches of rules in the past years. Not a single violation has been sanctioned. So there is little incentive to respect the rules when the worst that can happen is to file a declaration after you have been caught,"" he said. Another member, who did not want to be named, said MEPs contributing to sites like EU Chronicles had been identified as ""election tourists"". ""A ragtag group of MEPs from the bottom of the parliamentary barrel who prefer to travel on sponsored trips by unsavoury governments rather than invest in their mandate,"" the MEP told the BBC. ""How PR stunts with such individuals could be even conceived as helpful is baffling."" The BBC put questions to ANI and to nine other MEPs who have written op-eds for the EU Chronicle and made visits to India, Bangladesh and the Maldives, but received no response. The investigations from last year and this year show a man called Ankit Srivastava at the centre of the entire global operation that was uncovered. More than 400 domain names have been bought through Mr Srivastava's private email address or through email addresses belonging to his organisations, the EU DisinfoLab investigations found. Then, there's a case of the mysterious SG-owned tech firm Aglaya. Its website has been inaccessible since at least February this year but in the past the company has advertised products for ""hacking/spy tools"" and ""information warfare services"". Aglaya's marketing brochure mentioned the ability to ""hamper country level reputations"" and described some of its services as ""Cyber Nukes"". In a 2017 interview with Forbes magazine, a man called Ankur Srivastava claimed he ""only sold to Indian intelligence agencies"". It's unclear what relation, if any, he has to Ankit Srivastava. A third Srivastava appears to be Dr Pramila Srivastava, chairperson of the group and mother of Ankit Srivastava. Dr Harshindar Kaur, a paediatrician from the Indian state of Punjab, told the EU DisinfoLab researchers that in 2009 she had been invited to the UNHRC in Geneva to give a lecture on female foeticide when she was threatened by a woman called Dr P Srivastava, who claimed to be a ""very senior government official from India"". Dr Kaur told the BBC it was Pramila Srivastava who had threatened her. The BBC emailed Ankit Srivastava asking him to respond to this and the other allegations in the report, but received no reply. When the BBC visited the firm's offices in Delhi's Safdarjung Enclave, staff there would not answer questions. What might happen to the network, or how it might evolve, in the light of the latest investigation is unclear. The authors of Indian Chronicles say their findings ""should serve as a call to action for decision-makers to put in place a relevant framework to sanction actors abusing international institutions"". Mr Alaphilippe said following the 2019 investigation there had been ""no official communication, no sanction, nothing. This passivity gave a message to Indian Chronicles: you've been exposed, but no consequences"". ""We think there should be consequences to disinformation and we expect actions to be taken. The biggest failure from institutions would be if another report is released next year on the same actors with the same techniques,"" he told the BBC. ""This would mean that EU institutions are ok with foreign interference."" Update 19th October 2022: This article has been updated to include a response from Big News Network, the company which owns a number of the websites highlighted in the EU DisinfoLab report."
The disinformation tactics used by China,"The Chinese embassy in London has criticised the BBC following a documentary about Chinese disinformation campaigns. There have also recently been a series of denials from Beijing over reports into forced imprisonment of its minority Uighur population - these have included baseless accusations against media and human rights organisations. In the latest attack, an official falsely claimed a Uighur interviewee on a BBC programme was an actress. So what tactics does China use in the spread of misleading and false information? There have been almost daily anti-BBC articles in Chinese state media since mid-February. It follows a decision by the UK broadcasting regulator Ofcom to revoke the licence for China's state-run overseas broadcaster, CGTN. For years, China has broadly criticised Western outlets for reports on affairs in Xinjiang and elsewhere in China, saying they should not intervene in China's ""internal affairs"". But these latest attacks on Western media are a clear escalation. Chinese domestic media outlets have praised their government for banning the BBC's World News channel, although it was only available in some international hotels and residential compounds where foreigners live. Reports from leading outlets like China's Global Times have criticised the ""Cold War"" mentality when it comes to China - on topics ranging from Hong Kong, the Uighur population of Xinjiang and the Covid-19 pandemic. When China was facing a backlash over its handling of early stages of the pandemic last year, and some US officials were floating the theory that the virus could have escaped from a Wuhan lab, CGTN started to push its own conspiracy theory. Despite a complete lack of evidence, the station suggested the virus originated at a military base in Maryland in the US and was brought to China by American soldiers during an athletics competition. Listen to File on 4's The Disinformation Dragon with Krassimira Twigg and Paul Kenyon on BBC Sounds In recent months, China experts have noticed dozens of new and highly active official social media accounts representing Chinese embassies and leading diplomats. This has become known as ""wolf warrior"" diplomacy. The best-known account belongs to Zhao Lijian from the Chinese foreign ministry. He caused controversy in March after tweeting articles suggesting that coronavirus originated in the United States. Those tweets have been shared more than 40,000 times and referenced in 54 different languages, according to research from the Digital Forensic Research Lab, part of the Atlantic Council think tank. Popular hashtags referencing the posts have made waves at home too - they've been viewed by users of Chinese social network Weibo more than 300 million times. In December, Zhao Lijian was widely criticised for sharing a fake image of an Australian soldier killing an Afghan child, for which China refused to apologise. China draws on millions of citizens to monitor the internet and influence public opinion on a massive scale online. These recruits are known as the ""50 cent army"" - so named because of reports that they were paid 0.5 yuan per post. This ""keyboard army"" has long been active on Chinese social media platforms. Its aim has been to aggressively defend and protect China's image overseas. When tweeting in English, the messages are aimed at a Western audience, much like troll farms in Russia that sow discord. To the unsuspecting reader, they might appear as patriotic citizens acting independently, but frequently they are taking directions from Chinese authorities. One example is the way in which video footage of violent protests in Hong Kong in 2019 was promoted on social media via this keyboard army using terms such as ""terrorism"", while coverage of peaceful protests was censored. In August 2019, Facebook and Twitter announced they had removed accounts linked to a state-backed information campaign. Facebook said: ""Although the people behind this activity attempted to conceal their identities, our investigation found links to individuals associated with the Chinese government."" Twitter identified more than 900 accounts from China. But these were only the most active components of the campaign, which the company said involved some 200,000 accounts. A BBC investigation in May 2020 found hundreds of fake or hijacked social media accounts promoting pro-China messages on Facebook, Twitter and YouTube. Some 1,200 accounts targeted people critical of how Beijing was handling the pandemic. There was no definitive evidence tying these accounts to the Chinese government, but it did display similar characteristics to the state-backed network removed by Facebook and Twitter in 2019. It also resembled another network dubbed ""Spamouflage Dragon"", which pumped out pro-China posts and attacked critics with spam, which was uncovered by the social analytics firm Graphika. Subsequently Twitter said it had removed more than 23,000 accounts linked to China involved in a range of ""manipulative and co-ordinated activities"". In response to comments made by Yang Xiaoguang, from the Chinese Embassy in the UK on the BBC Today programme, a BBC spokesman said:  ""We completely reject these claims and stand by our journalism.   BBC News reporting in Xinjiang has been accurate and impartial - we did not use any false images and the interviewee who appeared on the BBC was not an 'actress' as claimed."" Additional reporting by Jack Goodman"
The haters and conspiracy theorists back on Twitter,"Hundreds of accounts that were recently allowed back on Twitter have been spreading abuse or misinformation, a BBC investigation has found. In exclusive research, BBC Monitoring analysed over 1,100 previously banned Twitter accounts that were reinstated under new owner Elon Musk. We found evidence of problematic content posted on the platform in over a third of them. Mr Musk says he is a ""free speech absolutist"". In November, he announced a ""general amnesty"" to suspended accounts that had ""not broken the law or engaged in egregious spam"". Twitter's rules prohibit violence, direct attacks and threats towards others on the basis of, for example, race, sexual orientation and gender, as well as slurs, tropes or other content that intends to ""dehumanise, degrade or reinforce negative or harmful stereotypes"". The site also claims to take a ""zero tolerance"" approach towards any material that features or promotes child sexual exploitation. However our research indicated a number of the reinstated accounts appear to be breaking these rules. We limited our data set to accounts reinstated between 27 October 2022 - the first day of Mr Musk's takeover - and January 10, only including profiles with over 10,000 followers. These accounts are just a portion of the thousands that have been allowed back on Twitter in recent months. To identify problematic content, we used a combination of keyword searches and manual analysis of dozens - and at times hundreds - of posts on each account in our dataset. Where possible, we also noted known reasons for previous suspensions. So what types of accounts are back from Twitter jail? Among the Twitter returnees in our dataset there were accounts with a history of making misogynistic comments. One well known to many is Andrew Tate, an online influencer who's previously said women should bear some responsibility for being raped. He's currently detained in Romania as part of a human trafficking and rape investigation. Since being reinstated his following on the platform has ballooned - going from 150,000 in November 2022 to five million currently. Among some lesser known users promoting misogyny was one who said he knows a woman is ""fine"" when he wants to beat her up. Another, after being allowed back, posted a video depicting a rape. A group repeatedly targeted was the LGBT community. We saw tweets disparagingly referring to them as ""sick humans"", ""groomers"" and ""paedophiles"". Imran Ahmed, from the Centre for Countering Digital Hate (CCDH), says his organisation has seen an increase in hateful terminology towards women and LGBT groups since Mr Musk took over Twitter, as well as racist slurs. He claims that by not adequately reviewing all the suspended accounts before allowing them back on Twitter, ""what [Musk] has done is essentially turn on the fire hose, allowing hate and disinformation to flood the platform"". Perhaps the most disturbing findings from this investigation were two accounts with images depicting child sexual abuse. They weren't real-life pictures, but drawings. We reported this content to Twitter, who have since suspended one of the accounts and removed a problematic image from another. Yet a few weeks ago we found and reported through Twitter's own site yet another account posting similar images. At the time of writing, the account was still active. Over a hundred accounts in our dataset spread false and misleading claims about elections and their outcome. For instance, some users incorrectly suggested former President Jair Bolsonaro had won both rounds of the presidential vote in Brazil. Others wrongly claimed that Donald Trump ""won by a landslide"" in the 2020 presidential election in the US. Some of the Trump supporters even celebrated their return to Twitter with posts echoing false election claims. Mike Lindell, the CEO of MyPillow and one of the biggest proponents of the bogus theory that the 2020 election was influenced by fraud, tweeted: ""I'm back!! Thank you @elonmusk and by the way melt down the electronic voting machines and turn them into prison bars!"" Twitter says it may label or remove false or misleading information about elections and their outcome. At the time of writing, none of the posts we saw spreading such claims about elections have been labelled. In November, Twitter stopped enforcing its Covid misinformation policy, prompting some of the notable spreaders of coronavirus myths and vaccine misinformation to come back. Among them were Dr Robert Malone, who has made misleading claims casting doubt on the effectiveness and safety of Covid vaccines, and cardiologist Peter McCullough, who has pushed false claims that Covid vaccines are killing large numbers of people. Evidence from different independent scientists all over the world, as well as the experiences of over five billion people, have shown that Covid vaccines are safe and effective and serious side effects are rare. We also encountered numerous posts baselessly linking people's ""sudden deaths"" to vaccines, and in at least one instance that led to the harassment of a bereaved parent. The majority of the reinstated accounts in our data set did not promote outright misinformation or hateful content. Sometimes it was even unclear why an account had been suspended in the first place. Yet for others, the amnesty seems to have been an opportunity to repeat the kind of behaviour that led to their ban. At the time of writing, just over a dozen accounts in our dataset of more than 1,100 had been independently resuspended. We contacted Twitter for comment but they have not replied. Lead reporting by Kayleen Devlin Research and analysis by Kayleen Devlin, Adam Robinson, Olga Robinson, Alistair Coleman, Paul Brown and Shayan Sardarizadeh Illustrations by Jenny Law Contributing research by Travis Brown Hundreds of accounts that were recently allowed back on Twitter have been spreading abuse or misinformation, a BBC investigation has found. In exclusive research, BBC Monitoring analysed over 1,100 previously banned Twitter accounts that were reinstated under new owner Elon Musk. We found evidence of problematic content posted on the platform in over a third of them. Mr Musk says he is a ""free speech absolutist"". In November, he announced a ""general amnesty"" to suspended accounts that had ""not broken the law or engaged in egregious spam"". Twitter's rules prohibit violence, direct attacks and threats towards others on the basis of, for example, race, sexual orientation and gender, as well as slurs, tropes or other content that intends to ""dehumanise, degrade or reinforce negative or harmful stereotypes"". The site also claims to take a ""zero tolerance"" approach towards any material that features or promotes child sexual exploitation. However our research indicated a number of the reinstated accounts appear to be breaking these rules. We limited our data set to accounts reinstated between 27 October 2022 - the first day of Mr Musk's takeover - and January 10, only including profiles with over 10,000 followers. These accounts are just a portion of the thousands that have been allowed back on Twitter in recent months. To identify problematic content, we used a combination of keyword searches and manual analysis of dozens - and at times hundreds - of posts on each account in our dataset. Where possible, we also noted known reasons for previous suspensions. So what types of accounts are back from Twitter jail? Among the Twitter returnees in our dataset there were accounts with a history of making misogynistic comments. One well known to many is Andrew Tate, an online influencer who's previously said women should bear some responsibility for being raped. He's currently detained in Romania as part of a human trafficking and rape investigation. Since being reinstated his following on the platform has ballooned - going from 150,000 in November 2022 to five million currently. Among some lesser known users promoting misogyny was one who said he knows a woman is ""fine"" when he wants to beat her up. Another, after being allowed back, posted a video depicting a rape. A group repeatedly targeted was the LGBT community. We saw tweets disparagingly referring to them as ""sick humans"", ""groomers"" and ""paedophiles"". Imran Ahmed, from the Centre for Countering Digital Hate (CCDH), says his organisation has seen an increase in hateful terminology towards women and LGBT groups since Mr Musk took over Twitter, as well as racist slurs. He claims that by not adequately reviewing all the suspended accounts before allowing them back on Twitter, ""what [Musk] has done is essentially turn on the fire hose, allowing hate and disinformation to flood the platform"". Perhaps the most disturbing findings from this investigation were two accounts with images depicting child sexual abuse. They weren't real-life pictures, but drawings. We reported this content to Twitter, who have since suspended one of the accounts and removed a problematic image from another. Yet a few weeks ago we found and reported through Twitter's own site yet another account posting similar images. At the time of writing, the account was still active. Over a hundred accounts in our dataset spread false and misleading claims about elections and their outcome. For instance, some users incorrectly suggested former President Jair Bolsonaro had won both rounds of the presidential vote in Brazil. Others wrongly claimed that Donald Trump ""won by a landslide"" in the 2020 presidential election in the US. Some of the Trump supporters even celebrated their return to Twitter with posts echoing false election claims. Mike Lindell, the CEO of MyPillow and one of the biggest proponents of the bogus theory that the 2020 election was influenced by fraud, tweeted: ""I'm back!! Thank you @elonmusk and by the way melt down the electronic voting machines and turn them into prison bars!"" Twitter says it may label or remove false or misleading information about elections and their outcome. At the time of writing, none of the posts we saw spreading such claims about elections have been labelled. In November, Twitter stopped enforcing its Covid misinformation policy, prompting some of the notable spreaders of coronavirus myths and vaccine misinformation to come back. Among them were Dr Robert Malone, who has made misleading claims casting doubt on the effectiveness and safety of Covid vaccines, and cardiologist Peter McCullough, who has pushed false claims that Covid vaccines are killing large numbers of people. Evidence from different independent scientists all over the world, as well as the experiences of over five billion people, have shown that Covid vaccines are safe and effective and serious side effects are rare. We also encountered numerous posts baselessly linking people's ""sudden deaths"" to vaccines, and in at least one instance that led to the harassment of a bereaved parent. The majority of the reinstated accounts in our data set did not promote outright misinformation or hateful content. Sometimes it was even unclear why an account had been suspended in the first place. Yet for others, the amnesty seems to have been an opportunity to repeat the kind of behaviour that led to their ban. At the time of writing, just over a dozen accounts in our dataset of more than 1,100 had been independently resuspended. We contacted Twitter for comment but they have not replied. Lead reporting by Kayleen Devlin Research and analysis by Kayleen Devlin, Adam Robinson, Olga Robinson, Alistair Coleman, Paul Brown and Shayan Sardarizadeh Illustrations by Jenny Law Contributing research by Travis Brown"
The misinformation bubble threatening Brazil's indigenous people,"False information from the mouths of politicians and preachers is reaching remote villages in the Amazon via WhatsApp, reports BBC News Brasil's Juliana Gragnani. A helicopter loaded with health workers and coronavirus vaccine doses took off from Labrea, in the southern part of the Amazon, heading to a village some 50km away. But the villagers, part of the indigenous Jamamadi group, greeted the chopper armed with bows and arrows - and demanded that it leave. They'd been hearing false rumours about vaccines and wanted reassurances from a religious missionary - not doctors - before getting jabbed. The helicopter left without administering any of the doses. The incident in early February was described to BBC News Brasil by several sources who asked not to be identified for fear of upsetting the fragile relationship between health teams and indigenous people. The people we spoke to say that armed welcoming parties are very rare, but they are worried about vaccine rumours being spread to indigenous people through mobile phones. Many mobile phone operators in Brazil include free use of Facebook and Facebook-owned Instagram and WhatsApp in their payment plans, whereas use of other networks and websites incurs a cost. WhatsApp - a common source of community and family news - presents a particular problem, experts say. Information on chat apps tends to come from people closer to us, who we instinctively trust - but data packages discourage people, particularly the cash-strapped, from double-checking health information. Indigenous journalist Anapuaka Tupinamba says WhatsApp enabled ""a leap"" for indigenous people in the areas of politics and education, but calls technology ""a double-edged sword"". ""What we have today is a 'fake' internet. When you see fake news, you can't check it,"" Anapuaka says. ""So it feels like I'm on the internet, but not really. I'm almost on the intranet of a large company."" Anapuaka cites one recent example circulated on the app - a story about 900 indigenous Xingu people dying after receiving a vaccine. It was false. Much of the bad vaccine information circulating on WhatsApp originates not from the villagers themselves but from politicians and religious leaders. This includes Brazil's President. ""Nobody can force me to get the vaccine,"" Jair Bolsonaro said in September. The following month, he declared: ""The Brazilian people will not be anyone's guinea pig"". He wasn't going to get the vaccine, he said, ""and that's it."" He appeared to echo bizarre and false claims, common in anti-vaccine groups online, about Covid vaccines altering people's DNA. ""If you become an alligator, it's your problem Â if a woman grows a beard or a man starts to speak with a thin voice, they [pharmaceutical companies] will have nothing to do with it."" It was those kinds of statements that resonated most with indigenous communities, says Indianara Machado, a nurse from Brazil's Central-West region. ""People in the village ask themselves: 'If the president didn't take it [the vaccine], how are we going to take it?'"" she says. Religious missionaries and evangelical churches have influence in indigenous territories, and some - though certainly not all - have also spread vaccine falsehoods. Indianara Machado says that many of the videos that went viral were of indigenous pastors holding services telling people not to get the vaccine, declaring it was ""the beast's microchip"" - calling to mind fake rumours that vaccines include chips that can track and enslave people. Pastor Henrique Terena, president of the National Council of Evangelical Indigenous Pastors and Leaders, admits that in the Central-West region there is ""a neo-Pentecostal segment that says that vaccines are not good, that they are from the devil, and they tell their members they shouldn't get the jab."" But he says his members are by and large not the problem, and he says anti-vaccine pastors only ""claim"" to be evangelical. The Anti-Vax Files: A new series from BBC Trending, on the World Service from 05:30 GMT Saturday. Download the podcast or listen online Online misinformation convinced Joel Paumari's parents that Covid vaccines were unsafe. He's a teaching coordinator in the Amazon region, and his concern for his parents grew as he saw a rise in the number of deaths of indigenous people. According to official figures, more than 650 indigenous people living in villages have died due to Covid-19 out of a total population of 517,000. Across Brazil, around 400,000 people have died. In raw numbers, the country's death toll is second only to the United States. Joel says that his parents saw videos that included false claims about drugs, about vaccines ""distancing"" people from God, and those rumours about DNA and genetic codes. All of them were untrue. It took three days of pleading WhatsApp voice notes to convince his parents to take the jab - and while they did in the end, Joel's brother did not. Audio, text and videos with disinformation have spread across Brazilian WhatsApp groups for years, and played a part in the 2018 elections. Since then, the company has limited message sharing to five times and inserted a tag that shows when a message has been forwarded multiple times. WhatsApp told BBC News Brasil that since it's encrypted, the company doesn't have access to the content of the messages. And the company says it has acted to combat misinformation, for instance by launching free services with information about Covid-19 within the app. Still, disinformation appears to be having an impact on vaccine uptake in indigenous villages. The villagers are a priority group when it comes to Covid vaccination, and statistics indicate that 75% have received at least one vaccine dose. But that lags behind other recent vaccine drives. BBC News Brasil obtained, via Brazil's Access to Information law, data on the immunisation of indigenous people in Brazil since 2011. We found that virtually all previous vaccines drives had a 90% take-up rate. After a decade-long campaign to build trust, take-up of the flu vaccine reached 90% in 2019. What's more, that level was reached within a month. By contrast, the current Covid-19 campaign began in mid-January - more than three months ago. The government remains optimistic, however. The office of Brazil's Special Secretary for Indigenous Health noted that it has a workforce of 14,000 indigenous health professionals. ""Indigenous vaccination continues at a favourable pace,"" it said. The Jamamadi - who met the helicopter armed with bows and arrows - are one group who've been strongly influenced by missionaries from the United States in recent decades. By contrast, according to anthropologist Miguel Aparicio, the Banawa people, who are neighbours to the Jamamadi, have been fully vaccinated. The difference? ""The missionary presence within the Banawa is not strong,"" he says. But a few days after the rejection of the jabs, a Jamamadi chief made contact with health officials saying he wanted to get the vaccine. The team returned and vaccinated some villagers. But that's not quite the end of the story - most of the Jamamadi have not yet had a jab. Follow Juliana on Twitter Listen to The Anti-Vax Files from BBC Trending, on the World Service. Download the podcast or listen online."
The people who think coronavirus is caused by 5G,nan
The rise of India's 'Covid quack',"A charismatic anti-vaccination campaigner has gained popularity by claiming that medical science's approach to the pandemic is entirely wrong. But critics say Biswaroop Roy Chowdhury is endangering lives by falsely claiming he can cure Covid-19 through diet alone, report Ed Main and Reha Kansara. Biswaroop Roy Chowdhury is not one to hold back. ""According to me, most deaths are not because of coronavirus itself but because of its treatment,"" he says in one video on his website. The Indian social media star - or former social media star, now that he's banned on several platforms - asserts that conventional medicine is a conspiracy designed to line the pockets of doctors and big business. ""Drugs do not help in curing any illness,"" he told the BBC. ""I strongly believe that humans do not need vaccines at all."" In his videos, he claims his diet plans, rich in fruits and vegetables, will cure not only Covid-19, but diabetes and Aids. Medical science says all of this is nonsense. But Mr Chowdhury has used the pandemic to spread his messages. He teaches his followers that hospitals increase their chances of dying and says that Covid patients with breathing difficulties would do better sitting in front of a handheld fan than receiving oxygen. To his many critics, he is a dangerous fraud whose bad advice can only further fuel India's horrific second wave of coronavirus. ""Biswaroop Roy Chowdhury is a quack,"" says Dr Sumaiya Shaikh, science editor of the Indian fact-checking website Alt News. ""He has a huge following and that makes him even more dangerous."" It's a following that has been cultivated through numerous books, online videos and courses and packed-out live events. YouTube, Twitter and Facebook banned Mr Chowdhury last year, but not before he assembled an army of followers - nearly one million on YouTube alone before his account was deleted. He still has official channels on WhatsApp and Telegram. Biswaroop's fans are also uploading and spreading his content on proxy accounts. WhatsApp told us they are working hard to limit the spread of false coronavirus information on their platform. Telegram didn't respond to a request for comment. Mr Chowdhury presents himself as a plucky underdog figure pitted against a medical establishment intent on deceiving the public. Covid-19 is ""just like normal flu"" he asserts - despite the fact it's actually significantly deadlier. And despite the overwhelming evidence to the contrary, he claims that face masks don't help stop the spread of virus and will actually make wearers ill. He has co-opted the Urdu word azaadi, meaning ""freedom"" - a rallying cry that resonates with many oppressed communities in India, for his slogan ""masks se azaadi"" (""freedom from masks""). In one of his several coronavirus e-books, Mr Chowdhury offers 100,000 rupees (about Â£960; $1,300) to anyone who ""can prove that vaccines have ever helped anyone in any way"". There is, of course, a vast literature of medical research stretching back decades that documents how vaccines have helped control and even eradicate diseases all over the world. But Mr Chowdhury discounts it entirely. Mr Chowdhury started developing his controversial diet ""cures"" about a decade ago. It's just one strand of a colourful and varied career. After training as an engineer, he dabbled in Bollywood film-making and even cast himself as the star in one movie. He is also the chief editor and founder of both the India and Asia Book of Records which is modelled on, but not affiliated with, the Guinness Book of Records. Nilesh Christopher, a journalist with the tech website Rest of World, says Mr Chowdhury became interested in nutrition when his wife couldn't shake a flu-like illness. ""What he told me was, he was running around from pillar to post, visiting doctors, and trying to figure out a cure for it, but he couldn't,"" he says. ""That is when he goes into this mode of self-learning and he claims to have read research papers and figured out this magic formula which is coconut water, citrus fruits and vegetables."" The Anti-Vax Files: A new series from BBC Trending, on the World Service weekly from 05:30 GMT Saturday. Download the podcast or listen online India has a long tradition of Ayurvedic medicine, which uses food and herbal treatments to treat ailments. But Mr Chowdhury has made a series of outrageous and fantastical claims for the miraculous effects that can supposedly be achieved by patients who follow his advice. ""He is definitely one of the biggest most prominent quacks in India,"" says Mr Christopher. When Covid-19 appeared, Mr Chowdhury quickly declared it an ""influenza-like illness"" that could be cured by his pre-existing three-step flu diet. He set up a consultation service where patients are charged 500 rupees (Â£4.80; $6.70) to receive a diet plan. ""He's built a massive digital empire through online nutrition courses, certification programmes and consultancy services and that's his business model,"" says Mr Christopher. ""That doesn't change, no matter what the disease you throw at him."" Mr Chowdhury says he has cured more than 50,000 people of Covid-19 without any fatalities. But Dr Arun Gupta, President of the Delhi Medical Council points out that most people will recover from the virus regardless of what they eat. ""If you claim you take 100 patients and I claim that I cure all of you, you see 97 per cent are going to get cured, even without any intervention,"" he says. Dr Gupta says more should be done to stop the spread of such misinformation. ""It is the responsibility of the government to take a note of it and make sure these people are contained,"" he says. Mr Chowdhury stands by his methods and rejects allegations that his teachings put people at risk. ""Are they giving any evidence? I don't think so,"" he told the BBC. However, the nutritionist is under investigation for one specific claim that his methods have caused real life harm. Jaideep Bihani, from Delhi, has made a criminal complaint against Mr Chowdhury over the death of his mother Shanti in August 2017. Mr Bihani told the BBC he blamed Mr Chowdhury for her death ""100%"". Mrs Bihani, 56, was suffering from diabetes, and heart and thyroid problems. After discovering Mr Chowdhury on the web, Mr Bihani paid hundreds of dollars to take his mother to a three-day event to learn his diabetes cure. The event was held at a holistic sanctuary on the outskirts of Delhi. A video of the first evening shows Mr Chowdhury urging his audience to stop taking their medicines. ""I've got a box with me, it is called the medical orange box... All the medicines, we will put here and put a lock [on it]. So I hope you will never need those medicines again,"" he said. Mr Chowdhury told the audience that patients who were in very poor health, like Shanti Bihani, would be monitored and given back some medicine if needed - but that food would act as their primary medication going forward. ""The moment you have your first diet, that will make you heart attack proof from that time,"" he told the assembly. Mrs Bihani had been taking a range of medicines, but into the large orange box they went. The next day she complained of feeling drowsy and later collapsed. Eventually she was taken to hospital where she died after suffering a heart attack. In his criminal complaint, Mr Bihani accuses Mr Chowdhury of falsely claiming to be a medical practitioner, offering fraudulent treatments and failing to provide emergency care at the course. Mr Chowdhury denies all this. The most prominent qualification listed on Biswaroop's website is an honorary PHD in diabetes, from Alliance International University, Zambia. It's an institution that according to its website is headquartered not in Africa but in the Caribbean. This degree appears to be why Mr Chowdhury calls himself a doctor, although he didn't answer our questions about this issue. In response to Mr Bihani's allegations, a spokesperson for Mr Chowdhury told us that Mrs Bihani was a very ill woman who had been chewing paan masala, a mild but addictive stimulant made with areca nut and other substances. Her son denies that she was during the course. The spokesperson for Mr Chowdhury also said Mr Bihani had his mother's medications on him throughout the course. But Mr Bihani also denies this was the case. Mr Bihani said he hoped his experiences should be a warning to anybody thinking of following Mr Chowdhury's advice. ""Watching my father every day just alone at this age, and watching my kids not being there with grandmum - you know, I can't even tell you what I feel."" With reporting from Shruti Menon in Delhi. Listen to The Anti-Vax Files from BBC Trending, on the World Service. Download the podcast or listen online."
The truth about 'medbeds' - a miracle cure that doesn't exist,"Strange corners of the internet are awash with chatter about miracle devices that can cure nearly any ailment you can think of using the power of mystical energy. Some companies charge thousands for these ""medbeds"" - but their claims are far from proven. A converted motel in a small town on the Mississippi River seems an unlikely home for a world-changing technology - what a flyer in the mostly deserted lobby calls a ""new wave of scientific healing"". But since last summer, this building in East Dubuque, Illinois - three hours west of Chicago - has been outfitted with medical devices that supposedly imbue patients with ""life force energy"". It's one of a number of locations run by Tesla BioHealing - no relation to the car company - dotted around the US. I tried out a medbed on a recent gloomy weekday afternoon. After being greeted at the front desk, a doctor tested my energy levels by having me place my fingers inside a metal box. Then I was ushered into one of the rooms, mostly unchanged from its motel days, and I waited for ""pure biophoton life-force energy"" to stream into my body. The idea of medbeds - short either for ""medical beds"" or ""meditation beds"" - has become increasingly popular on fringe medical channels, on mainstream social networks and chat apps. But people have very different ideas about what they actually are. Some insist that the technology is secret, unlikely to be encountered by mere mortals, hidden from the public by billionaires and the ""deep state"". The more conspiratorial theorising includes speculation about ""alien technology"" and bizarre claims like the idea that John F Kennedy is still alive, strapped to a medbed. A separate, more earthly avenue of thought holds that medbeds are very real and publicly available, just not part of the medical mainstream. It's this strand that Tesla BioHealing and a range of other companies are staking their rather expensive claims on. Tesla BioHealing offers home generators for prices up to $19,999 (Â£16,500), although an hour in one of their medbed motel rooms will only set you back $160 (Â£130). But even in the consumer-focused medbed world, where there is no talk of aliens or JFK, there's disagreement about what a medbed actually is. And there's a very good reason for that, says Sara Aniano, a disinformation analyst at the Anti Defamation League's Centre on Extremism. ""It's really hard to define something that doesn't exist,"" she says. Ms Aniano has been researching the spread of medbed chat online, and as part of her inquiries signed up for trial with a different medbed company, 90.10. ""The trial is nothing,"" she says. ""It tells you to lay on your bed and think really hard about the medbed."" ""In their defence, they do list on their website in the very fine print down at the bottom that the medbed is not meant to treat or diagnose illnesses,"" she says. It's a common disclaimer that we saw used in some form by just about every company offering a medbed-related product. Even though companies put out long lists of ailments that can supposedly be helped by their technologies, and provide testimonials from satisfied customers, they say that their products are not meant to replace treatments by a qualified doctor. Tesla BioHealing is no exception. The top of the company's website clearly states: ""We cannot diagnose, treat, cure, or prevent any disease or condition."" And yet their promotional material states: ""Many people note improvements in their wellbeing even after only an hour of resting on a Tesla MedBed."" They also make a number of specific, unsupported claims about particular diseases. The staff at the Tesla BioHealing motel in East Dubuque told me about legions of customers with all manner of ailments, all of whom they said had been helped by medbeds. But in my room, I felt nothing more than curiosity and a slight sense of unease as I gazed out the window at a mostly empty car park. The Tesla Medbed cannisters were sealed in wooden boxes and a bedside table. Cutting short my hour, I returned to the doctor's office where she repeated the test with my fingers in the metal box. Sure enough, my energy, as measured by the doctor's laptop, was already rising. But neither the doctor nor anyone else at Tesla BioHealing could tell me what was inside the medbed cannisters themselves. Some enterprising customers have taken it upon themselves to try to find out. We came across a TikTok video where an upset punter appears to have opened up a cannister, only to find a concrete-like substance. ""For anyone who's thinking about buying one of those Tesla biohealers, don't waste your money,"" she says. The company wouldn't be drawn on what active ingredients, if any, are inside the cannisters. But they told us in an email: ""There is much more going on with our technology than meets the eye."" And while they said the Tesla cannisters were not intended to replace a doctor's care, they also made further claims of cures and said: ""Health benefits are priceless."" Both Tesla BioHealing and 90.10 pointed us to thousands of positive customer testimonials. And despite the prominent claim on the company website that 90.10 offers ""Quantumfrequency medicine with scientific proof"", 90.10 chief executive Oliver Schalke told us: ""It is not a medical product and was never intended to be."" How, then, are the medbed companies allowed to offer their products, hint at miraculous effects, but escape any regulatory oversight? Dr Steven Barrett, a retired psychiatrist who has been investigating questionable claims for decades, says the health care regulator in the United States - the Food and Drug Administration (FDA) - is partly to blame. ""FDA registration is required by any manufacturer who wants to market products, but it just means that you've notified the FDA that you exist,"" he says. Tesla BioHealing and other companies advertise that they are FDA registered - but that is next to meaningless. ""FDA registration says nothing about whether a device is useful,"" says Dr Barrett. When it comes to making vague claims about general well-being or unprovable statements about increased energy, authorities ""do almost nothing about it"", he says. He speaks with a note of weariness, perhaps because of a lack of ""biophotons"" but more likely the result of spending decades tracking dubious health claims. ""Do I think that exposure to whatever it is that they're giving you in the bed is going to make you more energetic? I seriously doubt that,"" he says. Indeed, as I began a long evening drive home from East Dubuque under cloudy skies, I felt distinctly lacking in life force energy. With reporting by Elizabeth Hotson and Shayan Sardarizadeh Strange corners of the internet are awash with chatter about miracle devices that can cure nearly any ailment you can think of using the power of mystical energy. Some companies charge thousands for these ""medbeds"" - but their claims are far from proven. A converted motel in a small town on the Mississippi River seems an unlikely home for a world-changing technology - what a flyer in the mostly deserted lobby calls a ""new wave of scientific healing"". But since last summer, this building in East Dubuque, Illinois - three hours west of Chicago - has been outfitted with medical devices that supposedly imbue patients with ""life force energy"". It's one of a number of locations run by Tesla BioHealing - no relation to the car company - dotted around the US. I tried out a medbed on a recent gloomy weekday afternoon. After being greeted at the front desk, a doctor tested my energy levels by having me place my fingers inside a metal box. Then I was ushered into one of the rooms, mostly unchanged from its motel days, and I waited for ""pure biophoton life-force energy"" to stream into my body. The idea of medbeds - short either for ""medical beds"" or ""meditation beds"" - has become increasingly popular on fringe medical channels, on mainstream social networks and chat apps. But people have very different ideas about what they actually are. Some insist that the technology is secret, unlikely to be encountered by mere mortals, hidden from the public by billionaires and the ""deep state"". The more conspiratorial theorising includes speculation about ""alien technology"" and bizarre claims like the idea that John F Kennedy is still alive, strapped to a medbed. A separate, more earthly avenue of thought holds that medbeds are very real and publicly available, just not part of the medical mainstream. It's this strand that Tesla BioHealing and a range of other companies are staking their rather expensive claims on. Tesla BioHealing offers home generators for prices up to $19,999 (Â£16,500), although an hour in one of their medbed motel rooms will only set you back $160 (Â£130). But even in the consumer-focused medbed world, where there is no talk of aliens or JFK, there's disagreement about what a medbed actually is. And there's a very good reason for that, says Sara Aniano, a disinformation analyst at the Anti Defamation League's Centre on Extremism. ""It's really hard to define something that doesn't exist,"" she says. Ms Aniano has been researching the spread of medbed chat online, and as part of her inquiries signed up for trial with a different medbed company, 90.10. ""The trial is nothing,"" she says. ""It tells you to lay on your bed and think really hard about the medbed."" ""In their defence, they do list on their website in the very fine print down at the bottom that the medbed is not meant to treat or diagnose illnesses,"" she says. It's a common disclaimer that we saw used in some form by just about every company offering a medbed-related product. Even though companies put out long lists of ailments that can supposedly be helped by their technologies, and provide testimonials from satisfied customers, they say that their products are not meant to replace treatments by a qualified doctor. Tesla BioHealing is no exception. The top of the company's website clearly states: ""We cannot diagnose, treat, cure, or prevent any disease or condition."" And yet their promotional material states: ""Many people note improvements in their wellbeing even after only an hour of resting on a Tesla MedBed."" They also make a number of specific, unsupported claims about particular diseases. The staff at the Tesla BioHealing motel in East Dubuque told me about legions of customers with all manner of ailments, all of whom they said had been helped by medbeds. But in my room, I felt nothing more than curiosity and a slight sense of unease as I gazed out the window at a mostly empty car park. The Tesla Medbed cannisters were sealed in wooden boxes and a bedside table. Cutting short my hour, I returned to the doctor's office where she repeated the test with my fingers in the metal box. Sure enough, my energy, as measured by the doctor's laptop, was already rising. But neither the doctor nor anyone else at Tesla BioHealing could tell me what was inside the medbed cannisters themselves. Some enterprising customers have taken it upon themselves to try to find out. We came across a TikTok video where an upset punter appears to have opened up a cannister, only to find a concrete-like substance. ""For anyone who's thinking about buying one of those Tesla biohealers, don't waste your money,"" she says. The company wouldn't be drawn on what active ingredients, if any, are inside the cannisters. But they told us in an email: ""There is much more going on with our technology than meets the eye."" And while they said the Tesla cannisters were not intended to replace a doctor's care, they also made further claims of cures and said: ""Health benefits are priceless."" Both Tesla BioHealing and 90.10 pointed us to thousands of positive customer testimonials. And despite the prominent claim on the company website that 90.10 offers ""Quantumfrequency medicine with scientific proof"", 90.10 chief executive Oliver Schalke told us: ""It is not a medical product and was never intended to be."" How, then, are the medbed companies allowed to offer their products, hint at miraculous effects, but escape any regulatory oversight? Dr Steven Barrett, a retired psychiatrist who has been investigating questionable claims for decades, says the health care regulator in the United States - the Food and Drug Administration (FDA) - is partly to blame. ""FDA registration is required by any manufacturer who wants to market products, but it just means that you've notified the FDA that you exist,"" he says. Tesla BioHealing and other companies advertise that they are FDA registered - but that is next to meaningless. ""FDA registration says nothing about whether a device is useful,"" says Dr Barrett. When it comes to making vague claims about general well-being or unprovable statements about increased energy, authorities ""do almost nothing about it"", he says. He speaks with a note of weariness, perhaps because of a lack of ""biophotons"" but more likely the result of spending decades tracking dubious health claims. ""Do I think that exposure to whatever it is that they're giving you in the bed is going to make you more energetic? I seriously doubt that,"" he says. Indeed, as I began a long evening drive home from East Dubuque under cloudy skies, I felt distinctly lacking in life force energy. With reporting by Elizabeth Hotson and Shayan Sardarizadeh"
The vaccine misinformation battle raging in France,"France is one of the most vaccine-sceptical countries in the world - fertile ground for hard-line anti-vaccine activists spreading online misinformation, writes the BBC's specialist disinformation reporter Marianna Spring. In his spare time, Gilles loves to watch sci-fi films and read bandes dessinÃ©es - French comic books. He also helps run a conspiracy-themed French-language Facebook group with 50,000 members, many of whom spread falsehoods about coronavirus. He became a member just after the start of the pandemic, almost a year ago. ""I felt in my gut that this whole thing was overrated and wrong,"" Gilles says. He doesn't deny - like some others in the group - that Covid-19 is real. Instead he harbours vague suspicions about the disease, potential cures, and alleged cover-ups. And he doesn't want a Covid vaccine, because of posts he's seeing on the group. He fears, despite the weight of scientific evidence, that jabs have been developed too quickly to be safe. And Gilles' story is part of a bigger picture. The Facebook group that Gilles helps to run is just one example of a larger trend - an increase in French-language anti-vaccine content on social media over the past year. Research from BBC Monitoring found that the number of followers of pages sharing extreme anti-vaccine content in French grew in 2020, from 3.2m to nearly 4.1m likes. These pages aren't about asking legitimate medical questions - they're miles away from the scientific and political discussions currently under way in Europe and elsewhere. Instead, they're run by people who've firmly made up their minds against vaccinations, and who spread wild false rumours about vaccines killing millions, containing tracking devices, or altering our DNA. Anti-vaccine pages in French also tend to mix in anti-establishment posts. Many of the discussions centre around concerns that Covid jabs could be made compulsory, with anti-establishment and protest communities fearing that French democracy will be replaced with a so-called ""sanitary dictatorship"". Covid-19 vaccination is not currently mandatory in France, though children are legally required to be vaccinated against some diseases. Facebook says it is investigating the groups and pages flagged by the BBC's research, and that it has removed 12 million pieces of harmful misinformation about Covid-19 and approved vaccines. ""Last week we announced further measures to curb the spread of harmful misinformation in groups,"" a company spokesperson said, ""including by restricting the reach of those who break our rules."" The Anti-Vax Files: A new series from BBC Trending, on the World Service from 05:30 GMT Saturday - or listen online In the group run by Gilles, outlandish false conspiracy theories appear alongside posts expressing more moderate views, like opposition to making vaccines mandatory. He doesn't agree with the extreme content, but Gilles says he struggles to delete all of the offending posts. But there are others trying their best to fight the wave of anti-vaccine conspiracies. They create their own Facebook pages, infiltrating the spaces on social media where falsehoods thrive. Marie - not her real name - runs a group of volunteers pushing pro-vaccine messages online. She wants to remain anonymous because she fears for her safety. ""We had a lot of death threats,"" she explains, a little shaken as she speaks from her home in Paris, ""[from] people on social media who read our page and don't like what they see on it."" I asked her why she continues in the face of abuse. ""I love science,"" she says, ""and I hate fake news."" Her Facebook page arms followers with accurate information about vaccines, asks them to debate people and even to try to persuade them to get vaccinated. This battle for the truth is raging all over the world, but it's particularly fierce in France. According to a survey by Ipsos late last year, just 40% of French people intended to receive a Covid-19 vaccine - although a more recent study indicated that number has increased to more than half. But Tristan Mendes France, a university lecturer who helps run a site called Conspiracy Watch, is still worried about the figures. Fifteen years ago, he says, polls indicated that only about a tenth of France's population were sceptical about vaccines. ""It's important to differentiate between those who are sceptical about the vaccine and those who are absolutely anti-vaccine,"" he says. In his view, the online anti-vaccine movement has thrived in France in particular because it plays on pre-existing scepticism of authority and pharmaceutical companies. It's not just about online conspiracy theories. According to Mendes France and other experts, vaccine scepticism has deeper and more complicated roots - a combination of deep distrust in the state, a passion for personal liberty, and historical failings. The country experienced a genuine vaccine scandal in 2009. The French government bought enough doses of the vaccine against the H1N1 ""swine flu"" virus to vaccinate its entire population. It cost more than 600m euros (more than $700m or Â£500m), but with only a few hundred swine flu deaths in the country, many didn't want the jab. It was seen as huge waste of money. In recent weeks, France was one of several European countries to suspend use of the Oxford-AstraZeneca Covid-19 vaccine over concerns about blood clots. The UK and EU Medicine regulators have concluded that there is no evidence the vaccine causes clots, and that the jab safe and effective. But it's another news story that has been used by French-speaking anti-vaccine activists to promote conspiracy narratives. Then there's the so-called ""Didier Raoult effect"". Raoult is a doctor who's a household name in France - famed for his intellect and his outspokeness. ""If you just start to be clever, it's a crime in our country. It's very hard for me not to be clever. I'm sorry,"" he chuckles, speaking from his research institute in Marseille. Despite a once-stellar reputation for scientific research, Dr Raoult caused controversy when he advocated the use of a drug called hydroxychloroquine to treat coronavirus. His claims were repeated by Donald Trump, but lacked scientific evidence. The incident resulted in a formal complaint from his peers in the medical community. Aside from the controversy over the drug, Dr Raoult has become - through no choice of his own - a hero for hard-core activists pushing anti-vaccine conspiracies. Fictitious quotes falsely attributed to the doctor have been circulated on social media. While these posts are false, he still has some controversial opinions about vaccines. He says he isn't sure people under age 65 should get a Covid-19 vaccine. That's despite the benefits that public health experts point out: younger people can be seriously affected by the virus, and mass vaccination can limit harmful virus mutations. Dr Raoult's approach appears to be part of a more general outlook in French-speaking Europe. At the extreme end, it sometimes spills over to conspiratorial thinking. Gilles, the sci-fi fan, is sure he doesn't want a Covid-19 vaccine. He's blasÃ© about catching the disease. ""I don't think that anything could happen,"" he says, ""Maybe [I would] get symptoms of flu, but that's very unlikely."" Covid-19 has a higher mortality rate than flu in all age groups, except perhaps children under the age of 12. The long term effects of coronavirus can also be severe - and it's more infectious than flu. But his lingering suspicion leaves Gilles - and others like him - vulnerable to all sorts of misinformation. Hear The Anti-Vax Files from BBC Trending, on the World Service from 05:30 GMT Saturday - or listen online"
The women fighting South Africa's 'infodemic',"In South Africa, a small group of volunteers is waging an online battle against Covid-19 and vaccine misinformation. Much of it comes from abroad, Jack Goodman reports. When Sarah Downs tweeted about how her grandmother had died from Covid-19, there was one response she did not expect. ""I had just posted a message on Twitter basically saying my amazing grandma passed away and she meant a lot to me,"" she says. ""So then I had someone asking me, 'Well, was there an autopsy done? What were the autopsy results? You don't know that she passed away from Covid. She could have passed away from something else.'"" She had run directly into a Covid-19 denier. They're a relatively small but vocal group who have a range of beliefs - but in general, many think coronavirus is a ""hoax"" or ""not real"", and are against public health measures and lockdown rules. Right now, one of their main preoccupations is campaigning against vaccines. But Sarah - studying molecular biology and infectious diseases - was the wrong person to troll. She spends hours debunking false claims for friends, family and strangers under the alias Mistress of Science. She and others have had their work cut out as medical misinformation has taken hold in South Africa - the country worst hit by the pandemic on the continent. At the top end of the information pipeline are a relatively small collection of Facebook groups and users, including some that have actively promoted hard-line anti-vaccination content for years. ""We estimate that it's about 20,000 South Africans who are actually active on anti-vax Facebook pages,"" says Prof Hannelie Meyer, a pharmacist and adviser to the South African Vaccine and Immunisation Centre (Savic). That's just a fraction of the country's population of 59 million. And most anti-vaccine claims in South Africa actually originate in the United States, according to a 2015 study. Anecdotal evidence - for instance the viral take-off in the country of false claims about vaccines and DNA by an American osteopath - suggests this trend has continued through the pandemic. The Anti-Vax Files: A new series from BBC Trending, on the World Service from 05:30 GMT Saturday. Download the podcast or listen online Data about vaccine hesitancy in South Africa is limited, says Prof Meyer, but studies indicate that more wealthy and educated groups - which include people who are more likely to be white - are less willing to get a jab. South Africa's vaccine rollout, which was delayed because of concerns that the first vaccines available wouldn't work against a new coronavirus variant, is now under way. Meanwhile the government has run a public campaign to bust prevalent health myths. A leading virologist has also pushed back against rumours - for instance, that Covid-19 and the vaccines that prevent it are a Western plot to reduce Africa's population and control the continent's natural resources. Prof Jeffrey Mphahlele calls the misinformation ""mind boggling"" - pointing out the supposed plot would  require the West to create a virus that killed millions of its own people. But falsehoods have also come from people in positions of authority. South Africa's top judge was criticised after a video showed him linking vaccines to a ""Satanic agenda."" Religious scholars have sought to reassure Christians by explaining relevant excerpts of religious text. In a live-streamed address, Bishop Malusi Mpumlwana debunked another false conspiracy theory - that 5G is linked to the virus - after officials said masts had been burned down at the beginning of this year in KwaZulu-Natal province. South Africa has been battling the same fake scientific theories that have been spreading elsewhere. And, like in other countries, Facebook groups have been a hotbed of anti-vaccine sentiment. One of the most prominent groups - 10,000 strong - seeks to spread ""awareness"" about vaccines. In reality, the hard-line anti-vaccine outlook of members is very clear. The majority of the posts in the group ridicule or dismiss vaccines. One video posted in the group - originally aired on an evangelical US Christian television programme - suggested getting a jab could lead to ""a lifetime of illness"". The woman that runs the group, Christine Hewlett, sells immune system boosting supplements in an online shop along with a book about raising ""vaccine-free"" children. We repeatedly asked Christine Hewlett for comment, but she didn't respond. We also contacted Facebook, which says it's looking into the groups we found. A spokesperson pointed out that the social network ""has already connected two billion people to reliable information from health experts."" As unverified information flooded social media throughout the course of the pandemic, Sarah Downs stepped in to help answer questions. One of those she helped was swimming teacher Sheona Lottering. ""I had a friend that forwarded me a German article,"" Sheona says. ""She was trying to convince me that death was one of the side-effects [of a Covid-19 vaccination]. ""And I was a little bit freaked out about that."" Through an exchange of voice notes, Sarah explained the nuance of an adverse event - like a sudden sickness or even death - following someone's vaccination. These incidents are recorded, but it doesn't necessarily mean vaccines were the cause. Now Sheona is regularly in touch with Sarah about tricky vaccine-related questions. And some South African volunteers have gone a little deeper into the battle against disinformation. ""The claims are so bizarre I could hardly believe there are people believing these things,"" says Lisa - not her real name because she fears an online backlash. Lisa spends hours lurking in Facebook groups. Her aim is simple: guide people towards trusted sources of health information. ""I don't like misinformation, so when I see something, I just try to correct it,"" she says. She's been doing that in one form or another for well over a decade, so she's seen communities grow and has become familiar with their tactics. Young mothers in particular are targeted in Facebook groups, she says, where posts are coordinated to try and convince them not to vaccinate their children. That's when Lisa springs into action. She keeps her inbox open and believes gentle communication works best - asking about people's concerns rather than shouting statistics at them. But Sarah, Lisa and other volunteers we spoke to risk exposing themselves to online abuse, and the prospects of persuasion can often seem slim. It's difficult, pro-health work - that isn't paid. So do they judge success? ""I think if I can just help one person be a little bit less terrified... that's what I aim to get out of it,"" Sarah says. ""And if they're willing to take the vaccine, even more so."" Listen toThe Anti-Vax Files from BBC Trending, on the World Service from 05:30 GMT Saturday. Download the podcast or listen online."
The young Ukrainians battling pro-Russian trolls,"What's it like being a young Ukrainian experiencing war while wading through chaos and misinformation on social media? 24-year-old Katrin awoke in Kyiv last Thursday to the sound of an explosion - and soon enough found her social media feed awash with distressing posts. ""The first thing we had to do was to pack and go to the basement,"" she tells me, now safe in her small hometown outside of Lviv where she escaped with her boyfriend, neighbours and their dogs. ""But right after we went down, I started scrolling Instagram. And it was all on my Instagram stories and my posts."" She wasn't just seeing scary, factual posts from friends, but false information - including comments on TikTok from accounts that claimed the war ""wasn't real"" or that it was a ""hoax"". ""After I blocked this one account, another sprung up with a profile picture of a different girl, writing to me in Russian,"" Katrin says. The trolls have been prolific - and they have been interacting with young women across Ukraine. Alina, 18, found herself in a total panic after seeing posts in Russian suggesting that her neighbourhood in Zaporizhzhya in south-east Ukraine was about to be shelled and destroyed. But the rumours were false. Alina spoke to me from her bedroom, exhausted after nights of air raids and sheltering. She says that rumours moved rapidly on chat app Telegram, spread by people apparently setting out to cause panic. ""Russians specifically find our chats and write that something is exploding. Someone writes that there is a sign of a bomb in the area - then others refute the information,"" she says. Another video she saw on Telegram suggested there had been an explosion at the airport in her hometown. It turned out to be a different explosion, in the nearby city of Mariupol. Old footage from other conflicts, including the massive blast in Beirut in 2020, has also been shared widely - including on TikTok, where clips have racked up millions of views. Marta is 20 years old and was stuck in the UK where she was visiting friends when the war broke out. She says she's seen videos from Syria and Iraq. ""But they posted them as 'Ukraine',"" she says. She says videos on TikTok's For You Page - the main gateway into the video-sharing app - have left her terrified and angry, as she desperately worries for friends and family back home. All three women have found themselves battling accounts posting comments in support of Russia. ""Some of them started to post videos, they started to call Ukraine 'liars',"" Marta says. Some were blaming Ukraine for the violence, writing ""glory to Russia"" - and others falsely suggested that the war was somehow staged. ""Every time I decided to take a look at those accounts, they were a profile with zero followers, zero likes, zero following, with a profile picture of a Russian flag or something,"" Marta says. Many of the TikTok accounts that the women shared with me appear to have lifted photos from other accounts online. Like Marta says, they have few or no followers, and they don't use their real names - or use generic usernames. One I looked at used the name ""Jess"" and had just one follower. The only videos on the account are ones first shared just days ago, indicating that the account was created very recently. Almost all of the videos the account did share featured debunked and false claims: that a woman who was injured during a Russian attack was an actor, that news coverage is filled with footage of old conflicts, and even that the war somehow isn't happening. One account Katrin ended up arguing with on TikTok again had few followers - its profile image appears to be copied from the Pinterest page of a Korean woman. None of the accounts have responded to my attempts to get in touch - so it's hard to tell who is running them. Russia has created inauthentic accounts before to push messages and sow division. But it's also possible that the accounts are run by real people who believe false claims. Misinformation is a problem social media companies have been grappling with for some time. Now their policies are coming under fresh scrutiny. Meta, which owns Facebook and Instagram, along with Twitter and Google, have all announced commitments to tackle false information and propaganda around the war in Ukraine. But it's apps like Telegram and TikTok - used a lot by young Ukrainians - is where much of this disinformation continues to proliferate. TikTok told the BBC it has ""increased resources to respond to emerging trends and remove violative content, including harmful misinformation and promotion of violence."" Telegram did not respond to our request for comment. It's clear that what's happening online is causing even more panic and pain in the real world. ""We are scared by those who create this fake information,"" Alina tells me, ready to head yet again down to the basement as the air raid siren rings out."
They died suddenly - then the anti-vax trolling started,"""Seven days, 18 hours, 39 minutes ago my beloved... died suddenly of cardiac arrest"". When Victoria Brownworth logged onto Twitter to post these words about her partner of 23 years, she didn't know that two of them in particular would provoke a storm of online harassment. Because, as Victoria waited at her home in Philadelphia on Sunday night for her wife's ashes to be delivered, a video titled Died Suddenly was about to drop. In an hour and eight minutes of dramatic music and out-of-context news reports, the film tells a fictitious story of a dangerous vaccine killing off swathes of young people - all part of an imagined plot to depopulate the earth. It landed on niche video-sharing platform Rumble on Monday and began to spread. By Wednesday morning it had been viewed more than 4 million times on Rumble and at least 1.5 million times on Twitter. The claims made in the video quickly fall apart under scrutiny. Vast amounts of evidence from different independent scientists all over the world, as well as the experiences of billions of people, have shown that serious Covid vaccine side effects are rare. But its call for people to look at any reported deaths through a lens of suspicion had made Victoria fair game - and as the phrase ""died suddenly"" started to trend, people flocked to her memorial thread. ""How long's it been since she got the jab?"", hundreds of people began to reply. Victoria's wife, Madelaine Gold - a painter and design professor - had an advanced stage of cancer, though she had been doing better just before she died. There is no suggestion the vaccine had anything to do with her death. When she began to hit back, Victoria was told she was lying. ""She did die suddenly... We didn't have time to say goodbye, I didn't have time to give her a last kiss. I will never get to talk to her again."" ""They were trolling her obituary, literally."" So what was it about this film that led people online to deny Victoria's reality? The film flashes through dozens of upsetting news reports and images of people collapsing. One headline reads: ""My kind, compassionate son died unexpectedly."" Another clip shows a young athlete dramatically keeling over. Together, this can easily be used to paint an alarming picture of something suspicious going on. Yet just a couple more clicks would reveal the son in question died in a car crash. And the athlete, college basketball player Keyontae Johnson, collapsed in December 2020 before he could even have had a Covid vaccine. He didn't die suddenly as the title suggests - he returned to the court last week. Other people featured are also still alive. And several of the genuine deaths are explained by an alternative cause within the very news reports used as evidence by the film makers. Part of the film's power is that it takes scraps of truth but distorts them to tell a misleading story. There have been a small number of deaths from the vaccines - I've spoken to people affected - but these cases are rare and their causes are established through extensive monitoring, complex medical testing and statistical analysis. It's not possible to measure vaccine side effects by simply Googling news reports. As Dr Frank Han, a US cardiologist says, it can ""give you pieces of the puzzle, but actual medical training is necessary to link all the pieces of how the body works together"". Long stretches of the film involve gruesome images of clots being pulled out of bodies, designed to suggest Covid vaccines are having alarming effects. When people feel afraid or disgusted they might be more likely to leap to conclusions. But these images can't tell us anything on their own. Firstly, they are mostly based on the testimony of one embalmer with no indication this is a wider concern. And, Dr Han explains, it's ""insufficient to establish why the clots are there"". Blood clots are commonly found in dead bodies and are caused by a range of things from smoking to being bed-bound to having Covid-19. When unusual clotting was identified in rare cases after the AstraZeneca vaccine - not used in the US - it was quickly investigated and vaccine recommendations changed, after which the cases pretty much disappeared. Emotional stories, backed up by official numbers make a powerful persuasive tool. But it's important to understand where the numbers actually come from and whether they are being fairly represented - something many people won't have the time or resources to investigate. A graph in the film showing stillbirths shooting up around 2021, making the unsupported suggestion Covid vaccines are causing miscarriages, looks shocking. The film-makers don't provide a source, though. Although the voiceover claims the data is from Waterloo, Canada, genuine data from Ontario, the province Waterloo is part of, has not seen any increase in stillbirths, according to Dr Victoria Male, a reproductive immunologist. In fact, a large study found a ""lower (not higher) rate of stillbirth among those vaccinated in pregnancy, compared to those who were not,"" she said. This is supported by dozens of studies involving tens of thousands of people produced by different independent teams around the world. The tactics used in this video have been seen before and this isn't the first time misleading health information has been spread by verified accounts. What's new this time is the main account spreading the film on Twitter has bought verification - the blue tick which is supposed to be a mark of credibility, something experts have warned could help misinformation spread. ""Since Elon Musk took over he's just, you know, let it be the Wild West again,"" Victoria believes. Twitter did not respond to a request for comment. If you have a story you can contact Rachel rachel.schraer@bbc.co.uk or follow her on Twitter ""Seven days, 18 hours, 39 minutes ago my beloved... died suddenly of cardiac arrest"". When Victoria Brownworth logged onto Twitter to post these words about her partner of 23 years, she didn't know that two of them in particular would provoke a storm of online harassment. Because, as Victoria waited at her home in Philadelphia on Sunday night for her wife's ashes to be delivered, a video titled Died Suddenly was about to drop. In an hour and eight minutes of dramatic music and out-of-context news reports, the film tells a fictitious story of a dangerous vaccine killing off swathes of young people - all part of an imagined plot to depopulate the earth. It landed on niche video-sharing platform Rumble on Monday and began to spread. By Wednesday morning it had been viewed more than 4 million times on Rumble and at least 1.5 million times on Twitter. The claims made in the video quickly fall apart under scrutiny. Vast amounts of evidence from different independent scientists all over the world, as well as the experiences of billions of people, have shown that serious Covid vaccine side effects are rare. But its call for people to look at any reported deaths through a lens of suspicion had made Victoria fair game - and as the phrase ""died suddenly"" started to trend, people flocked to her memorial thread. ""How long's it been since she got the jab?"", hundreds of people began to reply. Victoria's wife, Madelaine Gold - a painter and design professor - had an advanced stage of cancer, though she had been doing better just before she died. There is no suggestion the vaccine had anything to do with her death. When she began to hit back, Victoria was told she was lying. ""She did die suddenly... We didn't have time to say goodbye, I didn't have time to give her a last kiss. I will never get to talk to her again."" ""They were trolling her obituary, literally."" So what was it about this film that led people online to deny Victoria's reality? The film flashes through dozens of upsetting news reports and images of people collapsing. One headline reads: ""My kind, compassionate son died unexpectedly."" Another clip shows a young athlete dramatically keeling over. Together, this can easily be used to paint an alarming picture of something suspicious going on. Yet just a couple more clicks would reveal the son in question died in a car crash. And the athlete, college basketball player Keyontae Johnson, collapsed in December 2020 before he could even have had a Covid vaccine. He didn't die suddenly as the title suggests - he returned to the court last week. Other people featured are also still alive. And several of the genuine deaths are explained by an alternative cause within the very news reports used as evidence by the film makers. Part of the film's power is that it takes scraps of truth but distorts them to tell a misleading story. There have been a small number of deaths from the vaccines - I've spoken to people affected - but these cases are rare and their causes are established through extensive monitoring, complex medical testing and statistical analysis. It's not possible to measure vaccine side effects by simply Googling news reports. As Dr Frank Han, a US cardiologist says, it can ""give you pieces of the puzzle, but actual medical training is necessary to link all the pieces of how the body works together"". Long stretches of the film involve gruesome images of clots being pulled out of bodies, designed to suggest Covid vaccines are having alarming effects. When people feel afraid or disgusted they might be more likely to leap to conclusions. But these images can't tell us anything on their own. Firstly, they are mostly based on the testimony of one embalmer with no indication this is a wider concern. And, Dr Han explains, it's ""insufficient to establish why the clots are there"". Blood clots are commonly found in dead bodies and are caused by a range of things from smoking to being bed-bound to having Covid-19. When unusual clotting was identified in rare cases after the AstraZeneca vaccine - not used in the US - it was quickly investigated and vaccine recommendations changed, after which the cases pretty much disappeared. Emotional stories, backed up by official numbers make a powerful persuasive tool. But it's important to understand where the numbers actually come from and whether they are being fairly represented - something many people won't have the time or resources to investigate. A graph in the film showing stillbirths shooting up around 2021, making the unsupported suggestion Covid vaccines are causing miscarriages, looks shocking. The film-makers don't provide a source, though. Although the voiceover claims the data is from Waterloo, Canada, genuine data from Ontario, the province Waterloo is part of, has not seen any increase in stillbirths, according to Dr Victoria Male, a reproductive immunologist. In fact, a large study found a ""lower (not higher) rate of stillbirth among those vaccinated in pregnancy, compared to those who were not,"" she said. This is supported by dozens of studies involving tens of thousands of people produced by different independent teams around the world. The tactics used in this video have been seen before and this isn't the first time misleading health information has been spread by verified accounts. What's new this time is the main account spreading the film on Twitter has bought verification - the blue tick which is supposed to be a mark of credibility, something experts have warned could help misinformation spread. ""Since Elon Musk took over he's just, you know, let it be the Wild West again,"" Victoria believes. Twitter did not respond to a request for comment. If you have a story you can contact Rachel rachel.schraer@bbc.co.uk or follow her on Twitter"
TikTok: GP posts videos to tackle vaccine fake news,nan
Trump allowed back onto Twitter,"US President Donald Trump has been allowed to Tweet again, after being locked out of his account for 12 hours. Posting a more conciliatory message, he refrained from reiterating false claims of voter fraud. Twitter said that it would ban Mr Trump ""permanently"" if he breached the platform's rules again. The move from Twitter puts clear water between it and Facebook, which suspended him ""indefinitely"" on Thursday. Twitter has instead given the outgoing president a final warning. Earlier on Thursday, the popular gaming platform Twitch also placed an indefinite ban on Mr Trump's channel, which he has used for rally broadcasts. Mr Trump tweeted several message on Wednesday, calling the people who stormed Capitol Hill ""patriots"". He also said ""We love you."" A spokesperson for Twitter said: ""After the Tweets were removed and the subsequent 12-hour period expired, access to @realDonaldTrump was restored. ""Any future violations of the Twitter Rules, including our Civic Integrity or Violent Threats policies, will result in permanent suspension of the @realDonaldTrump account."" Earlier in the day, the president was suspended from Facebook and Instagram. That suspension will be reviewed after the transition of power to Joe Biden on 20 January. The social network had originally imposed a 24-hour ban after the US Capitol attack. Facebook's chief, Mark Zuckerberg, wrote that the risks of allowing Mr Trump to post ""are simply too great"". Mr Zuckerberg said Facebook had removed the president's posts ""because we judged that their effect - and likely their intent - would be to provoke further violence"". He said it was clear Mr Trump intended to undermine the transfer of power to President-elect Joe Biden. ""Therefore, we are extending the block we have placed on his Facebook and Instagram accounts indefinitely and for at least the next two weeks until the peaceful transition of power is complete,"" he wrote. Mr Trump's favoured platform, Twitter, suspended the president for 12 hours on Wednesday. The company said it required the removal of three tweets for ""severe violations of our Civic Integrity policy"". It said the president's account would remain locked for good if the tweets were not removed. Twitter has now confirmed the offending tweets have been removed, and he is free to tweet again. Snapchat also stopped Mr Trump from creating new posts, but did not say if or when it would end the ban. YouTube also removed Wednesday's video. The president's supporters stormed the seat of US government and clashed with police, leading to the death of one woman. The violence brought to a halt congressional debate over Democrat Joe Biden's election win. In the House and Senate chambers, Republicans were challenging the certification of November's election results. Before the violence, President Trump had told supporters on the National Mall in Washington that the election had been stolen. Hours later, as the violence mounted inside and outside the US Capitol, he appeared on video and repeated the false claim."
Tunisia migrants: False content goes viral on social media,"False and misleading social media videos about migrants from sub-Saharan Africa in Tunisia have been widely shared amid a wave of anti-migrant sentiment in that country. President Kais Saied of Tunisia said migration was a ""plot"" to change the country's demographic profile, and Ivory Coast and Guinea have begun repatriating their nationals due to fears for their safety. We've looked at several videos circulating online that claim to show African migrants in Tunisia, nearly all of which are actually filmed elsewhere. Several TikTok videos posted recently show large groups running along a street in what appears to be an angry protest. One of the videos, with millions of views, is labelled in Arabic: ""Tunisia under occupation"". Another one says: ""Tunisia has become the kingdom of Africans."" But the event shown happened in Dakar, the capital of Senegal. This is clear from a distinctive obelisk, which can be seen at one point as the person filming moves around. It's in the Place de l'ObÃ©lisque in the Senegalese capital, visible on Google Maps. In addition, the Senegalese flag can be seen, and we've confirmed that the language heard is Wolof, a Senegalese national language. We traced the event back to an opposition protest held in Dakar in June 2022, video of which can be seen here. There are other TikTok videos falsely claiming that street protests involving African migrants are happening in Tunisia. One widely shared example shows groups of people who appear to be from sub-Saharan Africa confronting drivers and bystanders on a busy road with cars at a standstill. It's labelled in Arabic: ""Occupation by sub-Saharan Africans of more than one Tunisian province."" Some of the comments on this post point out that it's not Tunisia, but Morocco, and we've confirmed that from clues in the video. A red car seen at one point has a sign on the roof which reads ""small size"" in Arabic, which is a feature of red-coloured taxis in the Moroccan city of Casablanca. Although the rear number plate can't be seen clearly, it does have an initial five digits, which is what you would expect on Moroccan plates. We also checked the dialogue heard at one point, and some of the Arabic spoken has an accent unique to Morocco. Another recent video shared on TikTok shows groups of men walking across open desert with the caption: ""A large number of sub-Saharans crossing the desert towards Tunisia."" However, we've found an earlier TikTok post featuring a longer version of the same video. It was posted in September 2022 by a man recording his journey travelling away from Algeria, after he was forced to leave. The later video has been zoomed in slightly and has writing obscuring parts of the image, but all the same characters appear in the same groups wearing the same clothes, including a man with a striped pink and white bag balanced on his head. Thousands of migrants from sub-Saharan Africa were expelled from Algeria last year, according to aid agencies. In another video posted by the same man, he says he's arrived in Bamako, the capital of Mali, which would have involved an arduous journey south across the Sahara desert. Another video with tens of thousands of views shows vehicles full of armed men driving along watched by bystanders. It is captioned in Arabic: ""The Africans are also armed."" One of the Arabic hashtags below says: ""Africans in Tunisia"". However, we've identified an earlier posting of this same video, saying it's filmed in Sudan, and there are elements in the video that back this up. There's a shop along the roadside with the sign ""Tappco"", an oil and lubricant company based in Sudan. We can also see a white, red and green emblem on the door of one of the passing vehicles, which are the colours of the flag of Sudan. We have managed to match this to the insignia on uniforms worn by special forces in the Sudanese military. The red berets and white belts worn by the soldiers are also known to be worn by some units in Sudan's armed forces. And a final clue - one of the shop fronts in the video has the word ""rakshat"" in Arabic, a distinctively Sudanese description for rickshaw taxis. In some cases, video has been taken out of context to garner sympathy for the plight of sub-Saharan Africans in Tunisia. One example is a Twitter post of an incident at a Tunisian airport, in which a man is involved in a fracas and is being restrained by airport staff and security personnel. ""Black Africans are being attacked in Tunisia even when they are trying to leave..."", the post says. This incident did happen in Tunisia, but as some of the comments on the post point out, it's from July 2022. It was reported on by several news outlets at the time, including in the UK. So it's not from the current wave of anti-migrant feeling. But the broader context is that there have been cases of harassment and assault against migrants from sub-Saharan Africa in Tunisia, leaving many fearing for their safety. Research and reporting by Abdirahim Saeed, Alioune Diop, Alphonse Dioh, Taouba Khelifi, Kumar Malhotra, Peter Mwai and Raissa Okoi False and misleading social media videos about migrants from sub-Saharan Africa in Tunisia have been widely shared amid a wave of anti-migrant sentiment in that country. President Kais Saied of Tunisia said migration was a ""plot"" to change the country's demographic profile, and Ivory Coast and Guinea have begun repatriating their nationals due to fears for their safety. We've looked at several videos circulating online that claim to show African migrants in Tunisia, nearly all of which are actually filmed elsewhere. Several TikTok videos posted recently show large groups running along a street in what appears to be an angry protest. One of the videos, with millions of views, is labelled in Arabic: ""Tunisia under occupation"". Another one says: ""Tunisia has become the kingdom of Africans."" But the event shown happened in Dakar, the capital of Senegal. This is clear from a distinctive obelisk, which can be seen at one point as the person filming moves around. It's in the Place de l'ObÃ©lisque in the Senegalese capital, visible on Google Maps. In addition, the Senegalese flag can be seen, and we've confirmed that the language heard is Wolof, a Senegalese national language. We traced the event back to an opposition protest held in Dakar in June 2022, video of which can be seen here. There are other TikTok videos falsely claiming that street protests involving African migrants are happening in Tunisia. One widely shared example shows groups of people who appear to be from sub-Saharan Africa confronting drivers and bystanders on a busy road with cars at a standstill. It's labelled in Arabic: ""Occupation by sub-Saharan Africans of more than one Tunisian province."" Some of the comments on this post point out that it's not Tunisia, but Morocco, and we've confirmed that from clues in the video. A red car seen at one point has a sign on the roof which reads ""small size"" in Arabic, which is a feature of red-coloured taxis in the Moroccan city of Casablanca. Although the rear number plate can't be seen clearly, it does have an initial five digits, which is what you would expect on Moroccan plates. We also checked the dialogue heard at one point, and some of the Arabic spoken has an accent unique to Morocco. Another recent video shared on TikTok shows groups of men walking across open desert with the caption: ""A large number of sub-Saharans crossing the desert towards Tunisia."" However, we've found an earlier TikTok post featuring a longer version of the same video. It was posted in September 2022 by a man recording his journey travelling away from Algeria, after he was forced to leave. The later video has been zoomed in slightly and has writing obscuring parts of the image, but all the same characters appear in the same groups wearing the same clothes, including a man with a striped pink and white bag balanced on his head. Thousands of migrants from sub-Saharan Africa were expelled from Algeria last year, according to aid agencies. In another video posted by the same man, he says he's arrived in Bamako, the capital of Mali, which would have involved an arduous journey south across the Sahara desert. Another video with tens of thousands of views shows vehicles full of armed men driving along watched by bystanders. It is captioned in Arabic: ""The Africans are also armed."" One of the Arabic hashtags below says: ""Africans in Tunisia"". However, we've identified an earlier posting of this same video, saying it's filmed in Sudan, and there are elements in the video that back this up. There's a shop along the roadside with the sign ""Tappco"", an oil and lubricant company based in Sudan. We can also see a white, red and green emblem on the door of one of the passing vehicles, which are the colours of the flag of Sudan. We have managed to match this to the insignia on uniforms worn by special forces in the Sudanese military. The red berets and white belts worn by the soldiers are also known to be worn by some units in Sudan's armed forces. And a final clue - one of the shop fronts in the video has the word ""rakshat"" in Arabic, a distinctively Sudanese description for rickshaw taxis. In some cases, video has been taken out of context to garner sympathy for the plight of sub-Saharan Africans in Tunisia. One example is a Twitter post of an incident at a Tunisian airport, in which a man is involved in a fracas and is being restrained by airport staff and security personnel. ""Black Africans are being attacked in Tunisia even when they are trying to leave..."", the post says. This incident did happen in Tunisia, but as some of the comments on the post point out, it's from July 2022. It was reported on by several news outlets at the time, including in the UK. So it's not from the current wave of anti-migrant feeling. But the broader context is that there have been cases of harassment and assault against migrants from sub-Saharan Africa in Tunisia, leaving many fearing for their safety. Research and reporting by Abdirahim Saeed, Alioune Diop, Alphonse Dioh, Taouba Khelifi, Kumar Malhotra, Peter Mwai and Raissa Okoi"
Turkey earthquake: The false images shared online,"Within hours of the earthquake that struck Turkey and Syria, false and misleading content began circulating online. Pictures and video from previous disasters in other countries were shared by people with claims that they showed damage caused by Monday's tremors. We've looked at some of the most viral examples. One tweet - from a verified Twitter user - claimed to show a nuclear plant exploding, due to the earthquake in Turkey. The video got more than 1.2 million views. The tweet also said ""Not confirmed, is this real?"". It wasn't a real image of a Turkish nuclear plant exploding. Running the images through a search engine to see if they had appeared online before, revealed that they were actually from the aftermath of the Beirut explosion in August 2020, which resulted in the deaths of at least 200 people. Twitter later added a note underneath the tweet, clarifying its actual origin. In the early hours of Monday, a video claiming to show a building collapse in Turkey was shared online, racking up more than a million views on Twitter. However, a search of key frames from this video on Google revealed the clip actually shows the deadly Surfside condominium collapse in Florida in June 2021, footage of which was widely shared at the time. British-Iranian comedian Omid Djalili shared a video on his Twitter account of what he claimed was a ""tsunami after the earthquake hit the coast of Turkey"". It has been viewed nearly 300,000 times. The video shows a huge wave washing away buildings next to a beach, as people run for their lives. But, again, taking screenshots of the footage and searching for them on the internet revealed the clip actually dates back to September 2018 and was from Indonesia. It showed the aftermath of a 7.5-magnitude quake which struck off the island of Sulawesi, setting off a tsunami that damaged the coastal city of Palu. After people pointed this out to him, Mr Djalili tweeted again to say, ""I understand this was NOT Turkey yesterday ...tweeted emotionally late night from usually reliable sources."" A different post on Twitter showed a video with scaffolding from a high-rise building falling to the ground. The tweet falsely claimed that this was caused by the earthquake in Turkey and was shared across multiple platforms and garnered hundreds of thousands of views. This video was in fact from an incident in Japan in 2016. It was posted by the same user who posted the Beirut blast pictures. An image of a dog lying on top of rubble, with its paw next to a hand sticking out of the debris, was shared in the aftermath of the quake, accompanied with the caption ""heartbreaking photo of the day"" and a Turkey hashtag. The image has been viewed more than 1.4 million times so far. But a reverse image search using the freely-available Google Lens technology leads to the exact same photo on a stock image website, captioned ""Dog looking for injured people in ruins after earthquake"". The website says the image was taken on 18 October 2018, proving it has no link to the earthquake this week. Reporting by Shayan Sardarizadeh, Merlyn Thomas and Adam Robinson Within hours of the earthquake that struck Turkey and Syria, false and misleading content began circulating online. Pictures and video from previous disasters in other countries were shared by people with claims that they showed damage caused by Monday's tremors. We've looked at some of the most viral examples. One tweet - from a verified Twitter user - claimed to show a nuclear plant exploding, due to the earthquake in Turkey. The video got more than 1.2 million views. The tweet also said ""Not confirmed, is this real?"". It wasn't a real image of a Turkish nuclear plant exploding. Running the images through a search engine to see if they had appeared online before, revealed that they were actually from the aftermath of the Beirut explosion in August 2020, which resulted in the deaths of at least 200 people. Twitter later added a note underneath the tweet, clarifying its actual origin. In the early hours of Monday, a video claiming to show a building collapse in Turkey was shared online, racking up more than a million views on Twitter. However, a search of key frames from this video on Google revealed the clip actually shows the deadly Surfside condominium collapse in Florida in June 2021, footage of which was widely shared at the time. British-Iranian comedian Omid Djalili shared a video on his Twitter account of what he claimed was a ""tsunami after the earthquake hit the coast of Turkey"". It has been viewed nearly 300,000 times. The video shows a huge wave washing away buildings next to a beach, as people run for their lives. But, again, taking screenshots of the footage and searching for them on the internet revealed the clip actually dates back to September 2018 and was from Indonesia. It showed the aftermath of a 7.5-magnitude quake which struck off the island of Sulawesi, setting off a tsunami that damaged the coastal city of Palu. After people pointed this out to him, Mr Djalili tweeted again to say, ""I understand this was NOT Turkey yesterday ...tweeted emotionally late night from usually reliable sources."" A different post on Twitter showed a video with scaffolding from a high-rise building falling to the ground. The tweet falsely claimed that this was caused by the earthquake in Turkey and was shared across multiple platforms and garnered hundreds of thousands of views. This video was in fact from an incident in Japan in 2016. It was posted by the same user who posted the Beirut blast pictures. An image of a dog lying on top of rubble, with its paw next to a hand sticking out of the debris, was shared in the aftermath of the quake, accompanied with the caption ""heartbreaking photo of the day"" and a Turkey hashtag. The image has been viewed more than 1.4 million times so far. But a reverse image search using the freely-available Google Lens technology leads to the exact same photo on a stock image website, captioned ""Dog looking for injured people in ruins after earthquake"". The website says the image was taken on 18 October 2018, proving it has no link to the earthquake this week. Reporting by Shayan Sardarizadeh, Merlyn Thomas and Adam Robinson"
Twitter Blue accounts fuel Ukraine War misinformation,"False and misleading posts about the Ukraine conflict continue to go viral on major social media platforms, as Russia's invasion of the country extends beyond 500 days. Some of the most widely shared examples can be found on Twitter, posted by subscribers with a blue tick, who pay for their content to be promoted to other users. Many misleading posts have been shared online about the recent riots in France, but one viral post last week focused on US military aid to Ukraine. It featured a screenshot of what appeared to be a headline from a news website, along with an image of two rifles. ""French police are fired upon with American rifles that may have come from Ukraine,"" reads the headline. Several Twitter accounts with Blue subscriptions have shared the post, which has been viewed more than a million times. BBC Verify has traced it back to pro-Kremlin channels on the Telegram messaging app. The image used in the post appears in a Russian military blog from 2012 about a shooting competition held on a firing range near Moscow. We have also been unable to find any online articles with the headline and picture as above, and there is no evidence any weapons provided to Ukraine by the US have been used during the recent unrest in France. Several Twitter accounts with a blue tick have recently promoted a claim that Russia has discovered ""baby factories"" in Ukraine. Children between the ages of two and seven are said to be ""factory farmed"", and either sent to ""child sex brothels"" or to have their organs harvested and sold in the West. BBC Verify has traced the origin of the claim to an article published in March by The People's Voice, an alternative name for YourNewsWire, which has been described by fact-checking organisations as one of the biggest producers of fake news on the internet. It has previously promoted a wide range of false and misleading stories, including anti-vaccine conspiracy theories and false claims about the 2017 mass shooting in Las Vegas. The Russian government and Kremlin-controlled media have a history of promoting unsubstantiated claims about illegal organ harvesting in Ukraine. A Russian missile attack killed eight people in the centre of Kramatorsk in eastern Ukraine, at the end of June. In the immediate aftermath of the attack, a post by an account with a Twitter Blue subscription, which positions itself as a legitimate news source, claimed the strike was mistakenly launched by Ukraine and hit a military barracks housing Nato troops and foreign mercenaries. ""Storm Shadow missile suddenly changed trajectory dramatically, hitting Kramatorsk obliterated a Ukrainian military barracks housing foreign soldiers and mercenaries,"" the tweet claimed. The post was viewed more than a million times. There is no evidence that a missile launched by Ukrainian forces was responsible, nor that a military barracks was hit. Posts claiming Ukrainian President Volodymyr Zelensky has ""cancelled"" elections in Ukraine have recently gone viral on Twitter. As evidence, users cited remarks made by Mr Zelensky in an interview with the BBC in late June. Asked whether there will be elections in Ukraine next year, Mr Zelensky responded: ""If we win [the war], there will be. It means there will be no martial law, no war. Elections must be held in peacetime, when there is no war, according to the law."" Commenting on the statement, former Fox News host Tucker Carlson, who's been critical of US aid for Ukraine, said in his recently launched Twitter show that Mr Zelensky's comments proved he'd ended democracy in Ukraine. Twitter Blue accounts on a similar theme have been shared hundreds of thousands of times. The Ukrainian constitution prohibits the dissolution of parliament and national elections during martial law, meaning the current president and parliament will remain in charge until the period of martial law comes to an end. Oleksii Danilov, secretary of Ukraine's national security and defence council, recently confirmed that based on the Ukrainian constitution, ""no elections can take place"" while martial law is in effect in the country. Contacted by BBC Verify for a response to the false and misleading Twitter Blue posts highlighted in this article, Twitter's press office acknowledged receipt of our enquiry, but declined to comment. What do you want BBC Verify to investigate? False and misleading posts about the Ukraine conflict continue to go viral on major social media platforms, as Russia's invasion of the country extends beyond 500 days. Some of the most widely shared examples can be found on Twitter, posted by subscribers with a blue tick, who pay for their content to be promoted to other users. Many misleading posts have been shared online about the recent riots in France, but one viral post last week focused on US military aid to Ukraine. It featured a screenshot of what appeared to be a headline from a news website, along with an image of two rifles. ""French police are fired upon with American rifles that may have come from Ukraine,"" reads the headline. Several Twitter accounts with Blue subscriptions have shared the post, which has been viewed more than a million times. BBC Verify has traced it back to pro-Kremlin channels on the Telegram messaging app. The image used in the post appears in a Russian military blog from 2012 about a shooting competition held on a firing range near Moscow. We have also been unable to find any online articles with the headline and picture as above, and there is no evidence any weapons provided to Ukraine by the US have been used during the recent unrest in France. Several Twitter accounts with a blue tick have recently promoted a claim that Russia has discovered ""baby factories"" in Ukraine. Children between the ages of two and seven are said to be ""factory farmed"", and either sent to ""child sex brothels"" or to have their organs harvested and sold in the West. BBC Verify has traced the origin of the claim to an article published in March by The People's Voice, an alternative name for YourNewsWire, which has been described by fact-checking organisations as one of the biggest producers of fake news on the internet. It has previously promoted a wide range of false and misleading stories, including anti-vaccine conspiracy theories and false claims about the 2017 mass shooting in Las Vegas. The Russian government and Kremlin-controlled media have a history of promoting unsubstantiated claims about illegal organ harvesting in Ukraine. A Russian missile attack killed eight people in the centre of Kramatorsk in eastern Ukraine, at the end of June. In the immediate aftermath of the attack, a post by an account with a Twitter Blue subscription, which positions itself as a legitimate news source, claimed the strike was mistakenly launched by Ukraine and hit a military barracks housing Nato troops and foreign mercenaries. ""Storm Shadow missile suddenly changed trajectory dramatically, hitting Kramatorsk obliterated a Ukrainian military barracks housing foreign soldiers and mercenaries,"" the tweet claimed. The post was viewed more than a million times. There is no evidence that a missile launched by Ukrainian forces was responsible, nor that a military barracks was hit. Posts claiming Ukrainian President Volodymyr Zelensky has ""cancelled"" elections in Ukraine have recently gone viral on Twitter. As evidence, users cited remarks made by Mr Zelensky in an interview with the BBC in late June. Asked whether there will be elections in Ukraine next year, Mr Zelensky responded: ""If we win [the war], there will be. It means there will be no martial law, no war. Elections must be held in peacetime, when there is no war, according to the law."" Commenting on the statement, former Fox News host Tucker Carlson, who's been critical of US aid for Ukraine, said in his recently launched Twitter show that Mr Zelensky's comments proved he'd ended democracy in Ukraine. Twitter Blue accounts on a similar theme have been shared hundreds of thousands of times. The Ukrainian constitution prohibits the dissolution of parliament and national elections during martial law, meaning the current president and parliament will remain in charge until the period of martial law comes to an end. Oleksii Danilov, secretary of Ukraine's national security and defence council, recently confirmed that based on the Ukrainian constitution, ""no elections can take place"" while martial law is in effect in the country. Contacted by BBC Verify for a response to the false and misleading Twitter Blue posts highlighted in this article, Twitter's press office acknowledged receipt of our enquiry, but declined to comment. What do you want BBC Verify to investigate?"
Twitter Files spark debate about ÂblacklistingÂ,"What makes one social media post pop up all over people's feeds and another disappear into obscurity? It's a question anyone trying to make a splash online would love the answer to. We know that tweets don't just appear in chronological order - your feed is being engineered in some way. And platforms tend to keep the full details of their algorithm - the code that determines which posts you see in what order - under their hats. Under an initiative by Twitter's new chief Elon Musk, fragments of internal Twitter discussions about content moderation - dubbed ""the Twitter Files"" - have been shared on the platform by a few selected journalists. The ongoing revelations contain internal chats of Twitter's inner circle of senior executives about a series of controversial decisions: limiting the dissemination of the Hunter Biden laptop story, the permanent suspension of Donald Trump in the wake of the 6 January 2021 Capitol riot, and limiting the reach of some influential accounts. Part two of the revelations, shared by US journalist Bari Weiss, who had been provided with screenshots by Twitter's new head of safety Ella Irwin, reveals three influential conservative accounts in the US were put on different ""blacklists"", meaning their tweets either wouldn't trend, might not appear in search, or would not be ""amplified"". Ms Weiss said decisions were made ""all in secret, without informing users"". Mr Musk went even further, saying the revelations proved ""the rules were enforced against the right, but not against the left"". But it's incredibly hard to verify whether this is giving us the whole picture. We are missing the context of which other accounts have faced similar treatment, and whether the restricted accounts were in breach of other rules, for example inciting hate or spreading false claims about Covid that could cause harm. Restricting accounts can be a useful tool if they are spreading harmful material. A common phrase when we talk about regulating the internet is ""freedom of speech not freedom of reach"" - it's one Mr Musk himself has used to describe the platform's new approach. Twitter, for instance, confirmed just a few days ago that it would not ""amplify tweets containing slurs or hate speech"". The idea of an account being placed on ""trends blacklists"" doesn't seem totally out of step with this policy. The more controversial part comes from who gets to decide what can and can't trend, where the threshold for a restriction lies and who ends up on the list. One name on the Twitter files list that has drawn attention is Dr Jay Bhattacharya - a health policy professor at Stanford University - who vocally opposed coronavirus lockdowns, and whose tweets were reportedly prevented from trending. He has been criticised, including by a judge in a US case about mask mandates in schools, who accused him of oversimplifying research studies, and by other scientists for proposing an alternative to lockdowns they said was unworkable and would lead to more deaths. But he has said science required people to disagree with each other, arguing against ""censorship of scientific discussion"". There have been various reports suggesting marginalised groups including trans and plus size people were more likely to have their accounts restricted. Multiple liberal and left-leaning individuals have also previously complained about their accounts and tweets being ""suppressed"". The difficulty is, people will have a hunch they are being restricted- the engagement with their posts suddenly falls or their followers report not seeing them anymore - but that could be down to many other reasons, and it's incredibly hard to prove that's what is happening without access to the companies' internal workings. Alex Stamos, director of the Stanford Internet Observatory and a former Facebook chief security officer, says Mr Musk is ""providing extremely limited transparency"" to like-minded US media figures. He proposed that Mr Musk should make available details of all communications around content moderation with governments, political parties and politicians around the world. Mr Musk says he intends to introduce a new feature that will enable all users to see ""your true account status"", including whether they've been ""shadowbanned"" (hidden from other people's feeds), the reason for it, and a process to appeal. Twitter isn't the only company moving in this direction- Instagram recently launched a new tool of its own to let you know if your posts are barred from being recommended to other users. While these changes add some degree of transparency to the process, content moderation decisions are incredibly difficult and messy, and remain open to political influence from owners, senior executives and pressure from politicians and activists. The BBC approached Ms Weiss and Twitter for comment. By Marianna Spring, Disinformation and social media correspondent At its heart, this is a row over whether social media companies like Twitter should control what we're exposed to on their sites - and how transparent they are about how they do that. The 'Twitter Files' are challenging how the company made decisions about enforcing certain policies - and dealing with certain accounts. But, former employees I've spoken to are quick to point out that much of what they tell us is not new and that ultimately, how you interpret these 'Twitter Files' depends on where you stand on how social media sites should deal with misinformation and hate. We already know about Twitter's policies to tackle both of these issues, some of which involved suspending accounts as well as removing content. Twitter's curation teams, axed since Musk bought Twitter, were in charge of deciding which content could trend and what would be de-prioritised, including on issues like misinformation and discriminatory hate. After the pandemic, the riots at the Capitol in the US and the war in Ukraine, Twitter came under huge pressure to do more about these issues. What's new about the Twitter Files is detail on who was making the decisions - and specific accounts that have been targeted. Revealing internal conversations has sparked hate and backlash online directed at those caught up in this. And there are still unanswered questions about how other accounts have been affected, not just the select few listed. What makes one social media post pop up all over people's feeds and another disappear into obscurity? It's a question anyone trying to make a splash online would love the answer to. We know that tweets don't just appear in chronological order - your feed is being engineered in some way. And platforms tend to keep the full details of their algorithm - the code that determines which posts you see in what order - under their hats. Under an initiative by Twitter's new chief Elon Musk, fragments of internal Twitter discussions about content moderation - dubbed ""the Twitter Files"" - have been shared on the platform by a few selected journalists. The ongoing revelations contain internal chats of Twitter's inner circle of senior executives about a series of controversial decisions: limiting the dissemination of the Hunter Biden laptop story, the permanent suspension of Donald Trump in the wake of the 6 January 2021 Capitol riot, and limiting the reach of some influential accounts. Part two of the revelations, shared by US journalist Bari Weiss, who had been provided with screenshots by Twitter's new head of safety Ella Irwin, reveals three influential conservative accounts in the US were put on different ""blacklists"", meaning their tweets either wouldn't trend, might not appear in search, or would not be ""amplified"". Ms Weiss said decisions were made ""all in secret, without informing users"". Mr Musk went even further, saying the revelations proved ""the rules were enforced against the right, but not against the left"". But it's incredibly hard to verify whether this is giving us the whole picture. We are missing the context of which other accounts have faced similar treatment, and whether the restricted accounts were in breach of other rules, for example inciting hate or spreading false claims about Covid that could cause harm. Restricting accounts can be a useful tool if they are spreading harmful material. A common phrase when we talk about regulating the internet is ""freedom of speech not freedom of reach"" - it's one Mr Musk himself has used to describe the platform's new approach. Twitter, for instance, confirmed just a few days ago that it would not ""amplify tweets containing slurs or hate speech"". The idea of an account being placed on ""trends blacklists"" doesn't seem totally out of step with this policy. The more controversial part comes from who gets to decide what can and can't trend, where the threshold for a restriction lies and who ends up on the list. One name on the Twitter files list that has drawn attention is Dr Jay Bhattacharya - a health policy professor at Stanford University - who vocally opposed coronavirus lockdowns, and whose tweets were reportedly prevented from trending. He has been criticised, including by a judge in a US case about mask mandates in schools, who accused him of oversimplifying research studies, and by other scientists for proposing an alternative to lockdowns they said was unworkable and would lead to more deaths. But he has said science required people to disagree with each other, arguing against ""censorship of scientific discussion"". There have been various reports suggesting marginalised groups including trans and plus size people were more likely to have their accounts restricted. Multiple liberal and left-leaning individuals have also previously complained about their accounts and tweets being ""suppressed"". The difficulty is, people will have a hunch they are being restricted- the engagement with their posts suddenly falls or their followers report not seeing them anymore - but that could be down to many other reasons, and it's incredibly hard to prove that's what is happening without access to the companies' internal workings. Alex Stamos, director of the Stanford Internet Observatory and a former Facebook chief security officer, says Mr Musk is ""providing extremely limited transparency"" to like-minded US media figures. He proposed that Mr Musk should make available details of all communications around content moderation with governments, political parties and politicians around the world. Mr Musk says he intends to introduce a new feature that will enable all users to see ""your true account status"", including whether they've been ""shadowbanned"" (hidden from other people's feeds), the reason for it, and a process to appeal. Twitter isn't the only company moving in this direction- Instagram recently launched a new tool of its own to let you know if your posts are barred from being recommended to other users. While these changes add some degree of transparency to the process, content moderation decisions are incredibly difficult and messy, and remain open to political influence from owners, senior executives and pressure from politicians and activists. The BBC approached Ms Weiss and Twitter for comment. By Marianna Spring, Disinformation and social media correspondent At its heart, this is a row over whether social media companies like Twitter should control what we're exposed to on their sites - and how transparent they are about how they do that. The 'Twitter Files' are challenging how the company made decisions about enforcing certain policies - and dealing with certain accounts. But, former employees I've spoken to are quick to point out that much of what they tell us is not new and that ultimately, how you interpret these 'Twitter Files' depends on where you stand on how social media sites should deal with misinformation and hate. We already know about Twitter's policies to tackle both of these issues, some of which involved suspending accounts as well as removing content. Twitter's curation teams, axed since Musk bought Twitter, were in charge of deciding which content could trend and what would be de-prioritised, including on issues like misinformation and discriminatory hate. After the pandemic, the riots at the Capitol in the US and the war in Ukraine, Twitter came under huge pressure to do more about these issues. What's new about the Twitter Files is detail on who was making the decisions - and specific accounts that have been targeted. Revealing internal conversations has sparked hate and backlash online directed at those caught up in this. And there are still unanswered questions about how other accounts have been affected, not just the select few listed."
Twitter and Meta take down pro-US propaganda campaign,"Twitter and Meta have removed from their platforms an online propaganda campaign aimed at promoting US interests abroad, researchers say. This is the first major covert pro-US propaganda operation taken down by the tech giants, says a report by social media analytics firm Graphika and the Stanford Internet Observatory (SIO). They removed dozens of accounts used in the campaign in July and August. It is not clear who is behind the propaganda operation. The researchers say Twitter has identified the US and the UK as the ""presumptive countries of origin"", while Meta, which owns Facebook and Instagram, said the US was ""the country of origin"". However, the researchers were clear that even though the companies named these countries, it did not prove they were behind the campaign. ""We do not have the necessary information to attribute this activity to a single country or organisation,"" the SIO told the BBC. ""What is clear, is that the activity is meant to further Western interests, including those of the US and allies."" The BBC has approached the US State Department, the UK government, Twitter and Meta for comment. The suspended accounts, some of which were set up almost five years ago, were targeting audiences in the Middle East and Central Asia in multiple languages, according to Graphika and the SIO. The accounts promoted narratives in support of the US and its allies, while opposing countries like Russia, China and Iran, the researchers said. They found the campaign mirrored some of the tactics commonly used in propaganda campaigns against the West. These include creating fake personas using artificially generated images and running campaigns across multiple platforms. The researchers also found that in addition to Twitter and Meta-owned platforms, the suspended accounts were also active on a number of other social media websites globally. Similar to previously exposed online propaganda campaigns targeting the West, some of the fake accounts in the pro-US campaign posed as independent media outlets. In some cases, they attempted to pass off material taken from legitimate outlets, like BBC News Russian, as their own. The researchers also found that the accounts tailored their messaging depending on the region. For example, in one campaign targeting Central Asia, accounts focused on praising US aid to the region and criticising Russia for engaging in ""imperialist wars"" in Africa and Syria, and for the deaths of civilians in Ukraine. In contrast, some of the accounts targeting Iran criticised Iranian authorities and their policies and posted about issues like women's rights. Yet, the overall effectiveness of the campaign was limited, said Graphika's Jack Stubbs. The vast majority of posts and tweets reviewed ""received no more than a handful of likes or retweets"". This shows ""the limitations of using these inauthentic tactics"", he added. Andy Carvin, managing editor at US think tank the Atlantic Council's Digital Forensic Research Lab, said it would be ""ineffective and counterproductive"" for democracies to undertake such campaigns. This is because it meant using ""the very tactics used by your adversaries"" and ""further eroding public trust"", he added."
Twitter and hate speech: What's the evidence?,"Among the topics discussed during Elon Musk's interview with the BBC was the prevalence of hate speech and misinformation on the platform. ""Do you see a rise of hate speech?"" Mr Musk said. ""I don't."" He asked our reporter James Clayton for specific examples of hateful content. When he couldn't pinpoint individual messages, Mr Musk said: ""You don't know what you're talking aboutÂ you just lied."" It's prompted intense criticism on Twitter itself, mostly - but certainly not exclusively - from right-wing and far-right accounts. But there are both in-depth studies and anecdotal evidence that suggest hate speech has been growing under Mr Musk's tenure. Several fringe characters that were banned under the previous management have been reinstated. They include Andrew Anglin, founder of the neo-Nazi Daily Stormer website, and Liz Crokin, one of the biggest propagators of the QAnon conspiracy theory. Other lesser-known Twitter users have taken advantage of the new ownership. One account with a racial slur in its user name was able to get a blue checkmark. Another one was purchased by a neo-Nazi who tweets videos of himself reciting Mein Kampf - Hitler's autobiography. Anti-Semitic tweets doubled from June 2022 to February 2023, according to research from the Institute of Strategic Dialogue (ISD). The same study found that takedowns of such content also increased, but not enough to keep pace with the surge. The ISD also found an increase of nearly 70% in Islamic State accounts - a problem that was once huge on Twitter, but had been reduced to a trickle by account bans. The Center for Countering Digital Hate, a London-based campaign group, found that slurs increased substantially after Mr Musk's takeover. Our own reporting also provides some clues. The BBC analysed over 1,100 previously banned Twitter accounts that were reinstated under Mr Musk. A third appeared to violate Twitter's own guidelines. Some of the most extreme depicted rape and drawings showing child sexual abuse. Such content was also a scourge on Twitter for years before Mr Musk acquired the platform. But a BBC investigation heard from Twitter insiders who expressed concern that the company is no longer able to protect users from trolling, state-co-ordinated disinformation and child sexual exploitation. A few issues cloud the matter. One is that there is no blanket definition of hate speech under American law, which is generally much more permissive than other countries because of the First Amendment to the US Constitution. This, after all, is a country where in 1978 civil rights lawyers sued to defend the right of a neo-Nazi group to march through the Chicago suburb of Skokie, where many Holocaust survivors lived. Mr Musk's free-speech views - which are mainstream in the United States - may have encouraged people who were worried about a ban to speak more freely. In other words, we don't know if the spike identified by researchers will last. There is clearly still moderation happening on Twitter, and Mr Musk himself has robustly pushed back on the studies and investigations. He's argued that he has taken a politically neutral line - that not only right-wing accounts have been reinstated, but some left-wing accounts that were previously banned as well. ""This is not a right-wing takeover, but rather a centrist takeover,"" he tweeted. And, he argues, his strategy is working. In December, he tweeted that hate speech was down by a third. Researchers and journalists have focused on the most extreme content - not mere jokes or insults, but highly abusive language. Critics have pointed out, however, that Mr Musk's own definition of hate speech isn't clear. And he recently ended free access to Twitter's application programming interface or API - data that researchers use to study the platform. Without such data it will be hard to objectively study the issue going forward. Mr Musk has previously said he boosted transparency by making Twitter's algorithm open-source. Mr Musk said his efforts to delete bots - automated accounts - has decreased misinformation on Twitter since his takeover. And he cited the site's community notes feature, where users themselves can comment and add context to tweets. ""My experience is there is less misinformation rather than more,"" he told our reporter. Some outside experts disagree. An early study from NewsGuard, a company that tracks online misinformation, found that engagement with popular, misinformation-spreading accounts spiked after Mr Musk's takeover. In the week following his acquisition of Twitter, the most popular, untrustworthy accounts enjoyed an almost 60% increase in engagement in the form of likes and retweets, according to the survey. Science Feedback, another fact-checker, found that misinformation ""super spreaders"" - defined as accounts that consistently publish popular tweets containing links to known misinformation - have markedly increased engagement since Mr Musk's takeover. Both organisations have been attacked by Musk's supporters, as online fact-checking has become another arena fractured along political lines. The BBC's own analysis found false anti-vax claims and the denial of the 2020 US election result among the sample of more than 1,000 reinstated accounts. Mr Musk says that he's on the side of truth and believes that his strategy will make Twitter better in the long run. ""The acid test is people use the system and find it to be a good source of truth, or they don't,"" Mr Musk told our reporter. ""And no system is going to perfect in its pursuit of the truth, but I think we can be the best, the least inaccurate."" Mr Musk said he prefers ""ordinary people"" to information from journalists, at several points challenging the BBC's technology correspondent with questions of his own. But Mr Musk himself was not fully accurate when describing the BBC's reporting. At one point he claimed that the BBC had not reported on Covid vaccine side effects. But the BBC has reported on proven, very rare side effects when they emerged, and examples can be found online - for instance here, here and here. Update 5 June 2023: This article has been amended to remove a description of where two fact-checking organisations sit on the political spectrum, and to instead explain that online fact-checking is frequently the subject of political contention. Among the topics discussed during Elon Musk's interview with the BBC was the prevalence of hate speech and misinformation on the platform. ""Do you see a rise of hate speech?"" Mr Musk said. ""I don't."" He asked our reporter James Clayton for specific examples of hateful content. When he couldn't pinpoint individual messages, Mr Musk said: ""You don't know what you're talking aboutÂ you just lied."" It's prompted intense criticism on Twitter itself, mostly - but certainly not exclusively - from right-wing and far-right accounts. But there are both in-depth studies and anecdotal evidence that suggest hate speech has been growing under Mr Musk's tenure. Several fringe characters that were banned under the previous management have been reinstated. They include Andrew Anglin, founder of the neo-Nazi Daily Stormer website, and Liz Crokin, one of the biggest propagators of the QAnon conspiracy theory. Other lesser-known Twitter users have taken advantage of the new ownership. One account with a racial slur in its user name was able to get a blue checkmark. Another one was purchased by a neo-Nazi who tweets videos of himself reciting Mein Kampf - Hitler's autobiography. Anti-Semitic tweets doubled from June 2022 to February 2023, according to research from the Institute of Strategic Dialogue (ISD). The same study found that takedowns of such content also increased, but not enough to keep pace with the surge. The ISD also found an increase of nearly 70% in Islamic State accounts - a problem that was once huge on Twitter, but had been reduced to a trickle by account bans. The Center for Countering Digital Hate, a London-based campaign group, found that slurs increased substantially after Mr Musk's takeover. Our own reporting also provides some clues. The BBC analysed over 1,100 previously banned Twitter accounts that were reinstated under Mr Musk. A third appeared to violate Twitter's own guidelines. Some of the most extreme depicted rape and drawings showing child sexual abuse. Such content was also a scourge on Twitter for years before Mr Musk acquired the platform. But a BBC investigation heard from Twitter insiders who expressed concern that the company is no longer able to protect users from trolling, state-co-ordinated disinformation and child sexual exploitation. A few issues cloud the matter. One is that there is no blanket definition of hate speech under American law, which is generally much more permissive than other countries because of the First Amendment to the US Constitution. This, after all, is a country where in 1978 civil rights lawyers sued to defend the right of a neo-Nazi group to march through the Chicago suburb of Skokie, where many Holocaust survivors lived. Mr Musk's free-speech views - which are mainstream in the United States - may have encouraged people who were worried about a ban to speak more freely. In other words, we don't know if the spike identified by researchers will last. There is clearly still moderation happening on Twitter, and Mr Musk himself has robustly pushed back on the studies and investigations. He's argued that he has taken a politically neutral line - that not only right-wing accounts have been reinstated, but some left-wing accounts that were previously banned as well. ""This is not a right-wing takeover, but rather a centrist takeover,"" he tweeted. And, he argues, his strategy is working. In December, he tweeted that hate speech was down by a third. Researchers and journalists have focused on the most extreme content - not mere jokes or insults, but highly abusive language. Critics have pointed out, however, that Mr Musk's own definition of hate speech isn't clear. And he recently ended free access to Twitter's application programming interface or API - data that researchers use to study the platform. Without such data it will be hard to objectively study the issue going forward. Mr Musk has previously said he boosted transparency by making Twitter's algorithm open-source. Mr Musk said his efforts to delete bots - automated accounts - has decreased misinformation on Twitter since his takeover. And he cited the site's community notes feature, where users themselves can comment and add context to tweets. ""My experience is there is less misinformation rather than more,"" he told our reporter. Some outside experts disagree. An early study from NewsGuard, a company that tracks online misinformation, found that engagement with popular, misinformation-spreading accounts spiked after Mr Musk's takeover. In the week following his acquisition of Twitter, the most popular, untrustworthy accounts enjoyed an almost 60% increase in engagement in the form of likes and retweets, according to the survey. Science Feedback, another fact-checker, found that misinformation ""super spreaders"" - defined as accounts that consistently publish popular tweets containing links to known misinformation - have markedly increased engagement since Mr Musk's takeover. Both organisations have been attacked by Musk's supporters, as online fact-checking has become another arena fractured along political lines. The BBC's own analysis found false anti-vax claims and the denial of the 2020 US election result among the sample of more than 1,000 reinstated accounts. Mr Musk says that he's on the side of truth and believes that his strategy will make Twitter better in the long run. ""The acid test is people use the system and find it to be a good source of truth, or they don't,"" Mr Musk told our reporter. ""And no system is going to perfect in its pursuit of the truth, but I think we can be the best, the least inaccurate."" Mr Musk said he prefers ""ordinary people"" to information from journalists, at several points challenging the BBC's technology correspondent with questions of his own. But Mr Musk himself was not fully accurate when describing the BBC's reporting. At one point he claimed that the BBC had not reported on Covid vaccine side effects. But the BBC has reported on proven, very rare side effects when they emerged, and examples can be found online - for instance here, here and here. Update 5 June 2023: This article has been amended to remove a description of where two fact-checking organisations sit on the political spectrum, and to instead explain that online fact-checking is frequently the subject of political contention."
Twitter blocks Russian claims on hospital attack,"Twitter has removed two posts by the Russian embassy in London which claimed the bombing of a Ukrainian hospital by Russian forces had been faked. The Mariupol hospital was attacked on Wednesday, leaving three people dead. But the embassy's tweets made unfounded claims the hospital was not operational at the time, and that injured women pictured at the scene were actors. Twitter told the BBC the tweets violated rules ""related to the denial of violent events"". Officials at the embassy have offered no proof to back up their claims, and the BBC's disinformation team has found evidence which contradicts the allegations. The embassy claimed the hospital had been ""long non-operational"". However, a week-old post on the hospital's Facebook page asked for fuel to keep operations going. Reports from Mariupol last week - from the Associated Press news agency and Sky News - also says it was treating bombing victims, and that the maternity ward had been moved to the basement. The allegation that a beauty blogger was used to fake photos of a pregnant woman at the scene was also called into question, as the woman in question, who lives in the city, is seen heavily pregnant in Instagram posts dating from last month. The initial claims that the bombing was faked by Ukraine did not come from the embassy. They first began trending among Russian users of the Telegram messaging app earlier in the day, and were then mentioned on state television news bulletins and chat shows. A further claim circulating that the beauty blogger also pretended to be another woman caught up in the bombing and photographed at the scene is also untrue. A look at high-resolution images of the other woman featured in the claims shows she looks nothing like the beauty blogger. Those are two different women. Finally there were accusations that the hospital had been taken over by a far-right battalion of the Ukrainian army. As yet there is no evidence that this was the case. These claims all continue to circulate online, despite the tweets being removed. The pregnant beauty blogger's Instagram account has also now become a target for online trolls and conspiracy theorists. Social media companies have been trying to tackle misinformation on their platforms, with many big tech companies blocking Russian broadcasters RT and Sputnik. But Twitter has not banned several accounts linked to Russian government organisations - including Vladimir Putin's official Twitter account. The Russian embassy account also remains active."
Twitter chaos after wave of blue tick impersonations,"A wave of new paid blue tick accounts impersonating influential individuals and brands has led to chaos and confusion on Twitter. Fake ""verified"" accounts in the names of politicians, celebrities, major organisations and businesses started appearing on the platform on Thursday. Twitter suspended many of them, but the company's rapidly changing attempts to address the issue added to the confusion. Experts had previously warned that the new Twitter Blue subscription service announced by new chief Elon Musk, which allows users to pay Â£6.99 ($7.99) per month for a blue tick, would be immediately exploited by bad actors and scammers, and erode trust in the platform. The extent of the problem with new fake blue tick accounts was laid bare after the feature launched on Wednesday. Blue tick versions of major brand accounts such as Apple, Nintendo, BP and Chiquita were suspended. Fake accounts posing as high-profile individuals like Meta chief Mark Zuckerberg, current and former US Presidents Joe Biden, Donald Trump and George W Bush, and former UK Prime Minister Tony Blair were also removed. In one case, an account in the name of Republican candidate for Arizona governor Kari Lake tweeted to announce she was conceding to her Democratic opponent, despite the fact votes are still being counted in the tight race. It took hours for Twitter to remove the tweet and the fake account. A fake Tesla account, another company owned by Mr Musk, joked about 9/11, while Mr Musk himself was impersonated. One of the most disruptive accounts impersonated US pharmaceutical company Eli Lilly, and declared ""insulin is free now"". The company had to distance itself from the fake announcement. The paid blue tick system is also being exploited by conspiracy theorists and far-right activists. The BBC has seen at least three well-known QAnon influencer accounts which have purchased blue ticks on Twitter. Far-right activists Jason Kessler and Richard Spencer, who organised the 2017 Unite the Right rally in Charlottesville, have both purchased blue ticks. Twitter had previously removed verification badges from the accounts of Mr Kessler and Mr Spencer after the violent rally five years ago. Researchers also spotted a variety of accounts with purchased blue ticks using AI generated images of fake personalities. This is a specific area of concern as such inauthentic accounts are routinely used in influence operations, at times by foreign states with the aim of influencing political events in other countries. Twitter suspended many of the imposter blue tick accounts, but at times struggled to keep up with the pace of new ones appearing. New grey ""official"" badges were added under the handles of some high-profile accounts, before being scrapped by Mr Musk almost immediately. However, on Friday new grey official badges began reappearing on some Twitter profiles. And some users based in the US reported the Twitter Blue subscription system was no longer available to them. Mr Musk himself initially said blue tick parody accounts of high-profile users would have to clarify that they are not genuine in their profile bios. Later he declared the word parody would also need to be included in account names, adding that ""tricking people is not ok"". As of now, it is still unclear how Mr Musk and his newly acquired platform plan to address the issue of blue tick impersonations in the long run. While the issue of verified accounts temporarily changing their names in ways which might mislead had previously surfaced on the platform, such attempts were extremely rare. Experts worry that the harm caused by a lack of trust in Twitter's verification system could come to the fore during events such as mass shootings, terrorist attacks or natural disasters, where Twitter is often used by local authorities, police, emergency services and journalists for accurate information and advice. The BBC reached to Twitter for comment, but received no response. By Marianna Spring, Disinformation and social media correspondent A lot of the parody accounts springing up on Twitter right now might seem quite funny. But it's important to remember that when people don't know who and what to believe, it can pose serious risks. Throughout the pandemic, recent conflicts and elections - we're reminded time and time again of the real-world harm that online mistruths can have. Now, bad actors can use blue ticks to give the disinformation they promote an air of legitimacy - or to confuse users. Blue ticks had become a handy tool to identify official accounts, so its unsurprising that - at least at first - this is causing chaos. Not least because it's happening at the same time as other chaotic changes. Now that blue ticks may be rendered meaningless, users will instead have to rely on other tools to see if an account is really who they say they are. Check out their other tweets, look at their followers - and search off Twitter or via official websites to follow links to genuine social media profiles. Before, it felt like social media sites had woken up to the impact disinformation can have offline - and were at least starting to get to grips with it. This, though, feels like a step backwards - and there are fears there could be more. A wave of new paid blue tick accounts impersonating influential individuals and brands has led to chaos and confusion on Twitter. Fake ""verified"" accounts in the names of politicians, celebrities, major organisations and businesses started appearing on the platform on Thursday. Twitter suspended many of them, but the company's rapidly changing attempts to address the issue added to the confusion. Experts had previously warned that the new Twitter Blue subscription service announced by new chief Elon Musk, which allows users to pay Â£6.99 ($7.99) per month for a blue tick, would be immediately exploited by bad actors and scammers, and erode trust in the platform. The extent of the problem with new fake blue tick accounts was laid bare after the feature launched on Wednesday. Blue tick versions of major brand accounts such as Apple, Nintendo, BP and Chiquita were suspended. Fake accounts posing as high-profile individuals like Meta chief Mark Zuckerberg, current and former US Presidents Joe Biden, Donald Trump and George W Bush, and former UK Prime Minister Tony Blair were also removed. In one case, an account in the name of Republican candidate for Arizona governor Kari Lake tweeted to announce she was conceding to her Democratic opponent, despite the fact votes are still being counted in the tight race. It took hours for Twitter to remove the tweet and the fake account. A fake Tesla account, another company owned by Mr Musk, joked about 9/11, while Mr Musk himself was impersonated. One of the most disruptive accounts impersonated US pharmaceutical company Eli Lilly, and declared ""insulin is free now"". The company had to distance itself from the fake announcement. The paid blue tick system is also being exploited by conspiracy theorists and far-right activists. The BBC has seen at least three well-known QAnon influencer accounts which have purchased blue ticks on Twitter. Far-right activists Jason Kessler and Richard Spencer, who organised the 2017 Unite the Right rally in Charlottesville, have both purchased blue ticks. Twitter had previously removed verification badges from the accounts of Mr Kessler and Mr Spencer after the violent rally five years ago. Researchers also spotted a variety of accounts with purchased blue ticks using AI generated images of fake personalities. This is a specific area of concern as such inauthentic accounts are routinely used in influence operations, at times by foreign states with the aim of influencing political events in other countries. Twitter suspended many of the imposter blue tick accounts, but at times struggled to keep up with the pace of new ones appearing. New grey ""official"" badges were added under the handles of some high-profile accounts, before being scrapped by Mr Musk almost immediately. However, on Friday new grey official badges began reappearing on some Twitter profiles. And some users based in the US reported the Twitter Blue subscription system was no longer available to them. Mr Musk himself initially said blue tick parody accounts of high-profile users would have to clarify that they are not genuine in their profile bios. Later he declared the word parody would also need to be included in account names, adding that ""tricking people is not ok"". As of now, it is still unclear how Mr Musk and his newly acquired platform plan to address the issue of blue tick impersonations in the long run. While the issue of verified accounts temporarily changing their names in ways which might mislead had previously surfaced on the platform, such attempts were extremely rare. Experts worry that the harm caused by a lack of trust in Twitter's verification system could come to the fore during events such as mass shootings, terrorist attacks or natural disasters, where Twitter is often used by local authorities, police, emergency services and journalists for accurate information and advice. The BBC reached to Twitter for comment, but received no response. By Marianna Spring, Disinformation and social media correspondent A lot of the parody accounts springing up on Twitter right now might seem quite funny. But it's important to remember that when people don't know who and what to believe, it can pose serious risks. Throughout the pandemic, recent conflicts and elections - we're reminded time and time again of the real-world harm that online mistruths can have. Now, bad actors can use blue ticks to give the disinformation they promote an air of legitimacy - or to confuse users. Blue ticks had become a handy tool to identify official accounts, so its unsurprising that - at least at first - this is causing chaos. Not least because it's happening at the same time as other chaotic changes. Now that blue ticks may be rendered meaningless, users will instead have to rely on other tools to see if an account is really who they say they are. Check out their other tweets, look at their followers - and search off Twitter or via official websites to follow links to genuine social media profiles. Before, it felt like social media sites had woken up to the impact disinformation can have offline - and were at least starting to get to grips with it. This, though, feels like a step backwards - and there are fears there could be more."
Twitter ends Covid misinformation policy under Musk,"Twitter says it has stopped enforcing its policy on misleading information about coronavirus. According to the company's website, it stopped taking action against tweets breaching its Covid rules, on Wednesday, 23 November. Twitter had previously reported suspending more than 11,000 accounts for Covid misinformation as of September this year. BBC News has approached Twitter for comment. Its other policies on false information remain on Twitter's website, without a similar notice saying they will no longer be enforced. Under its Covid-specific policy, Twitter operated a ""five-strike system"" for accounts posting ""demonstrably false or misleading"" content that may ""lead to significant risk of harm"" - such as exposure to Covid or damage to public health systems. No action would be taken against accounts tweeting disinformation once. But repeat offenders could be suspended for a matter of hours, days - or even indefinitely, if they received five strikes against their account. Though he says the Covid reporting system on Twitter was never perfect, Dr Stephen Griffin of The University of Leeds School of Medicine says it was reassuring to know that many thousands of accounts spreading disinformation had been removed since 2020. Now, some of those who fell foul of the rules are returning to the website. For example, Twitter has reinstated the personal account of US congresswoman Marjorie Taylor Greene, banned in January. Millions of users voted for the reinstatement of suspended accounts in a Twitter poll, causing boss Elon Musk to tweet: ""The people have spoken... amnesty begins next week."" The Tesla chief executive has vowed to make Twitter a hub for free speech online following his $44bn (Â£37bn) purchase. Analysis by Rachel Schraer, BBC health and disinformation reporter Criticisms the platform has been slow to act on false or unproven health claims are nothing new. Even when Twitter did introduce an option to report misleading posts in the summer of 2021 - something it now seems to be rowing back on - I heard from dozens of people who said the process was unclear and the option didn't always seem to be available. But the site did seem to be trying to get a grip on some of its most potentially harmful posts, removing more than 10,000 accounts - like Dr Robert Malone, whose message Covid vaccines are ineffective or very dangerous is contradicted by the overwhelming weight of evidence. Now the direction at Twitter HQ is changing, the question is whether these accounts will return or new ones will be emboldened to share incorrect information, that could influence the decisions people make about their health. Twitter says it has stopped enforcing its policy on misleading information about coronavirus. According to the company's website, it stopped taking action against tweets breaching its Covid rules, on Wednesday, 23 November. Twitter had previously reported suspending more than 11,000 accounts for Covid misinformation as of September this year. BBC News has approached Twitter for comment. Its other policies on false information remain on Twitter's website, without a similar notice saying they will no longer be enforced. Under its Covid-specific policy, Twitter operated a ""five-strike system"" for accounts posting ""demonstrably false or misleading"" content that may ""lead to significant risk of harm"" - such as exposure to Covid or damage to public health systems. No action would be taken against accounts tweeting disinformation once. But repeat offenders could be suspended for a matter of hours, days - or even indefinitely, if they received five strikes against their account. Though he says the Covid reporting system on Twitter was never perfect, Dr Stephen Griffin of The University of Leeds School of Medicine says it was reassuring to know that many thousands of accounts spreading disinformation had been removed since 2020. Now, some of those who fell foul of the rules are returning to the website. For example, Twitter has reinstated the personal account of US congresswoman Marjorie Taylor Greene, banned in January. Millions of users voted for the reinstatement of suspended accounts in a Twitter poll, causing boss Elon Musk to tweet: ""The people have spoken... amnesty begins next week."" The Tesla chief executive has vowed to make Twitter a hub for free speech online following his $44bn (Â£37bn) purchase. Analysis by Rachel Schraer, BBC health and disinformation reporter Criticisms the platform has been slow to act on false or unproven health claims are nothing new. Even when Twitter did introduce an option to report misleading posts in the summer of 2021 - something it now seems to be rowing back on - I heard from dozens of people who said the process was unclear and the option didn't always seem to be available. But the site did seem to be trying to get a grip on some of its most potentially harmful posts, removing more than 10,000 accounts - like Dr Robert Malone, whose message Covid vaccines are ineffective or very dangerous is contradicted by the overwhelming weight of evidence. Now the direction at Twitter HQ is changing, the question is whether these accounts will return or new ones will be emboldened to share incorrect information, that could influence the decisions people make about their health."
Twitter pilot to let users flag 'false' content,"Twitter is asking its users for help in combating fake news. It has announced a pilot that allows people to submit notes on tweets that may be false or misleading. The initiative, named 'Birdwatch', is being trialled among a small group in the US initially. The firm acknowledged the new system would have to be ""resistant to manipulation attempts"". Companies like Twitter are looking at how they can better moderate their platforms. Twitter said on Monday: ""We know this might be messy and have problems at times, but we believe this is a model worth trying."" Twitter, along with other large social media companies, has struggled to deal with disinformation on its platform. The pilot will allow users to flag tweets they believe to be ""misleading or false"", provide evidence to the contrary and discuss them with other - on a separate 'Birdwatch' site. Additional notes and flags would then be placed on to content. Twitter says this new approach could help it respond more quickly when misleading information spreads. ""Eventually we aim to make notes visible directly on Tweets for the global Twitter audience, when there is consensus from a broad and diverse set of contributors,"" Twitter said. Twitter already adds labels to some misleading news. For example, many of Donald Trump's false claims of voter fraud were labelled by the company. Twitter also reserves the right to remove tweets - and in extreme circumstances ban users - which it did with the US president after the riots in Washington earlier this month. Twitter, though, wants to go further: ""We don't want to limit efforts to circumstances where something breaks our rules or receives widespread public attention,"" said Twitter's Vice-President Keith Coleman. Participants will have to provide a verified phone number and email to take part, in a bid to keep bots and bad actors away, as well as having no recent rule violations against their Twitter account. President Biden said in his inauguration speech that: ""We must reject a culture where facts are manipulated, or even manufactured."" James Clayton is the BBC's North America technology reporter based in San Francisco. Follow him on Twitter @jamesclayton5."
Twitter staff cuts leave Russian trolls unchecked,"Hundreds of Russian and Chinese state propaganda accounts are thriving on Twitter after Elon Musk wiped out the team that fought these networks, the BBC has found. The unit worked to combat ""information operations"", coordinated campaigns by countries such as Russia, China, and Iran, made to influence public opinion and disrupt democracy. But experts and former employees say the majority of these specialists resigned or were laid off, leaving the platform vulnerable to foreign manipulation. The BBC has spoken to several of them. They asked for anonymity, citing non-disclosure agreements and threats they received online. ""The whole human layer has been wiped out. All Twitter has left are automated detections systems,"" a former senior employee said. In a BBC interview on Tuesday, Musk claimed there was ""less misinformation [on Twitter] rather than more"" under his tenure. He did not comment on active state troll farms on the platform nor the team that used to fight them. We approached Twitter for comment but received no response other than a poo emoji - the standard auto-reply from the company to any press enquiry. Organised groups of people posting coordinated messages are called 'troll farms.' The term was first used by Russian reporters who exposed one of roughly 300 paid employees run by Yevgeny Prigozhin, head of the Wagner mercenary group. Since then, troll farms influencing elections and public opinion have been uncovered in many countries, from Poland and Turkey to Brazil and Mexico. They have also been used as a propaganda tool in ethnic conflicts and wars. Now, a new group of Russian trolls is active on Twitter. It supports Putin's war in Ukraine, ridicules Kyiv and the West, and attacks independent Russian-language publications, including the BBC Russian Service. Many of these trolls' accounts have been suspended, but dozens are still active. Darren Linvill, associate professor at the Clemson University Media Forensics Hub in South Carolina, says the network appears to originate from Prigozhin's troll factory. Mr Linvill and his colleagues have also discovered two similar Russian-language troll networks, but from an opposite camp. One tweets in support of Ukraine, and another promotes Russian opposition, including the jailed Putin critic Alexey Navalny. While they have all the markings of troll accounts, including random numbers in the Twitter handles and coordinated behaviour, these networks appear to remain undetected by the platform. The Clemson University team is also tracking pro-Chinese accounts targeting users in both Chinese and English about issues of importance to the Chinese government. With only a skeleton crew remaining, Twitter does not have resources to swiftly detect, attribute and take down this foreign propaganda, according to former employees. While the platform also established partnerships with research institutions that detected information operations, scholars say they have not heard anything from Twitter since November. Experts have long warned about the dangers of foreign influence on social media. In 2018, the FBI said that fake accounts impersonating real Americans had played a central role in the Russian effort to meddle in the 2016 election. That was when Twitter and Facebook started hiring ""information operations"" specialists. ""I still remember the rage I felt when I saw accounts with names like ""Pamela Moore"" and ""Crystal Johnson"" purporting to be real Americans from Wisconsin and New York, but with phone numbers tracing back to St Petersburg, Russia,"" recalls Yoel Roth, Twitter's former Trust and Safety head. Twitter has a fraction of Facebook's reach and budget. But over the years, it built a small but capable team. While it could not match the resources of its rival social network, Twitter ""nonetheless punched above its weight"", says Lee Foster, an independent expert in information operations. Twitter hired people with backgrounds in cybersecurity, journalism, government agencies and NGOs who spoke an array of languages including Russian, Farsi, Mandarin, Cantonese, Spanish and Portuguese. One former investigator says: ""We needed people who would be able to understand: if Russia is likely to be the responsible actor behind this, what is its motivation to do this particular operation?"" He says he resigned because his team did not fit into 'Twitter 2.0' that Musk was building. ""Our role was to help make the use of Twitter as safe as possible. And it did not feel like that was likely to continue as a priority."" The team worked in close contact, but separately from the ones countering misinformation. That is because state-run campaigns can use both fake news and factual stories to promote their messages. In 2016, Russian trolls targeted black voters in the US using real footage showing police violence. And in 2022, a coordinated network promoted negative - but sometimes accurate - news about the French contingent and United Nations missions in Africa's Sahel region. Both networks were taken down by Twitter. As similar information operations were conducted on different platforms, Twitter employees met with their peers at Meta and other companies to exchange information. But at such meetings, Twitter's investigators would be reminded of how small their operation was. ""Their team would be ten times the size of ours,"" says an investigator. Now even those resources are lacking. Without the team dedicated to fight coordinated campaigns, Twitter ""will slowly become more and more unsafe,"" says Linvill of Clemson University. With additional reporting from Hannah Gelbart. Hundreds of Russian and Chinese state propaganda accounts are thriving on Twitter after Elon Musk wiped out the team that fought these networks, the BBC has found. The unit worked to combat ""information operations"", coordinated campaigns by countries such as Russia, China, and Iran, made to influence public opinion and disrupt democracy. But experts and former employees say the majority of these specialists resigned or were laid off, leaving the platform vulnerable to foreign manipulation. The BBC has spoken to several of them. They asked for anonymity, citing non-disclosure agreements and threats they received online. ""The whole human layer has been wiped out. All Twitter has left are automated detections systems,"" a former senior employee said. In a BBC interview on Tuesday, Musk claimed there was ""less misinformation [on Twitter] rather than more"" under his tenure. He did not comment on active state troll farms on the platform nor the team that used to fight them. We approached Twitter for comment but received no response other than a poo emoji - the standard auto-reply from the company to any press enquiry. Organised groups of people posting coordinated messages are called 'troll farms.' The term was first used by Russian reporters who exposed one of roughly 300 paid employees run by Yevgeny Prigozhin, head of the Wagner mercenary group. Since then, troll farms influencing elections and public opinion have been uncovered in many countries, from Poland and Turkey to Brazil and Mexico. They have also been used as a propaganda tool in ethnic conflicts and wars. Now, a new group of Russian trolls is active on Twitter. It supports Putin's war in Ukraine, ridicules Kyiv and the West, and attacks independent Russian-language publications, including the BBC Russian Service. Many of these trolls' accounts have been suspended, but dozens are still active. Darren Linvill, associate professor at the Clemson University Media Forensics Hub in South Carolina, says the network appears to originate from Prigozhin's troll factory. Mr Linvill and his colleagues have also discovered two similar Russian-language troll networks, but from an opposite camp. One tweets in support of Ukraine, and another promotes Russian opposition, including the jailed Putin critic Alexey Navalny. While they have all the markings of troll accounts, including random numbers in the Twitter handles and coordinated behaviour, these networks appear to remain undetected by the platform. The Clemson University team is also tracking pro-Chinese accounts targeting users in both Chinese and English about issues of importance to the Chinese government. With only a skeleton crew remaining, Twitter does not have resources to swiftly detect, attribute and take down this foreign propaganda, according to former employees. While the platform also established partnerships with research institutions that detected information operations, scholars say they have not heard anything from Twitter since November. Experts have long warned about the dangers of foreign influence on social media. In 2018, the FBI said that fake accounts impersonating real Americans had played a central role in the Russian effort to meddle in the 2016 election. That was when Twitter and Facebook started hiring ""information operations"" specialists. ""I still remember the rage I felt when I saw accounts with names like ""Pamela Moore"" and ""Crystal Johnson"" purporting to be real Americans from Wisconsin and New York, but with phone numbers tracing back to St Petersburg, Russia,"" recalls Yoel Roth, Twitter's former Trust and Safety head. Twitter has a fraction of Facebook's reach and budget. But over the years, it built a small but capable team. While it could not match the resources of its rival social network, Twitter ""nonetheless punched above its weight"", says Lee Foster, an independent expert in information operations. Twitter hired people with backgrounds in cybersecurity, journalism, government agencies and NGOs who spoke an array of languages including Russian, Farsi, Mandarin, Cantonese, Spanish and Portuguese. One former investigator says: ""We needed people who would be able to understand: if Russia is likely to be the responsible actor behind this, what is its motivation to do this particular operation?"" He says he resigned because his team did not fit into 'Twitter 2.0' that Musk was building. ""Our role was to help make the use of Twitter as safe as possible. And it did not feel like that was likely to continue as a priority."" The team worked in close contact, but separately from the ones countering misinformation. That is because state-run campaigns can use both fake news and factual stories to promote their messages. In 2016, Russian trolls targeted black voters in the US using real footage showing police violence. And in 2022, a coordinated network promoted negative - but sometimes accurate - news about the French contingent and United Nations missions in Africa's Sahel region. Both networks were taken down by Twitter. As similar information operations were conducted on different platforms, Twitter employees met with their peers at Meta and other companies to exchange information. But at such meetings, Twitter's investigators would be reminded of how small their operation was. ""Their team would be ten times the size of ours,"" says an investigator. Now even those resources are lacking. Without the team dedicated to fight coordinated campaigns, Twitter ""will slowly become more and more unsafe,"" says Linvill of Clemson University. With additional reporting from Hannah Gelbart."
"Twitter suspends 70,000 accounts linked to QAnon","Twitter has suspended more than 70,000 accounts linked to the far-right movement QAnon. QAnon is a conspiracy claiming that President Donald Trump is waging a war against Satan-worshipping paedophiles in politics, business and the media. Supporters were involved in the storming of the US Congress building last week. Twitter has deleted accounts that Âshare harmful QAnon-associated content at scaleÂ. ÂWeÂve been clear that we will take strong enforcement action on behaviour that has the potential to lead to offline harm,Â Twitter said in a blog post. ÂGiven the violent events in Washington, DC, and increased risk of harm, we began permanently suspending thousands of accounts that were primarily dedicated to sharing QAnon content on Friday afternoon.Â Twitter said there were Âmany instances of a single individual operating numerous accounts"". The accounts were primarily dedicated to the propagation of this conspiracy theory across the service, it added. President Trump - viewed as a hero by the movement - has stopped short of endorsing the conspiracy theory but has described QAnon activists as ""people who love our country"". In July last year, Twitter said it would crack down on QAnon accounts on the platform, stop recommending associated content and block URLs linked to it from being shared on the platform. In 2019, the FBI issued a warning about ""conspiracy theory-driven domestic extremists"" and designated QAnon a potential domestic extremist threat. Analysis by Shayan Sardarizadeh, BBC Monitoring Twitter was one of the first major social networks to impose restrictions on QAnon-linked accounts and content back in the summer of 2020. But after Facebook and YouTube took sweeping action against the conspiracy in October, Twitter became the only mainstream platform still available to QAnon promoters. BBC research shows QAnon-related phrases and hashtags were used more than 20 million times on Twitter between January and September 2020. In the lead-up to the Capitol riots, major QAnon influencers repeatedly called on their followers to attend the rally in Washington DC and made violent statements about Vice-President Mike Pence and other senior members of Congress who refused to overturn the outcome of the election. While thousands of QAnon-related accounts are still active on the platform, the vast majority of the conspiracy's main influencers with millions of followers in total have now been removed. With the door closing on all the major platforms and the self-styled ""free speech"" social network Parler going offline, Gab - another platform popular with right-wing users - is emerging as the go-to place for QAnon followers. Groups which promote QAnon on Gab have added tens of thousands of followers in the last few days, and now boast more than 400,000 followers in total."
Twitter tests 'misleading' post report button for first time,"Twitter is introducing a way to report posts as ""misleading"" for the first time. Many of the large social media networks have been accused of not doing enough to fight the spread of disinformation during the Covid pandemic and US election campaigns. Twitter's reporting function has never offered a clear option for such posts. It said the new feature was only a test, and will only be available in a few countries to begin with. ""Some people"" in Australia, South Korea, and the United States will now see an option for ""it's misleading"" when trying to report a tweet, the tech giant said. It also warned users that the system may not have a significant effect. ""We're assessing if this is an effective approach so we're starting small,"" the company said on its safety account. ""We may not take action on and cannot respond to each report in the experiment, but your input will help us identify trends so that we can improve the speed and scale of our broader misinformation work."" Twitter plans to eventually launch the feature in other countries around the world. Currently, someone reporting misinformation must choose from options such as ""it's suspicious or spam"" or ""it's abusive or harmful"" - and then narrow that down to more specific sub-categories to make a report. Because the options are so specific, it can often be unclear which one to use. If I had a penny for how many times people message me asking why there's no option to report misinformation on Twitter, I'd be a very rich woman. Since the start of the pandemic, pressure has mounted on social media sites to do more to combat a wave of harmful falsehoods that have spread online. That includes unfounded conspiracies about Covid-19 and vaccines, as well as surrounding last year's US election, which went on to inspire the riots at Capitol Hill and saw US President Donald Trump's account suspended. I've spent the past year-and-a-half covering the real-world impact of misleading posts online - scaring people off Covid jabs, destroying relationships, and provoking violence. Some critics argue that the option to report misinformation should have been introduced months ago to help prevent this offline harm. But the question remains - what impact will this really have? There are fears that the social media site will struggle to moderate the avalanche of content reported - including from those promoting falsehoods, who then flag accurate information as misleading. Twitter has focused on issuing suspensions and bans to accounts which consistently spread harmful Covid-19 misinformation when they come to the company's attention. It also began putting warning labels on such tweets in early 2020, announced a collaboration with news organisations as part of an attempt to debunk false information, and started a pilot scheme in January to allow a small number of people to submit ""notes"" about misleading content. However, Twitter and other tech giants continue to be criticised for the spread of false information. Chief executives have repeatedly appeared before US politicians to answer questions about their policies, while  groups such as the Center for Countering Digital Hate have accused them of not doing enough to combat vaccine misinformation - among other forms of harm."
Twitter works with news sites to tackle disinformation,"Twitter will collaborate with two of the largest international news providers, Reuters and the Associated Press, to debunk disinformation on its messaging site. The news agencies will help Twitter give more context and background information on events which create a high volume of tweets. Twitter hopes this will counteract the spread of misleading information. There has been renewed pressure to remove false content from the platform. Twitter said the partnership will enable it to ensure accurate and credible information is rapidly available ""when facts are in dispute"". ""Rather than waiting until something goes viral, Twitter will contextualize developing discourse at pace with or in anticipation of the public conversation,"" Twitter said. Currently, when large or rapidly growing conversations happen on Twitter that may be noteworthy or controversial, Twitter's Curation team finds and promotes relevant context from reliable sources in order to counter potentially misleading information posted by users. In a blogpost, Twitter said the new programme would ""increase the scale and speed"" of this work by increasing their ""capacity to add reliable context to conversations happening on Twitter"". The post said material from Reuters and AP would improve information credibility on the platform when Twitter's Curation team ""doesn't have the specific expertise or access to a high enough volume of reputable reporting on Twitter"". It is the first time Twitter has formally collaborated with news organisations to promote accurate information on its site, according to a spokesperson from the social media firm. Earlier this year, Twitter launched Birdwatch, a new community-moderation system which enabled volunteers to label tweets they found to be inaccurate. Twitter will work separately with the two rival news agencies, and will focus initially on English-language content. Hazel Baker, head of user-generated content newsgathering at Reuters, said that trust, accuracy and impartiality were at the ""heart of what Reuters does every day,"" and ""drive"" the company's ""commitment to stopping the spread of misinformation"". Tom Januszewski, the AP's vice president of global business development, said in a statement that the news company had a ""long history of working closely with Twitter, along with other platforms, to expand the reach of factual journalism"". ""We are particularly excited about leveraging AP's scale and speed to add context to online conversations, which can benefit from easy access to the facts,"" he continued. Both Reuters and AP also work with Facebook on fact checks. Twitter added that this work would be independent of the work its Trust & Safety teams do to determine whether Tweets are in violation of the Twitter rules. The work of these teams includes labelling tweets which contain manipulated media, electoral misinformation and sensitive media that violates the platforms' rules. A 2020 report by NYU Stern suggested Twitter has about 1,500 moderators - with 199 million daily Twitter users worldwide."
US Election 2020: Fact-checking claims about the Pennsylvania vote,"With no result yet in a tightly-contested US election, claims which can be misleading are circulating on social media about voting and counting in key states. The count is still going on in the battleground state of Pennsylvania - we've looked at some of the most widely shared claims about the situation there. One viral video showed a poll watcher being denied entry to a Philadelphia polling station. It has had almost two million views on Twitter, and was shared by multiple pro-Trump accounts, saying Republican poll watchers were being banned. The man in the video, Gary Feldman, a local Republican, was asked to wait outside by officials - with a woman telling him that his ""city-wide"" poll watching certificate was not valid in that particular polling station. The video was authentic, and the man was being stopped from entering, but it turns out there was confusion over the rules. Poll watchers used to only be allowed in a certain station, but they can now visit multiple sites across Philadelphia. Philadelphia city commissioners said the man was later allowed into the station and received an apology. A tweet shared by Mike Roman, who worked for the Trump election campaign, claimed that a Democratic poster was a ""violation in sight"" for being in close proximity to a polling station. His tweet referred to ""bad things"" happening. Election rules in Pennsylvania prohibit campaign materials, signs, banners and literature being within 10 feet of a polling station. The post that Mr Roman originally amplified - now labelled as violating Twitter rules - gained significant traction online, but was rebutted by the Philadelphia District Attorney's office. They said they had investigated the claim and found that the actual polling place was ""located in an interior room and the sign in question was further than 10 feet from it"". So, that's not violating the election rules as they are in that area. This false claim appeared on Instagram, saying that an election worker in Erie County, Pennsylvania had thrown out more than 100 votes for President Trump. It was shared as a screenshot by businessman Mike Coudrey, who then deleted the tweet, although it had been re-tweeted more than 6,000 times by then. Screenshots have also been shared on Facebook by various pro-Trump and other groups, but some have been deleted. The election board for Erie County has rejected the claim, calling it ""false"". It said in a statement: ""The person making the statements [about throwing out ballots] does not work in any way with Erie County or have any part of Erie County's election process. In fact, the individual is not a registered voter and is not believed to be a resident of Erie County."" A claim that election workers in the city of Philadelphia were no longer counting ballots has been circulating, and was picked up by President Trump's lawyer, Rudy Giuliani. Mr Giulani refers to Mr Trump being in the lead in the state, and says the ""crooked Philly Democrat machine"" has stopped counting. But this has been denied by the Philadelphia City Commissioner Al Schmidt, who put out a statement on Twitter saying that Philadelphia will not stop counting. Another statement from the city commissioners clarified that counting was continuing, but there were some delays in reporting. ""We're going to continue to count all day long."" The statement did acknowledge that for technical reasons, and due to the number of mail-in ballots, reporting the results would be held up until the following day. There's a live stream online where you can watch the count going on. Read more from Reality Check Send us your questions Follow us on Twitter"
US election 2020: FBI links Iran to websites targeting poll officials,"Iranian cyber actors were ""almost certainly"" behind a number of websites and social media accounts which contained death threats against senior officials in charge of securing and managing the 2020 election, two US security agencies have announced. In a joint statement published on 23 December, the FBI and the Cybersecurity and Infrastructure Security Agency (Cisa) said they were in possession of ""highly credible information"" indicating Iran was responsible for the operation. The operation ""demonstrates an ongoing Iranian intent to create divisions and mistrust in the United States and undermine public confidence in the US electoral process"", it added. The websites and social media accounts, called ""Enemies of the People"" and ""Enemies of the Nation"", were created in early December and included the names, photos, contact details and home addresses of 38 US federal, state and local officials, as well as private citizens employed by Dominion - which sells electronic voting software and hardware. Rifle crosshairs were imposed on the images of the individuals listed on the websites. President Trump, his legal team and a number of his allies have made allegations in recent weeks about widespread electronic voting fraud in several swing states involving Dominion. But federal courts have dismissed lawsuits which referred to those claims. ""The following individuals have aided and abetted the fraudulent election against Trump,"" read a note on the domains. ""Changing votes and working against the president is treason and patriotic Americans should never forget those who helped overthrow our democracy,"" it added. The agencies also identified four email addresses linked to the websites which had sent ""threatening emails"" to the officials. The operation's social accounts on Facebook, Twitter, Parler, V-Kontakte, Pinterest and Gab spread the domains and called on President Trump's supporters to add details of more individuals who ""betrayed our country and democratic ideals"". FBI chief Christopher Wray, former Cisa head Chris Krebs - who was fired last month by Mr Trump for contradicting his claims of voter fraud - Michigan Governor Gretchen Whitmer, Georgia Secretary of State Brad Raffensperger and the state's voting systems implementation manager Gabriel Sterling were among the officials whose details appeared on the domains. Earlier this month, Mr Sterling rebuked his fellow Republicans, including the president, for allegations of fraud in the state after a number of election workers were subjected to intimidation and death threats. All the domains associated with the operation, and their archived versions, have now been taken down. The majority of the social media accounts have also been removed. But one account on Parler is still up, although it has been set to private. Joe Slowik, a senior security researcher at the firm DomainTools, said in a blog post that publicly available domain registration details were set up to indicate as though the operation had originated in Russia. However, emails associated with the domain registrars used the global-oriented ""yandex.com"" instead of the Russian language ""yandex.ru"". ""This may be circumstantial, or it could support the theory that the activity in question attempts to look like Russian-based actions but lack of language skills prompted the use of the com site instead of the Russian-language ru,"" Mr Slowik added in a later update. The is the second time US officials have linked Iran to attempts to interfere in this year's elections. In October, national security officials said Iran was responsible for sending threatening emails to Democratic voters. The emails appeared to come from the Proud Boys, a far-right pro-Trump group, and were meant to ""incite unrest"", National Intelligence Director John Ratcliffe said. Iran denied any involvement in those emails, and has not so far commented on the FBI statement. And Twitter removed nearly 130 accounts linked to Iran that attempted to ""disrupt the public conversation"" during the first presidential debate. Some of the accounts tweeted in favour of Mr Trump, while others were supportive of Joe Biden."
"US election 2020: Fox News, Newsmax walk back voter fraud claims after legal threat","US TV networks Fox News and Newsmax have aired segments highlighting the lack of evidence linking electronic voting machines to fraud in the US election. The networks had received legal threats from Smartmatic, a voting technology company targeted by fraud allegations. President Donald Trump's team have used unfounded claims about voting machines in a bid to overturn his defeat. Members of his team appeared repeatedly on the channels to push the theory. Fox News ran a two-minute fact-check in the form of questions and answers on three different programmes on Saturday which denied allegations of manipulation or fraud by the two companies. Newsmax published an online piece and aired a segment on ""facts about Dominion, Smartmatic you should know"". Smartmatic, which builds electronic voting systems, announced last week that it had sent ""legal notices and retraction demand letters"" to Fox News, Newsmax and One America News Network, accusing the three outlets of ""publishing false and defamatory statements"". ""The demand letters identify dozens of factually inaccurate statements made by each of the organisations as part of a 'disinformation campaign' to injure Smartmatic and discredit the 2020 US election,"" read a statement on the company's website. President Trump, his legal team and a number of his allies have made various allegations in recent weeks about widespread electronic voting fraud in several swing states involving Dominion - which sells electronic voting software and hardware - and Smartmatic. The unfounded allegations - some of which have been widely covered by the three networks - include claims that Dominion systems enable ""computerised ballot-stuffing"", millions of votes for Mr Trump were either deleted or flipped in favour of Joe Biden, voting machines are part of a plot originating under former Venezuelan leader Hugo Chavez or were accessed by foreign agents to manipulate results, and that Dominion used Smartmatic software in a number of states. No evidence has been provided for any of the allegations and dozens of federal courts have dismissed lawsuits which referred to those claims. The Fox segment - which ran on programmes hosted by Lou Dobbs, Maria Bartiromo and Jeanine Pirro - features Eddie Perez, an expert at the Open Source Election Technology Institute. In it, Mr Perez confirms there is no evidence Smartmatic software has been used to ""delete, change [or] alter anything related to vote tabulation"", adding Smartmatic and Dominion are independent companies and ""not related to each other"". And on Monday, Newsmax host John Tabacco read out in full the statement published on the network's website two days earlier. ""Newsmax would like to clarify its news coverage and note it has not reported as true certain claims made about these companies,"" he said. ""No evidence has been offered that Dominion or Smartmatic used software or reprogrammed software that manipulated votes in the 2020 election,"" Mr Tabacco added. According to the New York Times, Dominion has also hired a lawyer who has threatened legal action against the Trump campaign and Sidney Powell, a former member of the Trump legal team who has made dramatic claims of fraud in several public events and filed unsuccessful lawsuits in a number of swing states. One America News did not immediately respond to a BBC request for comment."
US midterm elections: Does Finland have the answer to fake news?,"As the midterm elections approach in the US, the wave of false claims surrounding the vote is a reminder of how hard it is to combat fake news. Does Finland have the answer? A few hours after Vladimir Putin called up 300,000 military reservists in September, a video showing long queues of cars at the Finnish-Russian border started circulating on social media. The Finnish Border Guard was quick to point out it was fake. ""Some of the videos were filmed earlier and now taken out of context,"" it said on Twitter. The tweet promptly made it to the top of the Ukraine live page on national broadcaster Yle's news website. The Border Guard's and Yle's response highlights a crucial element of Finland's success against disinformation - public trust in the authorities and the media. Finland is a high-trust society. According to an OECD report, 71% of the Finnish population trust the government, compared to the OECD average of 41%. And it's not just the government - parliament, the civil service, the police and the media all enjoy high levels of trust. In an annual study by the Open Society Institute, the country tops a global chart measuring resilience to disinformation. That does not mean Finns believe everything they read in the papers and never look at social media for information. But when they do, most have the ability to critically evaluate information. That shield against disinformation is being sorely tested in the US as the midterm elections approach. More than ever, the spotlight is on the so-called fake news problem and the real-world consequences it can have. Despite the increased focus on tackling false and misleading claims on social media, including from the tech giants themselves, disinformation is still seeping through the cracks. For the BBC's Americast podcast, we created social media accounts belonging to five fake characters, who reflect views from across the political spectrum in the US. One character in particular - Populist Right Britney - has been recommended pages on social media that continue to promote disinformation that Trump really won the 2020 election, as well as a range of conspiracies. Progressive Left Emma, on the other hand, has been more likely to encounter more radical activism - some that includes violent rhetoric but that stops short of conspiracy. The Finnish school system is the cornerstone of the fight against fake news. Critical thinking and media literacy have been part of the curriculum for a very long time. The curriculum was revised in 2016 to teach children the skills they needed to spot the kind of fabricated information that spread on social media during the US election campaign. ""We teach critical thinking across several subjects. For example in maths classes we look at how statistics can be manipulated,"" explains Marika Kerola, a teacher in the northern city of Oulu. ""In art, a typical project would be for children to create their own versions of a shampoo advertisement. It may be a picture showing that hair is not as shiny or radiant as it's been promised on the bottle."" In language classes they will compare the same story written as fact-based text and as propaganda, she says. In history they will compare war-time posters in Nazi Germany and the United States, for example. Another core line of defence against fake news is the government's National Emergency Supply Agency. ""To put it simply, Finland has a comprehensive publicly-funded security model,"" says Markus Kokko, head of communications for the European Centre of Excellence for Countering Hybrid Threats. ""The government works with private businesses and the media to build society's resilience to threats and prepare people for all kinds of disruptions."" In addition to a central government agency, Finland has a number of NGOs and voluntary organisations combating fake news. Fact-checking service Faktabaari is probably the best-known of them. Finland's approach is all about getting ahead of the tidal wave of disinformation - a wave that has already crashed down on US shores. The experience in Finland suggests proactive moderation in real-time can make a difference. Since the pandemic, where online disinformation surged online about Covid-19, the social media sites have all committed to doing more to battle falsehoods. On the whole, they have seen some success in removing harmful mistruths and labelling conspiracies with accurate information from third-party fact-checkers. More on this series, Seeking A Solution NORWAY: The world's youngest politicians FINLAND: Leading the fight against fake news BOLIVIA: How it nailed gender parity in politics SWITZERLAND: How to break gridlock in US Congress AUSTRALIA: Could mandatory voting boost US turnout? And around the midterms, they've variously announced specific initiatives in place to deal with this issue. For example - Meta, which owns Facebook and Instagram, says it has more than 40 teams working on the election, as well as partnerships with 10 fact-checking organisations in the US. But, across the social media platforms, there are still posts that rack up likes and views before they're removed - and many that get through the gaps in the first place, as the Undercover Voter Britney's social media feeds reveals. A proactive moderation approach that tackles these posts before they have the chance to spread like wildfire is one favoured by some experts. Social media literacy lies at the heart of Finland's long-term plan. Charities and projects in the US have been pushing for more permanent legislation across the country to ensure children are taught this topic in schools. There was a bill passed in Illinois last year, for example, which mandates every public high school to include media literacy somewhere in its curriculum. They'll be taught how to analyse everything they see online - and off. Ultimately though, these measures are all just plasters on a wound that's much harder to heal. There's no quick fix for restoring and repairing faith in institutions - some of which has been eroded by disinformation campaigns looking to undermine the election result. When social media feeds like those of my Undercover Voter Britney are still being punctuated by posts about how the election two years ago was fraudulent, there's still a problem. And with a majority of Republican candidates running next month having questioned the 2020 election result, the prospect of progress can seem remote."
US midterms: False and misleading claims about the vote go viral,"A series of false and misleading claims have gone viral online days before the US midterm elections. Some of the claims cast doubt on the legitimacy of the voting process in key states, while others include manipulated content from across the political spectrum. The BBC has examined some of the most widely shared claims. Claims that voting machines flip votes from Republicans to Democrats and vice versa have dogged US elections for years. Yet to date there is no evidence to suggest that election tampering has taken place. A handful of posts recently began circulating on social media from voters in Texas who claimed that voting machines were switching their votes from Democrat to Republican. One tweet read: ""Texas GOP up to the same dirty tricks."" Local county officials and the secretary of state's office all confirmed receiving a small handful of reports relating to voters experiencing difficulties with touch screen machines, and have encouraged voters to review their ballots before submitting them. In a local interview, Sam Taylor, a spokesperson for the Texas secretary of state's office, denied any tampering going on and instead put the instances down to user error. Voting machines have previously been hacked by researchers in controlled studies to test how vulnerable they might be. Electronic Systems Software, a company which provides voting machines to multiple Texas counties, has acknowledged such controlled studies on their website, but adds that these do not reflect an actual election scenario where ""multiple levels of physical and cyber security are always in place"". Texas voting machines are required to go through multiple tests, including one after the election to make sure there were no issues, and locks are placed on the machines to detect possible tampering. The film ""2,000 mules"" by right-wing political commentator Dinesh D'Souza claims to reveal widespread voter fraud operating across several swing states in the 2020 election, and has been promoted by multiple Republicans. On Facebook alone, mentions of the film have had over four million interactions. One map in the film claims to have used geolocation data to show an individual had visited multiple voting drop boxes in a single day in Georgia. Yet analysis of the map shows that the drop box locations shown in the video do not match up with the same locations on a map. Evidence from the independent Georgia Bureau of Investigation revealed that in the film coming within as much as 100ft of a drop box was counted as having visited one. Additionally, some people shown inserting multiple ballots are cited as evidence of voter fraud. One such individual is now suing the film's creators for defamation after a state investigation revealed he was legally depositing ballots for himself and his family members. In limited cases, election crime and voter fraud can happen. But the allegation that it is widespread enough to swing the results of an election is baseless. In Arizona, a three-year-long investigation into voter fraud prosecuted just 20 cases in a state of 7.2 million people. A manipulated video of former President Barack Obama campaigning for the Democrats in Detroit, Michigan, has been viewed more than two million times and widely shared. In the manipulated clip, it appears as though Mr Obama was cut off by the audience chanting an expletive against President Joe Biden. However, Mr Obama was in fact responding to a heckler in the audience, who shouted at him as the former president addressed violent rhetoric in US politics and last week's attack on Paul Pelosi, the husband of US House of Representatives Speaker Nancy Pelosi. Videos of the full rally show there were no chants against Mr Biden in the largely pro-Democrat crowd. House of Representatives minority leader Kevin McCarthy launched Republican campaign pledges for the midterms in September under the slogan ""Commitment to America"". It included pledges to reduce gas prices and crime, among others. But a fake version of Republican campaign pledges has been widely shared online, which has been manipulated to feature promises to cut Social Security benefits, raise the eligibility age for Medicare and tax veterans. None of these are in the real Republican ""Commitment to America"" plan. The Pennsylvania Senate race between Republican Mehmet Oz and Democrat John Fetterman is seen as one of the crucial battles of the midterms campaign, which could potentially decide whether the Senate remains in Democratic control or flips to the Republicans. A number of doctored memes featuring Dr Oz have been shared in recent weeks which claim to show voters in Pennsylvania tell him to his face that they don't intend to vote for him. One shows a house with Dr Oz's campaign sign upside down in the front garden, which makes one of them appear to read ""no"" above his name. But the same picture of the house, located in Pittsburgh, can be found on the website of a real estate company without the upside down Oz campaign signs. The person who created the picture told the BBC it was done as a joke and should not be taken seriously. A similarly doctored image was widely shared after Dr Oz visited a restaurant in Harrisburg by editing signs bearing his name. A series of false and misleading claims have gone viral online days before the US midterm elections. Some of the claims cast doubt on the legitimacy of the voting process in key states, while others include manipulated content from across the political spectrum. The BBC has examined some of the most widely shared claims. Claims that voting machines flip votes from Republicans to Democrats and vice versa have dogged US elections for years. Yet to date there is no evidence to suggest that election tampering has taken place. A handful of posts recently began circulating on social media from voters in Texas who claimed that voting machines were switching their votes from Democrat to Republican. One tweet read: ""Texas GOP up to the same dirty tricks."" Local county officials and the secretary of state's office all confirmed receiving a small handful of reports relating to voters experiencing difficulties with touch screen machines, and have encouraged voters to review their ballots before submitting them. In a local interview, Sam Taylor, a spokesperson for the Texas secretary of state's office, denied any tampering going on and instead put the instances down to user error. Voting machines have previously been hacked by researchers in controlled studies to test how vulnerable they might be. Electronic Systems Software, a company which provides voting machines to multiple Texas counties, has acknowledged such controlled studies on their website, but adds that these do not reflect an actual election scenario where ""multiple levels of physical and cyber security are always in place"". Texas voting machines are required to go through multiple tests, including one after the election to make sure there were no issues, and locks are placed on the machines to detect possible tampering. The film ""2,000 mules"" by right-wing political commentator Dinesh D'Souza claims to reveal widespread voter fraud operating across several swing states in the 2020 election, and has been promoted by multiple Republicans. On Facebook alone, mentions of the film have had over four million interactions. One map in the film claims to have used geolocation data to show an individual had visited multiple voting drop boxes in a single day in Georgia. Yet analysis of the map shows that the drop box locations shown in the video do not match up with the same locations on a map. Evidence from the independent Georgia Bureau of Investigation revealed that in the film coming within as much as 100ft of a drop box was counted as having visited one. Additionally, some people shown inserting multiple ballots are cited as evidence of voter fraud. One such individual is now suing the film's creators for defamation after a state investigation revealed he was legally depositing ballots for himself and his family members. In limited cases, election crime and voter fraud can happen. But the allegation that it is widespread enough to swing the results of an election is baseless. In Arizona, a three-year-long investigation into voter fraud prosecuted just 20 cases in a state of 7.2 million people. A manipulated video of former President Barack Obama campaigning for the Democrats in Detroit, Michigan, has been viewed more than two million times and widely shared. In the manipulated clip, it appears as though Mr Obama was cut off by the audience chanting an expletive against President Joe Biden. However, Mr Obama was in fact responding to a heckler in the audience, who shouted at him as the former president addressed violent rhetoric in US politics and last week's attack on Paul Pelosi, the husband of US House of Representatives Speaker Nancy Pelosi. Videos of the full rally show there were no chants against Mr Biden in the largely pro-Democrat crowd. House of Representatives minority leader Kevin McCarthy launched Republican campaign pledges for the midterms in September under the slogan ""Commitment to America"". It included pledges to reduce gas prices and crime, among others. But a fake version of Republican campaign pledges has been widely shared online, which has been manipulated to feature promises to cut Social Security benefits, raise the eligibility age for Medicare and tax veterans. None of these are in the real Republican ""Commitment to America"" plan. The Pennsylvania Senate race between Republican Mehmet Oz and Democrat John Fetterman is seen as one of the crucial battles of the midterms campaign, which could potentially decide whether the Senate remains in Democratic control or flips to the Republicans. A number of doctored memes featuring Dr Oz have been shared in recent weeks which claim to show voters in Pennsylvania tell him to his face that they don't intend to vote for him. One shows a house with Dr Oz's campaign sign upside down in the front garden, which makes one of them appear to read ""no"" above his name. But the same picture of the house, located in Pittsburgh, can be found on the website of a real estate company without the upside down Oz campaign signs. The person who created the picture told the BBC it was done as a joke and should not be taken seriously. A similarly doctored image was widely shared after Dr Oz visited a restaurant in Harrisburg by editing signs bearing his name."
US midterms: Misleading election claims fact-checked,"The US midterm elections saw several false and unsubstantiated rumours circulating online, with suggestions that the vote in certain states was being rigged. We've looked at some of the most widely shared claims. About a fifth of voting machines in Maricopa County, which includes the state's largest city, Phoenix, malfunctioned early on Tuesday due to a printer error. This slowed down voting, but election officials said every vote would be counted and that they were working to fix the problem. The glitch prompted claims that the vote was being rigged. Former President Donald Trump said: ""They are trying to steal the election with bad machines and delay. Don't let it happen."" Kari Lake, the Arizona Republican candidate for governor, did not immediately claim fraud but in an interview said: ""I hope there's been no malice involved, I know there's been incompetency."" Election officials also reassured voters they had a backup plan in place if machines malfunctioned, posting a video showing people how to place their ballot in the secure drop box attached to the machine. Ms Lake tweeted that any votes put in this drop box would ""likely not be counted for weeks"". But election officials disputed that, saying ballots in the drop box would be counted on election day. Ms Lake later deleted the tweet. She has previously falsely claimed the 2020 election was won by Donald Trump. Charlie Kirk, a prominent conservative pundit, tweeted that there was a ""two hour wait minimum at most polling places in Maricopa"". It's unclear where he got that information, but it was denied by county election officials. A judge in Maricopa County rejected a Republican request to keep polls open past their usual closing time, as they had provided no evidence that a voter was not able to cast a ballot because of the machine problems. A brief clip of a poll worker appearing to mark ballots, shown as part of a news montage, sent some people drawing the false conclusion that the man was altering votes. One tweet, which was shared more than 11,000 times, posted the clip saying: ""Rigging ballots live on TV."" But officials in Dane County, Wisconsin, where the video was taken, say that the worker was doing his job normally. Before passing the ballot on, election workers circle the correct local election ward printed on the ballot and initial it. ""This process is required by law and is a routine part of the check and balance process,"" county clerk Scott McDonell said in a statement. ""It is done in a public setting and the ballot would then need to be signed by a different poll worker before being handed to the voter."" Some of the debunked viral claims from the 2020 election have been seeing a resurgence this time around. One of them is ""Sharpiegate"" - the false claim that a voter's ballot won't be counted if they use a Sharpie pen (permanent marker) to fill it in. The claim was widely circulated in Arizona two years ago, despite election authorities confirming it was baseless. One tweet from an Illinois-based account this time said: ""La Grange Precinct 89 voters report sharpies being used on ballots, which isn't allowed. No sharpies on ballots."" The claim was also reported by a right-wing outlet The Gateway Pundit. However, the Illinois State Board of Elections said that ""sharpie pens are the preferred ballot-marking method for many voting systems"". It added that ballots are ""intentionally designed so that bleed through does not cause a problem."" Bleed through is when ink seeps from one side of the paper to the other. Twitter has since flagged the original post as ""misleading"". A woman said in a widely circulated tweet that she was ""kicked out"" along with her son as poll workers trying to ""ensure a free and fair election"" in Fulton County, Georgia. But officials said Laura Kronen was sacked because she was at the US Capitol in Washington during the riot on 6 January 2021. She was removed on Tuesday morning after social media posts were discovered that linked her to the storming of the US Capitol, according to state officials. Ms Kronen had boasted on Facebook about being in Washington that day, writing: ""I stormed the Capitol building."" Officials said that they also learned about a post in which the woman ""seemed to imply"" that she was going to videotape some of her work at the polling place, which is forbidden. On discovering this information, local officials approached the secretary of state's office for review. ""They agree with the concern,"" said a Fulton County spokeswoman. ""Out of the safety for the election, we decided to remove them until we can complete the investigation."" In messages sent to the BBC, Ms Kronen denied that she or any of her family members entered the Capitol building, and said she was unaware of the violence going on inside. ""I meant we were all at the rally... and walking to the Capitol together,"" she said. The US midterm elections saw several false and unsubstantiated rumours circulating online, with suggestions that the vote in certain states was being rigged. We've looked at some of the most widely shared claims. About a fifth of voting machines in Maricopa County, which includes the state's largest city, Phoenix, malfunctioned early on Tuesday due to a printer error. This slowed down voting, but election officials said every vote would be counted and that they were working to fix the problem. The glitch prompted claims that the vote was being rigged. Former President Donald Trump said: ""They are trying to steal the election with bad machines and delay. Don't let it happen."" Kari Lake, the Arizona Republican candidate for governor, did not immediately claim fraud but in an interview said: ""I hope there's been no malice involved, I know there's been incompetency."" Election officials also reassured voters they had a backup plan in place if machines malfunctioned, posting a video showing people how to place their ballot in the secure drop box attached to the machine. Ms Lake tweeted that any votes put in this drop box would ""likely not be counted for weeks"". But election officials disputed that, saying ballots in the drop box would be counted on election day. Ms Lake later deleted the tweet. She has previously falsely claimed the 2020 election was won by Donald Trump. Charlie Kirk, a prominent conservative pundit, tweeted that there was a ""two hour wait minimum at most polling places in Maricopa"". It's unclear where he got that information, but it was denied by county election officials. A judge in Maricopa County rejected a Republican request to keep polls open past their usual closing time, as they had provided no evidence that a voter was not able to cast a ballot because of the machine problems. A brief clip of a poll worker appearing to mark ballots, shown as part of a news montage, sent some people drawing the false conclusion that the man was altering votes. One tweet, which was shared more than 11,000 times, posted the clip saying: ""Rigging ballots live on TV."" But officials in Dane County, Wisconsin, where the video was taken, say that the worker was doing his job normally. Before passing the ballot on, election workers circle the correct local election ward printed on the ballot and initial it. ""This process is required by law and is a routine part of the check and balance process,"" county clerk Scott McDonell said in a statement. ""It is done in a public setting and the ballot would then need to be signed by a different poll worker before being handed to the voter."" Some of the debunked viral claims from the 2020 election have been seeing a resurgence this time around. One of them is ""Sharpiegate"" - the false claim that a voter's ballot won't be counted if they use a Sharpie pen (permanent marker) to fill it in. The claim was widely circulated in Arizona two years ago, despite election authorities confirming it was baseless. One tweet from an Illinois-based account this time said: ""La Grange Precinct 89 voters report sharpies being used on ballots, which isn't allowed. No sharpies on ballots."" The claim was also reported by a right-wing outlet The Gateway Pundit. However, the Illinois State Board of Elections said that ""sharpie pens are the preferred ballot-marking method for many voting systems"". It added that ballots are ""intentionally designed so that bleed through does not cause a problem."" Bleed through is when ink seeps from one side of the paper to the other. Twitter has since flagged the original post as ""misleading"". A woman said in a widely circulated tweet that she was ""kicked out"" along with her son as poll workers trying to ""ensure a free and fair election"" in Fulton County, Georgia. But officials said Laura Kronen was sacked because she was at the US Capitol in Washington during the riot on 6 January 2021. She was removed on Tuesday morning after social media posts were discovered that linked her to the storming of the US Capitol, according to state officials. Ms Kronen had boasted on Facebook about being in Washington that day, writing: ""I stormed the Capitol building."" Officials said that they also learned about a post in which the woman ""seemed to imply"" that she was going to videotape some of her work at the polling place, which is forbidden. On discovering this information, local officials approached the secretary of state's office for review. ""They agree with the concern,"" said a Fulton County spokeswoman. ""Out of the safety for the election, we decided to remove them until we can complete the investigation."" In messages sent to the BBC, Ms Kronen denied that she or any of her family members entered the Capitol building, and said she was unaware of the violence going on inside. ""I meant we were all at the rally... and walking to the Capitol together,"" she said."
US midterms: The election deniers running to control 2024 vote,"A coalition of candidates who have falsely claimed the last US election was stolen is running for office - this time in a bid to control the 2024 vote in key swing states. The group's founders also have deep connections to another conspiracy theory, QAnon. When Donald Trump called him up onto the stage at a rally in Nevada last month, Jim Marchant seized the opportunity to hammer home his campaign message. ""We have something in common,"" he told the raucous crowd, with the former president standing beside him. ""President Trump and I both lost an election in 2020 because of a rigged election."" While both men continue to spread false theories about their past defeats - the Nevada businessman lost his race for Congress - Mr Marchant also made clear he's looking to the future. ""When my coalition of secretary of state candidates around the country get elected we're going to fix the whole country and President Trump is going to be president again in 2024,"" he declared. Mr Trump beamed as his supporters roared their approval. But experts warn that having partisan election deniers responsible for setting election rules - and in some cases, certifying the results - is dangerous for democracy. Seven members of Mr Marchant's political group called the America First Secretary of State (SOS) Coalition will be on the ballot in November's midterm elections. As the name implies, they are targeting secretary of state positions (two Republican candidates for governor, in Pennsylvania and Arizona, also signed up). These normally obscure roles are distinct from the US secretary of state, a powerful job equivalent to foreign secretary. At the state level, secretary of states have a variety of bureaucratic duties, mostly to do with registering and licensing. But in most states, they also supervise elections. Rachel Orey, from the Elections Project at the Bipartisan Policy Center, says these SOS candidates are further eroding trust in the electoral process, and risk sowing chaos if there's another close race for the White House in 2024. ""I could absolutely see another January 6th happening at the state level,"" she says, referring to the 2021 riot at the US Capitol by a mob of Trump supporters. The position of secretary of state was highlighted in 2020 when a recording emerged of Mr Trump asking Brad Raffensperger in Georgia to ""find"" 11,780 votes to overcome his margin of defeat in the state. Mr Raffensperger, a Republican, resisted the president's efforts, and Georgia's votes ultimately landed in Joe Biden's column. Would that happen if a similar situation arises in a different state next time? The SOS coalition is one element of a much wider movement that has swept the Republican Party since the Trump-backed Stop the Steal campaign after the 2020 election. Polls have consistently indicated that around two-thirds of Republicans have doubts about the legitimacy of Joe Biden's victory - despite the fact that dozens of lawsuits have been thrown out and there's no evidence of any widespread fraud that would have changed the outcome. Among 595 Republicans running for state-wide or federal office, 308 have raised doubts about the validity or integrity of the 2020 election, according to an analysis by the BBC's US partner CBS News. The level of commitment to the false claim does vary - and many candidates backed away from talking about it once they'd secured the all-important Trump endorsement and won the Republican nomination in their race. But even a much narrower definition of election denial shows broad acceptance of false claims. A BBC analysis of Republican candidates running for Congress or governor found that 175 - or 35% - have fully and publicly denied the outcome of the 2020 election. These hardcore deniers are not just fringe outsiders. A majority are running in heavily Republican districts or are in competitive races. Some have made election conspiracy theories the cornerstone of their campaigns. Mark Finchem, the Republican candidate for secretary of state in Arizona, told the BBC he didn't believe it was possible for a Democrat to win in his state. And when the BBC challenged Kari Lake, the woman hoping to become the next Arizona governor, about her unfounded 2020 claims about hundreds of thousands of phony ballots, the Republican insisted - without any proof - that key evidence had been withheld by the government. The America First SOS coalition candidates say they just want fair elections. They've agreed on rules changes they'd introduce to prevent fraud - requiring voters to show identification at the polls, eliminating mail-in ballots, and an ""aggressive voter roll clean-up"". Bret Schafer, from the nonpartisan Alliance for Securing Democracy, says it's legitimate to discuss election security and to debate potential changes to the system, although he believes the coalition's proposed measures are unnecessary and will simply make it harder for Americans to vote. ""But we're seeing the injection of conspiratorial narratives into the conversation around security,"" he says. ""And an election administrator who has bought into or elevated those who push wild conspiracy theories is fundamentally dangerous."" Jim Marchant - the candidate who shared the stage with Donald Trump last month - doesn't limit his allegations to the 2020 election. He has claimed that all Nevada elections since 2006 have been rigged, with elected officials installed by a ""deep state cabal"". And in a campaign advert posted in October, he even suggests that Democratic leaders like Nancy Pelosi and Chuck Schumer only won their elections due to ballot stuffing funded by liberal donor George Soros. The reality, of course, is that they are popular politicians representing heavily Democratic areas. Experts say conspiracy thinking in one area easily spills over to others. ""Where conspiracy worlds used to be very siloed they're now all mixed together,"" says Mike Rothschild, author of The Storm Is Upon Us: How QAnon Became a Movement, Cult, and Conspiracy Theory of Everything. ""So you're just as likely to believe that the election was stolenÂ as you are to believe that ivermectin is the cure for all diseases and that Covid-19 is a hoax,"" he says. Which brings us to how the SOS coalition was formed in the first place. Mr Marchant was instrumental, as he explained at a conference in Las Vegas a year ago. ""We need to take back secretary of state offices across the countryÂ not only did they ask me to run, they asked me to put together a coalition of other like-minded secretary of state candidates."" The ""they"" Mr Marchant referred to was a group of unnamed Trump lawyers and supporters. But at the same conference, he did specifically pick out one person crucial to the formation of the coalition - a QAnon influencer who goes by the pseudonym Juan O Savin. Juan O Savin has been named in press reports as Wayne Willott, a private investigator who lives in Washington state. He appears on fringe YouTube podcasts, talking from behind the camera and often showing a shot of his boots or the view outside his window. He pushes elaborate conspiracy theories rooted in QAnon - the wide-ranging, unfounded theory that says that former President Trump is waging a secret war against elite Satan-worshipping paedophiles in government, business, the Democratic Party and the media. At the conference last year, the crowd erupted in applause when Mr Marchant mentioned Juan O Savin. Neither Mr Marchant nor Mr Willott responded to requests for comment for this story. While the seven candidates have not campaigned explicitly on QAnon ideas, several have attended QAnon and conspiracy-themed events. QAnon at the ballot box, from Trending on the BBC World Service. Download the podcast or listen online This October, four of members of the coalition - Mr Marchant, plus the secretary of state candidates for New Mexico, Arizona and Michigan - attended a forum where Juan O Savin also spoke. After Savin concluded a rant about Mr Soros, Audrey Trullijo, who is running in New Mexico, took the microphone back, according to the Daily Beast. ""Let's hear it for Juan O Savin,"" she told the crowd. ""Is he awesome?"" Another SOS coalition candidate, Kristina Karamo of Michigan, appeared on a QAnon podcast in 2020 pushing conspiracy theories about elites drinking blood and participating in satanic rituals, according to Vice News. The movement's online activities have fragmented, but experts say it's still affecting politics - in the US and elsewhere. ""QAnon has evolved into a very diffuse set of ideas that have really taken hold of the mainstream in many countries,"" says Melanie Smith head of the Digital Analysis Unit at the Institute of Strategic Dialogue. ""This can no longer really be talked about as a fringe political movement."" Not only have false beliefs about the election process propelled political candidates, but they've also spilled over into real-world violence. David DePape, the suspect in the attempted murder of Nancy Pelosi's husband Paul, wrote hundreds of conspiracy-themed blog posts on his personal website, including about the election. Bret Schafer, the nonpartisan expert who monitors the state of democracies around the world, says that whatever happens on 8 November, the US will suffer. If the coalition candidates are defeated, he says, they've primed their supporters to believe it can only have been because of fraud. If they're elected, they'll be a position of power to influence the result in 2024. ""Win or lose, this is going to lead to more people who doubt the integrity of our democracy."" Additional reporting by Kayleen Devlin"
Ukraine conflict: Further false images shared online,"The second day of the Russian invasion of Ukraine has been accompanied by further false or misleading imagery on social media claiming to be from the conflict. Some show military action taken from older conflicts, while other viral videos have proved difficult to verify. One video clip seen by the BBC and proven to be several years old has been viewed more than 27 million times in one day, while another showed video game footage. Misleading posts have come from ""official"" sources as well as from ""ordinary"" social media users. One example was a tweet posted by the verified account of the Ukrainian Ministry of Defence. Footage of an aerial dogfight is accompanied by the caption ""MiG-29 of the Air Force of the Armed Forces destroys the 'unparalleled' Su-35 of the Russian occupiers"". However, it's video game footage from the game Digital Combat Simulator World. This isn't the first time that game footage has been used to illustrate military action. One clip of old and incorrectly labelled footage has been viewed over 18 million times on video-sharing platform TikTok. It claims to show Ukrainian troops ""facing off"" with Russian soldiers at an airbase. While it does show a confrontation between Ukrainian and Russian forces, fact-checkers Logically have ascertained that the footage was shot in 2014 during the annexation of Crimea, and was shot at the Belbek airbase near Sevastopol. The same footage was aired by BBC Turkish at the time, after it was broadcast by Turkish television. One video, which was posted on both Facebook and Twitter from an unofficial account supporting Ukraine's armed forces, claims to show the destruction of Russian personnel and equipment in Ukraine, as seen through a drone aircraft's gunsight. However, it's footage from Syria shot in 2020. The new version sees the image flipped, perhaps in an attempt to prevent verification through reverse-image search tools. The Twitter post was subsequently deleted. Another incorrectly labelled clip on Twitter claims to be of a Russian airstrike on Ukraine ""that caused a chain reaction at the Luhansk power plant"". Various uploads of the clip have been viewed hundreds of thousands of times. The video actually shows footage of the 12 August 2015 Tianjin blasts in China, which killed around 173 people when a container containing chemicals exploded at a port. A BBC report on the Chinese incident can be viewed here. One TikTok video has been viewed 27.5m times and shared by thousands of users who assumed that it was from Ukraine. The clip shows some men in military fatigues shouting and laughing in Russian as they parachute over farmland. Although the caption just says ""Original sound - Roman"", users have assumed that the video is of Russian troops taking part in the invasion. In fact, it's footage shot by a man who appears to be a member of the Russian armed forces, and uploaded to his Instagram channel in 2015. He uploaded the old footage to his TikTok channel on 24 February, the day of the Russian invasion of the Ukraine, leading to viewers thinking it was footage from the conflict. More old footage on Twitter includes video of a rocket barrage, implying it is part of the Ukraine war. In fact it's from 2018, and shows a barrage launched from Multiple Launch Rocket Systems (MLRS). A tweet from 2018 shows the same footage, although there is some doubt about the accuracy of the caption. In some cases it has been impossible to verify the truth behind a viral post. One example is that of a video clip of a missile being fired toward a residential area in Kyiv by a low-flying jet. The footage has been viewed more than two million times on Twitter. However, the aircraft is travelling too fast and the video is of too poor a quality to verify which country's air force the plane belongs to. There is also debate as to whether the residential area was deliberately targeted, or if the missile was fired in error. There have also been conflicting claims over the identity and intention of the aircraft. Fast-moving events such as war mean that misleading imagery will inevitably appear on social media. Misinformation is easily shared, often by those who believe the images to be genuine. Social media users can limit the spread of bad information by taking a few seconds before sharing, to consider whether what they're seeing seems genuine and is from a source that they trust. Checking with multiple trusted sources can help to prevent these images from being widely shared. Read more from Reality Check Send us your questions"
Ukraine conflict: Many misleading images have been shared online,"The Russian invasion of Ukraine has led to false or misleading videos and photographs being posted on social media claiming to be from the conflict. Some of those checked by the BBC include footage from previous conflicts in Ukraine or elsewhere in the world, and images of troops on exercises. Social media platforms such as Twitter seem to be taking a proactive role in confronting misleading content, removing several videos shown to be misleading by fact-checkers and researchers. In the opening hours of the conflict, several videos claiming to be the Russian air force operating over Ukraine were posted and went viral on social media. One clip, which has subsequently been deleted, shows a fighter jet flying over an urban area. It is accompanied by a caption which implies it was filmed in the current Ukraine conflict. Closer inspection, however, reveals that the aircraft is an American-built F-16 Fighting Falcon, which has never been in service in either Russia or Ukraine. A second clip shows formations of fighters and bombers flying over an urban area to the sound of air raid sirens. Checks made by the BBC found that the footage showed preparations for a military parade flypast in 2020. The sound of an air raid siren had been dubbed over the original audio. Another video clip claims to show Russian paratroopers landing near the Ukrainian city of Kharkiv. It's been viewed hundreds of thousands of times on Twitter, but actually first appeared on Russian-language internet in 2016. A fourth clip shared widely on Twitter and YouTube is labelled as showing a Russian jet being shot down over Ukraine. However, BBC journalists have seen this footage before. It's a Libyan government aircraft being shot down by rebels over Benghazi in 2011. Voices on the video can be heard celebrating in Arabic. Some imagery does not show combat operations at all. Footage of an explosion behind some apartment blocks claims to be from the city of Mariupol in south-eastern Ukraine. Among those sharing the clip is the Twitter account of former Ukrainian ambassador to the US, Volodymyr Yelchenko. However, a version of this video was uploaded to TikTok on 29 January, on an account which regularly posts images and film of explosions. Further, as the caption to the video suggests in Russian, it shows the result of a lightning strike on a power station, rather than any military action. Users have also questioned the greenery on the trees, with available data showing average February temperatures in Mariupol at around zero Celsius. Some social media users have shared an image which claims to be of Russian troops raising a flag on the municipal building in the Ukrainian city of Kharkiv today. While the caption is correct - it does show Russians hoisting the flag on that building in Kharkiv - reverse image search tools show that the event took place in 2014, during an earlier period of unrest. Finally, a video shared by one Chinese-language Twitter account, with the caption ""Putin the Great has attacked Ukraine"" is easily recognisable as the explosion of a port building in Beirut in August 2020, which caused more than 200 deaths. Fast-moving events mean that misleading imagery will inevitably appear on social media. It is easily shared, often by those who believe the images to be genuine. Social media users can limit the spread of disinformation by taking a few seconds before hitting the ""share"" button to consider whether what they're seeing seems genuine and is from a source that they trust. Most news organisations go to great lengths to verify footage before using it in their reports, so checking with multiple trusted sources before sharing will help to prevent these images from being widely shared. Read more from Reality Check Send us your questions"
Ukraine conflict: Russian chemical attack claim fact-checked,"Russia is using a familiar tactic to blame an adversary for attacks it has not carried out - on this occasion accusing Ukrainian forces of blowing up a fertiliser storage facility. The purpose of the attack, says Russia's defence ministry, was so that the Ukrainians could then accuse Russian forces of having launched a chemical weapons attack. Russia also claims that the Ukrainian security forces have attempted to set up a second ""false flag"" event, by appealing for bodies to be used to ""simulate a Russian air attack"". There's no evidence that either of these claims is true. Moscow has a history of falsely accusing its opponents of staging ""provocations"" which either never happened at all, or were subsequently carried out by themselves or their allies. A Russian Ministry of Defence briefing on 11 May asserted that Ukrainian forces had ""carried out an explosion of a tanker with fertiliser, presumably ammonium nitrate, which resulted in a cloud of orange smoke that dissipated after some time"". According to Moscow, the aim of the explosion, which occurred in the Kharkiv region, was to accuse Russia of using chemical weapons in order to ""extract additional military aid from the West by the Kyiv regime"". No evidence was given in support of the claim that Ukrainian forces were responsible for the explosion. The location in a video showing the plumes of orange smoke rising into the sky was identified using satellite imagery as Dolgenkoye, an agricultural region near the city of Kharkiv. One Ukrainian media outlet quoted reports on Telegram that the cloud of smoke formed after ""a Russian drone hit an object"". Following the explosion, Oleksiy Arestovych, an adviser to the head of the Ukrainian president's office, said he did not believe it was a Russian chemical weapon attack, although he did add the qualification that he would have to ""clarify such preliminary data"". The BBC was unable to find evidence of Ukrainian officials subsequently accusing Russia of using chemical weapons in this incident. Video and satellite imagery showing the farm buildings hit are consistent with an explosion where facilities containing ammonium nitrate have been set on fire - releasing a characteristic orange-coloured cloud, says Wim Zwijnenburg, an arms researcher at Pax, a Dutch humanitarian organisation. Mr Zwijnenburg says up to 40 similar agricultural facilities have been destroyed in Ukraine since the start of the Russian invasion in February. In recent weeks, Dolgenkoye has been the target of shelling from Russian forces, with satellite imagery showing various fields in the area scarred by shelling. Operation Z, a pro-Russian social-media channel with almost 800,000 subscribers recently claimed doctors in Ukraine had been instructed to take the bodies of women and children to a hospital, from where they would be transported to ""one of the social facilities in the city where an air raid allegedly by Russian aviation will be simulated"". The Telegram post on 12 May said: ""Ukrainian special services are preparing a provocation in the Dnieper (Dnipro) region to accuse the Russian military of killing civilians."" There is no evidence for this narrative, which follows other similar claims by pro-Russian media. In early April, the Russian ministry of defence said UK intelligence operatives were putting civilian bodies in basements in the Sumy region, who could then be portrayed in the West as victims of a ""Russian massacre"". Again, there's no evidence that this happened. Russia has a history of accusing its enemies of staging what it calls ""provocations"", by which it means attacks that can be blamed on Russia. In some cases the claims are to cover for attacks committed by Russia or its proxies; in others the claims refer to future events that might not happen at all. During the Syrian conflict, Moscow repeatedly accused the White Helmet civil defence group, the UK, the US, France and Belgium of preparing chemical attacks that they could then blame on Russia and Syria. However, inquiries into chemical attacks during the war have concluded that the Syrian government was responsible for the attacks on Douma and Ghouta. Prior to the invasion of Ukraine, the BBC reported on a number of false-flag events, including claims that a burned-out and bullet-ridden car was ""evidence"" of Ukrainian attacks on citizens. However, closer inspection of the Russian separatists' own photos of the incident revealed that the bodies inside had surgical incisions consistent with being recently cut open for post-mortem examination, and were already dead at the time of the alleged attack. Read more from Reality Check Send us your questions"
Ukraine crisis: Is Russia staging 'false flag' incidents?,"Russian authorities have cited a number of incidents in eastern Ukraine in order to justify military action. In his speech on Monday, Vladimir Putin said that the Ukrainian authorities ""are not interested in a peaceful solution."" ""On the contrary, they are trying to set up a blitzkrieg in Donbas,"" he said. But the US has warned of Russia faking provocative acts - so-called ""false flag"" incidents which are staged to appear to come from one side in a conflict - in order to create a pretext for action. So what has happened in eastern Ukraine and what do we know about it? The Organisation for Security and Cooperation in Europe has tracked thousands of ceasefire violations in recent days. But there is a growing body of evidence indicating that online rumours have misrepresented some attacks, and that some events may have even been staged. For example, on Friday, a video circulated on a Telegram channel run by Russia-backed separatists. It claimed to show a clash between an ""enemy sabotage group"" and pro-Russian forces in eastern Ukraine. The post said the video showed pro-Ukrainian militants trying to blow up a chlorine tank in the separatist-held area of Donbas. ""The armed formations of Ukraine are purposefully trying to sow fear and panic among the civilian population,"" the post claimed. ""The above facts are direct confirmation of the preparations of the Ukrainian side to unleash hostilities."" The video was then picked up by pro-separatist and Russian news agencies. But open source investigators on social media pointed out several discrepancies which indicated the video was shot at an earlier date and had been manipulated. When inspecting the video's metadata - which can be used to see when a file was created or modified - investigators discovered it had a creation date of 8 February - ten days before it was posted. The video also appears to have audio dubbed over it taken from a YouTube clip posted in 2010 of a military firing range in Finland. It looks highly unlikely that this video shows what the separatists claim it shows. Other stories have created an impression of impending panic in the separatist areas. Also on Friday, leaders of the two separatist areas called for a mass evacuation of residents, saying Ukraine had intensified hostilities and was planning further attacks. Denis Pushilin, head of the self-proclaimed Donetsk People's Republic, published a video announcing the ""emergency"" evacuation. At one point in the video Mr Pushilin says ""today, on 18 February"". But a BBC analysis of the metadata showed that rather being recorded in the heat of the moment, this video was also filmed in advance - two days earlier. Russian state media also reported a ""powerful explosion"" in the centre of the city of Donetsk, near the separatist government headquarters. Pro-Russian separatists alleged it was a car bombing and Denis Sinenkov, chief of the Donetsk separatist police, claimed the vehicle belonged to him. Russian media reported that nobody was hurt in the incident. But questions have been raised about whether the attack was staged. Russian journalist Anton Pustovalov tweeted that the number plate on the destroyed car was taken from a different vehicle - one the head of the separatist police was previously spotted using - in order to then say that a ""terrorist attack was being launched against him"". The BBC is unable to independently verify these claims. The Ukrainian government has denied several of the online rumours. Questions have also been raised about some of the footage shown on Russian state TV as illustration of alleged Ukrainian acts of aggression. The Russian military claimed on Monday that its forces had killed five members of a Ukrainian ""saboteur group"" and destroyed two armoured personnel vehicles following an alleged incursion into Russian territory. Reporting from the site of the alleged clash, Channel One - one of Russia's most popular state TV channels - showed footage of what it described as one of the destroyed Ukrainian vehicles. But Sam Cranny-Evans, a research analyst at the defence think-tank RUSI, says there is ""no compelling evidence to say it's a Ukrainian vehicle"". Both Ukrainians and Russians have produced the BTR-70 vehicles, Mr Cranny-Evans says, and there are different versions of it, but the one shown on Russian TV is similar to the version produced in Russia. Experts with the Ukrainian military portal Militarnyy also said that the vehicle was the Russian version of BTR-70M, which has been produced at a plant in the Russian city of Arzamas since 2006. Footage has emerged from pro-Russian outlets claiming to show a car blown up by a roadside bomb in Donbas. According to one video, inside the charred vehicle are the remains of three dead civilians. Local news reports and posts on separatist Telegram channels said the intended target was a separatist military commander. But a retired bomb disposal expert who has reviewed the footage has cast serious doubts on the allegations. ""There is nothing in those images or videos to support the claims,"" says Pete Norton, a weapons intelligence specialist. The key is the location of the car - in footage shot at the scene, there's no evidence that a bomb had been buried in the road or that the vehicle was travelling at speed when it was destroyed. If, as claimed, the car was destroyed by a roadside device, it's much more likely that the car would have carried on moving instead of appearing to stop next to the site of the explosion. Mr Norton also says graphic up-close images of the bodies inside the cars that surfaced in a YouTube video further undermine the allegations. One of the skulls shows, he says, ""clear indication of having undergone a post-mortem cranial autopsy"" - it's impossible that such a procedure would happen at the scene of an attack. The suggestion, he says, is that cadavers were used in a staged incident. Read more from Reality Check Send us your questions"
Ukraine crisis: Is Russia waging an information war?,"As Russia continues its military build up on Ukraine's border, it's also attempting to control the media narrative - but which parts are misleading? We've looked at some examples of the methods used by pro-Kremlin outlets. Russian media have a history of promoting emotive content and questionable claims that portray Ukraine in a negative light. In one widely-cited example in 2014, Russian state TV repeatedly showed a female refugee claiming that Ukrainian troops had executed a three-year-old boy. No evidence has ever been produced to support her account, and the story was later retracted. The incident became known as the ""crucified boy"" story. More recently, Channel Five, a St Petersburg-based TV channel claimed that the Organization for Security and Co-operation in Europe (OSCE) special monitoring mission to Ukraine had uncovered evidence of illegal organ harvesting in the eastern region of Donbas. The channel alleged that OSCE monitors had found ""mobile crematoriums"" in the Ukrainian army's Joint Forces Operation zone that are ""supposed to be used for the disposal of bodies whose organs had been illegally harvested."" The Russian TV also claimed - without evidence - that the OSCE believed Global Rescue, an international company that provides medical, security, evacuation and crisis management services, ""may be linked to this illegal activity"". But the OSCE told BBC News its monitoring mission ""has neither observed nor reported about any of the claims"". Global Rescue told the BBC that they ""have not been in Ukraine for almost two years"" and had ""no current knowledge of events in Ukraine"". Pro-Kremlin outlets have also recently featured unverified content about Ukraine. In one example, Russian and pro-Kremlin media have reported on an unverified video allegedly showing migrants being shot at by Ukrainian forces on the border with Belarus. The poor-quality clip, which was shot with an infrared camera, was posted to Facebook in early December, prompting several Russian media outlets to cite ""local media reports"" saying that Ukrainian soldiers were shooting at refugees. The soldier on whose Facebook account the video first appeared has said his account had been hacked. A local news website and a non-governmental organisation whose websites featured stories about the alleged incident also claimed they had been hacked. The BBC is unable to independently verify these claims. Suggesting that Ukraine is a country aligned with Nazism has been a regular feature of Russian media coverage. In one example, the Russian Foreign Ministry stressed in posts on social media that Ukraine and the US had voted against a Russia-backed UN resolution condemning the glorification of Nazism. It's true that both countries refused to back the resolution. However, the Russian ministry's posts failed to provide the context for their decisions. Ukraine said its refusal was because it believed the resolution was driven by propaganda motives. The US claimed the document was a ""thinly veiled attempt to legitimise Russian disinformation campaigns."" Both the US and Ukraine stressed their condemnation of Nazism after the vote. Concerns have been raised about links between Ukrainian far-right groups and neo-Nazis - specifically the nationalist Azov battalion that came to prominence at the height of the Ukrainian conflict, and is now a unit within the country's military. However, the far-right remains a small minority in the country - during the 2019 elections, candidates and far-right groups such as Svoboda fell far short of the 5% minimum needed to gain entry into parliament. Since last November there have been big spikes in stories linking Ukraine to Nazism, according to Logically, a technology company which has been tracking hundreds of pro-Kremlin social media accounts. At ""key pivotal moments"", says Brian Murphy of Logically, these ideas have been widely shared across the pro-Russian media landscape. ""We see periods of spikes that tend to overlap with world events and against Russian diplomatic efforts or other things they care about,"" he adds. Russia is ""swift to label its adversaries and victims in Europe as Nazis"", says Keir Giles, an expert on the country, who wrote a Nato report on its information warfare. ""We have seen this not only in Ukraine, but also in Russia's vilification of the Baltic states,"" he says. In recent weeks, some Russian state media outlets have featured misleading headlines about international support for Ukraine based solely on user comments on Western media sites. One article published on the website of the state news agency RIA Novosti in late January claimed that ""British"" readers of the Daily Express supported the view that Ukraine should not be defended because Russia had a stronger military presence in the region than Nato. Another suggested that readers laughed at Ukraine's military potential. There have also been concerns that pro-Kremlin trolls, using fake accounts, have targeted British and other foreign media sites, to advance Russian interests. Research by Cardiff University's Crime and Security Research Institute from last year found that the comment sections of 32 prominent media websites across 16 countries, including the Daily Express, had been targeted by pro-Kremlin trolls. According to researchers, their anti-Western and pro-Russian comments were then used as the basis for news stories in Russian-language media. Activity on accounts spreading pro-Russian propaganda increased dramatically in November last year, according to research from the counter-disinformation group Mythos Labs. During this month, these accounts were tweeting about Ukraine 213 times a day on average. One tactic - as noted by researchers - was to share material from non-Russian voices with views that fall in line with Moscow's stance. One of those whose views have been shared is the Australian journalist John Pilger who, in a recent tweet, accused the US of overthrowing the elected government in Ukraine in 2014. His tweets have been retweeted by 87 accounts identified by researchers as having spread pro-Russian propaganda about Ukraine. Read more from Reality Check Send us your questions"
Ukraine invasion: False claims the war is a hoax go viral,"Nearly two weeks after Russia's invasion of Ukraine, the flow of false or misleading information about the war hasn't let up and now there are some outlandish theories being shared online. Some have begun to circulate claims the war is a hoax, a media fabrication, or has been exaggerated by the West in terms of its scale. We've examined some of them. A video of a young woman and a young man having fake blood applied to their faces has racked up millions of views on multiple platforms. It is shared as supposed evidence that the war in Ukraine is a hoax and civilian victims are actually ""crisis actors"" - people hired to act out scenes from an attack. But the video is unrelated to the war. It was shot in 2020 on the production set of Ukrainian TV series Contamin. The male actor can be seen in behind-the-scenes images from the set tweeted in December 2020. A video of a news reporter in front of multiple body bags has gone viral on several major social networks, and has been spread widely by pro-Kremlin accounts. Seconds into the clip, one of the body bags starts moving, a man removes the cover and is attended to by a photographer. Social media posts claim the video was shot in Ukraine and proves the war is either a hoax or manufactured by ""Western propaganda"". But the claims are false. The video clip is from a climate change protest in Vienna in early February, as reported by Austrian newspaper Osterreich. Organised by ""Friday for Future"" climate activists, the depiction of body bags aimed to highlight the danger of carbon emissions to human life. The same video was shared by conspiracy groups last month with false claims that it showed a Covid ""crisis actor"". A screenshot of a Fox News broadcast showing two Ukrainian men holding what appear to be wooden guns has gone viral. It is often accompanied by false claims that the war in Ukraine is a hoax and the fact that they are not real guns is proof of this. The footage actually dates back to mid-February, before the war began. It was taken during a training course provided by the far-right Azov battalion for civilian volunteers in the Ukrainian city of Kharkiv willing to defend themselves and their communities in case of a Russian invasion. A false tweet - seemingly sent by CNN's verified Twitter account - claims US actor Steven Seagal, who is a dual US-Russian national, has been spotted ""among Russian special forces"" near Ukraine's capital of Kyiv. Along with ordinary users, the tweet has been picked up by influential accounts with huge followings, including US podcast host Joe Rogan, who shared it with his 14 million followers on Instagram. But Mr Seagal is not fighting alongside Russian forces in Ukraine, and the tweet was probably generated by one of the multiple free online tools that enables users to create fake - but authentic-looking - tweets from verified accounts. The actor, 69, told Fox News last week he looked at both countries as ""one family"" and hoped for a ""positive, peaceful resolution"". CNN said the image was fabricated and it had ""never reported anything like this"". Mr Rogan later deleted his Instagram post. A Russian diplomat has shared screenshots showing a fabricated story about a journalist being killed in Ukraine during the Russian invasion. ""How to make a fakeÂ colleagues, beware, the main battle is not in Ukraine, it's with lies and fakes of MSM"" tweeted Dmitry Polyansky, Russia's deputy ambassador to the UN, referring to ""mainstream media"" as MSM. His post was accompanied by a tweet alleging that CNN had reported on the death of ""Bernie Gores"" in Ukraine, after sharing a story about the same man's demise in Afghanistan during the Taliban takeover last year. But the screenshots presented as proof of fabrication come from fake CNN accounts - both of which have since been suspended by Twitter. And the man presented in the images as Bernie Gores is in fact a YouTuber, who is very much alive, called Jordie Jordan. A CNN representative told fact-checkers from Reuters the posts were ""absolute fiction"". Different versions of a video of a large crowd being asked by a director to run and scream in fear have racked up hundreds of thousands of views on multiple platforms. It is claimed the video was leaked from Ukraine, suggesting some of the distressing scenes run by media outlets are actually fabricated. But the video was actually shot in Birmingham's Victoria Square in 2013 for the sci-fi film Invasion Planet Earth, which at the time was titled Kaleidoscope Man. The film's director, Simon Cox, said on Twitter he was ""shocked to see my footage being used like this"". Social media users have been sharing an image allegedly showing the wife of a 'Ukrainian vice-president' who has joined the country's armed forces to fight the Russian invasion. However, Ukraine does not have a vice-president. Another version of the claim doing the rounds on Twitter wrongly suggests that the woman in the picture is Ukraine's first lady Olena Zelenska. Fact-checkers Logically have ascertained that the photograph is an image of a Ukrainian soldier from August 2021. The original photo was taken during a rehearsal for a military parade in Kyiv. Read more from Reality Check Send us your questions"
Ukraine invasion: Misleading claims continue to go viral,"Five days into the Russian invasion of Ukraine, false or misleading videos and images about the invasion continue to go viral. Among the things spreading quickly are old videos being depicted as current - along with claims that pictures such as the one above are old, even when they verifiably come from the present conflict. We've been looking into some of the most viral claims. Claims have circulated online that images and clips from the destruction of a residential building in Chuhuiv, in eastern Ukraine, on Thursday are instead from a 2018 gas explosion in the Russian city of Magnitogorsk. Some also claimed that an image showing a bloodied woman at the scene was from 2018 or that she was a ""crisis actor"" - someone hired to act out scenes from an attack. These claims - made by a variety of pro-Russia and conspiracy-themed accounts - are false. Although at first glance they may bear a superficial resemblance, images from the gas explosion in Magnitogorsk in 2018 do not correspond with images from Thursday's fire in Kharkiv. Early on Thursday, the State Emergency Service of Ukraine posted on Facebook saying they had been informed of ""enemy fire"" resulting in the death of one child and several other injuries. A journalist at the scene posted a video showing the aftermath of the fire, and other sources including photographers at the scene posted images from the same event onto social media. Two photographers took images of the woman, and some of these photos appeared on websites and newspaper front pages all around the world over the weekend. Both photographers confirmed that the images were taken on 24 February - a fact further confirmed by metadata from the images which shows the same creation date. However, other photos and videos posted in recent days don't show what some people say they are depicting. A blurry video claiming to show a Ukrainian girl confronting a Russian soldier has generated 12 million views on TikTok and nearly one million views on Twitter. But it actually shows Palestinian girl Ahed Tamimi, aged 11 at the time, confronting an Israeli soldier after her older brother was arrested in 2012. Twitter has labelled the video ""out of context"", but it continues to rack up views on TikTok. Different versions of a video claiming to show Kyiv residents fighting Russian motorised infantry with Molotov cocktails went viral on multiple platforms over the weekend. It led many users to believe it showed clashes between Ukrainian citizens and Russian forces, and was shared by two British MPs. But the video is old. It was taken during the Euromaidan protests in 2014, which led to the toppling of Ukraine's then-president, Viktor Yanukovych. A dramatic video appearing to show a Ukrainian pilot shooting down a Russian fighter jet was tweeted by Nexta TV, a Belarussian outlet that became a major source for videos from the anti-government protests in Belarus following the disputed 2020 presidential election. The clip shows a jet on fire followed by the sound of a huge blast - and was viewed nearly a million times. However, it is not real. It is a clip from the video game Arma 3 and unrelated to the war in Ukraine. An image showing two children seeing off a convoy of Ukrainian forces into battle has generated millions of engagements - likes and shares. It was tweeted by US Congressman Adam Kinzinger and former Swedish Prime Minister Carl Bildt, among others. But the image was old - it was first published in 2016. It was taken by a volunteer photographer for the Ukrainian defence ministry who was later dismissed over allegations that he had staged some of his combat images. An image of Kyiv Mayor Vitali Klitschko has gone viral on Instagram claiming to show him on the front line. But again, it's an old photo - first posted by Mr Klitschko to his Instagram account in March 2021, showing him at the Desna training centre in the Chernihiv region. Despite this misleading image, it is true that Mr Klitschko has been defending his city alongside Ukrainian troops during this conflict. A video claiming to show Ukrainian President Volodymyr Zelensky in military fatigues giving a morale boost to Ukrainian forces by drinking tea with them on the battlefield racked up nearly 3 million views over the weekend. The video is genuine, but it was shot a week ago, before the invasion began. It was taken in Shyrokyne, when President Zelensky visited frontline soldiers to show support for his troops. Meanwhile, a Telegram account in Mr Zelensky's name drew attention over the weekend, posting messages that urged Ukrainian forces to drop their weapons and surrender. But it was fake. Mr Zelensky has a verified Telegram channel, and has been addressing the nation throughout the conflict via snappy videos posted to his verified social accounts. Read more from Reality Check Send us your questions"
"Ukraine war: 'My city's being shelled, but mum wonÂt believe me'","Oleksandra and her four rescue dogs have been sheltering in the bathroom of her flat in Kharkiv since the shelling began. ""When I heard the first explosions, I ran out of the house to get my dogs from their enclosures outside. People were panicking, abandoning their cars. I was so scared,"" she says. The 25-year-old has been speaking regularly to her mother, who lives in Moscow. But in these conversations, and even after sending videos from her heavily bombarded hometown, Oleksandra is unable to convince her mother about the danger she is in. ""I didn't want to scare my parents, but I started telling them directly that civilians and children are dying,"" she says. ""But even though they worry about me, they still say it probably happens only by accident, that the Russian army would never target civilians. That it's Ukrainians who're killing their own people."" It's common for Ukrainians to have family across the border in Russia. But for some, like Oleksandra, their Russian relatives have a contrasting understanding of the conflict. She believes it's down to the stories they are told by the tightly-controlled Russian media. Oleksandra says her mother just repeats the narratives of what she hears on Russian state TV channels. ""It really scared me when my mum exactly quoted Russian TV. They are just brainwashing people. And people trust them,"" says Oleksandra. ""My parents understand that some military action is happening here. But they say: 'Russians came to liberate you. They won't ruin anything, they won't touch you. They're only targeting military bases'."" While we were interviewing Oleksandra, the shelling went on. The internet connection was weak, so we had to exchange voice messages. ""I've almost forgotten what silence sounds like. They're shelling non-stop,"" she said. But on Russian state TV channels on the same day, there was no mention of the missiles striking Kharkiv's residential districts, of civilian deaths, or of four people killed while queuing for water. Russian state TV channels justify the war by blaming Ukrainian aggression, and continue to call it ""a special operation of liberation"". Any Russian outlet using the words ""war"", ""invasion"" or ""attack"" faces being blocked by the country's media regulator for spreading ""deliberately false information about the actions of Russian military personnel"" in Ukraine. And now a new law has passed through the Russian Parliament that means people who spread ""fake"" information about Russia's military forces could be jailed for up to 15 years. Some Russians have taken to the streets to protest against the war - but these demonstrations were not shown on the main state television channels. Mykhailo, a well-known Kyiv restaurateur, didn't have the time or inclination to watch Russian TV coverage of the invasion. When shelling of Ukraine's capital started, he and his wife were concentrating on how to protect their six-year-old daughter and baby son. At night their children woke up at the sound of explosions and couldn't stop crying. The family made the decision to move to the outskirts of Kyiv and then flee abroad. They travelled to Hungary, where Mykhailo left his wife and children and came back to Western Ukraine to help the war effort. He was surprised not to have heard from his father, who works at a monastery near Nizhny Novgorod in Russia. He called his father and described what was happening. His father replied that this wasn't true; there was no war and - in fact - Russians were saving Ukraine from Nazis. Mykhailo said he felt he knew the power of Russian propaganda, but when he heard it from his father, he was devastated. ""My own father does not believe me, knowing that I'm here and see everything with my own eyes. And my mum, his ex-wife, is going through this too,"" he says. ""She is hiding with my grandmother in the bathroom, because of the bombardment."" Russian media has been tightly controlled for many years and viewers are given an uncritical view of Russia and its actions around the world. ""The state narrative only ever shows Russia as the good guy."" says Dr Joanna Szostek, an expert in Russia and political communications at University of Glasgow. ""Even the tales they tell about World War Two, the Great Patriotic War, Russia has never really done anything wrong. And this is why they won't believe it now."" Most Russians, she says, don't look for other points of view. She believes the one-sided narrative that is highly critical of the West helps explain why Russians can have opposing views to their relatives in neighbouring countries. ""People who criticise Russia have for so long been presented as traitors or foreign agents; critics are all foreign agents working for the West. So you don't even believe your own daughter."" Anastasiya's parents live in a small village 20km (12 miles) away from the rebel-held Donetsk People's Republic. The village is still under the control of Kyiv authorities, but Russian state TV channels are always on in their house. They even have the clock set to Moscow time - a throwback to the Soviet past. So when on 24 February, Anastasiya woke up in Kyiv to the sound of sirens, she knew how her parents would react. 'My mum was the first person I called when I jumped out of bed at five, disoriented. She was surprised I called and sounded really calm, almost casual,"" she says. Anastasiya, a BBC Ukrainian correspondent who moved to Kyiv 10 years ago, heard bombs exploding after waking and was worried about where would be hit next. ""I called my mum again. I told her I was scared. 'Don't worry', she said, reassuringly. 'They [Russia] will never bomb Kyiv'."" But they are already doing it, Anastasiya replied. ""I told her there were casualties among civilians. 'But that's what we had too when Ukraine attacked Donbas!', she said, laughing. For a moment I couldn't breathe. Hearing my mum say this with such cruelty just broke my heart."" Anastasiya believes the image Russian media has created is one of the ""glorified Russian army"" ridding Ukraine from Nazis. For years she avoided political arguments with her parents, but this time she slammed the phone down on her mum. We spoke to Anastasiya when she was travelling away from Kyiv after four nights in a bomb shelter. Her mind was on an uncertain future. ""There are a lot of thoughts in my head now. What will happen to us all? Where is this going? Will I ever come back? Will I ever see my parents again? I still love them deeply, but something inside me has broken and I don't think it can ever be fixed."""
Ukraine war: Fact-checking Russia's biological weapons claims,"Russia has claimed without any evidence that biological weapons are being developed in laboratories in Ukraine with support from the United States. It says material is being destroyed to conceal the country's weapons programme, but the US says this is ""total nonsense"" and that Russia is inventing false narratives to justify its actions in Ukraine. Russia has accused the US and Ukraine of working with ""pathogens of dangerous infections"" in 30 laboratories across the country. Pathogens are microorganisms that can cause disease. Ukraine has dozens of public health laboratories that work to research and mitigate the threats of dangerous diseases. Some of these labs receive financial and other support from the US, the European Union and the World Health Organization (WHO) - as is the case in many other countries. Despite Russian claims that these are ""secret"" labs, details of US involvement can be found on the US embassy's website. Additionally, the US set up its ""Biological Threat Reduction Program"" in the 1990s following the fall of the Soviet Union to reduce the risk from biological weapons that had been left behind in countries including Ukraine. Under this programme certain labs receive funding from the US for modernisation and equipment, but are managed locally, not by the US. The US Department of Defense has been working in partnership with Ukraine's Ministry of Health since 2005 to improve the country's public health laboratories. The US provides technical support and, according to the US Embassy in Ukraine, ""works with partner countries to counter the threat of outbreaks (intentional, accidental or natural) of the world's most dangerous infectious diseases"". There is no evidence that they work to produce biological weapons. In January, the US said its programme does the opposite and in fact aims to ""reduce the threat of biological weapons proliferation"". There have been similar unsubstantiated claims by Russia in the past about US-backed biolabs operating in its neighbouring countries. In 2018, there were reports in Russian state media that untested drugs were given to citizens at a lab funded by the US in neighbouring Georgia. The BBC visited the site and spoke to individuals involved in the research and found no evidence to support the claims. Russian officials have also claimed Ukraine has tried to conceal evidence of prohibited activities. Gen Igor Kirillov said documents uncovered by the Russian military in Ukraine on 24 February - the day the Russian invasion started - ""show that the Ministry of Health of Ukraine has set the task of completely destroying bio-agents in laboratories"". ""The Pentagon knows that if these documents fall into the hands of Russian experts, then it's highly likely that Ukraine and the United States will be found to have violated the Convention on the Prohibition of Biological and Toxin Weapons,"" he said. BBC News has been unable to independently verify the documents cited by General Kirillov. The WHO has told BBC News that it had advised Ukraine to destroy high-threat pathogens stored at the country's public health labs to prevent ""any potential spills"" that would spread disease among the population. The agency said it had collaborated with Ukrainian public health labs for several years to enhance biosafety and biosecurity and help prevent ""accidental or deliberate release of pathogens"". The WHO did not say when the recommendation had been made nor whether it was followed. It also did not provide details of the kind of pathogens stored at Ukrainian labs. However, the US said Ukraine's health ministry had ordered the ""safe and secure disposal of samples"" after Russia's invasion to limit the risk in the event of a Russian military attack. ""There are no indications that Ukrainian labs have been involved in any nefarious activity, or any research or development in contravention of the Biological Weapons Convention,"" says Filippa Lentzos, a biosecurity expert at King's College London. She adds that pathogens stored at biological labs are simply bacteria and viruses, and ""not blueprints or components of biological weapons"". ""The reason they are kept in secure facilities is for bio-safety, so people don't make themselves sick by getting access to them."" The documents listing destroyed pathogens which Russian officials have presented as evidence of nefarious activity at several Ukrainian labs contain no highly dangerous pathogens, microbiologist Yevgeny Levitin told Sibir Realii, a regional outlet of Radio Liberty. ""Everything listed in the published documents are only notional pathogens, with the exception of Clostridium diphtheriae, but even that is not considered highly hazardous"". Gen Kirillov also claimed that the highly militarised nature of the work at Ukrainian bio-labs is confirmed by ""excess number of bio-pathogens"" stored there. But Dr Lentzos says this argument does not follow any logical science. ""The numbers don't really matter, you can easily grow pathogens in a lab"" starting from a small sample. ""These labs publish in openly available literature. They collaborate on many public health projects with global partners,"" says Brett Edwards, a senior lecturer in security and public policy at the University of Bath. ""Devoting considerable sums of money and significant resources to conducting bioweapons research makes no strategic sense for  Ukraine given the difficulty in using them in a conflict,"" argues Dan Kaszeta, a former US serviceman and expert on defence against biological weapons. ""Conventional warfare weapons are much easier and more effective to use for countries like Ukraine,"" he said. Moscow's claims about the Ukrainian labs were echoed by China this week, with foreign ministry spokesperson Zhao Lijian accusing the US of using the facilities to ""conduct bio-military plans"". Similar accusations have also been made by Iranian and Syrian officials. Although the allegations have been echoed elsewhere, ""most of the Russian messaging is meant to target their own population"", according to Milton Leitenberg, a senior research associate at the Center for International and Security Studies at the University of Maryland (CISSM). He said the claims were meant to ""muddy up the minds of Russian citizens"" who did not know they were false and had no access to alternative information. Read more from Reality Check Send us your questions"
Ukraine war: False TikTok videos draw millions of views,"TikTok has emerged as one of the leading platforms for snappy false videos about the war in Ukraine which are reaching millions. With a user base of more than one billion people - more than half of whom are under 30 - TikTok is where many young people have been getting updates about the conflict, as the platform struggles to stem the flow of misleading information. And you don't need to look that hard to find dubious content. According to an investigation by NewsGuard, a website that monitors online misinformation, new users could be recommended false content about Ukraine within 40 minutes of joining the network. While platforms such as Facebook, Instagram and Twitter have been labelling false or misleading viral videos about the war, TikTok seems to be playing catch-up. The company insists it has stepped up its efforts to combat misinformation. Here are some of the most common categories of misleading content the BBC has identified on the platform. From the early days of the war, fake livestreams have drawn some of the highest numbers of views on TikTok. The recipe is simple: a user finds a dramatic video of an old conflict or some military drill, dubs fake audio of a huge explosion or an intense shootout, starts a livestream, and once a sizeable audience tunes in, asks for donations to their channel. One such account had drawn nearly 30 million views by mid-March. All but three of the account's livestreams up to that point were short clips taken from a YouTube video of old Ukrainian military training, dating from 2017. At one point, a fake audio track of gunshots became so popular that it appeared in more than 13,000 videos. Users can react to livestreams by sending the accounts points that can be converted into cash. ""It seems like a lot of the looped scary livestreams were likely created with the hopes of earning money via TikTok's gifting system,"" says Abbie Richards, an independent researcher who creates videos with a focus on the dangers of misinformation. Most of the fake livestreams can be easily found under popular hashtags such as #Ukraine or #UkraineWar. ""The content is intended to blend in with all the other information available on the topic,"" says Ms Richards. Dramatic footage of military video games or computer-generated imagery (CGI) has been regularly used as a substitute for real war videos. Scenes from video games such as Arma 3 and Call of Duty have flooded TikTok. Fake aerial battles, including footage appearing to show fighter jets being shot down, have proved particularly popular. Some accounts try to make the action more realistic and use clips from war films, TV series or real-life games. One video, which was viewed 24 million times, shows a man appearing to drop an explosive item on a tank. It was taken from a video of an Airsoft match - a team combat game similar to paintball - and uploaded to YouTube in January. A separate fake livestream, viewed by 2.3 million users, is made up of CGI footage of missile strikes and has been circulating on the internet since last year. Ms Richards says she has seen instances of users warning in the comments section of such videos that they are taken from video games or are made up. But the people behind the accounts can disable comments - and the warnings disappear. Videos of old conflicts are typically used when a new one is under way. The BBC has seen videos from wars in Libya, Syria and Chechnya being used as though they show the current conflict. A video purporting to show intense fighting between Russian and Ukrainian forces outside a block of flats has racked up 7.7 million views. But the footage was in fact recorded in 2014 in the Chechen capital, Grozny, during a deadly attack by an armed jihadist group. Fake breaking news and live captions were overlaid on the original footage to hide the real source. Some have posted videos from the conflict between Russia and Ukraine in 2014, which could easily be mistaken for the current one, or footage of military exercises or parades in either country. A video of a column of Ukrainian tanks in central Kyiv was presented as if they were on their way to defend the capital against a Russian offensive. It received nine million views. But it was filmed during an independence-day military parade several years ago. And a video of a tank with a Ukrainian flag, speeding down a residential street - viewed four million times - also dated back to the Russia-Ukraine conflict of 2014. Ms Richards says TikTok could address the problem of viral old videos by taking simple measures, such as making the date a video was posted clearer. Like Facebook and Instagram parent Meta, TikTok collaborates with independent fact-checkers, albeit on a smaller scale. But while Facebook and Instagram have been labelling false and misleading content about Ukraine on their platforms, such labels are rare on TikTok. Unlike some of its rivals, TikTok does not provide transparency or analytics tools to academics, researchers and journalists, which Ms Richards says misinformation experts like her have been ""desperately"" demanding for some time. What that means for independent fact-checkers is a time-consuming process of manually researching a huge volume of content on a regular basis. Another issue, according to Ms Richards, is the absence of a community of TikTok users willing to debunk falsehoods on the platform. ""When TikTok fails to ensure the accuracy of information receiving millions of views on its platform, that burden is falling on outside researchers and everyday TikTok users."" A TikTok spokesperson told the BBC: ""We continue to respond to the devastating war in Ukraine with increased safety and security resources to detect emerging threats and remove harmful misinformation. ""To support our efforts to help keep TikTok a safe and authentic place, we've added more resources to our moderation and fact-checking for content in Russian and Ukrainian, including local language experts and partnerships with independent fact-checking organisations."" Have you been affected by what is happening in Ukraine? Or do you have any questions about the conflict? Email us at: haveyoursay@bbc.co.uk. Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways: I accept the Terms of Service In some cases a selection of your comments and questions will be published, displaying your name and location as you provide it unless you state otherwise. Your contact details will never be published. At no time should you endanger yourself or others, take any unnecessary risks or infringe any laws. The BBC retains the right to select from these contributions based on editorial requirements and subject to online terms and conditions and  BBC editorial guidelines. For more information about how the BBC handles your personal data,  see here. If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or comment or you can email us at HaveYourSay@bbc.co.uk. Please include your name, age and location with any submission."
Ukraine war: History is rewritten for children in occupied areas,"When Ukrainian children in occupied areas return to school on 1 September, history lessons will be taught very differently. The BBC has discovered that Ukrainian teachers are being pressured to use the Russian curriculum, which means studying the world according to the Kremlin. Most names in this report have been changed. In the occupied areas of Ukraine's south, administrative and educational buildings - including schools - have been dressed with Russian flags. In Russian-controlled Melitopol, Iryna's 13-year-old child is getting ready to begin the 8th grade. Iryna is worried. ""What really bothers me [about the Russian curriculum] is what they'll be taught in history. It will be taught from the 'other side',"" she says. She's also angered by lessons being held in Russian rather than Ukrainian: ""It's the imposition of their traditions and culture - I do not want the children to be hostages to the situation,"" she said. Users of pro-Russian social media channels have boasted publicly about the attempted erasure of Ukrainian history in occupied areas. There are regular images of Russian forces removing Ukrainian history books from libraries, while Russia's so-called Ministry of Enlightenment has started to provide several occupied areas of Ukraine with Russian textbooks. The BBC has analysed the content of the main school textbooks approved for use by the Ministry of Enlightenment and the differences with their pre-war 2016 and 2022 editions. Most references to Ukraine and Kyiv were removed. Even ""Kyivan Rus"" - the name of a medieval Eastern European state with its capital in Kyiv - was replaced with the name ""Rus"" or just ""Old Rus"". The books include false statements that during the Russian annexing of Crimea in 2014, people came out to ""protect their rights"" after ""radical nationalistsÂ came to power [in Kyiv] with the support of the West"". Meanwhile, in the current version of the textbooks, the number of references to Putin and his achievements has grown. The BBC contacted Russia's Ministry of Enlightenment but did not receive a response. Iryna has considered leaving for Ukraine-controlled areas but doesn't want to abandon her home. She's adamant that she doesn't want her child to learn under the Russian curriculum, but is concerned about keeping her child at home. In principle, children can learn the Ukrainian curriculum online, but parents are concerned about repercussions. ""What if someone informs on us to the new [Russian-installed] authorities or if they start persecuting me and my child for not receiving a Russian education?"" she says. On 19 August, a post on the social media platform Telegram from a local pro-Ukrainian outlet quoted a message allegedly sent to parents from a pro-Russian teacher at a school just outside Melitopol. It said that there will be ""no remote learning on our liberated territory,"" which is how the Kremlin describes occupied areas. Parents who refuse to send their children for in-person teaching would be ""stripped of parental rights"" if they violated the rule multiple times. Meanwhile, parents who agree to send their children to schools in occupied regions of Ukraine will be rewarded. On 24 August, Russian President Vladimir Putin announced the one-off payment of 10,000 rubles (Â£140) to parents, as long as their kids attend a school by 15 September. Pro-Ukrainian teachers have also been hit hard by the war, with some forced to go into hiding, sent for 're-training' and threatened with deportation. Dmytro, a headteacher in Melitopol, had a bustling school of more than 500 pupils before the invasion. Now he's in hiding after being sought out by Russian officials for trying to organise for students to learn the Ukrainian curriculum online. He says he knows teachers who were either forced or decided to cooperate with Russian officials and were sent to Crimea or Russia to be re-trained in a way that's palatable to the Kremlin ideology. ""They were told, 'we're Russia, we're one people. We should be united,' and that these narratives should be passed to children,"" he says. While Dmytro has chosen to stay in Russian-controlled areas, many teachers and parents have decided to leave. Marina, a teacher from Nova Kakhovka in the Kherson region fled at the end of July. Her decision came weeks after armed Russian soldiers and a Russian-installed head of education announced that they were shutting her school because the headteacher would not cooperate with them. She says she has heard of staff shortages in Nova Kakhovka, with some teachers having to teach multiple unrelated subjects. She's worried that the Russian-installed education system will be detrimental to children's sense of identity. ""Their main task is to brainwash and to put their own narratives into a child's mind. They want our children to forget what country they've been living in, to forget who they are."" Leonid Katsva is a Russian author who has taught history to school pupils in Moscow for 42 years. He has seen how history has been misrepresented in Russian textbooks. In the case of the 2014 annexation of Crimea, he says there are ""no mentions of activities of any Russian forces in the peninsula."" In the next school year, Mr Katsva believes books will likely feature a tough assessment of the West's activities. ""Textbooks that are being rigidly moderated now will fully follow the line of Channel One (Russian state TV),"" he says. ""This is a clear evidence that the Kremlin uses school education as a propaganda tool"", says Dmytro from Melitopol. However, he hopes that even with a limited access to an online version of the Ukrainian curriculum, children from his region will still be able to learn the true course of events and have a clearer understanding of Ukraine's recent history. ""Our kids keep asking why their schools have been dressed with a flag of another state. What can I say... Even six-year-old children understand this is not normal."" Additional reporting by Yana Lyushnevskaya"
Ukraine war: How Russia replaces Ukrainian media with its own,"Serhiy Starushko and his journalist colleagues had just finished their morning editorial meeting in early March when Russian military vehicles drew up outside. Within minutes, soldiers stormed through the front doors of the three-storey building, home to a local news station in the occupied Ukrainian port city of Berdyansk. About 50 employees were held hostage for five hours. They had become victims of the real-world fight to control the flow of information. Russian forces are occupying towns, threatening journalists and demanding they spread pro-Kremlin views. Those who refuse are forced to close down their operations. The strategy to replace Ukrainian media with pro-Kremlin press coverage includes capturing transmitter towers and switching off access to national Ukrainian news programmes in areas controlled by Russian forces. Instead, signals for pro-Russian broadcasts are switched on. The State Special Communications Service of Ukraine told the BBC that eight stations are being used to air ""propaganda and disinformation"" to the local population in southern Ukraine. In Berdyansk, Serhiy - a broadcast journalist - was forced to lie on camera and announce he was declaring a war against so-called ''Ukrainian nationalists"". The Russians said they would post this coerced declaration online if he refused to co-operate. ""There were armed people everywhere, a few dozen of them, and I think five to six of them were from the FSB [Russian security service]. They said, 'now it's Russia, and if you want to live, you'll have to co-operate',"" recalls Serhiy, now safely out of the region. For him and his colleagues, ""co-operation"" meant demands to divulge the contacts of local pro-Ukrainian activists and soldiers, and air pro-Russian propaganda. These were not empty threats. ""They took me to a separate room. They started beating me on my head, chest, legs, they were beating me with their knees and palms, so there were fewer bruises,"" he says, recalling the incident. ""Then one of them threatened me with a gun: he held it to my head and genitals. They asked me if I wanted to call my wife to say 'goodbye' to her."" The next day, Russian TV channels showed a video claiming to show the capturing of the station - but the building was already empty when they turned up with cameras. The Russian reporter said the army had to take control of the station because it was spreading ""disinformation about the situation in the city"". It was the last functioning Ukrainian broadcasting company in Berdyansk. Another company was also shut down; national broadcasting has been cut off. Before the invasion, residents in the region could watch dozens of national Ukrainian channels - and a few local ones - but these have since been blocked. Unless they have a satellite dish, citizens in occupied cities now only have access to 24 Russian state TV channels and those channels broadcasting from self-proclaimed republics in eastern Ukraine. ""It's just fake news, I don't even want to watch it. They're brainwashing people,"" says 28-year-old Anna (not her real name), who still lives in Berdyansk. She only watches a music channel and relies on limited access to the internet for reliable news. And now a Crimea-based channel has launched news bulletins for residents in what Russia calls the ""liberated areas"" of the south of Ukraine. There's no mention of a war. Journalists claim ""the life in the region has improved with the arrival of the Russian forces"", and these areas ""have real prospects to get out of the crisis created by the Ukrainian authorities"". ""This is a key part of the Russian strategy. Because information warfare is always a part of a real war,"" explains Natalia Vyhovska, from the Ukrainian Institute of Mass Information. ""They start broadcasting Russian TV, they threaten independent journalists. They come with weapons to their newsrooms, their houses and their parents' houses."" The same tactics were also employed when Crimea was invaded in 2014, according to Reporters Without Borders, an organisation that supports press freedom. But as well as hijacking the airwaves, Russians are producing imposter content - as Mykhailo Kumok, who owns a media company in the southern Ukrainian city of Melitopol, discovered. After the Russian forces took over the city, five armed officers knocked on his door. They confiscated his laptop and computer, and took Mykhailo and his wife to their base - for a ""conversation"". They asked him why his media company called the Russians ""occupiers"". Mykhailo replied, what else should he call them? ""They started talking about so-called 'de-Nazification' and I replied, 'I'm a Jew, I'm a Russian-speaking Jew - so why did you come here? For me, you're nothing but occupiers'."" Mykhailo says he wasn't going to co-operate with the Russians and publish their propaganda, so he decided to shut down both his newspaper and website. But he was shocked when he saw a fake newspaper with his company's branding being delivered to locals. ""That was a fake newspaper with terrible printing, but with our logo. On the first page there was a portrait of the mayor installed by Russia, a small portrait of Putin and a picture showing the occupiers helping those in need."" One of the articles said the Russian authorities would lower gas prices, write off all bank debts and temporarily cancel all tax payments. Unrealistic pledges which echo those made by Russia in annexed Crimea in 2014. ""That time they also promised the residents [they would] write off credit debts, return their savings - but nothing happened,"" says Eugen Fedchenko, chief editor of StopFake, a fact-checking organisation specialising in tackling Russian propaganda and fake news. ""That's why most Ukrainians understand that all these promises are just empty words."" Mykhailo agrees. He is concerned that propaganda such as the fake newspaper may influence older people, but most, he says, will look at what happened when Russian forces invaded Crimea and backed separatist forces in eastern Ukraine in 2014. ""People here won't blindly believe the [Russian] media. First of all, they'll ask themselves, 'has my life become better or worse since the Russian troops invaded?' And life here has certainly become worse - almost for everyone."""
Ukraine war: How TikTok fakes pushed Russian lies to millions,"A Russian propaganda campaign involving thousands of fake accounts on TikTok spreading disinformation about the war in Ukraine has been uncovered by the BBC. Its videos routinely attract millions of views and have the apparent aim of undermining Western support. Users in several European countries have been subjected to false claims that senior Ukrainian officials and their relatives bought luxury cars or villas abroad after Russia's invasion in February 2022. The fake TikTok videos played a part in the dismissal last September of Ukrainian Defence Minister Oleksiy Reznikov, according to his daughter Anastasiya Shteinhauz. The BBC has uncovered nearly 800 fake accounts since July. TikTok says it was already investigating the issue and says it has taken down more than 12,000 fake accounts originating in Russia. Ms Shteinhauz told the BBC she found out about the Russian disinformation campaign when she received a surprising call from her husband while on holiday. ""OK, so now you've got a villa in Madrid,"" he told her, before sending a link to a TikTok video narrated by an AI-generated voice that claimed she had bought a home in the Spanish capital. Ms Shteinhauz initially dismissed the video as a one-off, but the following morning she was sent a similar TikTok clip alleging she had bought a villa on the French Riviera. The videos had been circulating among her friends before finally reaching her husband. Ms Shteinhauz says she does not own property in Spain or France or ""anywhere else outside Ukraine"". BBC Verify also traced the pictures of the houses in Madrid and Cannes to two local property websites and they were both still for sale. Other videos directly targeted her father. The videos sent to Ms Shteinhauz belong to a vast Russia-based network of fake TikTok accounts posing as real users from Germany, France, Poland, Israel and Ukraine. Using a combination of hashtag searches and TikTok's own recommendations, BBC Verify was able to trace hundreds of similar videos targeting dozens of Ukrainian officials. The accounts that posted them used stolen profile pictures, including those of celebrities like Scarlett Johansson, Emma Watson and Colin Farrell. With only a handful of exceptions, they posted just one video each - a tactic TikTok says is new and aimed at evading detection and manipulating the platform's system for recommending videos to users. The effort appeared to have been co-ordinated: sometimes videos were released by different accounts on the same day and featured identical, or very similar scripts. During the investigation, BBC Verify found consistent, circumstantial evidence pointing to a possible Russian origin of the network. This included linguistic mistakes typical of Russian speakers, including some Russian phrases that are not used in other languages. Also, many of the videos contained links to a website previously exposed by Meta as part of a Russian-linked network impersonating legitimate Western news websites. Many of the videos analysed by BBC Verify targeted Mr Reznikov, Ukrainian President Volodymyr Zelensky and other Ukrainian officials, portraying them as obsessed with money and uncaring about ordinary Ukrainians or the war effort. They avoided direct allegations of wrongdoing, but implied politicians had bought luxury property or goods during a time of war - claims that, when checked, always turned out to be false. Ms Shteinhauz believes this steady drip of innuendo played a role in her father's dismissal: ""It affected the life of my dad and his career."" Previously praised as a key figure in Ukraine's efforts to lobby Western countries for arms supplies, Mr Reznikov was sacked from his job as defence minister in September. One video on its own may not have had any effect, Ms Shteinhauz said, but ""when it goes like five times from different parts of the world and from inside the country, it starts to work"". Mr Reznikov lost his job amid an anti-corruption drive and a number of scandals at the defence ministry involving the procurement of goods and equipment for the army at inflated prices. However, he was not personally accused of corruption. Announcing the decision to replace Mr Reznikov, President Zelensky said ""the ministry needs new approaches"". Although he made no mention of corruption in his statement, some in Ukraine welcomed the resignation that followed multiple accusations of corruption which involved Mr Reznikov's subordinates. Roman Osadchuk from the Atlantic Council's Digital Forensic Research Lab, who investigated the network in collaboration with the BBC, said that the fake accounts targeting Ukrainians were trying to undermine their trust in the country's leadership. ""They're trying to make Ukraine less resilient in a way and [make] Ukrainian society stop fighting the Russians,"" he said. Renee DiResta, technical research manager at Stanford Internet Observatory, says the videos' focus on corruption in Ukraine's war effort was particularly aimed at the West. ""All of these different things they're alleging [about Ukrainian officials] as the forms in which the corruption becomes grift, it would be to undermine continued support, particularly by European countries for the Ukrainian war effort."" When we reported our findings to TikTok, a spokesperson said: ""We constantly and relentlessly pursue those that seek to influence our community through deceptive behaviours, and we have removed a covert influence operation originating from Russia, as part of an investigation initiated by TikTok and to which the BBC has contributed."" TikTok said it was still investigating who was behind the network and had found fake videos in two additional languages - Italian and English. Despite TikTok's efforts to shut down the network, in the weeks since BBC Verify reported the accounts, the app has recommended us dozens more videos that appear to be part of the same network. Some of them were posted as recently as late November and covered recent events. Graphics: Katherine Gaynor A Russian propaganda campaign involving thousands of fake accounts on TikTok spreading disinformation about the war in Ukraine has been uncovered by the BBC. Its videos routinely attract millions of views and have the apparent aim of undermining Western support. Users in several European countries have been subjected to false claims that senior Ukrainian officials and their relatives bought luxury cars or villas abroad after Russia's invasion in February 2022. The fake TikTok videos played a part in the dismissal last September of Ukrainian Defence Minister Oleksiy Reznikov, according to his daughter Anastasiya Shteinhauz. The BBC has uncovered nearly 800 fake accounts since July. TikTok says it was already investigating the issue and says it has taken down more than 12,000 fake accounts originating in Russia. Ms Shteinhauz told the BBC she found out about the Russian disinformation campaign when she received a surprising call from her husband while on holiday. ""OK, so now you've got a villa in Madrid,"" he told her, before sending a link to a TikTok video narrated by an AI-generated voice that claimed she had bought a home in the Spanish capital. Ms Shteinhauz initially dismissed the video as a one-off, but the following morning she was sent a similar TikTok clip alleging she had bought a villa on the French Riviera. The videos had been circulating among her friends before finally reaching her husband. Ms Shteinhauz says she does not own property in Spain or France or ""anywhere else outside Ukraine"". BBC Verify also traced the pictures of the houses in Madrid and Cannes to two local property websites and they were both still for sale. Other videos directly targeted her father. The videos sent to Ms Shteinhauz belong to a vast Russia-based network of fake TikTok accounts posing as real users from Germany, France, Poland, Israel and Ukraine. Using a combination of hashtag searches and TikTok's own recommendations, BBC Verify was able to trace hundreds of similar videos targeting dozens of Ukrainian officials. The accounts that posted them used stolen profile pictures, including those of celebrities like Scarlett Johansson, Emma Watson and Colin Farrell. With only a handful of exceptions, they posted just one video each - a tactic TikTok says is new and aimed at evading detection and manipulating the platform's system for recommending videos to users. The effort appeared to have been co-ordinated: sometimes videos were released by different accounts on the same day and featured identical, or very similar scripts. During the investigation, BBC Verify found consistent, circumstantial evidence pointing to a possible Russian origin of the network. This included linguistic mistakes typical of Russian speakers, including some Russian phrases that are not used in other languages. Also, many of the videos contained links to a website previously exposed by Meta as part of a Russian-linked network impersonating legitimate Western news websites. Many of the videos analysed by BBC Verify targeted Mr Reznikov, Ukrainian President Volodymyr Zelensky and other Ukrainian officials, portraying them as obsessed with money and uncaring about ordinary Ukrainians or the war effort. They avoided direct allegations of wrongdoing, but implied politicians had bought luxury property or goods during a time of war - claims that, when checked, always turned out to be false. Ms Shteinhauz believes this steady drip of innuendo played a role in her father's dismissal: ""It affected the life of my dad and his career."" Previously praised as a key figure in Ukraine's efforts to lobby Western countries for arms supplies, Mr Reznikov was sacked from his job as defence minister in September. One video on its own may not have had any effect, Ms Shteinhauz said, but ""when it goes like five times from different parts of the world and from inside the country, it starts to work"". Mr Reznikov lost his job amid an anti-corruption drive and a number of scandals at the defence ministry involving the procurement of goods and equipment for the army at inflated prices. However, he was not personally accused of corruption. Announcing the decision to replace Mr Reznikov, President Zelensky said ""the ministry needs new approaches"". Although he made no mention of corruption in his statement, some in Ukraine welcomed the resignation that followed multiple accusations of corruption which involved Mr Reznikov's subordinates. Roman Osadchuk from the Atlantic Council's Digital Forensic Research Lab, who investigated the network in collaboration with the BBC, said that the fake accounts targeting Ukrainians were trying to undermine their trust in the country's leadership. ""They're trying to make Ukraine less resilient in a way and [make] Ukrainian society stop fighting the Russians,"" he said. Renee DiResta, technical research manager at Stanford Internet Observatory, says the videos' focus on corruption in Ukraine's war effort was particularly aimed at the West. ""All of these different things they're alleging [about Ukrainian officials] as the forms in which the corruption becomes grift, it would be to undermine continued support, particularly by European countries for the Ukrainian war effort."" When we reported our findings to TikTok, a spokesperson said: ""We constantly and relentlessly pursue those that seek to influence our community through deceptive behaviours, and we have removed a covert influence operation originating from Russia, as part of an investigation initiated by TikTok and to which the BBC has contributed."" TikTok said it was still investigating who was behind the network and had found fake videos in two additional languages - Italian and English. Despite TikTok's efforts to shut down the network, in the weeks since BBC Verify reported the accounts, the app has recommended us dozens more videos that appear to be part of the same network. Some of them were posted as recently as late November and covered recent events. Graphics: Katherine Gaynor"
Ukraine war: How a school survivor became a target of Russian disinformation,"After an air strike hit a school in Chernihiv, a video of a bloodied survivor went viral on Ukrainian social media. But soon her story was hijacked by pro-Kremlin accounts, including one promoted by the Russian Foreign Ministry, which falsely accused her of being a fake. ""There was no whistle, rustling or sound of shelling,"" Tania says. ""It just hit the building and suddenly everything went dark. The building collapsed."" Tania was caught up in an air strike in early March. She was helping sort clothes for a humanitarian aid drive in school number 21 in Chernihiv, north of Kyiv, when a missile hit the building. Although authorities did not name the school, the BBC was able to confirm the specific building via images posted on the Telegram social media app. Local authorities reported at the time that Russian aircraft had hit two schools that day, leaving nine people dead and four injured. Tania was knocked out by the blast. She says when she regained consciousness, she realised she was alive and could walk. She stood up, looked around and saw people in a state of panic. She also noticed bodies lying on the floor, including that of a woman who had been standing next to her just minutes before the strike. Scared, she fled to her home. There, she posted a video on Instagram - still covered in blood and with visible injuries on her face - in which she explained what had happened. ""I was at school number 21 when the explosion happened,"" she says in the clip. ""I survived. Good luck to everyone. I hope you are luckier than me. ""Why am I recording this story? It's just that there were many children at that school. I don't know whether they have survived. Just send this video to all your Russian friends."" In a matter of hours, her video went viral in Ukraine. The clip garnered tens of thousands of views on Instagram alone, and was picked up by a number of Ukrainian news websites. Tania told the BBC that she had acquired thousands of new followers and received dozens of messages on Instagram - some supportive, some threatening. People from Russia were among those who wrote to her. Some of them apologised for the actions of the Russian authorities. But others did not believe her story and called her ""fake"". Soon Tania's friends started sending her screenshots from Russian and Belarusian media outlets, in which her video was described as a fabrication. These reports described her as a ""pupil"", claimed that the wound on her face was not real, and alleged the blood on her face did not look natural and that she was behaving too ""normally"" for a person who had just survived a bombing. The claims were false. Tania is no ""pupil"" - she is 29 years old and worked as a waitress before the invasion started. Pictures she took of herself on the second day after the attack - shared with the BBC - clearly show facial injuries consistent with the footage she posted on Instagram. As for her seemingly calm composure, Tania told the BBC that she was in ""deep shock"" when she recorded the video. ""I was calm and wasn't scared. Just shocked,"" she says. ""A few hours after that, I was in hysterics. For the next two days, I couldn't eat or sleep, I just cried. It was a nightmare."" Some Russian reports also claimed schools across Ukraine stopped operating at the beginning of the invasion, and claimed there could not have been many children in the school at the time of the strike. But the school was being used as a collection point for humanitarian aid and considered a safe place by local residents, Tania says, some of whom had brought their children there. Officials confirmed that account. Vyacheslav Chaus, the head of the Chernihiv regional state administration, told us the school's basement was open so that local civilians could hide in case of shelling. Tania is one of a number of Ukrainian civilians who have been falsely accused by Russian media outlets - and even the Russian government - of somehow faking attacks. Among the key sources spreading false claims about Tania was an account called War on Fakes, whose ""debunk"" of her video has so far been viewed more than 400,000 times on Telegram. Promoted by the Russian Foreign Ministry and embassies on social media, it is a multilingual ""fact-checking"" project that claims to provide ""unbiased information about what is happening in Ukraine"". While some of its fact-checks are genuine, it includes false information such as the allegations against Tania. And its content repeats Moscow's talking points on the war: claims that Ukraine is the aggressor, that Ukrainians are committing widespread war crimes, and that any evidence of Russian wrongdoing is fabricated. Stories either attributed to War on Fakes or echoing its arguments have appeared in pro-Kremlin communities on Russian social network VK, a number of regional Russian media outlets, at least one news agency and Belarusian state TV. Tania says she felt not anger but sadness when she saw the false claims about herself circulating online. ""I felt sad and sorry for these people who believe all these lies. They are so scared to admit this war is real and all these things are happening, so it's easier for them to find excuses or reasons not to believe in it or call my story a fake. It's easier for them to believe that Ukraine is a theatre and Ukrainians are actors."" She has left Ukraine for Poland. She now has a scar on her face. Her eyesight was damaged by the bombing and she says she's suffering from post-traumatic stress. ""I have flashbacks of the attack even when I'm in Poland,"" she says. ""Frankly, I don't think I'm ready to go back home."""
Ukraine war: Kremenchuk shopping centre attack claims fact-checked,"Within hours of the attack on a shopping centre in the central Ukrainian city of Kremenchuk, false and unproven claims began circulating online. Stories were spread by Russian Telegram channels and by Dmitry Polyanskiy, Russia's deputy ambassador to the United Nations. They included rumours that the attack was ""false"" or ""staged"" - and were repeated on Russian television. On Tuesday, Russia's defence ministry released a statement claiming the shopping centre was ""non-functioning"" and that the bombing of a nearby ammunitions dump sparked a secondary fire at the centre. Those claims were denied by Ukrainian officials. What's the truth? This claim is false. BBC reporters on the ground have spoken to shoppers and employees who were inside the building at the time of the attack. Multiple posts listing details of missing people who were either working at the shopping centre on the day or went shopping there, were published in a local Telegram channel in the hours after the attack. One pro-Kremlin ""fact-checking"" channel suggested that no photographs from inside the shopping centre had been posted on Instagram since March. However, a woman who lives in a nearby village and regularly goes shopping in Kremenchuk, told the BBC that the shopping centre had been ""constantly open"" and her family had visited it at least once a week. She also shared video she had taken at the shopping centre from 25 June, showing open shops and people walking inside the building. Other, similar footage posted online appears even more recent - including a YouTube video apparently filmed just a day before the attack, also showing shoppers and businesses open as normal. Some Telegram channels claimed there were no women or children at the shopping centre -  implying that the building had been turned into a military facility. That claim is false, according to several eyewitness accounts and online videos. The Russian Defence Ministry claimed a strike on an arms storage facility detonated ammunition which set the shopping centre on fire. ""Western-manufactured weapons and ammunition stockpiled in the warehouse to be sent to a Ukrainian military grouping in Donbas were hit with a high-precision strike,"" the ministry said. Ukrainian officials have denied there was a weapons depot nearby. CCTV footage captured near a pond roughly 600 metres north of the shopping centre, on the other side of a factory building, shows two missile strikes in the area. Matching the exact spots where the two missiles land in the CCTV video with aerial images of the area, it appears one missile hit close to the eastern end of the shopping centre, while the other struck the northern end of the factory, near the southern edge of the pond. The factory mentioned by the Russian defence ministry is located roughly 300 metres north of the shopping centre. The buildings are separated by a wall, vegetation and rail tracks, making the claim that ""secondary explosions"" caused a large fire with multiple casualties in the shopping centre unlikely. According to the Ukrainian online publication Kyiv Independent, a press officer of the regional administration confirmed that the machinery plant had been hit, injuring two individuals. Svitlana Rybalko, from the regional State Emergency Service, denied there were weapons stored at the facility.""It's a place for making road equipment, machines for road construction,"" she told the BBC. ""There's also a greenhouse nearby where workers grow cucumbers."" Contains disturbing scenes. Satellite images of the area, along with a video released by Ukrainian President Volodymyr Zelensky provide further evidence that these were the locations of the strikes. This video also supports an earlier Ukrainian assessment that the missile was an air-launched Kh-22 weapon. This is a medium-range cruise missile developed in the 1960s, originally to attack large warships. There is also a land-attack variant. The weapon is large, liquid-fuelled and supersonic - but inaccurate by today's standards. The relatively shallow angle of impact further points to its cruise nature. A ballistic missile follows a much more parabolic path. Ukraine says the missiles were launched from bombers in the Kursk region of Russia, some 300km (185 miles) away. This claim contradicts the official Russian defence ministry statement - even though top diplomats such as Mr Polyanskiy, the deputy UN ambassador, described the Kremenchuk attack as ""a new Bucha-style Ukrainian provocation"" on Twitter. There's simply no evidence - nor has any been offered - that Ukraine bombed the shopping centre, or that the attack was ""staged"". It's the latest example of a common tactic used by supporters of the Russian government - throwing multiple, conflicting, evidence-free narratives out in the immediate aftermath of an attack. The claim echoes other, debunked false assertions by Russia and its supporters, for instance that the attack on a maternity hospital in Mariupol and the killings of civilians in Bucha were somehow faked or staged. In a Twitter message, Mr Polyanskiy said the attack ""will be used by Ukraine to attract as much attention as possible through promoting [a] false version of what happened"" and ""my tweet doesn't contradict the explanation provided by Russian [Ministry of Defence]"". Reporting by: Olga Robinson, Shayan Sardarizadeh, Daniele Palumbo, Chris Partridge, Joshua Cheetham and Nick Beake. What claims do you want BBC Reality Check to investigate? Get in touch Read more from Reality Check"
Ukraine war: Russians kept in the dark by internet search,"In many places, searching the web is a gateway to a wider world of information, but in Russia, it is part of a system that helps trap people in an alternative reality. Shortly after 20 people were killed in a Russian missile attack on the Ukrainian city of Kremenchuk in June, Lev Gershenzon - a former manager at Russian tech company Yandex - typed the city's name into its search engine to find out more. The results he got back shocked him. ""The sources that ranked at the top of the page were strange and obscure,"" he told the BBC. ""There was one blog by an unknown author claiming that the information about casualties was fake."" The Kremlin keeps a tight grip on the country's media, especially TV, which glorifies Russia's invasion of Ukraine as a mission of liberation and dismisses reports of atrocities as fake. The internet in Russia was for a long time the main space for alternative sources of information, but after starting the war in February the Kremlin launched a crackdown on independent online media. Digital rights watchdog Roskomsvoboda estimates that - in the first six months of the conflict - nearly 7,000 websites were blocked in Russia, including those of major independent media and human rights groups. BBC Monitoring wanted to find out what people in Russia see when they search the web now. We used a virtual private network (VPN), so it would appear as though we were searching the web from Russia. Between June and October, we carried out dozens of searches on Russia's top search engines - Yandex and Google - for key words relating to the war in Ukraine. Yandex is one of the big stars of Russia's homegrown tech scene. It runs the country's largest search engine and presents itself as independent of the authorities. According to the company's own statistics, it handles about 60% of web searches done in Russia - with Google responsible for about 35%. From the start of the war, Yandex faced criticism for the pro-Kremlin slant of the sites and stories featured on its news aggregator, Yandex News. In September, it sold Yandex News to the Kremlin-linked owner of social network VK. But Yandex retains control of its general search engine, and here, the results of BBC Monitoring's experiment reveal an alternative reality dominated by Russian propaganda about the war. One topic searched for was Bucha, the Ukrainian town where hundreds of civilians were killed by Russian troops before they withdrew in early April. The deaths shocked the world, but in Russia, many seem to believe the state media line that they were staged by Ukraine. When we searched for Bucha on Yandex - using a VPN as if based in Russia and typing in Russian - the top page of results made it look like the killings had never taken place. Three of the nine top results were anonymous blog posts denying the involvement of Russian troops. The remaining six contained no independent reporting of the events. The discovery of mass burial sites in October in the town of Lyman, after it was retaken from Russian forces, was also reflected on Yandex from a pro-Kremlin viewpoint. Several pro-Kremlin news stories blaming the deaths on Ukrainian ""Nazis"" were in the top 10 results. Searching for ""Ukraine"" on the search engine in the same way also produced results heavily slanted towards the Kremlin's narrative. Four of the nine first-page results linked to pro-Kremlin news outlets, and none to independent media. Glimpses of independent reporting only occasionally appeared in Yandex search results with links to Wikipedia articles or YouTube. Asked to comment by the BBC, Yandex said its search in Russia ""displays content [that is] available on the internet, excluding sites which are blocked by the [media] regulator"". It denied there was any ""human interference"" in ranking results. So what happens if you switch from Yandex to Russia's second-largest search engine, Google? Searching on the US-based company's search engine with our VPN set to a Russian location, and typing in Russian, still brought up pro-Kremlin media outlets, but mixed with some independent and Western sources. Even more independent sources appeared when we searched Google with the VPN set as though we were in the UK, although still typing in Russian. There were plenty of results covering either the civilian deaths or the war. Google told the BBC that its search ""reflects the content that is available on the open web"", and its algorithm is trained to ""prominently surface high quality information from reliable sources"". So why did Yandex's search results differ so much from Google's? Several specialists the BBC spoke to said they believed it was unlikely that large-scale manipulation was taking place from inside Yandex, as this would be too complicated to do. One possibility is that the company's results are simply being skewed by the Kremlin's crackdown on independent reporting of the invasion. Because thousands of websites have been blocked by Russia's media regulator, huge swathes of information do not appear in Yandex's search results. ""They [the authorities] can cleanse the results completely,"" Alexei Sokirko, a former Yandex developer, told the BBC. At the same time, the Kremlin is spending heavily to make sure web content is created reflecting its own worldview, he added. Search experts Guido Ampollini and Mykhailo Orlov, from the marketing firm GA Agency, say this will also potentially skew the results users see in Yandex, as the search engine's algorithm may reward pro-Kremlin material with higher rankings and down-rank alternative views. Could using a VPN help Russians find out more about the war in their own language? If they are using Yandex to find that information, then not necessarily. When searching its engine with the VPN set to the UK and using Russian, the odd independent source appeared, but pro-Kremlin sources still dominated. Mr Ampollini and Mr Orlov say the pro-Kremlin content appears carefully tailored to make the algorithm rank it higher. And with one obscure news site that featured prominently in results, they also found signs of possible web traffic manipulation. A large number of potentially artificial links to the site were found from external websites - a common technique to improve a site's search ranking. Finally, Yandex may be reflecting the fact Russian users themselves are choosing pro-Kremlin content. Search specialist Nick Boyle, of digital marketing agency The Audit Lab, told the BBC that - unlike Google - Yandex takes into account user behaviour. This means, for example, that a website's search ranking may be affected by the number of visits to it. Google says this is not the case for its search engine. The GA Agency team thought it possible that many Russians are clicking on content that portrays their military positively, prompting Yandex's algorithm to reward it with higher rankings. Lev Gershenzon believes that, no matter how the Kremlin's dominance of Yandex's search results has been achieved, it means that anyone wanting to question what they hear on state media will only get information confirming the official view. ""You open the Yandex main page and you start [searching for the] Kremenchuk [attack] to receive some alternative picture from other sources, and all you get is that 'yeah ok, you're right, it's fake' - and that's it,"" he told the BBC. ""It's like a double punch."" In many places, searching the web is a gateway to a wider world of information, but in Russia, it is part of a system that helps trap people in an alternative reality. Shortly after 20 people were killed in a Russian missile attack on the Ukrainian city of Kremenchuk in June, Lev Gershenzon - a former manager at Russian tech company Yandex - typed the city's name into its search engine to find out more. The results he got back shocked him. ""The sources that ranked at the top of the page were strange and obscure,"" he told the BBC. ""There was one blog by an unknown author claiming that the information about casualties was fake."" The Kremlin keeps a tight grip on the country's media, especially TV, which glorifies Russia's invasion of Ukraine as a mission of liberation and dismisses reports of atrocities as fake. The internet in Russia was for a long time the main space for alternative sources of information, but after starting the war in February the Kremlin launched a crackdown on independent online media. Digital rights watchdog Roskomsvoboda estimates that - in the first six months of the conflict - nearly 7,000 websites were blocked in Russia, including those of major independent media and human rights groups. BBC Monitoring wanted to find out what people in Russia see when they search the web now. We used a virtual private network (VPN), so it would appear as though we were searching the web from Russia. Between June and October, we carried out dozens of searches on Russia's top search engines - Yandex and Google - for key words relating to the war in Ukraine. Yandex is one of the big stars of Russia's homegrown tech scene. It runs the country's largest search engine and presents itself as independent of the authorities. According to the company's own statistics, it handles about 60% of web searches done in Russia - with Google responsible for about 35%. From the start of the war, Yandex faced criticism for the pro-Kremlin slant of the sites and stories featured on its news aggregator, Yandex News. In September, it sold Yandex News to the Kremlin-linked owner of social network VK. But Yandex retains control of its general search engine, and here, the results of BBC Monitoring's experiment reveal an alternative reality dominated by Russian propaganda about the war. One topic searched for was Bucha, the Ukrainian town where hundreds of civilians were killed by Russian troops before they withdrew in early April. The deaths shocked the world, but in Russia, many seem to believe the state media line that they were staged by Ukraine. When we searched for Bucha on Yandex - using a VPN as if based in Russia and typing in Russian - the top page of results made it look like the killings had never taken place. Three of the nine top results were anonymous blog posts denying the involvement of Russian troops. The remaining six contained no independent reporting of the events. The discovery of mass burial sites in October in the town of Lyman, after it was retaken from Russian forces, was also reflected on Yandex from a pro-Kremlin viewpoint. Several pro-Kremlin news stories blaming the deaths on Ukrainian ""Nazis"" were in the top 10 results. Searching for ""Ukraine"" on the search engine in the same way also produced results heavily slanted towards the Kremlin's narrative. Four of the nine first-page results linked to pro-Kremlin news outlets, and none to independent media. Glimpses of independent reporting only occasionally appeared in Yandex search results with links to Wikipedia articles or YouTube. Asked to comment by the BBC, Yandex said its search in Russia ""displays content [that is] available on the internet, excluding sites which are blocked by the [media] regulator"". It denied there was any ""human interference"" in ranking results. So what happens if you switch from Yandex to Russia's second-largest search engine, Google? Searching on the US-based company's search engine with our VPN set to a Russian location, and typing in Russian, still brought up pro-Kremlin media outlets, but mixed with some independent and Western sources. Even more independent sources appeared when we searched Google with the VPN set as though we were in the UK, although still typing in Russian. There were plenty of results covering either the civilian deaths or the war. Google told the BBC that its search ""reflects the content that is available on the open web"", and its algorithm is trained to ""prominently surface high quality information from reliable sources"". So why did Yandex's search results differ so much from Google's? Several specialists the BBC spoke to said they believed it was unlikely that large-scale manipulation was taking place from inside Yandex, as this would be too complicated to do. One possibility is that the company's results are simply being skewed by the Kremlin's crackdown on independent reporting of the invasion. Because thousands of websites have been blocked by Russia's media regulator, huge swathes of information do not appear in Yandex's search results. ""They [the authorities] can cleanse the results completely,"" Alexei Sokirko, a former Yandex developer, told the BBC. At the same time, the Kremlin is spending heavily to make sure web content is created reflecting its own worldview, he added. Search experts Guido Ampollini and Mykhailo Orlov, from the marketing firm GA Agency, say this will also potentially skew the results users see in Yandex, as the search engine's algorithm may reward pro-Kremlin material with higher rankings and down-rank alternative views. Could using a VPN help Russians find out more about the war in their own language? If they are using Yandex to find that information, then not necessarily. When searching its engine with the VPN set to the UK and using Russian, the odd independent source appeared, but pro-Kremlin sources still dominated. Mr Ampollini and Mr Orlov say the pro-Kremlin content appears carefully tailored to make the algorithm rank it higher. And with one obscure news site that featured prominently in results, they also found signs of possible web traffic manipulation. A large number of potentially artificial links to the site were found from external websites - a common technique to improve a site's search ranking. Finally, Yandex may be reflecting the fact Russian users themselves are choosing pro-Kremlin content. Search specialist Nick Boyle, of digital marketing agency The Audit Lab, told the BBC that - unlike Google - Yandex takes into account user behaviour. This means, for example, that a website's search ranking may be affected by the number of visits to it. Google says this is not the case for its search engine. The GA Agency team thought it possible that many Russians are clicking on content that portrays their military positively, prompting Yandex's algorithm to reward it with higher rankings. Lev Gershenzon believes that, no matter how the Kremlin's dominance of Yandex's search results has been achieved, it means that anyone wanting to question what they hear on state media will only get information confirming the official view. ""You open the Yandex main page and you start [searching for the] Kremenchuk [attack] to receive some alternative picture from other sources, and all you get is that 'yeah ok, you're right, it's fake' - and that's it,"" he told the BBC. ""It's like a double punch."""
Ukraine war: The stolen faces used to promote Vladimir Putin,"Indian influencer ER Yamini has never tweeted in her life - she prefers to cultivate her big fan bases on Instagram and YouTube. But in early March, a Twitter account using her picture tweeted: ""#IStandWithPutin. True Friendship"" accompanied by a video showing two men hugging - one representing India, the other, Russia. Yamini says she doesn't support either country in the Russia-Ukraine war, and worries about her fans. ""If they see that tweet, what will they think about me?"" she asks, ""I wish they wouldn't use my photo on that profile."" The fake account is part of a network promoting Russian president Vladimir Putin on Twitter, which used the hashtags #IStandWithPutin and #IStandWithRussia on 2 and 3 March. This led to trending topics in different regions - particularly in the global south, apparently showing support for the war, in countries including India, Pakistan, South Africa and Nigeria. Part of the activity tracked was organic - in other words, produced by real people - reflecting genuine support in some countries for Mr Putin and Russia. But many other profiles appear to have been inauthentic. They retweeted messages in high quantities, produced few original messages, and were created very recently. ""They were likely produced by bots, fake profiles or compromised accounts, artificially amplifying support for Putin in these countries,"" says Carl Miller, co-founder of CASM Technology, a company that researches online harms and disinformation. It tracked 9,907 profiles promoting support for Russia on 2 and 3 March, in several different languages. CASM found more than 1,000 of those accounts had spam-like characteristics. The BBC investigated hundreds of these seemingly inauthentic profiles. Our research confirms Mr Miller's thinking - they try to pass as genuine, but in fact are fake. Through reverse image searching, we have found that pictures used by these profiles were copied from celebrities, influencers and ordinary users, who had no idea their images were being used to support Russia in its war against Ukraine. We have not been able to determine who set up the accounts, or whether they have any connection to the Russian government. An account named Preety Sharma, for example, states in its bio that they are a ""model and entrepreneur"" originally from India, now in Miami. It was created on 26 February, two days after Russia's invasion. ""Putin is a good person"", says one of its retweets. But the woman depicted in the account's profile picture is in the other side of the world. Nicole Thorne is an Australian social media influencer who has 1.5 million followers on Instagram, and only occasionally uses her original profile on Twitter. Another account tries to pass as Indian singer Raja Gujjar. Its first tweet was posted on 24 February, the first day of the invasion. And all 178 posts by the account are retweets, a strong indicator of automation. The BBC contacted Ms Thorne and Mr Gujjar, and both confirmed these accounts weren't theirs. Although very bot-like, not all accounts investigated were inauthentic. Take one profile, created in February 2022 with tweets starting on 2 March. It has no followers. Reverse searching its profile picture, the BBC came across a young Indian man's account on LinkedIn. But it's authentic, and set up by Senthil Kumar, an aeronautical engineer. We asked why he created an account just to retweet pro-Russia messages. ""Usually, I open Twitter and see what is trending. So I saw these posts and just retweeted them,"" he said. He believes Russia has supported India in the past, and Indians should now support Russia. And his profile was new, he said, because he had forgotten the password of his previous account. The accounts tweet a mixture of criticism of Western countries, express solidarity between the so-called Brics countries (Brazil, Russia, India, China, South Africa), and offer direct support to Mr Putin. ""We default to the idea that information campaigns will be directed to the West. Yet none of the accounts were addressing the West nor claimed to be from the West,"" says Mr Miller. To identify what might be a group of inauthentic accounts, he adds, researchers look at accounts' creation dates, an ""inhuman"" tweeting pattern (such as an account tweeting 24 hours a day), and the range of topics tweeted. ""None of these things are a smoking gun, but they all add up together to allow us to see if a given community of accounts look like it's suspicious,"" says Mr Miller. The lack of a genuine profile picture can also be a telltale sign. Out of a sample of 100 accounts tracked by CASM, the BBC found that 41 had no profile pictures. Another 30 had illustrations or pictures of personalities like Mr Putin or Facebook chief executive Mark Zuckerberg. Only a quarter had pictures depicting people - and some of those were stolen. Twitter prohibits the impersonation of ""individuals, groups, or organisations to mislead, confuse, or deceive others"". The company told us that since the war began, it has removed more than 100,000 accounts for violations of its platform manipulation and spam policy, including the suspension of dozens of accounts connected with the hashtags #IStandWithRussia and #IStandWithPutin. Twitter says it has investigated and suspended hundreds of the accounts pointed out by CASM's research and sent to the platform by the BBC, including 11 out of 12 accounts specifically flagged by us for using other people's profile pictures. But it said it found no evidence of widespread co-ordination to artificially amplify sentiment around the Ukraine war."
Ukraine war: Viral conspiracy theories falsely claim the war is fake,"The first anniversary of Russia's full-scale invasion of Ukraine has led to a spike in false claims about the war on social media, with some posts gaining millions of engagements. A number of US right-wing accounts with large followings posted a series of baseless claims that suggested the entire Ukraine war might be a hoax perpetrated by Western media and governments. Those spreading the most viral claims included some who had previously been suspended from Twitter and allowed back onto the platform following Elon Musk's takeover. One false claim that has been gaining traction on Twitter and elsewhere suggested that the entire war has somehow been faked. As evidence, some prominent right-wing accounts in the US cited the supposed lack of footage from the front line. A commentator complained about ""the lack of war footage"" in a viral post, saying it ""smacks of a scam"". Another Twitter influencer with 1.4 million followers claimed there was ""no footage"" and ""no detailed updates"" of the war. That post was later shared by former US national security adviser Michael Flynn, who added: ""I double dare anyone to say he is wrong."" However, the war in Ukraine has been well-documented. Alongside eyewitness accounts, there's been ample footage from the Ukrainian front line filed by the BBC and other global broadcasters who have also examined false narratives about some of the conflict's key events. There's also evidence from governments and agencies around the world that confirms that the war is real. From its outset, social media has been full of videos of the war, many of which have been verified as genuine by journalists. Two days after Russia's invasion, footage of a high-rise apartment building in Kyiv with a huge hole in it after it was hit by a missile was widely shared around the world. Reporters covered the aftermath of the damage in detail from the scene of the incident. In the past few days, images of the block, which has since been repaired and partially reconstructed, went viral again on social media. The image led to claims that either the block had never been hit, or that the entire war is a hoax, because - the argument went - it would be impossible to restore a building during an ongoing conflict. A right-wing podcaster and anti-vaccine activist, whose previously banned account was recently reinstated by Twitter, was among those that shared the claim. However, apart from regular Russian missile attacks, Kyiv has not been on the frontline of the war since late March 2022, when Russian forces withdrew from the city and its surroundings to focus on eastern Ukraine. The process of the block's repair and reconstruction began in May of last year, and has been reported in detail by Ukrainian outlets, coupled with images of the block under construction throughout the summer and autumn. A video claiming to show a news reporter in Ukraine standing in front of rows of corpses in body bags, with one of the bodies ""moving"" has been viewed millions of times in the past few days. It led to claims that it was ""proof"" of actors being hired to play dead bodies to support the Western narrative on the Ukraine war. ""Stop moving - you're supposed to be dead! Psyop?"" claimed a widely shared tweet by a right-wing account. The video was shared with similar claims by several other right-wing influencers on Facebook and TikTok. The video is taken from a report by Austrian newspaper Osterreich of a climate protest in Vienna in early February last year, before the Russian invasion had even begun, in which activists aimed to highlight the danger of carbon emissions to human life. This video is not only false, it's a repeat offender. It had previously been shared as ""evidence"" that Covid deaths had been faked. Then, as now, it is not what it claims to be. Viral photos and a video shared online claim to show the ""accidental"" reveal of Ukrainian President Volodymyr Zelensky's body double. One claim, viewed by millions, is that the Ukrainian president has a ""secret body double"" who appeared by mistake in footage aired by Polish television, seemingly wearing the same outfit as the president. Other posts show the same man in the background during US President Joe Biden's visit to Kyiv last week. However, the man in question is easily identifiable as Maksym Donets, Mr Zelensky's personal bodyguard. According to Reuters, Mr Donets has been the head of the president's security team since May 2019. Images of him following the Ukrainian president around in public in different attire can be easily found online. The first anniversary of Russia's full-scale invasion of Ukraine has led to a spike in false claims about the war on social media, with some posts gaining millions of engagements. A number of US right-wing accounts with large followings posted a series of baseless claims that suggested the entire Ukraine war might be a hoax perpetrated by Western media and governments. Those spreading the most viral claims included some who had previously been suspended from Twitter and allowed back onto the platform following Elon Musk's takeover. One false claim that has been gaining traction on Twitter and elsewhere suggested that the entire war has somehow been faked. As evidence, some prominent right-wing accounts in the US cited the supposed lack of footage from the front line. A commentator complained about ""the lack of war footage"" in a viral post, saying it ""smacks of a scam"". Another Twitter influencer with 1.4 million followers claimed there was ""no footage"" and ""no detailed updates"" of the war. That post was later shared by former US national security adviser Michael Flynn, who added: ""I double dare anyone to say he is wrong."" However, the war in Ukraine has been well-documented. Alongside eyewitness accounts, there's been ample footage from the Ukrainian front line filed by the BBC and other global broadcasters who have also examined false narratives about some of the conflict's key events. There's also evidence from governments and agencies around the world that confirms that the war is real. From its outset, social media has been full of videos of the war, many of which have been verified as genuine by journalists. Two days after Russia's invasion, footage of a high-rise apartment building in Kyiv with a huge hole in it after it was hit by a missile was widely shared around the world. Reporters covered the aftermath of the damage in detail from the scene of the incident. In the past few days, images of the block, which has since been repaired and partially reconstructed, went viral again on social media. The image led to claims that either the block had never been hit, or that the entire war is a hoax, because - the argument went - it would be impossible to restore a building during an ongoing conflict. A right-wing podcaster and anti-vaccine activist, whose previously banned account was recently reinstated by Twitter, was among those that shared the claim. However, apart from regular Russian missile attacks, Kyiv has not been on the frontline of the war since late March 2022, when Russian forces withdrew from the city and its surroundings to focus on eastern Ukraine. The process of the block's repair and reconstruction began in May of last year, and has been reported in detail by Ukrainian outlets, coupled with images of the block under construction throughout the summer and autumn. A video claiming to show a news reporter in Ukraine standing in front of rows of corpses in body bags, with one of the bodies ""moving"" has been viewed millions of times in the past few days. It led to claims that it was ""proof"" of actors being hired to play dead bodies to support the Western narrative on the Ukraine war. ""Stop moving - you're supposed to be dead! Psyop?"" claimed a widely shared tweet by a right-wing account. The video was shared with similar claims by several other right-wing influencers on Facebook and TikTok. The video is taken from a report by Austrian newspaper Osterreich of a climate protest in Vienna in early February last year, before the Russian invasion had even begun, in which activists aimed to highlight the danger of carbon emissions to human life. This video is not only false, it's a repeat offender. It had previously been shared as ""evidence"" that Covid deaths had been faked. Then, as now, it is not what it claims to be. Viral photos and a video shared online claim to show the ""accidental"" reveal of Ukrainian President Volodymyr Zelensky's body double. One claim, viewed by millions, is that the Ukrainian president has a ""secret body double"" who appeared by mistake in footage aired by Polish television, seemingly wearing the same outfit as the president. Other posts show the same man in the background during US President Joe Biden's visit to Kyiv last week. However, the man in question is easily identifiable as Maksym Donets, Mr Zelensky's personal bodyguard. According to Reuters, Mr Donets has been the head of the president's security team since May 2019. Images of him following the Ukrainian president around in public in different attire can be easily found online."
Ukraine: How do you prove a war crime has been committed?,nan
Ukraine: Online posts 'transform' war crimes documentation,"Images posted online will be crucial in prosecuting war crimes in Ukraine, according to UK legal experts. A law professor said the use of bomb footage from Yemen during a mock war crimes trial showed how images shared online had ""transformed"" the documentation of atrocities. One online investigator said there was ""so much"" useful and verifiable information in warzone footage. But experts also said eyewitness accounts must not be overshadowed. Cases against individuals who have committed war crimes in Ukraine could depend on social media posts about unlawful killings, wartime sexual violence and torture, said Prof Yvonne McDermott Rees, who runs the Open Source Research for Human Rights project at Swansea University. She said material, known as open-source information, had ""completely transformed our way of knowing about human rights violations"". ""We're seeing increasingly the UN commissions of inquiry, fact-finding missions, even the International Criminal Court in the Hague, using this kind of evidence,"" she explained. Prof McDermott Rees said open-source information had also been used in Swedish and Dutch courts to prosecute members of the so-called Islamic State returning from Syria. Open-source information is information that is freely available online. ""A video of a beheading that's recorded or shared on YouTube or Facebook... is evidence,"" she said, adding that similar material was recently tested for use in a UK court. In 2018, unverified footage of the aftermath of a deadly airstrike on the office of the presidency in Sana'a, the capital of Yemen, was posted on Twitter. The open-source investigative website, Bellingcat, used geolocation, satellite imagery and comparisons of hundreds of images to document the attack. Their evidence was then presented in the mock trial of a fictitious Saudi pilot accused of war crimes. ""We wanted to see if one of these videos would be accepted as evidence in a common-law court in England and Wales,"" said Nick Waters, the justice accountability lead at Bellingcat. He said the result was a methodology ""we're now using to collect and verify incidents in Ukraine"". The problem, said Prof McDermott Rees, is that in the midst of war, bystanders are rarely thinking about a criminal trial. ""They're sharing it with the intention of showing the world what they've witnessed,"" she explained. Bystanders are being encouraged to film landmarks and known buildings in their footage of war crimes and to use a mobile phone app developed by the International Bar Association, called eyeWitness. ""It does things like capturing the metadata, the time, the date, the place where this piece of content was recorded,"" she said. ""If you are recording this, as well as showing the injuries suffered, the weapon, see if you can include landmarks or buildings in the background."" She said Witness, a charity that uses videos to document human rights abuses, has published guidelines on how bystanders can gather images that will be acceptable for use in courts. War crimes investigators are also fighting against the widely held view that online images cannot be trusted. ""That misses out on the fact that there is so much useful and verifiable information being posted on the Internet,"" Mr Waters said, adding that it is difficult to fake incidents online because real events come with a pattern of tweets from multiple sources. ""With the advent of social media, of smartphones, you effectively have an incredibly powerful information network where people are able to take pictures and take videos of the events,"" Mr Waters added. Solicitor Dearbhla Minogue works with the human rights charity,  Global Legal Action Network and Bellingcat, She said viewing a video of something happening is a lot more compelling than hearing somebody talk about it. ""Think about... the death of George Floyd,"" said Ms Minogue. ""People actually saw that happening in real-time, including the jury, by watching what was filmed by a passer-by. ""That impacted the outcome of that trial because it was no longer one person's word against another person's."" The University of California has developed rules for the use of digital open-source material, called the Berkeley Protocol. The question facing war crimes prosecutors, Ms Minogue said, is how to reassure a judge that the video is not faked or manipulated for political reasons. ""With a video that just appears online purporting to be the aftermath of an airstrike, how do we know that it is what it says it is?"" she said. ""That it's not staged or faked or these issues that are being raised by Russia in the context of these Bucha videos."" Ms Minogue said the normal way in domestic courts is to call the person who filmed it to give evidence in court. ""But in the cast of open-source information, where you don't have the creator, you can't ask them how they created it, whether they manipulated it [or] whether someone else could manipulate it. ""Using the information in the video and comparing it with other satellite imagery or other videos showing the same event, they can piece together all these bits of content and assess whether they think it real or fake."" Contains sexual violence and upsetting scenes. Prof McDermott Rees warned that while open-source material can help, ""it's important not to lose the human side in all of this"". She said: ""In Yemen, this kind of evidence wasn't seen on its own, it was in close collaboration with accounts that were gathered by NGOs on the ground."" In Ukraine, she said evidence of rape had been documented in the testimony of survivors, ""so it's really important that we don't underplay the importance of those human accounts"". ""It's about showing that when international crimes are committed, they're not committed with impunity,"" Prof McDermott Rees said. ""So this work in documenting and gathering informationÂ we have to make sure that's going to stand up in court and that we'll see justice. ""All of us are seeing this really disturbing content coming out of Bucha, other areas in Ukraine and I think universally we want to see justice done."""
Ukraine: Watching the war on Russian TV - a whole different story,"Never was there a better illustration of the alternative reality presented by Russian state media than at 17:00 GMT on Tuesday. As BBC World TV opened its bulletin with reports of a Russian attack on a TV tower in the capital Kyiv, Russian TV was announcing that Ukraine was responsible for strikes on its own cities. So what are Russian TV viewers seeing of the war? What messages are they hearing over the airwaves? Below is a snapshot of what ordinary Russians would have picked up, on Tuesday 1 March, while channel-hopping across the country's key TV stations, which are controlled by the Kremlin and its corporate allies. Good Morning, on state-controlled Channel One, one of Russia's most popular channels, is to the casual observer not unlike the breakfast broadcasting found in many other countries with its mix of news, culture and light entertainment. On Tuesday the normal running order is interrupted at 05:30 Moscow time [02:30 GMT]. The presenters announce that TV schedules have been changed ""due to well known events"", and there will be more news and current affairs. The news bulletin suggests that reports about Ukrainian forces destroying Russian military hardware are false, designed to ""mislead inexperienced viewers"". ""Footage continues to be circulated on the internet which cannot be described as anything but fake,"" the presenter explains as the viewer is shown photographs of what is described as ""unsophisticated virtual manipulations"". Later in the morning, at 08:00 Moscow time, we tune in for the morning bulletin from television channel NTV, which is owned by a subsidiary of Gazprom, a Kremlin-controlled firm. It concentrates almost exclusively on events in Donbas, the region in the east of Ukraine where on 24 February, Russia stated it was beginning its ""special military operation"" to demilitarise and denazify Ukraine. There is no mention of reports of the ominous miles-long military convoy snaking its way from Belarus in the north to Ukraine's capital Kyiv, which, in the UK, leads the BBC Radio 4 news bulletin half-an-hour later. ""We start with the latest news from Donbas. LNR [Luhansk People's Republic] fighters continue their offensive, having travelled 3km, while DNR [Donetsk People's Republic] units have travelled 16km,"" the NTV presenter says. The presenter is referring to the Moscow-backed rebels who have been in control of the so-called Donetsk and Luhansk People's Republics since Russia's intervention in east Ukraine eight years ago. On Rossiya 1 and Channel One - Russia's two most popular channels, both state-controlled - Ukrainian forces are accused of war crimes in the Donbas region. The threat to civilians in Ukraine comes not from Russian forces, but from ""Ukrainian nationalists"", says the Rossiya 1 presenter. ""They use civilians as a human shield, deliberately positioning strike systems in residential areas and stepping up the shelling of cities in Donbas."" Channel One's presenter announces that Ukrainian troops ""are preparing to shell residential houses"" and bomb warehouses with ammonia, in ""acts of provocation against civilians and Russian forces"". Events in Ukraine are not referred to as war. Instead, the offensive is described as a demilitarisation operation targeting military infrastructure or a ""special [military] operation to defend the people's republics"". Across state-controlled TV, presenters and correspondents use emotive language and images to draw ""historical parallels"" between Russia's ""special military operation"" in Ukraine and the Soviet Union's fight against Nazi Germany. ""The tactics of nationalists who use children to shield themselves have not changed since the Second World War,"" says the presenter of a morning show on Rossiya 1's sister channel, Rossiya 24. ""They behave like fascists, in the very sense of this word: neo-Nazis put their hardware not just next to residential houses but where children take shelter in basements,"" adds the correspondent in a video report captioned ""Ukrainian fascism"". The passage echoes the unproven claims made by Vladimir Putin last week that Ukraine was using women, children and the elderly as human shields. While media in the West has been asking whether Putin's assault has struggled to make quick progress, Russian TV portrays the Russian operations as very successful. Regular updates give numbers of destroyed Ukrainian hardware and weaponry. More than 1,100 Ukrainian military infrastructure facilities have been disabled and hundreds of pieces of hardware have been destroyed, morning news reports say. There is no mention of any Russian casualties. Russian morning news bulletins barely acknowledge its army's offensives in other parts of Ukraine. State TV correspondents are not reporting on the ground from places like Kyiv and Kharkiv, the two major cities that have seen shelling of people's homes. Instead, they are embedded with troops in Donbas. But by the afternoon edition of the news, NTV finally mentions the news event that has dominated hours of coverage on the BBC by this stage - the shelling of the city of Kharkiv. However, it debunks any reports that Russian forces are responsible, calling them ""fake"". ""Judging by the trajectory of the missile, the strike was delivered from the north-west where there are no Russian forces,"" the presenter says during the 16:00 Moscow time edition of the news. Four hours later, a bulletin by Rossiya 1 goes further, blaming Ukraine itself for the bombing. ""To strike Kharkiv and say that it was Russia. Ukraine is hitting its own and is lying to the West. But is it possible to deceive the people?"" it asks. During a 17:00 bulletin, the Rossiya 1 presenter outlines what she says is Russia's ""main objective"" in Ukraine: ""The defence of Russia against the threat from the West, which is using the Ukrainian people in its stand-off with Moscow."" To counter what is described as ""fake news and rumours"" about Ukraine which are circulating online"", she announces that the Russian government is launching a new website where ""only true information will be published"". TV stations are required by the media watchdog Roskomnadzor to follow the official narrative. But that is not to say that there was no variety in the tone of Tuesday's reporting. While the news bulletins talked of Ukrainian war crimes, Vyacheslav Nikonov, pro-Kremlin host of Channel One TV's current affairs talk show The Great Game, spoke about his love of Ukraine as he signed off. ""I very much love Ukraine, I love Ukrainians. I have travelled across the country on multiple occasions. It indeed is a brilliant, wonderful country. And I think Russia is, of course, interested in it being a prosperous, friendly countryÂ Our cause is just. We shall be victorious."" Increasing numbers of younger Russians tend to get their news from independent websites or social media, and the longer the war goes on, the more images and videos of dead soldiers and prisoners of war are surfacing. But the authorities are responding to this and turning the screws on independent reporting. Roskomnadzor has ordered TikTok to remove military and political content in its suggestions to minors, complaining, ""in most cases, these materials have a pronounced anti-Russian character"". It also demanded that Google remove what it describes as false information about the Russian army's reported losses, and Reuters reports it has re-imposed a slowdown on Twitter's loading speeds over ""fake reports"" of Moscow's ""special military operation"", and restricted access to Facebook. It has instructed media outlets to use information only from official Russian sources when reporting the invasion, demanding that they take down any reports referring to ""a declaration of war"" or ""an invasion"". It has threatened them with fines and blocking if they do not take action. The websites of the independent TV channel Dozhd and popular liberal radio station Ekho Moskvy have been blocked for alleged calls for extremism and violence, and ""systematic spread of false information about the activities of the Russian military"". With additional reporting by Francis Scarr"
Undercover with RussiaÂs fake arms dealers,"Russian state TV claims Ukrainians are selling US-donated weapons on the dark web. The BBC investigated one such marketplace, spoke undercover to those apparently selling weapons, and gathered evidence that suggests the adverts for weapons are fake. ""Ukrops [a derogatory Russian slang term used to refer to Ukrainians] are selling Javelins on the darknet. The command of the Armed Forces of Ukraine resells equipment and weapons supplied by Nato."" This message about anti-tank weapons was posted on 2 June by pro-Kremlin English-language account ASB Military News. The account has been recently suspended by Twitter but still exists on Telegram, where it has more than 100,000 subscribers. On the same day, another pro-Kremlin Telegram channel, with 700,000 followers, posted in Russian: ""Thanks to Biden and European friends of Ukraine, Javelins, machine guns and even tanks will pop up all over the world in the hands of terrorists and criminals."" Pictures attached to the post showed an advert allegedly selling the FGM-148 Javelin, a US-made anti-tank missile system, for $30,000 (Â£26,000) and promising to deliver the weapons to the Ukraine-Poland border or abroad. These posts were quickly picked up by mainstream Russian state TV, which routinely runs stories claiming Ukraine is selling weapons supplied by the West. We decided to investigate these accusations ourselves using laptops that could not be linked back to the BBC. With a specialised web browser, we accessed the dark web where the level of anonymity attracts criminal activity. We found several sellers on the same marketplace mentioned by Russian state media outlets. They said they were selling Nato weapons, and their geolocation was Kyiv. However, the name of Ukraine's capital was misspelled in Ukrainian. This was not the only inconsistency. One of the main sellers often mentioned in Russian media reports is known as ""Weapons Ukraine"". The seller claims to have made 32 successful deals selling US-made carbines [a type of automatic rifle], pistols and other rifles all allegedly delivered within Ukraine. However, the BBC found that many of the photos of the weapons were not as they appeared. The red warning sign indicates the image is old or has been manipulated We found the image of the M4 carbine posted on a Russian website in 2014. The image of another rifle advertised by the seller had also been taken in 2014 and posted on a gun enthusiast's site. Another seller called ""Big Discounts On Weapons"", claiming to sell US-made Javelins and drones recently provided to Ukraine by its Nato allies, was more inventive. The vendor photoshopped several old pictures - including ones of damaged drones - to make them look as if they were taken directly by him, and added the name of the marketplace. We spoke to StopFake, a Ukrainian fact-checking organisation. It found that the drones attached to the advert matched those of two Switchblade 300 drones with the same serial numbers shot down in Syria in 2015 and 2016. Russian state media repeatedly claim that the people behind these advertisements are Ukrainian. So we decided to get in touch with so-called ""sellers"" and check for ourselves. The vendor selling Javelins and Switchblade 300 drones asked us to contact them on a messaging app where they were registered under the username ""javelinusa"". We spoke to them undercover, asking how we could buy weapons. ""Put money into your account, then we'll invite an administrator to this chat. We'll announce our terms and conditions. We'll place goods into a stash. When you receive them, you'll text us that you're happy with everything, and then the administrator will transfer your money to me,"" javelinusa texted us in Ukrainian. However, in the course of our online conversation we noticed that their Ukrainian was full of grammatical errors. When asked about it, the ""seller"" replied that they were from Poland. We asked a linguist to analyse our chat with the trader. ""The person behind these messages is Russian-speaking,"" said Daria Lewicka, expert in Polish language and a Ukrainian-Russian-Polish interpreter. She says there is substantial evidence that the messages written in Ukrainian were translated from Russian with the help of an online translator. ""I see a lot of 'Russianisms' in his Ukrainian language, but I don't see any 'Polonisms' at all. For example, he uses a phrase ""???? ?? ?????????"" [which can be translated as ""don't beat around the bush""]. This is a common Russian phrase and it has no equivalent in Polish."" The seller also made several typos, which meant the online translator could not understand them, and left the original words. They were both Russian words written with Russian letters. Later, we managed to contact another seller from ""Weapons Ukraine"". In the online chat, the trader also made grammatical mistakes in tenses and word endings, suggesting he was not a native Ukrainian speaker and that he was translating his messages. The linguist also found inconsistencies in many reviews mostly posted in Polish on the site, suggesting they were posted with the aid of a translation service. ""Real people don't talk like this,"" Ms Lewicka said. Despite the inconsistencies, Russian state media site RT depicts the sellers' ads and reviews as evidence that ""potentially suggests that the Ukrainian arms smugglers may have already established contacts with [Polish] border guards and are able to cross in and out of Poland without complications"". ""Javelins can shoot down planes. And Stingers?[US-made air-defence systems] can fall into the hands of terrorists and become?a safety risk to European airports,"" claimed a separate report by Russia's Channel One. Serhiy Kharchenko is a fact-checker from StopFake specialising in tackling Russian propaganda. He says this is how the Kremlin uses fake news to reduce trust in Ukraine and disrupt arms supplies to Kyiv. ""Their goal is to sow panic in Europe, saying that these weapons can be used against European citizens."" He says these stories were produced by Russia primarily to influence an international audience. The BBC found stories about the weapons sales published in English, Japanese, Vietnamese and several other languages across a range of sites including a mainstream Turkish news outlet and fringe American blogs and conspiracy sites. Cybercrime Threat Intelligence Company KELA investigated the marketplace. It believes the listings were publicised by pro-Russian propaganda sources, or possibly created by them. KELA says it is suspicious that the marketplace has relatively minimal activity - a low number of trades taking place - and that it is reasonably unknown, even among those who visit dark web marketplaces. ""Usually, you would find people who know a marketplace. But we didn't find any reviews or recommendations of this platform. We had a lot of trouble finding anything about this marketplace, any kind of feedback,"" says Irina Nesterovsky, KELA chief research officer. She questions how Russian journalists found it so easily. Ms Nesterovsky says it is not clear if the adverts were created specifically by pro-Russian actors or if scammers active on the dark web created them independently, and then pro-Kremlin sources picked them up. But the timing and the similarity of claims made by Russian state media outlets suggest that it could be an organised disinformation campaign. Mr Kharchenko agrees and is concerned that the same marketplace could be used by Russian propagandists to produce other false stories. ""Now Russians have been creating stories accusing Ukraine of selling weapons. But who knows - later they might use the same marketplace to spread fakes about so called 'sales' of other 'goods' and 'services'. If they have created this marketplace, why not to use it? All they want is to sow the seeds of doubt and denigrate Ukrainians."""
Using my family's dark history to teach about vaccines,"How do you ask a community to trust medicine when history has given them many reasons not to? It's a dilemma US nurse Victoria Baptiste has to deal with every day as she travels around Baltimore County, Maryland, in a mobile clinic, administering Covid vaccines. Over the past couple of years, one question has kept coming up, especially from her black patients. We've been experimented on in the past - how can we trust this treatment? Often they've come across inaccurate posts on Facebook or Twitter. But her black patients' fears have not just come from online misinformation - their mistrust began long ago. ""When they start to tell their stories they say, 'Remember Tuskegee and Henrietta Lacks, they always experiment on people of colour,'"" she says. Tuskegee was a 40-year experiment conducted by the US government in which hundreds of black men were deliberately left untreated for syphilis, without their knowledge. After it was exposed, regulations were introduced in 1974 that required voluntary informed consent from all subjects taking part in research. And as for Henrietta Lacks - few people are better placed than Victoria to understand that story of unethical medical research. Henrietta was the mother of Victoria's beloved grandfather, Lawrence. Henrietta Lacks was an African-American woman who died of cervical cancer in 1951 and whose cells were used for medical research without her or her family's consent. As she was being treated for her cancer, some tissue was scraped from Henrietta's cervix into a petri dish, as part of a search for cells that could be studied and experimented on outside the body. She wasn't told this was happening. Nor was she kept fully informed about the effects of the treatment she was receiving for her cancer, Victoria tells me. She had radium - a radioactive substance - sewn into her cervix to try to kill off the tumour. It was an accepted treatment at the time, but she was not told that this could prevent her from having more children. Meanwhile, where other cell samples quickly died despite scientists' best efforts, Henrietta's cells not only stayed alive - they multiplied at a rapid rate, leading them to be termed ""immortal"". The spiralling number of these cells, a feature of her cancer, would prove devastating for her - but revolutionary for science. This stock of human cells can then be used to understand how diseases affect the body, and as a first testing ground for treatments, improving both the speed and safety of medical research. Henrietta Lacks's cells - dubbed HeLa - have been involved in understanding cervical cancer, tuberculosis, Ebola and HIV as well as laying the groundwork for polio, Human Papilloma Virus (HPV) and Covid vaccines. They have benefited millions of people - and made potentially billions of dollars for the drug companies that use them to test their products. Yet the Lacks family has never seen a penny of these profits. At one point some family members couldn't even afford medical insurance. The full details about HeLa cells were only drawn to some of the family's attention when science writer Rebecca Skloot, who wrote a best-selling book about the case, started investigating. So when Victoria says she understands why people might be mistrustful of the pharmaceutical industry, she means it. Victoria grew up hearing about the mother her grandfather Lawrence lost before he reached adulthood: a mother of five who cared for everyone and yearned for more children, and who loved to cook, dance, and make herself look nice. Victoria and her posse of cousins - her best friends to this day - spent their early years running around the home of Henrietta's husband David, known as Day. And it was really thanks to him that Victoria became a nurse in the first place. ""He had to live with diabetes when I was a young child, and I was always very curious and asking questions like, 'Pop why are you giving yourself needles? And what is this for?' And he was always very patient with me."" She eventually learnt to administer his insulin injections. In early 2020, Victoria was working as a nurse in a hospital kidney unit. But when Covid hit, her work changed dramatically. Like many healthcare workers she was afraid of taking the disease home. Fearing burnout, but wanting to keep caring for people, in 2021 she became a travelling nurse, giving Covid-19 vaccines. She quickly realised she had a knack for working with people who were anxious or hesitant and had questions - pointing them to the best research and helping them to find the information themselves. And Henrietta Lacks's story was always in the back of her mind. ""Knowing what my family history has been, I don't want anybody else's family to have that same history. I don't want them to feel like they were silenced or a silent voice in their care, like Henrietta was."" For someone who feels personally connected with the darker side of what has been done in the name of science, Victoria knows that simply asking patients to ignore online rumours and trust the science would not be enough. ""I'm never going to try to dance around those hard topics,"" she says. ""Yes, these things happened to Henrietta. We've come a long way since then. And we are still fighting to make sure that these types of injustices don't happen now."" But at the same time Covid was disproportionately affecting the black community, and vaccines were the most powerful tool available to prevent serious illness and death. Victoria believes in the possibility of acknowledging genuine problems in medicine and the pharmaceutical industry and holding them to account, while also recognising the weight of independent data about a vaccine that has saved an estimated 20 million lives in its first year. She will explain to her patients how things have changed since Henrietta's day - including safeguards like the Institutional Review Board, designed to make sure research is conducted ethically, and the need for informed consent. ""We've come a long way from 1951. Research has so many checks and balances before they put things out to the public,"" she says. That doesn't mean there aren't still issues to solve. Now, as well as her day-to-day work as a nurse and with her family's initiative HELA100, Victoria is serving as a World Health Organization ambassador for cervical cancer elimination, which she sees as something of a personal mission. ""We know what we know now about cervical cancer because of the loss that my family had to go through,"" she says. It's another illness that black people in the US are more likely to die of. Victoria wants as many people as possible to be screened for the HPV virus, to be given access to the vaccine and to early treatment, to bring down deaths from a cancer that is preventable in more than 90% of cases. ""We lost our loved one to cervical cancer,"" she says. ""But through her death, science was able to come up with the vaccination."" Photographs courtesy of CELLebrate Henrietta Lacks #HELA100 BBC 100 Women names 100 inspiring and influential women around the world every year. Follow BBC 100 Women on Instagram, Facebook and Twitter. Join the conversation using #BBC100Women. How do you ask a community to trust medicine when history has given them many reasons not to? It's a dilemma US nurse Victoria Baptiste has to deal with every day as she travels around Baltimore County, Maryland, in a mobile clinic, administering Covid vaccines. Over the past couple of years, one question has kept coming up, especially from her black patients. We've been experimented on in the past - how can we trust this treatment? Often they've come across inaccurate posts on Facebook or Twitter. But her black patients' fears have not just come from online misinformation - their mistrust began long ago. ""When they start to tell their stories they say, 'Remember Tuskegee and Henrietta Lacks, they always experiment on people of colour,'"" she says. Tuskegee was a 40-year experiment conducted by the US government in which hundreds of black men were deliberately left untreated for syphilis, without their knowledge. After it was exposed, regulations were introduced in 1974 that required voluntary informed consent from all subjects taking part in research. And as for Henrietta Lacks - few people are better placed than Victoria to understand that story of unethical medical research. Henrietta was the mother of Victoria's beloved grandfather, Lawrence. Henrietta Lacks was an African-American woman who died of cervical cancer in 1951 and whose cells were used for medical research without her or her family's consent. As she was being treated for her cancer, some tissue was scraped from Henrietta's cervix into a petri dish, as part of a search for cells that could be studied and experimented on outside the body. She wasn't told this was happening. Nor was she kept fully informed about the effects of the treatment she was receiving for her cancer, Victoria tells me. She had radium - a radioactive substance - sewn into her cervix to try to kill off the tumour. It was an accepted treatment at the time, but she was not told that this could prevent her from having more children. Meanwhile, where other cell samples quickly died despite scientists' best efforts, Henrietta's cells not only stayed alive - they multiplied at a rapid rate, leading them to be termed ""immortal"". The spiralling number of these cells, a feature of her cancer, would prove devastating for her - but revolutionary for science. This stock of human cells can then be used to understand how diseases affect the body, and as a first testing ground for treatments, improving both the speed and safety of medical research. Henrietta Lacks's cells - dubbed HeLa - have been involved in understanding cervical cancer, tuberculosis, Ebola and HIV as well as laying the groundwork for polio, Human Papilloma Virus (HPV) and Covid vaccines. They have benefited millions of people - and made potentially billions of dollars for the drug companies that use them to test their products. Yet the Lacks family has never seen a penny of these profits. At one point some family members couldn't even afford medical insurance. The full details about HeLa cells were only drawn to some of the family's attention when science writer Rebecca Skloot, who wrote a best-selling book about the case, started investigating. So when Victoria says she understands why people might be mistrustful of the pharmaceutical industry, she means it. Victoria grew up hearing about the mother her grandfather Lawrence lost before he reached adulthood: a mother of five who cared for everyone and yearned for more children, and who loved to cook, dance, and make herself look nice. Victoria and her posse of cousins - her best friends to this day - spent their early years running around the home of Henrietta's husband David, known as Day. And it was really thanks to him that Victoria became a nurse in the first place. ""He had to live with diabetes when I was a young child, and I was always very curious and asking questions like, 'Pop why are you giving yourself needles? And what is this for?' And he was always very patient with me."" She eventually learnt to administer his insulin injections. In early 2020, Victoria was working as a nurse in a hospital kidney unit. But when Covid hit, her work changed dramatically. Like many healthcare workers she was afraid of taking the disease home. Fearing burnout, but wanting to keep caring for people, in 2021 she became a travelling nurse, giving Covid-19 vaccines. She quickly realised she had a knack for working with people who were anxious or hesitant and had questions - pointing them to the best research and helping them to find the information themselves. And Henrietta Lacks's story was always in the back of her mind. ""Knowing what my family history has been, I don't want anybody else's family to have that same history. I don't want them to feel like they were silenced or a silent voice in their care, like Henrietta was."" For someone who feels personally connected with the darker side of what has been done in the name of science, Victoria knows that simply asking patients to ignore online rumours and trust the science would not be enough. ""I'm never going to try to dance around those hard topics,"" she says. ""Yes, these things happened to Henrietta. We've come a long way since then. And we are still fighting to make sure that these types of injustices don't happen now."" But at the same time Covid was disproportionately affecting the black community, and vaccines were the most powerful tool available to prevent serious illness and death. Victoria believes in the possibility of acknowledging genuine problems in medicine and the pharmaceutical industry and holding them to account, while also recognising the weight of independent data about a vaccine that has saved an estimated 20 million lives in its first year. She will explain to her patients how things have changed since Henrietta's day - including safeguards like the Institutional Review Board, designed to make sure research is conducted ethically, and the need for informed consent. ""We've come a long way from 1951. Research has so many checks and balances before they put things out to the public,"" she says. That doesn't mean there aren't still issues to solve. Now, as well as her day-to-day work as a nurse and with her family's initiative HELA100, Victoria is serving as a World Health Organization ambassador for cervical cancer elimination, which she sees as something of a personal mission. ""We know what we know now about cervical cancer because of the loss that my family had to go through,"" she says. It's another illness that black people in the US are more likely to die of. Victoria wants as many people as possible to be screened for the HPV virus, to be given access to the vaccine and to early treatment, to bring down deaths from a cancer that is preventable in more than 90% of cases. ""We lost our loved one to cervical cancer,"" she says. ""But through her death, science was able to come up with the vaccination."" Photographs courtesy of CELLebrate Henrietta Lacks #HELA100 BBC 100 Women names 100 inspiring and influential women around the world every year. Follow BBC 100 Women on Instagram, Facebook and Twitter. Join the conversation using #BBC100Women."
"Vaccine rumours debunked: Microchips, 'altered DNA' and more","We've looked into some of the most widely shared false vaccine claims - everything from alleged plots to put microchips into people to the supposed re-engineering of our genetic code. The fear that a vaccine will somehow change your DNA is one we've seen aired regularly on social media. The BBC asked three independent scientists about this. They said that the coronavirus vaccine would not alter human DNA. Some of the newly created vaccines, including the one now approved in the UK developed by Pfizer/BioNTech, use a fragment of the virus's genetic material - or messenger RNA. ""Injecting RNA into a person doesn't do anything to the DNA of a human cell,"" says Prof Jeffrey Almond of Oxford University. It works by giving the body instructions to produce a protein which is present on the surface of the coronavirus. The immune system then learns to recognise and produce antibodies against the protein. This isn't the first time we've looked into claims that a coronavirus vaccine will supposedly alter DNA. We investigated a popular video spreading the theory back in May. Posts have noted that messenger RNA (mRNA) vaccine technology ""has never been tested or approved before"". It is true that no mRNA vaccine has been approved before now, but multiple studies of mRNA vaccines in humans have taken place over the last few years. And, since the pandemic started, the vaccine has been tested on tens of thousands of people around the world and has gone through a rigorous safety approval process. Like all new vaccines, it has to undergo rigorous safety checks before it can be recommended for widespread use. In Phase 1 and Phase 2 clinical trials, vaccines are tested in small numbers of volunteers to check they are safe and to determine the right dose. In Phase 3 trials they are tested in thousands of people to see how effective they are. The group who received the vaccine and a control group who have received a placebo are closely monitored for any adverse reactions - side-effects. Safety monitoring continues after a vaccine has been approved for use. Next, a conspiracy theory that has spanned the globe. It claims that the coronavirus pandemic is a cover for a plan to implant trackable microchips and that the Microsoft co-founder Bill Gates is behind it. There is no vaccine ""microchip"" and there is no evidence to support claims that Bill Gates is planning for this in the future. The Bill and Melinda Gates Foundation told the BBC the claim was ""false"". Rumours took hold in March when Mr Gates said in an interview that eventually ""we will have some digital certificates"" which would be used to show who'd recovered, been tested and ultimately who received a vaccine. He made no mention of microchips. This led to one widely shared article headlined: ""Bill Gates will use microchip implants to fight coronavirus."" The article makes reference to a study, funded by The Gates Foundation, into a technology that could store someone's vaccine records in a special ink administered at the same time as an injection. However, the technology is not a microchip and is more like an invisible tattoo. It has not been rolled out yet, would not allow people to be tracked and personal information would not be entered into a database, says Ana Jaklenec, a scientist involved in the study. The billionaire founder of Microsoft has been the subject of many false rumours during the pandemic. He's been targeted because of his philanthropic work in public health and vaccine development. Despite the lack of evidence, in May a YouGov poll of 1,640 people suggested 28% of Americans believed Mr Gates wanted to use vaccines to implant microchips in people - with the figure rising to 44% among Republicans. We've seen claims that vaccines contain the lung tissue of an aborted fetus. This is false. ""There are no fetal cells used in any vaccine production process,"" says Dr Michael Head, of the University of Southampton. One particular video that was posted on one of the biggest anti-vaccine Facebook pages refers to a study which the narrator claims is evidence of what goes into the vaccine developed by AstraZeneca and Oxford University. But the narrator's interpretation is wrong - the study in question explored how the vaccine reacted when introduced to human cells in a lab. Confusion may have arisen because there is a step in the process of developing a vaccine that uses cells grown in a lab, which are the descendants of embryonic cells that would otherwise have been destroyed. The technique was developed in the 1960s, and no fetuses were aborted for the purposes of this research. Many vaccines are made in this way, explains Dr David Matthews, from Bristol University, adding that any traces of the cells are comprehensively removed from the vaccine ""to exceptionally high standards"". The developers of the vaccine at Oxford University say they worked with cloned cells, but these cells ""are not themselves the cells of aborted babies"". The cells work like a factory to manufacture a greatly weakened form of the virus that has been adapted to function as a vaccine. But even though the weakened virus is created using these cloned cells, this cellular material is removed when the virus is purified and not used in the vaccine. We've seen arguments against a Covid-19 vaccine shared across social media asking why we need one at all if the chances of dying from the virus are so slim. A meme shared by people who oppose vaccination put the recovery rate from the disease at 99.97% and suggested getting Covid-19 is a safer option than taking a vaccine. To begin with, the figure referred to in the meme as the ""recovery rate"" - implying these are people who caught the virus and survived - is not correct. About 99.0% of people who catch Covid survive it, says Jason Oke, senior statistician at the University of Oxford. So around 100 in 10,000 will die - far higher than three in 10,000, as suggested in the meme. However, Mr Oke adds that ""in all cases the risks very much depend on age and do not take into account short and long-term morbidity from Covid-19"". It's not just about survival. For every person who dies, there are others who live through it but undergo intensive medical care, and those who suffer long-lasting health effects. This can contribute to a health service overburdened with Covid patients, competing with a hospital's limited resources to treat patients with other illnesses and injuries. Concentrating on the overall death rate, or breaking down the taking of a vaccine to an individual act, misses the point of vaccinations, says Prof Liam Smeeth of the London School of Hygiene and Tropical Medicine. It should be seen as an effort by society to protect others, he says. ""In the UK, the worst part of the pandemic, the reason for lockdown, is because the health service would be overwhelmed. Vulnerable groups like the old and sick in care homes have a much higher chance of getting severely ill if they catch the virus"". Additional reporting by Kris Bramwell, Olga Robinson and Marianna Spring Read more from Reality Check Send us your questions"
Vitamin D: The truth about an alleged Covid Âcover-upÂ,"As Covid-19 swept the world, so did misinformation about how to treat it. But sometimes misinformation can develop even around ideas that have some truth to them - and that can be the most difficult kind to tackle. There are many treatments that have been suggested for Covid-19. Hydroxychloroquine, Ivermectin and vitamin D - all are, or were, being studied. Suggesting that a treatment could be effective and then finding it isn't upon further research is all part of the normal scientific process. But online, early or low quality research can be shared out of context. And the confusion this creates can be exploited by people promoting conspiracy theories. There is some logic behind why vitamin D might be useful in treating or preventing Covid. It plays a role in immunity and it's already recommended that everyone in the UK take the supplement in the winter, with those at higher risk of vitamin D deficiency advised to take it all year round. So far, no research has shown a convincing enough effect to support higher doses to prevent or treat illness  - although this doesn't mean that won't change in the future. Should I start taking vitamin D? So it's understandable it was taken up as advice by many online. Yet some have gone much further, suggesting on Reddit forums that governments are ""barely mentioning"" vitamin D's effectiveness, instead focusing on ""vaccines and police state tracking""; or alleging the vitamin is being ignored because the World Health Organization is in the ""pay of Big Pharma"". But governments have taken up other cheap, effective treatments like dexamethasone, once proven. And vitamins themselves are a multi-million pound industry. Many studies have shown an association between vitamin D and Covid outcomes, but the evidence is largely observational - meaning it looks at what happens to people with higher and lower levels of vitamin D without controlling for other factors. This isn't gold standard evidence - that would a need randomised control trial, where people are allocated a treatment or a dummy version, so scientists can be clear an outcome is caused by the treatment. Observational studies do show certain groups are both more likely to have vitamin D deficiencies and to catch Covid - older people, people with higher weights, people with darker skin (including black and South Asian people). It may be that a deficiency is the reason these groups are at higher risk, or there may be other health and environmental factors driving both a fall in levels of vitamin D and greater susceptibility to the virus. The NHS recommends people with dark skin, ""for example people with an African, African-Caribbean or south Asian background"", should consider taking a vitamin D supplement ""throughout the year"". Levels of the vitamin can also fall as a consequence, rather than a cause, of illness. We will only be able to isolate vitamin D as a cause by running properly conducted randomised controlled trials like the one being run at the moment at Queen Mary University of London. One particular paper from the University of Barcelona has attracted attention, claiming to be just this type of study. It suggested vitamin D had staggering success, with an 80% reduction in intensive care admissions and a 60% reduction in Covid deaths. It was widely shared online. But it has since been removed from the Lancet's preprint server over ""concerns about the description of the research"", and it is now being investigated. The removal has not been shared in the way the original paper was. Vitamin D was given to whole wards which often care for patients based on how ill they are, not randomly assigned to individuals. And the Covid patients in the study who died had radically different levels of the vitamin to start with, suggesting they were more ill in the first place. The Conservative MP David Davis, who called in Parliament for vitamin D supplementation to be introduced in hospitals, told the BBC that despite the retraction, he believed the study still showed vitamin D was important, and argued the government should be funding more research into it. Aurora Baluja, an anaesthesiologist and critical care doctor in Spain, who reviewed the Barcelona study for the Lancet before it was withdrawn, said the kind of ""extreme"" effect found in the paper is ""never found"" in a randomised controlled trial, making it highly likely to be the result of bias. She said, although vitamin D deficiency was a ""well-established risk factor"" among people who die in intensive care, ""vitamin D supplementation alone has always failed to reduce the risk of those patients"". Dr Baluja explains the deficiency is often being caused by something much more profound, like malnourishment or kidney failure, rather than patients' deaths being caused by the deficiency. When the findings fit in with people's world views - for example that ""natural things can't harm you"", Prof Sander Van der Linden, a social psychologist at the University of Cambridge explained - this makes them more likely to be shared. While the online worlds of natural health and alternative medicine, and of people who are ideologically anti-vaccination are distinct, they can overlap. Anti-vax accounts are ""densely connected to other topics - religion, herbal and alternative medicine, the natural community,"" says Prof Van der Linden. This means they can share topics that will intersect with people in those communities' interests and spread a message that, for example, ""you don't need a vaccine, you can just take vitamin D,"" without it being overtly flagged to someone that the message is anti-vax when it appears on their feed, he explains. Vitamin D is relatively safe (although few medical interventions are entirely risk-free, especially at high doses) so it may not appear to be the most harmful of misinformation. The danger, Prof Van der Linden explains, is when people suggest the supplement is a miracle cure and should be substituted for vaccines, masks and social distancing. Follow Rachel on Twitter"
Voice referendum: Lies fuel racism ahead of Australia's Indigenous vote,"""People have been let off the leash,"" Thomas Mayo says quietly, swiping through screenshots. Racist memes depicting First Nations Australians as ""grifters"", ""wife beaters"" and ""primitives"" flash across his phone. Then, personal threats appear - accusing him of ""providing cover for evil"". Mr Mayo is one of the public faces of the Yes campaign in Australia's historic Voice to Parliament referendum, to be held on 14 October. If successful, the vote will change the nation's constitution for the first time in 46 years, creating a body for Aboriginal and Torres Strait Islander people to advise the government on policies affecting their communities. Opinion polls had long shown support for the change but now suggest the No vote is leading. Though some argue the shift reflects public sentiment, Yes campaigners blame it on an ecosystem of disinformation - which they say is being led by figures in the No camp and ""amplified"" by suspicious accounts on social media. Independent experts say the most ""pernicious"" and pervasive falsehoods ""spreading like wildfire"" online concern race. Amid all the noise, concerns are growing over the mental health of First Nations communities, who find themselves at the centre of an increasingly divisive debate. And questions are again being raised over whether Australia is ready to grapple with the open wounds at the heart of its nationhood. Some of the most difficult chapters include massacres and violence against First Nations people and the theft of their land and livelihoods. Aboriginal and Torres Strait Islander Australians weren't fully counted in the nation's census until 1971, and for most of the last century many of their children were forcibly removed by the government under assimilation policies. At the heart of the Voice is a debate that has long persisted in Australia over how to ""close the gap"" on the glaring disparities that First Nations people still experience. These include vastly poorer health, wealth, and education outcomes. The suicide rate among Indigenous Australians, for example, is almost double that of non-Indigenous Australians. And despite representing less than 4% of Australia's population, Aboriginal and Torres Strait Islander people account for 32% of prisoners. Prime Minister Anthony Albanese has framed the Voice as ""a once-in-a-generation opportunity for real, overdue and much-needed change"". Supporters say it will lead to greater self-determination for First Nations communities. The No campaign says the Voice will have too much power though - arguing it will undermine government processes and clog up the courts with its objections. But the Voice will have no power of veto and many fears raised by the No campaign have been debunked or strongly disputed, including by Australia's solicitor-general. The debate online has been dominated by discussions of race, say fact-checkers and monitors. ""Race is a prime vector for abuse, trolling, disinformation and conspiracy theorising and on the No side of the debate, Twitter [X] is rife with that,"" says Dr Timothy Graham, a digital media lecturer who has analysed over 250,000 Voice-related posts. The Australian Associated Press' FactCheck team - which has been hired to monitor content on Facebook, Instagram and TikTok - has noticed the same on those platforms. The official campaign has only just begun, but they are already seeing volumes of misinformation and disinformation that outstrips what they saw at Australia's 2022 election, says editor Ben James. The team has debunked posts on everything from the rules of a referendum to false claims about the constitution, key campaign figures, and the possibility of a future ""black state"". Among them have been lies that Mr Mayo told another Indigenous man to ""sit down and shut up"" for asking questions at a Yes campaign event; manipulated videos of the prime minister; rants insisting that non-Indigenous people will be banned from the country's biggest sporting venues; and claims that the Voice had already failed at a referendum over 20 years ago. ""We have checked claims from both sides, but we have certainly seen more claims from those against the proposal,"" says Mr James. He tells the BBC a ""fair proportion"" of those claims contain racist undertones or abusive and derogatory language. Mr James stresses that not all the anti-Voice claims are coming from the official No campaign, and that the most offensive content is generally not emanating from representatives of either camp. But analysts say a lot of the content mirrors the narratives that underpin the No campaign. That includes claims from Australia's opposition leader Peter Dutton that the Voice will ""permanently divide"" the nation based on race, creating an ""Orwellian effect"" that gives First Nations communities greater rights and privileges. These warnings are unfounded, say legal and constitutional experts. Mr Dutton has not directly addressed accusations he has spread misinformation, but said in a speech to parliament: ""When Australians raise reasonable and legitimate concerns about the Voice model, the government dismisses them as a scare campaign, as nonsense, as noise, and misinformation."" However, some online accounts responsible for spreading messaging around racial division show signs of ""inauthenticity"" and bot-like behaviour, according to social media experts working with the Yes campaign. Those accounts were recently created, have almost no history, and have been ""duplicating the exact same content"", says communications adviser Ed Coper. One example he cites is an anti-Voice Facebook post which was shared over 53,000 times shortly after being created, while only tallying 92 likes and 23 comments. He argues this is evidence of an attempt to ""game the platform's algorithm"" and spread disinformation as ""far and wide as possible"". In July, Meta - which owns Facebook and Instagram - announced a funding boost for its fact-checking teams tasked with monitoring the referendum. Last week, however, it suspended one partner organisation to review the group's certification and complaints against it. ""We've also improved our AI so that we can more effectively detect and block fake accounts, which are often behind this activity,"" said Meta's director of public policy for Australia Mia Garlick. For Mr Mayo, there is a growing disconnect between the narratives permeating social media and what he experiences in public. ""You deal with all this vitriol online - and for me even in the mainstream media - but among fellow Australians, the feeling is totally different. I can feel a great momentum towards success,"" the Kaurareg Aboriginal and Kalkalgal, Erubamle Torres Strait Islander man tells the BBC. Mental health agencies say they are recording marked increases in reports of online hate speech and abuse. ""We've had a 106% rise in the last four months on abuse calls, which I'd put down to the Voice basically,"" says Marjorie Anderson, the national manager at 13Yarn, a crisis support line for First Nations Australians. She describes the racist abuse on social media as ""scary"". ""We won't know the scale of the damage until after the referendum. Think about the responsibility if the Aboriginal suicide rate goes up and we can link that back to disinformation around the Voice"" she says. But Fair Australia - the conservative organisation spearheading the No vote - stands behind its claims. ""The government and the Yes campaigns wear the entire responsibility for this divisive referendum. We are not the ones trying to divide Australians by race,"" its leader, Senator Jacinta Nampijinpa Price, tells the BBC. Megan Krakouer, a Menang woman who helps run the National Suicide Prevention and Trauma Recovery Project, says her team has also seen a serious spike in reports of ""racism and comments of hate"". Ms Krakouer had initially argued against the Voice, believing it did not go far enough because the advisory body will have no veto power over MPs. But she recently changed her position following a spate of suicides in her local community in Western Australia. Her hope now is that the body - though not ""perfect"", she says - will shift the dial on ""the stark issues killing and hurting First Nations people"". Publicly, Yes campaigners are still projecting confidence despite the recent drop in polling. But Mr Mayo worries about the scars the debate itself may inflict, win or lose. ""People are going to suffer throughout this campaign. I think the most shameful thing is what the opposition has done to this conversation, and history will reflect that,"" he says. ""This takes nothing away from anybody other than the burdens of our colonial past. It is hopeful and unifying, and they've made it a divisive political issue when it's really a basic, modest reform."" Update 19 September 2023: This article has been updated to reflect that some First Nation Australians were included in censuses before 1971. Additional reporting by Tiffanie Turnbull in Sydney. ""People have been let off the leash,"" Thomas Mayo says quietly, swiping through screenshots. Racist memes depicting First Nations Australians as ""grifters"", ""wife beaters"" and ""primitives"" flash across his phone. Then, personal threats appear - accusing him of ""providing cover for evil"". Mr Mayo is one of the public faces of the Yes campaign in Australia's historic Voice to Parliament referendum, to be held on 14 October. If successful, the vote will change the nation's constitution for the first time in 46 years, creating a body for Aboriginal and Torres Strait Islander people to advise the government on policies affecting their communities. Opinion polls had long shown support for the change but now suggest the No vote is leading. Though some argue the shift reflects public sentiment, Yes campaigners blame it on an ecosystem of disinformation - which they say is being led by figures in the No camp and ""amplified"" by suspicious accounts on social media. Independent experts say the most ""pernicious"" and pervasive falsehoods ""spreading like wildfire"" online concern race. Amid all the noise, concerns are growing over the mental health of First Nations communities, who find themselves at the centre of an increasingly divisive debate. And questions are again being raised over whether Australia is ready to grapple with the open wounds at the heart of its nationhood. Some of the most difficult chapters include massacres and violence against First Nations people and the theft of their land and livelihoods. Aboriginal and Torres Strait Islander Australians weren't fully counted in the nation's census until 1971, and for most of the last century many of their children were forcibly removed by the government under assimilation policies. At the heart of the Voice is a debate that has long persisted in Australia over how to ""close the gap"" on the glaring disparities that First Nations people still experience. These include vastly poorer health, wealth, and education outcomes. The suicide rate among Indigenous Australians, for example, is almost double that of non-Indigenous Australians. And despite representing less than 4% of Australia's population, Aboriginal and Torres Strait Islander people account for 32% of prisoners. Prime Minister Anthony Albanese has framed the Voice as ""a once-in-a-generation opportunity for real, overdue and much-needed change"". Supporters say it will lead to greater self-determination for First Nations communities. The No campaign says the Voice will have too much power though - arguing it will undermine government processes and clog up the courts with its objections. But the Voice will have no power of veto and many fears raised by the No campaign have been debunked or strongly disputed, including by Australia's solicitor-general. The debate online has been dominated by discussions of race, say fact-checkers and monitors. ""Race is a prime vector for abuse, trolling, disinformation and conspiracy theorising and on the No side of the debate, Twitter [X] is rife with that,"" says Dr Timothy Graham, a digital media lecturer who has analysed over 250,000 Voice-related posts. The Australian Associated Press' FactCheck team - which has been hired to monitor content on Facebook, Instagram and TikTok - has noticed the same on those platforms. The official campaign has only just begun, but they are already seeing volumes of misinformation and disinformation that outstrips what they saw at Australia's 2022 election, says editor Ben James. The team has debunked posts on everything from the rules of a referendum to false claims about the constitution, key campaign figures, and the possibility of a future ""black state"". Among them have been lies that Mr Mayo told another Indigenous man to ""sit down and shut up"" for asking questions at a Yes campaign event; manipulated videos of the prime minister; rants insisting that non-Indigenous people will be banned from the country's biggest sporting venues; and claims that the Voice had already failed at a referendum over 20 years ago. ""We have checked claims from both sides, but we have certainly seen more claims from those against the proposal,"" says Mr James. He tells the BBC a ""fair proportion"" of those claims contain racist undertones or abusive and derogatory language. Mr James stresses that not all the anti-Voice claims are coming from the official No campaign, and that the most offensive content is generally not emanating from representatives of either camp. But analysts say a lot of the content mirrors the narratives that underpin the No campaign. That includes claims from Australia's opposition leader Peter Dutton that the Voice will ""permanently divide"" the nation based on race, creating an ""Orwellian effect"" that gives First Nations communities greater rights and privileges. These warnings are unfounded, say legal and constitutional experts. Mr Dutton has not directly addressed accusations he has spread misinformation, but said in a speech to parliament: ""When Australians raise reasonable and legitimate concerns about the Voice model, the government dismisses them as a scare campaign, as nonsense, as noise, and misinformation."" However, some online accounts responsible for spreading messaging around racial division show signs of ""inauthenticity"" and bot-like behaviour, according to social media experts working with the Yes campaign. Those accounts were recently created, have almost no history, and have been ""duplicating the exact same content"", says communications adviser Ed Coper. One example he cites is an anti-Voice Facebook post which was shared over 53,000 times shortly after being created, while only tallying 92 likes and 23 comments. He argues this is evidence of an attempt to ""game the platform's algorithm"" and spread disinformation as ""far and wide as possible"". In July, Meta - which owns Facebook and Instagram - announced a funding boost for its fact-checking teams tasked with monitoring the referendum. Last week, however, it suspended one partner organisation to review the group's certification and complaints against it. ""We've also improved our AI so that we can more effectively detect and block fake accounts, which are often behind this activity,"" said Meta's director of public policy for Australia Mia Garlick. For Mr Mayo, there is a growing disconnect between the narratives permeating social media and what he experiences in public. ""You deal with all this vitriol online - and for me even in the mainstream media - but among fellow Australians, the feeling is totally different. I can feel a great momentum towards success,"" the Kaurareg Aboriginal and Kalkalgal, Erubamle Torres Strait Islander man tells the BBC. Mental health agencies say they are recording marked increases in reports of online hate speech and abuse. ""We've had a 106% rise in the last four months on abuse calls, which I'd put down to the Voice basically,"" says Marjorie Anderson, the national manager at 13Yarn, a crisis support line for First Nations Australians. She describes the racist abuse on social media as ""scary"". ""We won't know the scale of the damage until after the referendum. Think about the responsibility if the Aboriginal suicide rate goes up and we can link that back to disinformation around the Voice"" she says. But Fair Australia - the conservative organisation spearheading the No vote - stands behind its claims. ""The government and the Yes campaigns wear the entire responsibility for this divisive referendum. We are not the ones trying to divide Australians by race,"" its leader, Senator Jacinta Nampijinpa Price, tells the BBC. Megan Krakouer, a Menang woman who helps run the National Suicide Prevention and Trauma Recovery Project, says her team has also seen a serious spike in reports of ""racism and comments of hate"". Ms Krakouer had initially argued against the Voice, believing it did not go far enough because the advisory body will have no veto power over MPs. But she recently changed her position following a spate of suicides in her local community in Western Australia. Her hope now is that the body - though not ""perfect"", she says - will shift the dial on ""the stark issues killing and hurting First Nations people"". Publicly, Yes campaigners are still projecting confidence despite the recent drop in polling. But Mr Mayo worries about the scars the debate itself may inflict, win or lose. ""People are going to suffer throughout this campaign. I think the most shameful thing is what the opposition has done to this conversation, and history will reflect that,"" he says. ""This takes nothing away from anybody other than the burdens of our colonial past. It is hopeful and unifying, and they've made it a divisive political issue when it's really a basic, modest reform."" Update 19 September 2023: This article has been updated to reflect that some First Nation Australians were included in censuses before 1971. Additional reporting by Tiffanie Turnbull in Sydney."
Wales Health Minister vows to help dispel BAME vaccine lies,"Wales' health minister says he wants to stop false information which might put off people from ethnic minorities from taking the coronavirus vaccine. Race Council Cymru (RCC) said lies were being shared online and urged the Welsh Government to take action. Health minister Vaughan Gething  said he was ""disappointed"" to hear of a campaign of ""targeted disinformation"". It comes as UK Vaccine minister Nadhim Zahawi warned of the impact of such conspiracy theories. Vaccinations started in the UK last week following the approval of the Pfizer/BioNTech jab. RCC's Patience Bentu called for ""community champions"" to spread positive messages about the vaccine. She said some conspiracy theories were wrongly making out that people from ethnic minorities were being used as ""guinea pigs"" for the vaccine and so those people would experience any side effects first. A recent study published in eClinicalMedicine/The Lancet suggested those from Black, Asian and Minority Ethnic (BAME) backgrounds were disproportionately impacted by the virus. Health minister Vaughan Gething said he would ""happily work alongside Race Council Cymru"". Owen Williams, of social media agency Siml, said the combination of misinformation and the pandemic could lead to a ""a perfect storm of problems"". ""What needs to happen fundamentally is that the platforms themselves need to get a better handle on the distribution of this fake news and fake content,"" he said. Facebook said it ""removes Covid-19 misinformation that could lead to imminent physical harm, including false information about approved vaccines"". Between March and October it said it had taken down more than 12 million pieces of this type of content on Facebook and Instagram. Twitter said it prioritised removing Covid-19 misinformation. It said it had removed thousands of tweets since March but would not take enforcement action on every tweet which contains incomplete or disputed information."
War in Ukraine: The making of a new Russian propaganda machine,"The port city of Berdyansk had been occupied by Russian troops for less than a week, but a new pro-Kremlin online media outlet had already moved in. The company, whose name translates as Southern Front, makes and distributes pro-Vladimir Putin propaganda across YouTube, social media app Telegram, and through a website that targets areas newly under Russian control. The Southern Front news site posted its first message on day one of the Russian invasion of Ukraine, and now has several correspondents filing stories on a daily basis. The BBC has found evidence that the site's reporting contains falsehoods and misleading claims. In early March, Southern Front's correspondent was at the scene in Berdyansk. They reported that Russian soldiers had apparently thwarted an attack, and killed two Moroccan men involved. The reporter alleged the men were working as mercenaries for Ukraine.  But it appears elements of the video were staged. The two Moroccan men identified in the attack were allegedly found with their Ukrainian residency permits still on them. The BBC tracked down one of the men implicated. According to the report he was dead, but we spoke to him on social media. He requested anonymity but says he was not aware of the Russian report and that he left Ukraine before the invasion and returned to Morocco. Southern Front regularly posts videos containing unsubstantiated claims. The majority of the reports claim to show ""peaceful life"" has been established in occupied areas. The channel often runs stories that justify Russia's invasion. In one video package, a correspondent reports from a library where she says she found numerous examples of books containing ""Nazi symbols"". No evidence is seen on screen. The books that do appear on camera include works by contemporary Ukrainian writers about genuine historical events, such as the battle of Ilovaisk. ""Southern Front is likely to be part of the wider Russian strategy to establish control over the occupied territories of Ukraine,"" says Julia Smirnova, an analyst at the Institute for Strategic Dialogue. The company and its social media channels are portraying the Russian occupation in the southern regions of Ukraine as a ""liberation"", and Russian forces as ""protectors"", says Ms Smirnova. Southern Front's first message on Telegram to its small audience of 25 subscribers on the day of the invasion said: ""Vladimir Putin announced the start of a special operation to demilitarise and de-Nazify the territory of Ukraine!"" Three months into the occupation, its audience has now grown to 23,000. A website was registered a day after the invasion started. Initially using a Russian server from St Petersburg, it then moved to the American provider Cloudflare, which allows a site to hide the identity of its owner. The channel produces a regular news service fronted by young, apparently amateur presenters from annexed Crimea or self-declared separatist republics. Ukrainian news sources have been largely cut off. One of the presenters contacted by BBC Russian said they worked for free, and didn't know who funded the operations. We also asked Southern Front about the ownership, but did not receive a reply. But it does appear an influential organisation with ties to the Russian government is hosting Southern Front's content. After researching dozens of videos, we noticed some clues as to who might be behind the shadowy media organisation. Many of them were recorded in a conference room displaying the logo of the Russia-Donbas Integration Committee, which suggests this organisation's premises are used to film.  The Crimea-based committee's mission, listed on its website, is to build economic and humanitarian ties with the annexed Crimea and the pro-Russian separatist republics in the Donbas. The leaders of these self-proclaimed republics in eastern Ukraine have key roles in the organisation. The co-ordinator is Andrei Kozenko Â a former Russian MP, currently under US and EU sanctions. Southern Front's content reaches far beyond its website. A network of like-minded Telegram accounts covering occupied cities often publishes its material. Collectively, these channels now have more than 80,000 subscribers, although our research shows at least one-third of these were probably paid for to artificially inflate the audience. In three channels the number of followers jumped by more than 10,000 in an hour overnight on 29 March, according to analysis of TG Stat, which tracks Telegram data. Despite the relatively small following on social media, Southern Front has been boosted by influential accounts, including a pro-Russian blogger with more than 650,000 followers, and by pro-Kremlin media such as Moskovsky Komsomolets - a Moscow-based newspaper found in most post-Soviet countries. But the fightback has started. Recently pro-Ukrainian activists hacked Southern Front's website with a message about Kherson, which the region's new rulers say they want to be annexed by Russia. One of the posts warned that any individuals involved in a so-called referendum on the future of the region will be punished by Ukraine. It said: ""Welcome to Hell!!!"" Despite the attack, the site was up and running again shortly afterwards. There are worrying signs for residents if the project establishes itself. After nearby Crimea was annexed in 2014, independent media outlets were expelled, says Ms Smirnova. ""In southern Ukraine, Russian authorities are likely to follow a similar path by threatening and arresting independent journalists, silencing independent media outlets and replacing them with propaganda channels."" Additional reporting by Samia Hosny and Olga Robinson, BBC Monitoring."
Welsh election: Inquiry into campaigns' social media use,"Could the Welsh Parliament election have been used to spread disinformation online? A Senedd inquiry, supported by political parties, plans to investigate social media use after the election has taken place. Andy Regan, from the Institute of Welsh Affairs (IWA), said there was evidence even small nations' elections can be used to create discord. The probe will also look at whether the campaigns have broken any rules. Mr Regan, policy and external affairs manager at the IWA, said: ""People are very aware misinformation was a factor in the Brexit referendum, we have clear evidence, as well as in the 2016 US election where actors were apparently spreading information. ""How do we know this isn't happening in Wales? SIGN UP FOR WALES ALERTS:  Get extra updates on BBC election coverage ""What's become clear is it's absolutely a factor in small nations' elections, not just globally significant elections. ""We can't say this is happening, but it's reasonable to say we should look at whether or not it is, because we don't know."" Mr Regan said there was a difference between disinformation - knowingly and deliberately misleading - and misinformation, which can be done sincerely by people who believe what they are saying is correct. ""Both are a problem and it's a problem when they're used to influence how people vote,"" he said. ""I think this is something we were talking about before lockdown happened, the question of whether it is possible to hold a free and fair election given this social media activity. I think we probably would still have been saying this but it's going to be more prominent as a result of Covid. ""Social media can be a really positive tool, and a bigger part of everybody's life these days. What Covid has perhaps done in the context is give us quite an obvious thing to talk about, in terms of where that misinformation can fit."" Mr Regan said it was considered fair to critique the way governments had handled the pandemic and lockdowns on social media, but where it crossed the line would be misinformation, for example, about vaccines. ""Nobody was happy about lockdown, there are opinions about how it should be approached by governments and it's fair to criticise, what's not correct or accurate is claims that lockdowns don't work or vaccinations don't work, claims that aren't true.,"" he said. ""Another issue would be the targeting of individual candidates with factually inaccurate smears, pile-ons orchestrated as an attempt to create negative messages around a particular person which is a particular problem for women and BAME candidates and can be a disincentive to even stand in the first place."" WHO SHOULD I VOTE FOR? Compare what the parties are promising to do in Wales with our election manifesto guide. There are existing rules and regulations over the activities of political parties in an election, but Mr Regan said there was a grey area when it came to external influences using an election to simply create discord rather than trying to influence the outcome. He called for existing rules to be updated to keep up with the developments in social media and its influence on elections. ""The issue of abuse and harassment falls into the scope of existing rules and regulations, but there are shades of grey when it comes to those trying to sow discord and disunity because it's a destabilising agenda rather than to influence an election,"" he added. ""It's harder to pin down where rules have been broken, when it falls outside the remit of party campaigns and goes much wider. ""We know this is a feature of the modern election but is it something we should just accept and allow to become normalised?"" Mr Regan said ""deep fake videos"", technology which creates videos of figures such as Barack Obama saying something they have not said, could become a much bigger problem in future. ""They are very convincing, and if you don't take a stand now then next time the kind of activity could be much more worrying than a text or a picture that isn't true,"" he said. ""And the use of outside actors is troubling, whatever the agenda, it is something they can use to draw attention to other agendas, not just party politics. ""The fact is the parties have all come out so strongly for this inquiry, which is probably quite brave of them, and we really welcome the Senedd taking this approach."" WALES ELECTION: THE BASICS What's happening? On 6 May, people will vote to elect 60 Members of the Senedd (MSs). The party that can command the support of a majority of MSs will form the Welsh government.  Find out more here. What powers does the Senedd have? MSs pass laws on aspects of life in Wales such as health, education and transport - and have some tax powers. Mr Regan said while the inquiry would look at the activities of candidates and political parties, it was not seeking to overturn any result. ""The most high profile example of this would be the Brexit referendum, and the calls for this to be looked into which are associated with the Remain side - but would Brexit have won anyway? ""The thing is that there are rules already that people should be complying with and in some cases those rules are out of date, so it's not going to be about saying there would be a different result if that hadn't taken place."" Rather than punishing any party or candidate for alleged rule-breaking or ""deeply questionable"" use of social media, Mr Regan said the aim would be to raise awareness among the public about misinformation ""and make people more sophisticated consumers of information they find online"". A modern browser with JavaScript and a stable internet connection is required to view this interactive. More information about these elections Enter your postcode, or the name of your English council or Scottish or Welsh constituency to find out. Eg 'W1A 1AA' or 'Westminster' nan nan It is also looking at the global activity of spreading falsehoods online. ""It's hard to imagine a solution without requiring the involvement of sites with a properly resourced system for checking, removing and letting people know if something they have shared was not legitimate,"" Mr Regan said. ""On a Welsh level, we should have a proper commitment to our election having integrity, and it's about the Senedd taking control of the integrity of its own election and being clear if this is a problem."" The inquiry is supported by Welsh Labour, Plaid Cymru, the Welsh Conservatives, the Liberal Democrats and the Green Party."
What claims do you want BBC Reality Check to investigate?,"BBC Reality Check is dedicated to examining the facts and claims behind a story to try to determine whether or not it is true. What would you like us to investigate? We're particularly interested in claims you have heard people making, like the ones that sparked these stories: It could be something you've heard said about Brexit or climate change or a story in the news or on social media that just doesn't feel right. Or it can simply be something you've always wanted to know the truth about. If your question is chosen we will try to get to the bottom of it and publish the findings on the BBC Reality Check page. Send us your claims, fact checking ideas and questions for our Reality Check team. Use this form to ask your question: Please don't publish my name I accept the Terms of Service The BBC retains the right to select from these contributions based on editorial requirements and subject to online terms and conditions and  BBC editorial guidelines. For more information about how the BBC handles your personal data,  see here. If you are reading this page on the BBC News app, you will need to visit the mobile version of the BBC website to submit your question on this topic."
What claims do you want BBC Verify to investigate?,"BBC Verify is dedicated to examining the facts and claims behind a story to try to determine whether or not it is true. What would you like us to investigate? We're particularly interested in claims you have heard people making. It could be something you've heard said about a story in the news or seen circulating on social media that just doesn't feel right. Or it can simply be something you've always wanted to know the truth about. Here are some previous fact checks from BBC Verify: If your question is chosen we will try to get to the bottom of it and publish the findings on the BBC Verify page. Send us your fact checking ideas and questions for our BBC Verify team. Use this form to ask your question: Please don't publish my name I accept the Terms of Service The BBC retains the right to select from these contributions based on editorial requirements and subject to online terms and conditions and  BBC editorial guidelines. For more information about how the BBC handles your personal data,  see here. If you are reading this page on the BBC News app, you will need to visit the mobile version of the BBC website to submit your question on this topic. BBC Verify is dedicated to examining the facts and claims behind a story to try to determine whether or not it is true. What would you like us to investigate? We're particularly interested in claims you have heard people making. It could be something you've heard said about a story in the news or seen circulating on social media that just doesn't feel right. Or it can simply be something you've always wanted to know the truth about. Here are some previous fact checks from BBC Verify: If your question is chosen we will try to get to the bottom of it and publish the findings on the BBC Verify page. Send us your fact checking ideas and questions for our BBC Verify team. Use this form to ask your question: Please don't publish my name I accept the Terms of Service The BBC retains the right to select from these contributions based on editorial requirements and subject to online terms and conditions and  BBC editorial guidelines. For more information about how the BBC handles your personal data,  see here. If you are reading this page on the BBC News app, you will need to visit the mobile version of the BBC website to submit your question on this topic."
What is the Great Reset - and how did it get hijacked by conspiracy theories?,"A vague set of proposals from an influential organisation has been transformed by online conspiracy theorists into a powerful viral rallying cry. What is the truth behind the ""Great Reset""? Believers spin dark tales about an authoritarian socialist world government run by powerful capitalists and politicians - a secret cabal that is broadcasting its plan around the world. Despite all the contradictions in the last sentence, thousands online have latched on to this latest reimagining of an old conspiracy theory - updated for the age of Covid. Like many popular conspiracy theories, this one starts with a grain of fact. In June 2020, the Prince of Wales and the head of the annual Davos summit launched an initiative calling for the pandemic to be seen as a chance for what they called a Great Reset of the global economy. A flashy launch video interspersed images of a world in chaos - a dead killer whale, a hurricane, a kangaroo caught in a fire - with a speech by Prince Charles. ""We have an incredible opportunity to create entirely new sustainable industries,"" the prince said. ""The time to act is now."" The other founder of the initiative is Prof Klaus Schwab, head of the World Economic Forum (WEF), which organises an annual summit in a Swiss ski resort for some of the world's wealthiest and most powerful people. He explained the idea behind the Great Reset in an article accompanying the launch: ""The pandemic represents a rare but narrow window of opportunity to reflect, reimagine, and reset our world to create a healthier, more equitable, and more prosperous future."" There's a Great Reset podcast and even a 280-page book. But the plan is light on specific detail. Prof Schwab does speak about a ""wealth tax"" and ending fossil fuel subsidies. But the scope is huge - covering technology, climate change, the future of work, international security and other themes - and it's difficult to see precisely what the Great Reset might mean in practice. This lack of clarity, combined with the plan being launched by an influential organisation, provided fertile ground for conspiracy theories to grow. The proposals, along with the WEF itself, face legitimate criticism from a variety of sources. Conservative political figures and media outlets accuse the organisation of pushing for environmental policies that would hurt the economy. There are questions about whether unelected individuals like Mr Schwab should have the power to lobby so prominently for ideas that could potentially transform the global economy. The Davos meeting is certainly filled with powerful people who have a huge influence on world events. There are also concerns about the impact of technology on civil liberties and jobs. But the real energy online is not about legitimate political questions - discussions about fossil fuels and income equality - but in the shape of wild and unsubstantiated claims. The term ""Great Reset"" has received more than eight million interactions on Facebook and been shared almost two million times on Twitter since the initiative was launched, according to BBC Monitoring research. Among the most popular posts are baseless statements that the Great Reset is a strategic part of a grand conspiracy by the global elite, who somehow planned and managed the Covid-19 pandemic. In this narrative, lockdown restrictions were introduced not to curb the spread of the virus, but to deliberately bring about economic collapse and a socialist world government, albeit run for the benefit of powerful capitalists. The nebulousness of this conspiracy theory means it has found followers among anti-vaccine activists, anti-lockdown campaigners, new-age healers, and those on the far right and far left. Melanie Smith, head of analysis at Graphika, who researches online movements and disinformation, says the rumours are typical of an ""anti-establishment conspiracy theory"". ""The most intricate of those typically prove popular with government sceptics from across the political spectrum,"" she says. In the hands of a diverse group of online activists, the Great Reset has been transformed - from a call to encourage people to think about a sustainable future, to a sinister plot against humanity. These conspiracy theories began circulating online around the June 2020 launch, but only gained significant traction later in the year. On 15 November, the phrase started trending on Twitter when a video went viral showing Canadian Prime Minister Justin Trudeau at a UN meeting in September, saying the pandemic provided an opportunity for a ""reset"". It's unclear whether he was referring to the WEF plan. But some claimed his speech was proof that global leaders were using the pandemic as a pretext to introduce a range of socialist and environmental policies. Thousands of Donald Trump supporters boosted this idea. They claimed that that a victory for Mr Trump in November's election was the only chance to thwart the so-called secret plot. Most of the narratives being promoted around the Great Reset are not new. Experts say similar ideas about the emergence of a totalitarian world government have been circulating since the 1960s under the umbrella term New World Order, which itself borrows ideas from conspiracy theories of the 18th Century. Great Reset sceptics repackage those ideas, folding in new baseless Covid-era claims - for instance about how vaccines ""contain microchips"" and ""enslave"" people. Its ""adaptability and close ties with New World Order narrative"", Ms Smith says, make it likely that the conspiracy theory will outlast the pandemic. In a video from January, the WEF acknowledged that the messaging around the Great Reset didn't quite go to plan. ""Hands up, this kind of slogan hasn't gone down well,"" a voiceover says. In response to questions about whether the discussion had been hijacked by conspiracists, the WEF said in a statement: ""Conspiracy theories replace reason with fantasy. They are a noisy but peripheral part of the public sphere. ""We encourage rationally grounded, fact-based debate."" Conspiracy beliefs are also seeping into discussions about the global response to climate change. Mr Schwab's proposal emphasises the use of more green public infrastructure projects and ""greener growth"". Ms Smith says online activists who deny the existence of climate change often engage with the Great Reset theory to ""dismiss sustainability and renewable energy initiatives as an elite agenda for control"". ""The overlap of those conversations may become stronger as climate issues become even more prominent,"" she says. Reporting by Olga Robinson, Shayan Sardarizadeh, Jack Goodman, Christopher Giles and Hugo Williams."
What's behind the rise of QAnon in the UK?,"A wide-ranging conspiracy theory about elite Satan-worshiping paedophiles has migrated from the US, inspiring a series of regular street protests. How did QAnon find a British audience? On a sunny day in late August, nearly 500 people gathered in central London. It was the first event held by a new group, Freedom for the Children UK. As the crowd marched from the London Eye to Buckingham Palace, chants of ""Save our children!"" echoed in the air. The ethnically diverse crowd was made up mostly of young people and women, some with their children. At the head of the march were group leaders Laura Ward and Lucy Davis. Ms Ward, 36, who says she underwent a ""spiritual awakening"" during the Covid-19 lockdown, created a Facebook group in July ""to promote and organise peaceful events that raise the awareness of child exploitation and human trafficking"". It took off, gathering thousands of followers in just a few weeks. The London march was just one of 10 rallies held across the UK, including events in Birmingham, Bristol and Manchester. A Liverpool rally drew similar numbers of people. The organisers say their movement is not directly linked with QAnon, a wide-ranging, baseless, pro-Trump conspiracy theory. But their themes are similar, and their evidence-free claims largely the same. And when images began to appear on the FFTCUK Facebook group later that day, placards, signs and items of clothing directly referencing QAnon were prevalent at almost all of the rallies. QAnon began life - most likely as a joke or prank - on extreme message boards in 2017. It's an unfounded conspiracy theory that claims President Trump is secretly battling a clandestine network of Satan-worshipping elites who run a child trafficking ring. The ""Q"" in QAnon is the person or persons writing cryptic messages to the movement's followers. Q claims to have top secret clearance within the US government. Q has told followers to ""trust the plan"" for a ""great awakening"". The messages have predicted mass arrests or purges of top Democratic Party officials. And none of the prognostications have come true. Despite its bizarre premises, QAnon took off in niche online communities and rapidly grew on social networks. BBC Trending Until this year, the conspiracy theory was confined to the internet's fringes. But then came the pandemic. QAnon influencers took advantage of fear, uncertainty and doubt - and the fact that many people were at home, worried, and living more of their lives online. Surveys from the Pew Research Center indicate that the number of Americans who are aware of QAnon and support its ideas increased substantially this year. Supporters have been linked to several violent crimes. In light of this, several major social networks including Twitter, Facebook and TikTok began restricting QAnon terms, phrases and hashtags on their platforms over the summer. Believers changed tack. Urged by a Q message to ""learn the use of camouflage digitally"", followers avoided direct references to QAnon and began hijacking well-known, established hashtags and phrases used by genuine campaigners against child trafficking - such as the innocuous sounding #SaveTheChildren and #SaveOurChildren. A BBC analysis based on data from Facebook-owned tool CrowdTangle, and Spredfast, found that in the last three months, the two hashtags were used a total of 1.5 million times on Twitter and generated more than 28 million interactions on public Facebook and Instagram posts. And outside the US, British followers lead the way. Our analysis of online data from the last three months puts the UK ahead of all European countries, followed by Germany and the Netherlands. Marc-Andre Argentino, a researcher at Concordia University in Montreal, has identified at least 114 Facebook groups which spread QAnon content under the guise of campaigning against child trafficking. Membership of such groups has risen by more than 3,000 percent since July, he says. A key British YouTube influencer is Charlie Ward, who lives in Spain and began uploading QAnon-themed videos during lockdown. While older clips about his personal life received barely any attention, his channel now boasts more than 170,000 subscribers and he has hosted discussions with FFTCUK leaders. Mr Ward did not respond to a request for comment. In May, Ms Ward (no relation to Mr Ward) began engaging with social media posts by conspiracy theorist David Icke and a number of QAnon influencers in the US and Canada about Covid-19 lockdowns, George Floyd protests, and global child trafficking. ""I'm feeling powerless and I want to do more to create change. What do you suggest?"" she tweeted at a Canadian QAnon influencer. A few weeks later, inspired by a global ""Save Our Children"" movement launched by a California-based rapper and actor, Ms Ward set up the FFTCUK Facebook group with the aim of launching a similar movement at home. By the end of August, Save Our Children street rallies were held in more than 200 towns and cities around the world, including a dozen in the UK. The FFTCUK Facebook group has now amassed more than 13,000 members. While moderators are cautious about direct references to QAnon, discussion in the group is peppered with QAnon-related talk and hashtags. Members also routinely organise coordinated online campaigns targeting news organisations. For instance, when an independent magazine published a piece about a local FFTCUK rally, its Facebook page was swamped by comments that abused its staff. This, coupled with threats of violence, led the magazine to temporarily deactivate its social media accounts. On their personal accounts, FFTCUK leaders are vocal about their beliefs. Ms Ward's Twitter and Facebook accounts feature frequent accusations of paedophilia against leading US Democrats, and she regularly defends QAnon and its followers. She turned down an interview request for this story. The vast majority of the protesters on the FFTCUK march in August ignored Covid-19 restrictions and social distancing guidelines. As they finished the march and gathered near Wellington Arch for a meditation session, Ms Ward talked about a ""fake pandemic"". While most of the UK rallies are organised by Ms Ward and FFTCUK, one in London was co-organised by StandUPX, a campaign group behind rallies featuring speakers such as David Icke. The rallies attract a wide range of speakers and attendees, from those who oppose government restrictions to those who claim that the pandemic is a ""hoax"" or somehow caused by 5G technology. A spokesperson for StandUPX said: ""We cannot be accountable for the views of each and everyone appearing at the rally and have no views about QAnon."" Experts say a number of national controversies and scandals in relation to elite child abuse had already primed the UK for the rise of conspiratorial narratives. ""Activists in the UK have easily woven British issues - such as Operation Yewtree investigations into historical child sexual abuse - into Q narratives,"" says David Lawrence, a researcher for the campaign group Hope not Hate. ""Long before the birth of QAnon, prominent British conspiracy theorists have promoted ideas about elite, occult paedophile circles engaging in large-scale child trafficking and abuse, and British activists are drawing on this broader tradition,"" he says. And the upheaval of the pandemic created a perfect storm which helped QAnon find common ground with Covid-19 conspiracists. ""Public trust in institutions has declined in the UK in recent years, and has been exacerbated by the handling of the pandemic,"" Mr Lawrence added. ""This has provided ideal conditions for conspiracy theories to spread."" Two weeks after their first protests, FFTCUK held a bigger protest in London on 5 September. Around 1,000 people marched from Oxford Street to the BBC's Broadcasting House, and then to Parliament Square. The protesters paused outside the Disney Store on Oxford Street. ""Shame on you,"" they angrily chanted, echoing a widely-held, evidence-free belief among QAnon followers that the company is part of a child trafficking cabal. Once again, women and young people were at the forefront of the march. People were dressed in QAnon shirts or ones displaying the slogan ""WWG1WGA"". Short for ""Where we go one we go all"", it is the best-known rallying cry for QAnon believers. Other bizarre terms - albeit ones well-known to QAnon followers - were on display: ""adrenochrome"", ""frazzledrip"", ""dark to light"", ""spirit cooking"", ""paedogate"". One marcher held up a placard referencing Pizzagate, a conspiracy theory that alleged Hillary Clinton and Democratic Party politicians were running a paedophile ring out of a Washington pizza restaurant. It prompted a heavily armed man to enter the restaurant, searching for non-existent child prisoners. He was later sentenced to four years in prison. In London, the vast majority of the protesters I spoke to said they first heard about FFTCUK via social media, especially Facebook. Some said they fully believed in QAnon and followed every Q message, while others were only partially familiar with it. There were supporters of President Trump, people who don't like him very much, and those that said they don't pay much attention to politics. However, they all shared a strong suspicion of the establishment, coupled with the belief that there is a ""deep state"" of elites in the UK who are committing crimes against children with impunity. ""Pizzagate is 100% true,"" said Jada, a young protester. ""There are paedophiles in our elite everywhere and they need to be taken down. This is happening in the US, in the UK and all over the world."" ""I'm not sure if I'm QAnon, I don't follow that stuff much,"" said Audrey, another young protester. ""But the deep state is not a secret, it's not a conspiracy theory."" And although she said she was initially not a fan of President Trump, her opinion has recently changed. ""He's doing a lot of good but that's not being shown on TV,"" she said. Charities and professionals who work to fight real child abuse and human trafficking say the conspiracy theorists aren't helping by supposedly ""raising awareness"". In fact, they say they're distracting attention away from real crimes and authentic issues. Laura Duran, senior policy and research officer at Every Child Protected Against Trafficking, says QAnon's false claims about child trafficking are ""a slap in the face of survivors who have gone through exploitation"". As an example, she cites the viral Wayfair conspiracy theory, which claimed in June that a US-based furniture retailer was involved in trafficking children. The viral, untrue rumours caused ""a significant level of trauma and distress to child trafficking survivors,"" Ms Duran says. Although QAnon has always had female followers, the sudden shift towards #SaveOurChildren seems to have brought into fold even larger numbers of women, some via health, yoga and wellness Facebook groups and Instagram accounts. The majority of the FFTCUK Facebook group's admins are women, and a few come from wellness communities. ""Early barrages of viral disinformation in the UK lockdown spread 5G and 'fake virus' narratives, both of which found their way into anti-vaccination communities and then wellness groups,"" says Joe Ondrak, a senior investigator at Logically, a tech startup that fights online disinformation. ""From here concerned 'Facebook mums' and other well-meaning parents stuck online started doing 'research'"" - in the conspiracy world, this usually means watching YouTube videos and trawling fringe websites - ""or finding videos reasserting conspiracy beliefs,"" he says. Annie Kelly co-presents the weekly QAnon Anonymous podcast, which investigates the movement. She also reported on the first FFTCUK rally in London. She says by focusing on highly emotive content about child safety, #SaveOurChildren has managed to ""worm its way into normal, basically apolitical parenting groups"". On Instagram, ""soft"" QAnon narratives have crept into content posted by female lifestyle influencers with tens of thousands of followers. Mothers who spend time in online communities where concerns about children's products and content are shared have been a key driver of the new wave of QAnon believers, Ms Kelly adds. ""They can very easily become influencers themselves by sharing things they've noticed which they think add to the conspiracy,"" she notes. The demographic makeup of the UK marches is significant, the experts say, as it does not match the stereotypical crowd of young men drawn from the right and the far-right. ""These weren't your typically 'red-pilled' conspiracy theorists,"" says Nick Backovic, a contributing editor at Logically. ""They were worried mums and dads who had been scared into believing these exaggerated stats that aren't backed up by any evidence."" In terms of size and appeal, the British QAnon movement is still fringe compared to the US, where the conspiracy has leaked into the mainstream. A number of politicians who have previously endorsed QAnon are set to win seats in Congress and state or local legislatures in November's elections. But the growth of QAnon in the UK also shows no sign of stopping. Every Sunday, Ms Ward and Ms Davis broadcast on Facebook Live to update members about their plans and discuss ways to spread the message. The FFTCUK group keeps adding members, and further events are planned. Follow Shayan on Twitter. Subscribe to the BBC Trending podcast or follow us on Twitter @BBCtrending or Facebook."
Where is the anti-lockdown movement headed?,nan
Why are QAnon believers obsessed with 4 March?,"Their hero is no longer president, but some followers of the fringe QAnon conspiracy theory have latched onto obscure, irrelevant laws in an attempt to keep the faith. It's been six weeks since the inauguration of President Joe Biden, and it would seem that Donald Trump's best chance of regaining the presidency would be the 2024 election. But some of his fervent followers who support the baseless QAnon conspiracy theory believe he'll be coming back sooner - and will somehow be returned to power on 4 March. The idea stems from the belief among some QAnon followers that the United States turned from a country into a corporation after the passage of the District of Columbia Organic Act of 1871. It's an odd, unfounded theory drawn from the sovereign citizen movement, an extreme libertarian fringe that opposes federal laws, general taxation and even the US currency on the grounds that they restrict individual rights. Believers in the QAnon offshoot maintain that every US president, act and amendment passed after 1871 is illegitimate. But the theory is based on a false interpretation of the Organic Act, which merely turned the District of Columbia into a municipal corporation, better known as a local governing body, and has no relation to a president or the US as a whole. Before the 20th amendment of the US Constitution - adopted in 1933 - moved the swearing-in dates of the president and Congress to January, American leaders took office on 4 March. That's why QAnon followers have latched on to this date to underpin their latest theory. The date 4 March began spreading among QAnon followers only days after Mr Biden was sworn in on 20 January. That completely predictable event caused tumult in the world of QAnon - a wide-ranging, completely unfounded theory that says Mr Trump is waging a secret war against elite Satan-worshipping paedophiles. QAnon followers had been promoting 20 January as a day of reckoning, when prominent Democrats and other members of the alleged ""cabal"" would be arrested and executed on the orders of Mr Trump. When the promised ""storm"" failed to materialise, there was shock and despair among many believers. ""The real POTUS can't get back into office fast enough. March 4 at the latest... PLEASE GOD!"" read a comment in a major QAnon channel on the messaging app Telegram in late January. Other QAnon followers on alternative social media platforms such as Gab echoed the sentiment. One influencer, with 55,000 subscribers, suggested there was a 150-year-old clue in the 1871 Organic Act itself. The digits of the act add up to make 17, a symbolic number for the conspiracy's followers - with Q being the 17th letter of the English alphabet. Numerology ""proofs"" are big in the world of QAnon. Authorities have warned of intelligence that an unnamed militia group has planned an attack in Washington on 4 March. But some QAnon influencers have moved in recent days to manage expectations. They are claiming that 4 March could be a ""false flag by the deep state"" and mainstream media to frame the movement and encourage supporters to engage in additional acts of violence after the Capitol riots. QAnon influencers have gone out of their way to distance themselves from the events of 6 January after a number of followers took part. At least two prominent supporters, ""Q Shaman"" Jacob Anthony Chansley and Doug Jensen, have subsequently been arrested. Both men have pleaded not guilty to the charges. A major QAnon online forum warned followers to ""stay home, stay alert, and stay safe"" on Thursday. ""QAnon influencers are doing damage control,"" says Julian Feeld, co-host of the QAnon Anonymous podcast, which investigates the movement. ""Influencers are attempting to insulate themselves from less media-savvy QAnon followers who will say or do things on camera that aren't strategic for the longevity of QAnon."" Despite the recent pushback from influencers, some followers remain convinced that the promised ""storm"" or reckoning is set to be fulfilled on 4 March, with some warning that without a major event on Thursday, they might take matters into their own hands. ""I'm giving this... till March 4 I am packed and ready for civil war,"" one supporter said in a Telegram chat. ""March 4 better yield results or some of us are going rogue,"" read another post. But with 4 March set to be yet another disappointment and no new posts by ""Q"" since 8 December, followers are floating new potential dates for Mr Trump's supposed return to power, ranging from 20 March to April to later in 2021 or even some time before the next election. And experts believe these failed prophecies are unlikely to change the views of the most faithful supporters. ""Shifting goal posts have defined the movement from the very beginning and I believe they will continue to,"" Mr Feeld says. ""Weakened as it may appear from the outside, the alternate realities of QAnon won't just go away,"" says Sarah Hightower, an independent researcher and expert in conspiratorial movements. ""As long as there are still people holding on to those alternate realities, QAnon will continue to exist in some form."" Follow Shayan on Twitter Subscribe to the BBC Trending podcast or follow us on Twitter @BBCtrending or Facebook."
Why is climate 'doomism' going viral Â and who's fighting it?,"Climate ""doomers"" believe the world has already lost the battle against global warming. That's wrong - and while that view is spreading online, there are others who are fighting the viral tide. As he walked down the street wearing a Jurassic Park cap, Charles McBryde raised his smartphone, stared at the camera, and hit the record button. ""Ok, TikTok, I need your help."" Charles is 27 and lives in California. His quirky TikTok videos about news, history, and politics have earned him more than 150,000 followers. In the video in question, recorded in October 2021, he decided it was time for a confession. ""I am a climate doomer,"" he said. ""Since about 2019, I have believed that there's little to nothing that we can do to actually reverse climate change on a global scale."" Climate doomism is the idea that we are past the point of being able to do anything at all about global warming - and that mankind is highly likely to become extinct. That's wrong, scientists say, but the argument is picking up steam online. Charles admitted to feeling overwhelmed, anxious and depressed about global warming, but he followed up with a plea. ""I'm calling on the activists and the scientists of TikTok to give me hope,"" he said. ""Convince me that there's something out there that's worth fighting for, that in the end we can achieve victory over this, even if it's only temporary."" And it wasn't long before someone answered. Alaina Wood is a sustainability scientist based in Tennessee. On TikTok she's known as thegarbagequeen. After watching Charles' video, she posted a reply, explaining in simple terms why he was wrong. Alaina makes a habit of challenging climate doomism - a mission she has embraced with a sense of urgency. ""People are giving up on activism because they're like, 'I can't handle it any more... This is too much...' and 'If it really is too late, why am I even trying?'"" she says. ""Doomism ultimately leads to climate inaction, which is the opposite of what we want."" Climate scientist Dr Friederike Otto, who has been working with the UN's Intergovernmental Panel on Climate Change, says: ""I don't think it's helpful to pretend that climate change will lead to humanity's extinction."" In its most recent report, the IPCC laid out a detailed plan that it believes could help the world avoid the worst impacts of rising temperatures. It involves ""rapid, deep and immediate"" cuts in emissions of greenhouse gases - which trap the sun's heat and make the planet hotter. ""There is no denying that there are large changes across the globe, and that some of them are irreversible,"" says Dr Otto, a senior lecturer in climate science at the Grantham Institute for Climate Change and the Environment. ""It doesn't mean the world is going to end - but we have to adapt, and we have to stop emitting."" Last year, the Pew Research Center in the US ran a poll covering 17 countries, focusing on attitudes towards climate change. An overwhelming majority of the respondents said they were willing to change the way they lived to tackle the problem. But when asked how confident they were that climate action would significantly reduce the effects of global warming, more than half said they had little to no confidence. Doomism taps into, and exaggerates, that sense of hopelessness. In Charles's case, it all began with a community on Reddit devoted to the potential collapse of civilisation. ""The most apocalyptic language that I would find was actually coming from former climate scientists,"" Charles says. Listen to 'The online boom in climate doom' from BBC Trending It's impossible to know whether the people posting the messages Charles read were genuine scientists. But the posts had a profound effect on him. He admits: ""I do think I fell down the rabbit hole."" Alaina Wood, the sustainability scientist, says Charles's story is not unusual. ""I rarely at this point encounter climate denial or any other form of misinformation [on social media],"" she says. ""It's not people saying, 'Fossil fuels don't cause climate change' ... It's people saying, 'It's too late'."" TikTok's rules forbid misinformation that causes harm. We sent the company some videos that Alaina has debunked in the past. None was found to have violated the rules. TikTok says it works with accredited fact-checkers to ""limit the spread of false or misleading climate information"". Although it can take many forms (and is thus difficult to accurately measure), Alaina says doomism is particularly popular among young people. ""There's people who are climate activists and they're so scared. They want to make change, but they feel they need to spread fear-based content to do so,"" she says. ""Then there are people who know that fear in general goes viral, and they're just following trends, even if they don't necessarily understand the science."" I've watched several of the videos that she debunked. Invariably, they feature young users voicing despair about the future. ""Let me tell you why I don't know what I want to do with my life and why I'm not planning,"" says one young woman. ""By the year 2050, most of us should be underwater from global warming."" But that's a gross exaggeration of what climate scientists are actually telling us. ""A lot of that is often fatalistic humour, but people on TikTok are interpreting that as fact,"" Alaina says. But is Charles still among them, after watching Alaina's debunks? Is he still a climate doomer? ""I would say no,"" he tells me. ""I have convinced myself that we can get out of this."" For more information about mental health support, visit the BBC Action Line. Do you have a story for me? Get in touch."
Why some people are spreading false rumours about the Texas gunman,"Social media posts by the man who killed eight people at a mall in Texas show he was deep into neo-Nazi and far-right imagery and propaganda. But some activists have tried to cast doubt on the authenticity of the posts. They're claiming - without evidence - that the material is somehow part of a ""psychological operation"" or that the social media account is ""fake"". It may seem fringe, but the doubts have spread to millions via Elon Musk and others with popular Twitter accounts. Six people, including children, were pronounced dead at the scene in the north Dallas suburbs on Saturday, while two died later in hospital. The suspect, named by police as Mauricio Garcia, used an AR-15 style rifle and wore combat tactical gear during the shooting. Garcia, police say, wore a patch reading ""RWDS"", short for ""Right Wing Death Squad"" - a phrase commonly referenced by hate groups. Hank Sibley, regional director of the Texas Department of Public Safety, said in a press conference on Tuesday that the motivation for the shootings was still under investigation, and that the victims appear to have been chosen at random. ""We do know he had neo-Nazi ideation,"" he said. ""We're trying to find what he looked at [online] and trying to find any information we can."" Mr Sibley said investigators were continuing to examine Garcia's electronic devices and social media posts. Garcia posted a huge variety of material on a lightly-moderated, Russia-based site named Odnoklassniki. The account was mentioned in news reports and uncovered by the investigative outlet Bellingcat. His posts included pictures of a swastika tattoo, long violent screeds, and pictures of the mall taken as recently as last month - interspersed with other pictures of boxes of ammunition and guns. Other posts praised Nazis and the Chilean dictator Augusto Pinochet, who is often feted by people who use the ""Right Wing Death Squad"" phrase. He directly addressed his ethnic background in one meme he posted which mentioned ""Latino children"" and the phrase ""become white supremacist"". The BBC has examined the material and we can be confident the suspect was the person behind the posts. Garcia appeared to use the account, on a social network popular in Russia, as an online diary. He posted multiple documents including his name, date of birth and other identifying details, including a plane ticket, a speeding ticket and an ID card. Photos on the account also showed a distinct tattoo on his hand, which matches a graphic video of Garcia's dead body taken at the scene of the shooting. The shooter also posted images of the mall and its location on Google Maps, including the time the mall had the highest number of visitors, weeks in advance. In addition, open-source investigators found a YouTube channel with a video showing Garcia taking off a mask. Material on the channel was also posted on the Odnoklassniki account. Despite the clear evidence, several activists and internet personalities, including at least one mentioned in Garcia's posts, have attempted to cast doubt on the authenticity of the material. They've claimed, without evidence, that it's part of a ""psychological operation"" or ""false flag"" by the government to smear those on the right or far-right. A number of posts spreading the false rumours were viewed millions of times. Among them, one by Twitter chief Elon Musk called the fact the suspect had an account on a Russian platform ""very odd"" and in another message said it was ""either the weirdest story ever or a very bad psyop!"" However, Odnoklassniki has an English interface, and its lax content moderation policies mean extreme content is less likely to be taken down. Mr Musk and Twitter's communications team did not respond to a request for comment. The podcaster Tim Pool, a former Occupy Wall Street supporter and Vice News reporter, was among those mentioned several times in the suspect's posts. There's no evidence that Garcia was inspired to action by Mr Pool's podcasts, which cover right-wing talking points and conspiracy theories. But Mr Pool immediately tried to cast doubt on the veracity of the material, accusing those digging up the material as being part of a ""psyop"". Mr Pool did not respond to requests for comment. Adding to the misinformation were a photo of a man who shared a name with the suspect which circulated widely online, and several viral posts have claimed the gunman was part of a Mexican cartel or drug gang. Police said during Tuesday's press conference that he had no prior criminal record. Social media posts by the man who killed eight people at a mall in Texas show he was deep into neo-Nazi and far-right imagery and propaganda. But some activists have tried to cast doubt on the authenticity of the posts. They're claiming - without evidence - that the material is somehow part of a ""psychological operation"" or that the social media account is ""fake"". It may seem fringe, but the doubts have spread to millions via Elon Musk and others with popular Twitter accounts. Six people, including children, were pronounced dead at the scene in the north Dallas suburbs on Saturday, while two died later in hospital. The suspect, named by police as Mauricio Garcia, used an AR-15 style rifle and wore combat tactical gear during the shooting. Garcia, police say, wore a patch reading ""RWDS"", short for ""Right Wing Death Squad"" - a phrase commonly referenced by hate groups. Hank Sibley, regional director of the Texas Department of Public Safety, said in a press conference on Tuesday that the motivation for the shootings was still under investigation, and that the victims appear to have been chosen at random. ""We do know he had neo-Nazi ideation,"" he said. ""We're trying to find what he looked at [online] and trying to find any information we can."" Mr Sibley said investigators were continuing to examine Garcia's electronic devices and social media posts. Garcia posted a huge variety of material on a lightly-moderated, Russia-based site named Odnoklassniki. The account was mentioned in news reports and uncovered by the investigative outlet Bellingcat. His posts included pictures of a swastika tattoo, long violent screeds, and pictures of the mall taken as recently as last month - interspersed with other pictures of boxes of ammunition and guns. Other posts praised Nazis and the Chilean dictator Augusto Pinochet, who is often feted by people who use the ""Right Wing Death Squad"" phrase. He directly addressed his ethnic background in one meme he posted which mentioned ""Latino children"" and the phrase ""become white supremacist"". The BBC has examined the material and we can be confident the suspect was the person behind the posts. Garcia appeared to use the account, on a social network popular in Russia, as an online diary. He posted multiple documents including his name, date of birth and other identifying details, including a plane ticket, a speeding ticket and an ID card. Photos on the account also showed a distinct tattoo on his hand, which matches a graphic video of Garcia's dead body taken at the scene of the shooting. The shooter also posted images of the mall and its location on Google Maps, including the time the mall had the highest number of visitors, weeks in advance. In addition, open-source investigators found a YouTube channel with a video showing Garcia taking off a mask. Material on the channel was also posted on the Odnoklassniki account. Despite the clear evidence, several activists and internet personalities, including at least one mentioned in Garcia's posts, have attempted to cast doubt on the authenticity of the material. They've claimed, without evidence, that it's part of a ""psychological operation"" or ""false flag"" by the government to smear those on the right or far-right. A number of posts spreading the false rumours were viewed millions of times. Among them, one by Twitter chief Elon Musk called the fact the suspect had an account on a Russian platform ""very odd"" and in another message said it was ""either the weirdest story ever or a very bad psyop!"" However, Odnoklassniki has an English interface, and its lax content moderation policies mean extreme content is less likely to be taken down. Mr Musk and Twitter's communications team did not respond to a request for comment. The podcaster Tim Pool, a former Occupy Wall Street supporter and Vice News reporter, was among those mentioned several times in the suspect's posts. There's no evidence that Garcia was inspired to action by Mr Pool's podcasts, which cover right-wing talking points and conspiracy theories. But Mr Pool immediately tried to cast doubt on the veracity of the material, accusing those digging up the material as being part of a ""psyop"". Mr Pool did not respond to requests for comment. Adding to the misinformation were a photo of a man who shared a name with the suspect which circulated widely online, and several viral posts have claimed the gunman was part of a Mexican cartel or drug gang. Police said during Tuesday's press conference that he had no prior criminal record."
World Cup 2022: TikTok brings football fever to millions of fans,"From Bukayo Saka's spelling school to team analysis and score predictions, our social feeds are showing us loads of content from the Qatar World Cup. Videos under the #FifaWorldCup hashtag have been viewed over 12 billion times since the tournament started, according to new figures from TikTok. Quarter-final opponents England and France have both picked up more than one million followers. And it's not just team accounts growing online. Ben Black has been going to every game in Qatar after winning a competition organised by the hosts, and been documenting his experience on TikTok. The 24-year-old account has felt the World Cup effect with more than 170 million views over the course of the tournament so far. ""A bit of a ridiculous number when you think about it. It's showing a big portion of football fans what the World Cup is like and I think it's extremely powerful,"" he tells BBC Newsbeat. Away from the beaches and sand dunes, Alice Abrahams is following all the action with her analysis videos from the comfort of her home in Essex. ""It's such a good, positive atmosphere. I'm almost enjoying this World Cup more than the Russia one,"" the 22-year-old says. Junior Pereira, 19, has gained over two million followers with his dance-style videos - but says he tries not to let the numbers get to him too much. ""There is that little competition of 'who does it slightly better? Who pulls in more views and fans?' But at the end of the day we're also just trying to do the same thing and we respect each other,"" he says. ""We talk about content ideas and congratulate each other too."" But, just like the football, not everything goes to plan on TikTok either. ""There was a point [in the group stage] where Japan and Costa Rica were going to knock Spain and Germany out. I was getting ready to film a TikTok and was so excited - and then Spain went through,"" Alice says. Junior adds: ""I think all content creators felt the same in those 60 seconds - like yes, content!"" And there have been plenty of those spontaneous moments for Ben in Qatar too. He went to the Brazil v Cameroon game in a Brazil shirt. ""All I see is Cameroon fans when I get to my seat. I'm the only person in my Brazil top but the fans started embracing me anyway. ""We ended up having a full-on party for 90 minutes."" The TikToks he made ended up being ""nothing about the game"" but the ""random moments"" of the wider experience. Showcasing positive elements of the World Cup on TikTok are a contrast to some of the human rights controversies surrounding the tournament. Alice admits that she went into the World Cup with a viewpoint that was ""quite negative"". Qatar has been criticised for its ban on same-sex relationships and its treatment of migrant workers. ""But then I see people like Ben out in Qatar capturing footage of the stadiums and the vibes,"" she adds. By Marianna Spring, disinformation and social media correspondent This World Cup certainly hasn't been short of speculation and debate online. From the get-go, allegations that ""fake"" fans had been paid by Qatar to support England and other popular teams went viral. I identified and tracked down several of the people in those videos. Those ""fake"" England fans I was able to speak to were people from India and Sri Lanka who live and work in Qatar. They told me they were committed fans and were delighted to be able to watch their favourite teams play. Their social media profiles, which have posted about these football teams for years, support this. There's no evidence otherwise to support the allegation they were paid to pretend to support specific teams - and it's a claim World Cup organisers reject. Nonetheless, confusion still remains. That's because it's a fertile time for online disinformation to go viral. This World Cup has been surrounded with controversies and it's just such a hot topic on social media, especially on TikTok. The combination of hype and controversy means we all have to be careful we don't fall for evidence-free rumours. Interrogate who has shared videos and why. Look for clues about whether footage is old and, when it sparks a strong reaction, just pause before you share. It's about separating fact from fiction, understanding what's happening and why - and piecing together the truth of this complex World Cup. Follow Newsbeat on Twitter and YouTube. Listen to Newsbeat live at 12:45 and 17:45 weekdays - or listen back here. From Bukayo Saka's spelling school to team analysis and score predictions, our social feeds are showing us loads of content from the Qatar World Cup. Videos under the #FifaWorldCup hashtag have been viewed over 12 billion times since the tournament started, according to new figures from TikTok. Quarter-final opponents England and France have both picked up more than one million followers. And it's not just team accounts growing online. Ben Black has been going to every game in Qatar after winning a competition organised by the hosts, and been documenting his experience on TikTok. The 24-year-old account has felt the World Cup effect with more than 170 million views over the course of the tournament so far. ""A bit of a ridiculous number when you think about it. It's showing a big portion of football fans what the World Cup is like and I think it's extremely powerful,"" he tells BBC Newsbeat. Away from the beaches and sand dunes, Alice Abrahams is following all the action with her analysis videos from the comfort of her home in Essex. ""It's such a good, positive atmosphere. I'm almost enjoying this World Cup more than the Russia one,"" the 22-year-old says. Junior Pereira, 19, has gained over two million followers with his dance-style videos - but says he tries not to let the numbers get to him too much. ""There is that little competition of 'who does it slightly better? Who pulls in more views and fans?' But at the end of the day we're also just trying to do the same thing and we respect each other,"" he says. ""We talk about content ideas and congratulate each other too."" But, just like the football, not everything goes to plan on TikTok either. ""There was a point [in the group stage] where Japan and Costa Rica were going to knock Spain and Germany out. I was getting ready to film a TikTok and was so excited - and then Spain went through,"" Alice says. Junior adds: ""I think all content creators felt the same in those 60 seconds - like yes, content!"" And there have been plenty of those spontaneous moments for Ben in Qatar too. He went to the Brazil v Cameroon game in a Brazil shirt. ""All I see is Cameroon fans when I get to my seat. I'm the only person in my Brazil top but the fans started embracing me anyway. ""We ended up having a full-on party for 90 minutes."" The TikToks he made ended up being ""nothing about the game"" but the ""random moments"" of the wider experience. Showcasing positive elements of the World Cup on TikTok are a contrast to some of the human rights controversies surrounding the tournament. Alice admits that she went into the World Cup with a viewpoint that was ""quite negative"". Qatar has been criticised for its ban on same-sex relationships and its treatment of migrant workers. ""But then I see people like Ben out in Qatar capturing footage of the stadiums and the vibes,"" she adds. By Marianna Spring, disinformation and social media correspondent This World Cup certainly hasn't been short of speculation and debate online. From the get-go, allegations that ""fake"" fans had been paid by Qatar to support England and other popular teams went viral. I identified and tracked down several of the people in those videos. Those ""fake"" England fans I was able to speak to were people from India and Sri Lanka who live and work in Qatar. They told me they were committed fans and were delighted to be able to watch their favourite teams play. Their social media profiles, which have posted about these football teams for years, support this. There's no evidence otherwise to support the allegation they were paid to pretend to support specific teams - and it's a claim World Cup organisers reject. Nonetheless, confusion still remains. That's because it's a fertile time for online disinformation to go viral. This World Cup has been surrounded with controversies and it's just such a hot topic on social media, especially on TikTok. The combination of hype and controversy means we all have to be careful we don't fall for evidence-free rumours. Interrogate who has shared videos and why. Look for clues about whether footage is old and, when it sparks a strong reaction, just pause before you share. It's about separating fact from fiction, understanding what's happening and why - and piecing together the truth of this complex World Cup. Follow Newsbeat on Twitter and YouTube. Listen to Newsbeat live at 12:45 and 17:45 weekdays - or listen back here."
"YouTube deletes 30,000 vaccine misinfo videos","YouTube has removed more than 30,000 misleading Covid-19 vaccination videos in the past five months, it said. A YouTube spokeswoman said the videos contradicted vaccine information from the World Health Organization (WHO) or health authorities such as the NHS. In October, it banned vaccine misinformation in a bid to clamp down on attempts to discredit the jabs. It added that in the past year, it had removed more than 800,000 videos for coronavirus misinformation. That figure covers more than just vaccines, but wider ""medically unsubstantiated"" claims about the virus. It includes false claims that the vaccine kills people, causes infertility, or contains a secret microchip that will be implanted into recipients. In the early stages of the pandemic, YouTube was home to many conspiracy theories about the disease and even false claims of non-existent ""cures"". Despite its ban on such content, finding and deleting it remains a struggle for YouTube and other social platforms. A universal criticism of social media sites throughout the pandemic has been the slow speed at which they have acted over harmful disinformation. In recent months, attention has turned to how much they have allowed falsehoods about the vaccine to proliferate on their platforms. YouTube has generally been ahead of the curve when it comes to introducing policies to tackle this. But I have investigated the impact of anti-vaccine content online for a number of months, and there is no doubt that it had already scared people off the jab long before this announcement. To make matters worse, the minority of committed activists who spread harmful anti-vaccine content online are using increasingly sophisticated tactics that pose problems for a video platform such as YouTube. My recent investigation for BBC Panorama revealed how videos featuring people who brandish medical credentials to promote false vaccine claims are very effective at playing on pre-existing concerns. These kinds of videos have thrived on platforms such as YouTube - and a number of the main culprits still use YouTube to cultivate an audience of hundreds of thousands of subscribers."
YouTube stops deleting false 2020 election claims,"YouTube will stop removing videos with false claims of fraud in the 2020 presidential election, the social media platform announced on Friday. The move, ahead of the 2024 elections, is a reversal of its policy put in place after the 2020 vote. The company said it has deleted tens of thousands of videos questioning the integrity of past elections, but now ""it was time to re-evaluate"". The policy goes into effect from 2 June. YouTube and other social media platforms have faced intense pressure since the 2016 elections to safeguard against political misinformation. The Google-owned platform says the new policy is being put into place because of today's changed landscape. ""In the current environment, we find that while removing this content does curb some misinformation, it could also have the unintended effect of curtailing political speech without meaningfully reducing the risk of violence or other real-world harm,"" the company said in a statement. YouTube said it would continue to tweak its policies in advance of the 2024 election, but did not provide specifics about what led to the policy change. The BBC has contacted the company for comment. The company added that it will continue to enforce other election misinformation policies - for instance, videos that include misleading instructions on where or how to vote. The election fraud policy was enacted in December 2020 and led to the deletion of a video posted by Donald Trump on 6 January 2021 telling protesters to leave the US Capitol. That video fell afoul because Trump also repeated his false claims of widespread fraud. ""This was a fraudulent election, but we can't play into the hands of these people,"" Trump said in the clip. ""We have to have peace. So go home, we love you, you're very special."" A video posted by a US congressional committee investigating the Capitol riot was deleted in 2022 because it too contained a clip of Mr Trump repeating election falsehoods. The company lifted restrictions on Mr Trump's YouTube channel - which has more than 2.7 million subscribers - in March of this year. Since then, the former president has posted around 20 short clips in support of his campaign. YouTube will stop removing videos with false claims of fraud in the 2020 presidential election, the social media platform announced on Friday. The move, ahead of the 2024 elections, is a reversal of its policy put in place after the 2020 vote. The company said it has deleted tens of thousands of videos questioning the integrity of past elections, but now ""it was time to re-evaluate"". The policy goes into effect from 2 June. YouTube and other social media platforms have faced intense pressure since the 2016 elections to safeguard against political misinformation. The Google-owned platform says the new policy is being put into place because of today's changed landscape. ""In the current environment, we find that while removing this content does curb some misinformation, it could also have the unintended effect of curtailing political speech without meaningfully reducing the risk of violence or other real-world harm,"" the company said in a statement. YouTube said it would continue to tweak its policies in advance of the 2024 election, but did not provide specifics about what led to the policy change. The BBC has contacted the company for comment. The company added that it will continue to enforce other election misinformation policies - for instance, videos that include misleading instructions on where or how to vote. The election fraud policy was enacted in December 2020 and led to the deletion of a video posted by Donald Trump on 6 January 2021 telling protesters to leave the US Capitol. That video fell afoul because Trump also repeated his false claims of widespread fraud. ""This was a fraudulent election, but we can't play into the hands of these people,"" Trump said in the clip. ""We have to have peace. So go home, we love you, you're very special."" A video posted by a US congressional committee investigating the Capitol riot was deleted in 2022 because it too contained a clip of Mr Trump repeating election falsehoods. The company lifted restrictions on Mr Trump's YouTube channel - which has more than 2.7 million subscribers - in March of this year. Since then, the former president has posted around 20 short clips in support of his campaign."
YouTube suspends Donald Trump's channel,"YouTube has become the latest social network to suspend President Trump. The Google-owned service has prevented his account from uploading new videos or live-streaming material for a minimum of seven days, and has said it may extend the period. The firm said the channel had broken its rules over the incitement of violence. The president had posted several videos on Tuesday night, some of which remain online. Google has not provided details of what Mr Trump said in the video it banned, however the BBC has discovered it was a clip from a press conference he had given on Tuesday. The move came hours after civil rights groups had threatened to organise an ads boycott against YouTube. Jim Steyer - who previously helped coordinate similar action against Facebook last year - had called on Google to go further and take the president's channel offline. ""We hope they will make it permanent. It is disappointing that it took a Trump-incited attack to get here, but appears that the major platforms are finally beginning to step up,"" he tweeted after the suspension.YouTube suspends Donald Trump's channel Google said that Mr Trump could still face his page being closed if he falls foul of its three-strikes policy. ""After review, and in light of concerns about the ongoing potential for violence, we removed new content uploaded to Donald J Trump's channel for violating our policies,"" it said in a statement. ""It now has its first strike and is temporarily prevented from uploading new content for a minimum of seven days. ""Given the ongoing concerns about violence, we will also be indefinitely disabling comments on President Trump's channel, as we've done to other channels where there are safety concerns found in the comments section."" Meanwhile, Apple chief Tim Cook told CBS News that those involved with the riots on the US Capitol last week should be held accountable. ""Everyone that had a part in it needs to be held accountable. I think no one is above the law. We're a rule of law country."" He did not mention President Trump by name, but added: ""I don't think we should let it go. This is something we've got to be serious about."" Mr Trump had already been suspended by Facebook and Instagram following last week's rioting on Capitol Hill, until at least the transition of power to Joe Biden on 20 January. Twitter has gone further by imposing a permanent ban. Amazon's Twitch has also disabled his account on its platform. And Snapchat has locked his account. Shopify, Pinterest, TikTok and Reddit have also taken steps to restrict content associated with the president and his calls for the results of the US election to be challenged. YouTube has often been behind its social media rivals when it comes to moderating user-posted content. Over the years it has come under fire from campaign groups and big advertisers for not acting swiftly. Now it has followed Facebook, Twitter and Snapchat in restricting Donald Trump's access to its platform. And as so often, there's a lack of transparency about exactly what prompted the President's suspension. It's only saying that a video violated its policies on incitement to violence, but is indicating that the issue was the President's remarks to reporters on Tuesday where he refused to take responsibility for the attack on Congress. Of course, those comments were broadcast on TV channels, including the BBC, and are still widely available. It's not long ago that the social media landscape was being described as the Wild West when it came to moderating content - now the platforms suddenly seem eager to appear more cautious than the mainstream media. It's amazing what the threat of regulation can do."
YouTube to remove all anti-vaccine misinformation,"YouTube has said it will remove content that spreads misinformation about all approved vaccines, expanding a ban on false claims about Covid-19 jabs. Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people's scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs ""spill over into misinformation about vaccines in general"". The new policy covers long-approved vaccines, such as those against measles or hepatitis B. ""We're expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO,"" the post said, referring to the World Health Organization. Personal testimonies relating to vaccines, content about vaccine policies, new vaccine trials, and historical videos about vaccine successes or failures will be allowed to remain on the site, the company said. The move follows a similar ban introduced by Facebook in February, targeting false claims that vaccines are not effective or cause autism, among others. But since then the company has faced challenges in enforcing it. In March, Twitter announced that users who repeatedly shared misinformation about vaccines would be banned from the platform."
